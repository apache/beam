---
layout: post
title:  "Use Beam SQL DSL to build a pipeline"
date:   2017-07-21 00:00:00 -0800
excerpt_separator: <!--more-->
categories: blog
authors:
  - mingmxu
---

Beam SQL DSL provides the capability to execute standard SQL queries using Beam Java SDK. It packages the backend parsing/validation/assembling features, and delivers a SDK style API to developers, to express a processing logic using SQL statements, from simple TABLE_FILTER, to complex queries containing JOIN/GROUP_BY etc.

<!--more-->

# <a name="overview"></a>1. Overview
SQL is a well-adopted standard to process data with concise syntax. With DSL APIs, now `PCollection`s can be queried with standard SQL statements, like a regular table. The DSL APIs leverage [Apache Calcite](http://calcite.apache.org/) to parse and optimize SQL queries, then translate it into a _composite_ Beam `PTransform`. In this way, both SQL and normal Beam `PTransform`s can be mixed in one pipeline.

# <a name="usage"></a>2. Usage of DSL APIs 
`BeamSql` is the only interface(with two methods `BeamSql.query()` and `BeamSql.simpleQuery()`) for developers. It wraps the back-end details of parsing/validation/assembling, and deliver a Beam SDK style API that can take either simple TABLE_FILTER queries or complex queries containing JOIN/GROUP_BY etc. 

*Note*, the two methods are equivalent in functionality, `BeamSql.query()` applies on a `PCollectionTuple` with one or many input `PCollection`s; `BeamSql.simpleQuery()` is a simplified API which applies on single `PCollection`.

[BeamSqlExample](https://github.com/apache/beam/blob/DSL_SQL/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/example/BeamSqlExample.java) in code repository shows the usage of both APIs:

```
//Step 1. create a source PCollection with Create.of();
BeamRecordSqlType type = BeamRecordSqlType.create(fieldNames, fieldTypes);
...

PCollection<BeamRecord> inputTable = PBegin.in(p).apply(Create.of(row...)
    .withCoder(type.getRecordCoder()));

//Step 2. (Case 1) run a simple SQL query over input PCollection with BeamSql.simpleQuery;
PCollection<BeamRecord> outputStream = inputTable.apply(
    BeamSql.simpleQuery("select c1, c2, c3 from PCOLLECTION where c1=1"));


//Step 2. (Case 2) run the query with BeamSql.query over result PCollection of (case 1);
PCollection<BeamRecord> outputStream2 =
    PCollectionTuple.of(new TupleTag<BeamRecord>("CASE1_RESULT"), outputStream)
        .apply(BeamSql.query("select c2, sum(c3) from CASE1_RESULT group by c2"));
```

In Step 1, a `PCollection<BeamRecord>` is prepared as the source dataset. The work to generate a queriable `PCollection<BeamRecord>` is beyond the scope of Beam SQL DSL. 

Step 2(Case 1) shows the usage to run a query with `BeamSql.simpleQuery()`, be aware that the input `PCollection` is named with a fixed table name __PCOLLECTION__. Step 2(Case 2) is another example to run a query with `BeamSql.query()`. A Table name is specified when adding `PCollection` to `PCollectionTuple`. As each call of either `BeamSql.query()` or `BeamSql.simpleQuery()` has its own schema repository, developers need to include all `PCollection`s that would be used in your query.

# <a name="functionality"></a>4. Functionality in Beam SQL
Just as the unified model for both bounded and unbounded data in Beam, SQL DSL provides the same functionalities for bounded and unbounded `PCollection` as well. 

Note that, SQL support is not fully completed. Queries that include unsupported features would cause an `UnsupportedOperationException`.

## <a name="features"></a>4.1. Supported Features
The following features are supported in current repository:

1. filter clauses;
2. data field projections;
3. aggregations (global_window, fixed_window, sliding_window, session_window);
4. Join (inner, left_outer, right_outer);
5. built-in SQL functions
6. User Defined Function (UDF) and User Defined Aggregate Function (UDAF);

For more deep dive, please visit [DSLs: SQL]({{ site.baseurl }}/documentation/dsls/sql/)

