---
layout: post
title:  "Use Beam SQL DSL to build a pipeline"
date:   2017-07-21 00:00:00 -0800
excerpt_separator: <!--more-->
categories: blog
authors:
  - mingmxu
---

Beam SQL DSL provides the capability to execute standard SQL queries using Beam Java SDK. It packages the backend parsing/validation/assembling features, and delivers a SDK style API to developers, to express a processing logic using SQL statements, from simple TABLE_FILTER, to complex queries containing JOIN/GROUP_BY etc.

<!--more-->

# <a name="overview"></a>1. Overview
SQL is a well-adopted standard to process data with concise syntax. With DSL APIs, now `PCollection`s can be queried with standard SQL statements, like a regular table. The DSL APIs leverage [Apache Calcite](http://calcite.apache.org/) to parse and optimize SQL queries, then translate into a composite Beam `PTransform`. In this way, both SQL and normal Beam `PTransform`s can be mixed in the same pipeline.

# <a name="usage"></a>2. Usage of DSL APIs 
The DSL interface (`BeamSql.query()` and `BeamSql.simpleQuery()`), is the only endpoint exposed to developers. It wraps the back-end details of parsing/validation/assembling, to deliver a Beam SDK style API that can take either simple TABLE_FILTER queries or complex queries containing JOIN/GROUP_BY etc. 

*Note*, the two APIs are equivalent in functionality, `BeamSql.query()` applies on a `PCollectionTuple` with one or many input `PCollection`s, and `BeamSql.simpleQuery()` is a simplified API which applies on single `PCollection`.

[BeamSqlExample](https://github.com/apache/beam/blob/DSL_SQL/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/example/BeamSqlExample.java) in code repository shows the usage of both APIs:

```
//Step 1. create a source PCollection with Create.of();
PCollection<BeamSqlRow> inputTable = PBegin.in(p).apply(Create.of(row)
    .withCoder(new BeamSqlRowCoder(type)));

//Step 2. (Case 1) run a simple SQL query over input PCollection with BeamSql.simpleQuery;
PCollection<BeamSqlRow> outputStream = inputTable.apply(
    BeamSql.simpleQuery("select c2, c3 from PCOLLECTION where c1=1"));


//Step 2. (Case 2) run the query with BeamSql.query
PCollection<BeamSqlRow> outputStream2 =
    PCollectionTuple.of(new TupleTag<BeamSqlRow>("TABLE_B"), inputTable)
        .apply(BeamSql.query("select c2, c3 from TABLE_B where c1=1"));
```

In Step 1, a `PCollection<BeamSqlRow>` is prepared as the source dataset. The work to generate a queriable `PCollection<BeamSqlRow>` is beyond the scope of Beam SQL DSL. 

Step 2(Case 1) shows the way to run a query with `BeamSql.simpleQuery()`, be aware that the input `PCollection` is named with a fixed table name __PCOLLECTION__. Step 2(Case 2) is an example to run a query with `BeamSql.query()`. A Table name used in the query is specified when adding `PCollection` to `PCollectionTuple`. As each call of either `BeamSql.query()` or `BeamSql.simpleQuery()` has its own schema repository, developers need to include all `PCollection`s that would be used in your query.

# <a name="functionality"></a>4. Functionality in Beam SQL
Just as the unified model for both bounded and unbounded data in Beam, SQL DSL provides the same functionalities for bounded and unbounded `PCollection` as well. 

Note that, SQL support is not fully completed. Queries that include unsupported features would cause a UnsupportedOperationException.

## <a name="features"></a>4.1. Supported Features
The following features are supported in current repository (this chapter will be updated continually).

1. filter clauses;
2. data field projections;
3. aggregations (global_window, fixed_window, sliding_window, session_window);
4. Join (inner, left_outer, right_outer);
5. built-in SQL functions
6. User Defined Function (UDF) and User Defined Aggregate Function (UDAF);

For more deep dive, please visit [DSLs: SQL]({{ site.baseurl }}/documentation/dsls/sql/)

