pipeline:
  transforms:

  # Step 1: Creating rows to be written to Spanner
  # The element names correspond to the column names in the Spanner table
    - type: Create
      name: CreateRows
      config:
        elements:
          - shipment_id: "S5"
            customer_id: "C5"
            shipment_date: "2023-05-09"
            shipment_cost: "300"
            customer_name: "Erin"
            customer_email: "erin@example.com"

  # Step 2: Writing the created rows to a Spanner database
  # We require the project ID, instance ID, database ID and table ID to connect to Spanner
  # Error handling can be specified optionally to ensure any failed operations aren't lost
  # The failed data is passed on in the pipeline and can be handled 
    - type: WriteToSpanner
      name: WriteSpanner
      input: CreateRows
      config:
        project_id: 'apache-beam-testing'
        instance_id: 'shipment-test'
        database_id: 'shipment'
        table_id: 'shipments'
        error_handling:
          output: my_error_output

  # Step 3: Writing the failed records to a JSON file
    - type: WriteToJson
      input: WriteSpanner.my_error_output
      config:
        path: errors.json

  # The operation fails as "shipment_cost" required a float value, whereas a string value is provided in the CreateRows transform
  # Changing the value of "shipment_cost" from "300" to 300.0 will result in a successful write operation

# Expected:
#  Row(error_message="INSERT_OR_UPDATE operation failed at instance: shipment-test, database: shipment, table: shipments", failed_row=Row(shipment_id='S5', customer_id='C5', shipment_date='2023-05-09', shipment_cost=300.0,  customer_email='erin@example.com'))
