# coding=utf-8
#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This is an example of a Beam YAML pipeline that reads from spanner database
# and writes to GCS avro files.  This matches the Dataflow Template located
# here - https://cloud.google.com/dataflow/docs/guides/templates/provided/cloud-spanner-to-avro

# A pipeline that reads for iceberg table to and writes to AlloyDB.

pipeline:
  type: chain
  transforms:
    # Step 1: Reading data from Iceberg
    - type: ReadFromIceberg
      name: ReadFromIcebergTable
      config:
        table: "db.users.CA"
        catalog_name: "hadoop_catalog"
        catalog_properties:
          type: "hadoop"
          warehouse: "gs://MY-WAREHOUSE"
        # Hadoop catalog config required to run pipeline locally
        # Omit if running on Dataflow
        config_properties:
          "fs.gs.auth.type": "SERVICE_ACCOUNT_JSON_KEYFILE"
          "fs.gs.auth.service.account.json.keyfile": "/path/to/service/account/key.json"

    # Step 2: Write records out to AlloyDB
    - type: WriteToPostgres
      name: WriteToPostgresTable
      config:
        url: 'jdbc:postgresql://localhost:12345/db?user=user&password=postgres123'
        location: "users"
