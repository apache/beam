# coding=utf-8
#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# A pipeline that both writes to and reads from the same Kafka topic.

pipeline:
  type: chain
  transforms:
    # Step 1: Reading messages from Pub/Sub topic
    - type: ReadFromPubSub
      name: ReadMessages
      config:
        topic: "projects/apache-beam-testing/topics/my-topic"
        format: JSON
        schema: 
          type: object
          properties:
            data: {type: BYTES}
            attributes: {type: object}
    # Step 2: Write records out to Iceberg
    - type: WriteToIceberg
      name: WriteToAnIcebergTable
      config:
        # Dynamic destinations
        table: "db.users.{zip}"
        catalog_name: "hadoop_catalog"
        catalog_properties:
          type: "hadoop"
          warehouse: "gs://MY-WAREHOUSE"
        # Hadoop catalog config required to run pipeline locally
        # Omit if running on Dataflow
        config_properties:
          "fs.gs.auth.type": "SERVICE_ACCOUNT_JSON_KEYFILE"
          "fs.gs.auth.service.account.json.keyfile": "/path/to/service/account/key.json"

options:
  streaming: true

# Expected:
#  Row(label='37a', rank=1)
#  Row(label='37b', rank=4)
#  Row(label='37c', rank=3)
#  Row(label='37d', rank=2)

