# coding=utf-8
#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

pipeline:
  transforms:
    # ...
    - type: ReadFromPubSub
      name: TaxiEvents
      config:
        topic: "projects/pubsub-public-data/topics/taxirides-realtime"
        format: "JSON"
        schema:
          type: object
          properties:
            ride_id: { type: string }
            longitude: { type: number }
            latitude: { type: number }
            passenger_count: { type: integer }
            meter_reading: { type: number }
            timestamp: { type: string }
            ride_status: { type: string }

    # ...
    - type: AssignTimestamps
      name: AssignTimestamps
      input: TaxiEvents
      config:
        language: python
        timestamp:
          callable: |
            from datetime import datetime, timezone
            def fn(row):
              return datetime.fromisoformat(row.timestamp).astimezone(timezone.utc)

    # ...
    - type: WindowInto
      name: Windowing
      input: AssignTimestamps
      config:
        windowing:
          type: sessions
          gap: 10m

    # ...
    - type: Filter
      name: PickupEvents
      input: Windowing
      config:
        language: python
        keep: "ride_status == 'pickup'"

    - type: MapToFields
      name: FormatPickupEvents
      input: PickupEvents
      config:
        fields:
          ride_id: ride_id
          pickup_latitude: latitude
          pickup_longitude: longitude
          pickup_datetime: timestamp
          passenger_count: passenger_count

    # ...
    - type: Filter
      name: DropoffEvents
      input: Windowing
      config:
        language: python
        keep: "ride_status == 'dropoff'"

    - type: MapToFields
      name: FormatDropoffEvents
      input: DropoffEvents
      config:
        fields:
          ride_id: ride_id
          dropoff_latitude: latitude
          dropoff_longitude: longitude
          dropoff_datetime: timestamp

    # ...
    - type: Join
      name: Join
      input:
        pickup: FormatPickupEvents
        dropoff: FormatDropoffEvents
      config:
        equalities: ride_id
        type: inner
        fields:
          pickup: [ride_id, passenger_count, pickup_longitude, pickup_latitude, pickup_datetime]
          dropoff: [dropoff_longitude, dropoff_latitude]

    # ...
    - type: WriteToKafka
      name: WriteKafka
      input: Join
      config:
        format: "JSON"
        topic: "{{ TOPIC }}"
        bootstrap_servers: "{{ BOOTSTRAP_SERVERS }}"
        producer_config_updates:
          sasl.jaas.config: "org.apache.kafka.common.security.plain.PlainLoginModule required \
            username={{ USERNAME }} \
            password={{ PASSWORD }};"
          security.protocol: "SASL_PLAINTEXT"
          sasl.mechanism: "PLAIN"

    # ...
    - type: ReadFromKafka
      name: ReadKafka
      config:
        topic: "{{ TOPIC }}"
        format: "JSON"
        schema: |
          {
            "type": "object",
            "properties": {
              "ride_id": { "type": "string" },
              "pickup_longitude": { "type": "number" },
              "pickup_latitude": { "type": "number" },
              "pickup_datetime": { "type": "string" },
              "dropoff_longitude": { "type": "number" },
              "dropoff_latitude": { "type": "number" },
              "passenger_count": { "type": "integer" },
            }
          }
        bootstrap_servers: "{{ BOOTSTRAP_SERVERS }}"
        auto_offset_reset_config: earliest
        consumer_config:
          sasl.jaas.config: "org.apache.kafka.common.security.plain.PlainLoginModule required \
            username={{ USERNAME }} \
            password={{ PASSWORD }};"
          security.protocol: "SASL_PLAINTEXT"
          sasl.mechanism: "PLAIN"

    # ...
    - type: MapToFields
      name: FeatureEngineering
      input: ReadKafka
      config:
        language: python
        fields:
          ride_id: ride_id
          pickup_longitude: pickup_longitude
          pickup_latitude: pickup_latitude
          dropoff_longitude: dropoff_longitude
          dropoff_latitude: dropoff_latitude
          passenger_count: passenger_count
          pickup_datetime_year:
            callable: |
              from datetime import datetime
              def fn(row):
                return datetime.fromisoformat(row.pickup_datetime).year
          pickup_datetime_month:
            callable: |
              from datetime import datetime
              def fn(row):
                return datetime.fromisoformat(row.pickup_datetime).month
          pickup_datetime_day:
            callable: |
              from datetime import datetime
              def fn(row):
                return datetime.fromisoformat(row.pickup_datetime).day
          pickup_datetime_weekday:
            callable: |
              from datetime import datetime
              def fn(row):
                return datetime.fromisoformat(row.pickup_datetime).weekday()
          pickup_datetime_hour:
            callable: |
              from datetime import datetime
              def fn(row):
                return datetime.fromisoformat(row.pickup_datetime).hour

    # ...
    - type: LogForTesting
      input: FeatureEngineering

    # ...
    - type: RunInference
      name: PredictFare
      input: FeatureEngineering
      config:
        inference_tag: "inference"
        model_handler:
          type: VertexAIModelHandlerJSON
          config:
            endpoint_id: "5903336203645616128"
            project: "silicon-synapse-460717-a0"
            location: "us-central1"
            preprocess:
              callable: |
                def preprocess(row):
                  input_cols = [
                    'pickup_longitude', 'pickup_latitude',
                    'dropoff_longitude', 'dropoff_latitude',
                    'passenger_count',
                    'pickup_datetime_year', 'pickup_datetime_month', 'pickup_datetime_day',
                    'pickup_datetime_weekday', 'pickup_datetime_hour']
                  return [row.as_dict().get(key) for key in input_cols]

    - type: MapToFields
      name: FormatInferenceOutput
      input: PredictFare
      config:
        language: python
        fields:
          ride_id:
            expression: ride_id
            output_type: string
          pickup_longitude:
            expression: pickup_longitude
            output_type: number
          pickup_latitude:
            expression: pickup_latitude
            output_type: number
          dropoff_longitude:
            expression: dropoff_longitude
            output_type: number
          dropoff_latitude:
            expression: dropoff_latitude
            output_type: number
          passenger_count:
            expression: passenger_count
            output_type: integer
          predicted_fare_amount:
            callable: 'lambda row: row.inference.inference'
            output_type: number

    # ...
    - type: WriteToBigQuery
      name: WritePredictionsBQ
      input: FormatInferenceOutput
      config:
        table: "silicon-synapse-460717-a0.test.nyc_taxifare_predictions"
        create_disposition: "CREATE_IF_NEEDED"
        write_disposition: "WRITE_APPEND"

options:
  yaml_experimental_features: ML
