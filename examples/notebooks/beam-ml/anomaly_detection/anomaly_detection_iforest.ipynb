{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNZiZSqkiSznhrGdyErsjKG"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title ###### Licensed to the Apache Software Foundation (ASF), Version 2.0 (the \"License\")\n",
        "\n",
        "# Licensed to the Apache Software Foundation (ASF) under one\n",
        "# or more contributor license agreements. See the NOTICE file\n",
        "# distributed with this work for additional information\n",
        "# regarding copyright ownership. The ASF licenses this file\n",
        "# to you under the Apache License, Version 2.0 (the\n",
        "# \"License\"); you may not use this file except in compliance\n",
        "# with the License. You may obtain a copy of the License at\n",
        "#\n",
        "#   http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing,\n",
        "# software distributed under the License is distributed on an\n",
        "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
        "# KIND, either express or implied. See the License for the\n",
        "# specific language governing permissions and limitations\n",
        "# under the License"
      ],
      "metadata": {
        "cellView": "form",
        "id": "IA9uYREbI3m3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Anomaly Detection with Ensemble Models using Apache Beam (Isolation Forest)\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/apache/beam/blob/master/examples/notebooks/beam-ml/anomaly_detection/anomaly_detection_iforest.ipynb\"><img src=\"https://raw.githubusercontent.com/google/or-tools/main/tools/colab_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/apache/beam/blob/master/examples/notebooks/beam-ml/anomaly_detection/anomaly_detection_iforest.ipynb\"><img src=\"https://raw.githubusercontent.com/google/or-tools/main/tools/github_32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ],
      "metadata": {
        "id": "Eef1VqflIrXW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook demonstrates how to perform anomaly detection on streaming data using the AnomalyDetection PTransform, a new feature introduced in Apache Beam 2.64.0 with more improvement on offline model support in 2.65.0.\n",
        "\n",
        "We will first fetch the data set of Statlog (shuttle) from UCI Machine Learning Repository (cached in gs://apache-beam-samples/anomaly_detection/shuttle/, original link: https://archive.ics.uci.edu/dataset/148/statlog+shuttle). This data will be streamed into the pipeline following a periodic impulse. Our Beam pipeline will then apply the AnomalyDetection PTransform with the a pre-trained isolation forest model, compute model metrics.\n",
        "\n",
        "We demonstrate running the pipeline with Prism (our new local runner) and Dataflow Runner."
      ],
      "metadata": {
        "id": "m0xhMRWfX07o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparation"
      ],
      "metadata": {
        "id": "V1950SxGb0u2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting Environment Variables"
      ],
      "metadata": {
        "id": "EKkFQE8iwT7M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "L_18eUf7QU2I"
      },
      "outputs": [],
      "source": [
        "# GCP project id\n",
        "PROJECT_ID = 'apache-beam-testing'  # @param {type:'string'}\n",
        "\n",
        "# Temporary root path, used to store generated files (and temp and staging files if running on Dataflow)\n",
        "TEMP_ROOT = 'gs://apache-beam-testing-temp'  # @param {type:'string'}\n",
        "\n",
        "# Required if running on Dataflow\n",
        "REGION = 'us-central1'  # @param {type:'string'}\n",
        "\n",
        "# TODO: Change this to an official release once 2.65.0 is available\n",
        "BEAM_VERSION = '2.65.0rc2'\n",
        "\n",
        "import random\n",
        "SUFFIX = str(random.randint(0, 10000))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user(project_id=PROJECT_ID)"
      ],
      "metadata": {
        "id": "A_49Y2aTQeiH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing Beam and Other Dependencies"
      ],
      "metadata": {
        "id": "0WXpo4aDwG3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For running with local prism runner\n",
        "!pip install 'apache_beam[interactive]=={BEAM_VERSION}' --quiet"
      ],
      "metadata": {
        "id": "5hpDAMOyQfHP",
        "outputId": "a4469114-c9dd-4b9f-f66c-4c868dd4c7d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.1/831.1 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.8/272.8 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for timeloop (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipython==7.34.0, but you have ipython 8.36.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the latest prism\n",
        "# TODO: We don't need this step once 2.65.0 is available.\n",
        "! wget https://dist.apache.org/repos/dist/dev/beam/2.65.0/prism/linux/amd64/apache_beam-v2.65.0-prism-linux-amd64.zip"
      ],
      "metadata": {
        "id": "jAKBvrgq-J3f",
        "outputId": "860564d1-ab62-4b8c-b2a5-6bb74771487d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-08 00:53:47--  https://dist.apache.org/repos/dist/dev/beam/2.65.0/prism/linux/amd64/apache_beam-v2.65.0-prism-linux-amd64.zip\n",
            "Resolving dist.apache.org (dist.apache.org)... 13.90.137.153\n",
            "Connecting to dist.apache.org (dist.apache.org)|13.90.137.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24922389 (24M) [application/octet-stream]\n",
            "Saving to: ‘apache_beam-v2.65.0-prism-linux-amd64.zip’\n",
            "\n",
            "apache_beam-v2.65.0 100%[===================>]  23.77M  16.2MB/s    in 1.5s    \n",
            "\n",
            "2025-05-08 00:53:48 (16.2 MB/s) - ‘apache_beam-v2.65.0-prism-linux-amd64.zip’ saved [24922389/24922389]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install pyod for offline anomaly detectors\n",
        "!pip install pyod==2.0.3"
      ],
      "metadata": {
        "id": "KlkX-iwVm42J",
        "outputId": "6fcbf4bc-d109-471d-a011-8c8efb60a724",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyod==2.0.3\n",
            "  Downloading pyod-2.0.3.tar.gz (169 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/169.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.6/169.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from pyod==2.0.3) (1.4.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from pyod==2.0.3) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.11/dist-packages (from pyod==2.0.3) (2.0.2)\n",
            "Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.11/dist-packages (from pyod==2.0.3) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.5.1 in /usr/local/lib/python3.11/dist-packages (from pyod==2.0.3) (1.15.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from pyod==2.0.3) (1.6.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51->pyod==2.0.3) (0.43.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.0->pyod==2.0.3) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyod==2.0.3) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyod==2.0.3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyod==2.0.3) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyod==2.0.3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyod==2.0.3) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyod==2.0.3) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyod==2.0.3) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyod==2.0.3) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->pyod==2.0.3) (1.17.0)\n",
            "Building wheels for collected packages: pyod\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-2.0.3-py3-none-any.whl size=200466 sha256=8986d8fbc9aed9ae64b9cce885ceac4a00be9ce294d60a9bcbf78301fa6a20d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/60/5b/f74eccd2c9c892a2c298202ca510f10995f9940647fcc2d97f\n",
            "Successfully built pyod\n",
            "Installing collected packages: pyod\n",
            "Successfully installed pyod-2.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Training and Scoring with an Offline Isolation Forest Model"
      ],
      "metadata": {
        "id": "pAoMoi0McEIH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training"
      ],
      "metadata": {
        "id": "UIzbsGtWto5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the sample data from GCS\n",
        "train_data_fn = \"./shuttle.trn\"\n",
        "! gcloud storage cp \"gs://apache-beam-samples/anomaly_detection/shuttle/shuttle.trn\" {train_data_fn}"
      ],
      "metadata": {
        "id": "vb6ubiSyipuG",
        "outputId": "1cc1f376-1c15-46a0-df1e-33a4f976395d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://apache-beam-samples/anomaly_detection/shuttle/shuttle.trn to file://./shuttle.trn\n",
            "\n",
            "Average throughput: 61.0MiB/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pyod.models.iforest as iforest\n",
        "import pickle\n",
        "\n",
        "FIELD_NAMES = [\"time\", \"f1\", \"f2\", \"f3\", \"f4\", \"f5\", \"f6\", \"f7\", \"f8\", \"target\"]\n",
        "SEP = \" \"\n",
        "df = pd.read_csv(train_data_fn, sep=\" \", names=FIELD_NAMES)\n",
        "\n",
        "# We don't need the time and target field for training.\n",
        "train_data = df.drop(['time', 'target'], axis=1)\n",
        "train_data_np = train_data.to_numpy()\n",
        "\n",
        "# Training an isolation forest model\n",
        "my_iforest = iforest.IForest(random_state=1234)\n",
        "my_iforest.fit(train_data_np)\n",
        "\n",
        "# Save the model into a file\n",
        "pickled_fn = './iforest_pickled'\n",
        "with open(pickled_fn, 'wb') as fp:\n",
        "  pickle.dump(my_iforest, fp)"
      ],
      "metadata": {
        "id": "P9MzeokSiPxK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the pickled model file to GCS\n",
        "PICKLED_PATH = TEMP_ROOT + '/anomaly/iforest-notebook-' + SUFFIX + '/pickled'\n",
        "pickled_fn_gcs = PICKLED_PATH + '/iforest.pickled'\n",
        "\n",
        "! gcloud storage cp {pickled_fn} {pickled_fn_gcs}"
      ],
      "metadata": {
        "id": "01JdmTuXuqY_",
        "outputId": "2ce77da0-e07f-4d82-ec8f-cdb1f274960a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying file://./iforest_pickled to gs://apache-beam-testing-temp/anomaly/iforest-notebook-3489/pickled/iforest.pickled\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining a Streaming Source and a DoFn for Model Metrics"
      ],
      "metadata": {
        "id": "q9HmkOY5vW-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from typing import Any\n",
        "from collections.abc import Sequence\n",
        "\n",
        "import sklearn\n",
        "\n",
        "import apache_beam as beam\n",
        "from apache_beam.coders import PickleCoder\n",
        "from apache_beam.coders import VarIntCoder\n",
        "from apache_beam.transforms.periodicsequence import PeriodicImpulse\n",
        "from apache_beam.transforms.userstate import ReadModifyWriteStateSpec\n",
        "from apache_beam.transforms.window import FixedWindows\n",
        "from apache_beam.ml.anomaly.base import AnomalyResult\n",
        "\n",
        "class SequenceToPeriodicStream(beam.PTransform):\n",
        "  \"\"\" A streaming source that generate periodic event based on a given sequence. \"\"\"\n",
        "  def __init__(self, data:Sequence[Any], delay: float = 0.1, repeat: bool = True):\n",
        "    self._data = data\n",
        "    self._delay = delay\n",
        "    self._repeat = repeat\n",
        "\n",
        "  class EmitOne(beam.DoFn):\n",
        "    INDEX_SPEC = ReadModifyWriteStateSpec('index', VarIntCoder())\n",
        "\n",
        "    def __init__(self, data, repeat):\n",
        "      self._data = data\n",
        "      self._repeat = repeat\n",
        "      self._max_index = len(self._data)\n",
        "\n",
        "    def process(self, element, model_state=beam.DoFn.StateParam(INDEX_SPEC)):\n",
        "      index = model_state.read() or 0\n",
        "      if index >= self._max_index:\n",
        "        return\n",
        "\n",
        "      yield self._data[index]\n",
        "\n",
        "      index += 1\n",
        "      if self._repeat:\n",
        "        index %= self._max_index\n",
        "      model_state.write(index)\n",
        "\n",
        "  def expand(self, input):\n",
        "    return (input | PeriodicImpulse(fire_interval=self._delay)\n",
        "        | beam.Map(lambda x: (0, x))\n",
        "        | beam.ParDo(SequenceToPeriodicStream.EmitOne(self._data, self._repeat))\n",
        "        | beam.WindowInto(FixedWindows(self._delay)))\n",
        "\n",
        "\n",
        "class ComputeMetrics(beam.DoFn):\n",
        "    \"\"\" A DoFn to compute Area Under Curve (AUC) \"\"\"\n",
        "    METRIC_STATE_INDEX = ReadModifyWriteStateSpec('saved_tracker', PickleCoder())\n",
        "\n",
        "    def __init__(self, get_target):\n",
        "        self._underlying: tuple[list[float], list[int]]\n",
        "        self._get_target = get_target\n",
        "\n",
        "    def process(self,\n",
        "              element: tuple[Any, AnomalyResult],\n",
        "              metric_state=beam.DoFn.StateParam(METRIC_STATE_INDEX),\n",
        "              **kwargs):\n",
        "        self._underlying: tuple[list[float], list[int]] = metric_state.read()\n",
        "        if self._underlying is None:\n",
        "            scores = []\n",
        "            labels = []\n",
        "            targets = []\n",
        "            self._underlying = (scores, labels, targets)\n",
        "        else:\n",
        "            scores, labels, targets = self._underlying\n",
        "\n",
        "        prediction = next(iter(element[1].predictions))\n",
        "        if math.isnan(prediction.score):\n",
        "            yield element[0], beam.Row()\n",
        "        else:\n",
        "            # buffer the scores and targets for auc computation\n",
        "            scores.append(prediction.score)\n",
        "            labels.append(prediction.label)\n",
        "            targets.append(self._get_target(element[1].example))\n",
        "\n",
        "            accuracy = sklearn.metrics.accuracy_score(targets, labels)\n",
        "            recall = sklearn.metrics.recall_score(targets, labels)\n",
        "            precision = sklearn.metrics.precision_score(targets, labels)\n",
        "            f1 = sklearn.metrics.f1_score(targets, labels)\n",
        "            fpr, tpr, _ = sklearn.metrics.roc_curve(targets, scores)\n",
        "            auc = sklearn.metrics.auc(fpr, tpr)\n",
        "\n",
        "            yield element[0], beam.Row(id=element[1].example.id,\n",
        "                                       target=element[1].example.target,\n",
        "                                       predicted_label=next(iter(element[1].predictions)).label,\n",
        "                                       predicted_score=next(iter(element[1].predictions)).score,\n",
        "                                       accuracy=float(accuracy),\n",
        "                                       recall=float(recall),\n",
        "                                       precision=float(precision),\n",
        "                                       f1=float(f1),\n",
        "                                       auc=float(auc))\n",
        "\n",
        "        metric_state.write(self._underlying)"
      ],
      "metadata": {
        "id": "4WgxpmAPQrbv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing Test Data for Streaming"
      ],
      "metadata": {
        "id": "OGRa4fbKxpr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the data from GCS\n",
        "test_data_fn = \"./test.trn\"\n",
        "! gcloud storage cp \"gs://apache-beam-samples/anomaly_detection/shuttle/shuttle.tst\" {test_data_fn}"
      ],
      "metadata": {
        "id": "fnidxXybxuFD",
        "outputId": "d233faff-1107-425a-dd01-42199bd50b1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://apache-beam-samples/anomaly_detection/shuttle/shuttle.tst to file://./test.trn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from apache_beam.io.filesystems import FileSystems\n",
        "import pandas as pd\n",
        "\n",
        "FIELD_NAMES = [\"time\", \"f1\", \"f2\", \"f3\", \"f4\", \"f5\", \"f6\", \"f7\", \"f8\", \"target\"]\n",
        "SEP = \" \"\n",
        "with FileSystems().open(test_data_fn) as f:\n",
        "  df = pd.read_csv(f, sep=\" \", names=FIELD_NAMES)\n",
        "  # just use first 500 instances for demo\n",
        "  df = df[:500]\n",
        "  rows = [row.to_dict() for _, row in df.iterrows()]\n",
        "  for i, row in enumerate(rows):\n",
        "    row[\"id\"] = i\n",
        "\n",
        "# Dropping time and target for testing\n",
        "test_data_cols = FIELD_NAMES.copy()\n",
        "test_data_cols.remove(\"time\")\n",
        "test_data_cols.remove(\"target\")"
      ],
      "metadata": {
        "id": "iwkrY8oXSAlQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constructing the Pipeline and Running with Prism"
      ],
      "metadata": {
        "id": "GKFwC-ky0XZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from apache_beam.ml.anomaly.detectors.pyod_adapter import PyODFactory\n",
        "\n",
        "# Create detector for PyOd model pickled file\n",
        "detector = PyODFactory.create_detector(pickled_fn_gcs, features=test_data_cols)"
      ],
      "metadata": {
        "id": "jP_M9pY2mp1C"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n",
        "from apache_beam.ml.anomaly.transforms import AnomalyDetection\n",
        "from apache_beam.transforms.window import GlobalWindows\n",
        "from apache_beam.io import fileio\n",
        "\n",
        "import logging\n",
        "logging.getLogger().setLevel(logging.INFO)\n",
        "\n",
        "# Running the pipeline on prism\n",
        "options = PipelineOptions([\n",
        "    \"--streaming\",\n",
        "    \"--job_server_timeout=600\",\n",
        "    \"--environment_type=LOOPBACK\",\n",
        "    # TODO: remove --prism_location once 2.65 is released\n",
        "    \"--runner=PrismRunner\", \"--prism_location=./apache_beam-v2.65.0-prism-linux-amd64.zip\"\n",
        "])\n",
        "\n",
        "with beam.Pipeline(options=options) as p:\n",
        "  _ = (p\n",
        "       | SequenceToPeriodicStream(rows, delay=1, repeat=True)\n",
        "       | beam.Map(lambda x: beam.Row(**x))\n",
        "       | beam.WithKeys(0)\n",
        "       | AnomalyDetection(detector=detector)\n",
        "       | beam.WindowInto(GlobalWindows()) # put everything into global window to compute overall auc\n",
        "       | beam.ParDo(ComputeMetrics(lambda x: 1 if x.target != 1 else 0))\n",
        "       | beam.LogElements()\n",
        "  )"
      ],
      "metadata": {
        "id": "ghFoWPAeS6SH",
        "outputId": "616fb58d-c5c7-4fef-c6dc-f2f4f2f2213c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.transforms.core:Key coder FastPrimitivesCoder for transform <ParDo(PTransform) label=[[19]: ParDo(ComputeMetrics)]> with stateful DoFn may not be deterministic. This may cause incorrect behavior for complex key types. Consider adding an input type hint for this transform.\n",
            "INFO:apache_beam.runners.worker.worker_pool_main:Listening for workers at localhost:44645\n",
            "INFO:apache_beam.runners.portability.prism_runner:Using local prism binary/zip from ./apache_beam-v2.65.0-prism-linux-amd64.zip\n",
            "INFO:apache_beam.runners.portability.prism_runner:Unzipping prism from ./apache_beam-v2.65.0-prism-linux-amd64.zip to /root/.apache_beam/cache/prism/bin/apache_beam-v2.65.0-prism-linux-amd64\n",
            "INFO:apache_beam.runners.portability.prism_runner:Prism binary path resolved to: /root/.apache_beam/cache/prism/bin/apache_beam-v2.65.0-prism-linux-amd64\n",
            "INFO:apache_beam.utils.subprocess_server:Starting service with ('/root/.apache_beam/cache/prism/bin/apache_beam-v2.65.0-prism-linux-amd64' '--job_port' '38741' '--serve_http' 'False')\n",
            "INFO:apache_beam.utils.subprocess_server:\u001b[2m\u001b[37m[2025-05-08T01:05:34.948932456Z]\u001b[0m \u001b[42m\u001b[30m INFO \u001b[0m \u001b[32mServing JobManagement\u001b[0m\n",
            "INFO:apache_beam.utils.subprocess_server:\u001b[34m*\u001b[0m \u001b[35mendpoint\u001b[0m: \u001b[4m\u001b[34mlocalhost:38741\u001b[0m\u001b[0m\n",
            "INFO:apache_beam.utils.subprocess_server:\n",
            "INFO:apache_beam.utils.subprocess_server:\u001b[2m\u001b[37m[2025-05-08T01:05:34.958677036Z]\u001b[0m \u001b[42m\u001b[30m INFO \u001b[0m \u001b[32mServing WebUI\u001b[0m\n",
            "INFO:apache_beam.utils.subprocess_server:\u001b[34m*\u001b[0m \u001b[35mendpoint\u001b[0m: \u001b[4m\u001b[34mhttp://localhost:8074\u001b[0m\u001b[0m\n",
            "INFO:apache_beam.utils.subprocess_server:\n",
            "INFO:apache_beam.utils.subprocess_server:\u001b[2m\u001b[37m[2025-05-08T01:05:35.945141535Z]\u001b[0m \u001b[43m\u001b[30m WARN \u001b[0m \u001b[33mempty transform, with payload and identical input and output pcollection\u001b[0m\n",
            "INFO:apache_beam.utils.subprocess_server:\u001b[34m*\u001b[0m \u001b[35murn\u001b[0m  : \u001b[4m\u001b[34mbeam:transform:pickled_python:v1\u001b[0m\u001b[0m\n",
            "INFO:apache_beam.utils.subprocess_server:  \u001b[35mname\u001b[0m : [19]: SequenceToPeriodicStream/PeriodicImpulse/ImpulseElement/MaybeReshuffle\n",
            "INFO:apache_beam.utils.subprocess_server:  \u001b[35mpcoll\u001b[0m: ref_PCollection_PCollection_2\n",
            "INFO:apache_beam.utils.subprocess_server:\n",
            "INFO:apache_beam.runners.portability.portable_runner:Environment \"LOOPBACK\" has started a component necessary for the execution. Be sure to run the pipeline using\n",
            "  with Pipeline() as p:\n",
            "    p.apply(..)\n",
            "This ensures that the pipeline finishes before this program exits.\n",
            "INFO:root:starting job-001[job]\n",
            "INFO:root:running job-001[job]\n",
            "INFO:apache_beam.runners.portability.portable_runner:Job state changed to RUNNING\n",
            "INFO:apache_beam.runners.worker.statecache:Creating state cache with size 0\n",
            "INFO:apache_beam.runners.worker.sdk_worker:Creating insecure control channel for localhost:38741.\n",
            "INFO:apache_beam.runners.worker.sdk_worker:Control channel established.\n",
            "INFO:apache_beam.runners.worker.sdk_worker:Initializing SDKHarness with unbounded number of workers.\n",
            "INFO:apache_beam.runners.worker.sdk_worker:Creating insecure state channel for localhost:38741.\n",
            "INFO:apache_beam.runners.worker.sdk_worker:State channel established.\n",
            "INFO:apache_beam.runners.worker.data_plane:Creating client data channel for localhost:38741\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, Row(id=0, target=4, predicted_label=0, predicted_score=-0.043273046417952266, accuracy=0.0, recall=0.0, precision=0.0, f1=0.0, auc=nan))\n",
            "(0, Row(id=1, target=4, predicted_label=0, predicted_score=-0.1475705627129747, accuracy=0.0, recall=0.0, precision=0.0, f1=0.0, auc=nan))\n",
            "(0, Row(id=2, target=1, predicted_label=0, predicted_score=-0.11675834074391167, accuracy=0.3333333333333333, recall=0.0, precision=0.0, f1=0.0, auc=0.5))\n",
            "(0, Row(id=3, target=4, predicted_label=0, predicted_score=-0.08698219095013143, accuracy=0.25, recall=0.0, precision=0.0, f1=0.0, auc=0.6666666666666666))\n",
            "(0, Row(id=4, target=1, predicted_label=0, predicted_score=-0.12194074770933055, accuracy=0.4, recall=0.0, precision=0.0, f1=0.0, auc=0.6666666666666666))\n",
            "(0, Row(id=5, target=1, predicted_label=0, predicted_score=-0.15440580096479756, accuracy=0.5, recall=0.0, precision=0.0, f1=0.0, auc=0.7777777777777778))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, Row(id=6, target=1, predicted_label=0, predicted_score=-0.05099042972651385, accuracy=0.5714285714285714, recall=0.0, precision=0.0, f1=0.0, auc=0.6666666666666666))\n",
            "(0, Row(id=7, target=1, predicted_label=0, predicted_score=-0.17796149714613052, accuracy=0.625, recall=0.0, precision=0.0, f1=0.0, auc=0.7333333333333333))\n",
            "(0, Row(id=8, target=1, predicted_label=0, predicted_score=-0.15675169491269175, accuracy=0.6666666666666666, recall=0.0, precision=0.0, f1=0.0, auc=0.7777777777777778))\n",
            "(0, Row(id=9, target=1, predicted_label=0, predicted_score=-0.16808018675634556, accuracy=0.7, recall=0.0, precision=0.0, f1=0.0, auc=0.8095238095238095))\n",
            "(0, Row(id=10, target=1, predicted_label=0, predicted_score=-0.12107176709195522, accuracy=0.7272727272727273, recall=0.0, precision=0.0, f1=0.0, auc=0.7916666666666667))\n",
            "(0, Row(id=11, target=4, predicted_label=0, predicted_score=-0.1493176313563489, accuracy=0.6666666666666666, recall=0.0, precision=0.0, f1=0.0, auc=0.71875))\n",
            "(0, Row(id=12, target=1, predicted_label=0, predicted_score=-0.05912035647013747, accuracy=0.6923076923076923, recall=0.0, precision=0.0, f1=0.0, auc=0.6666666666666666))\n",
            "(0, Row(id=13, target=1, predicted_label=0, predicted_score=-0.13555904216462783, accuracy=0.7142857142857143, recall=0.0, precision=0.0, f1=0.0, auc=0.65))\n",
            "(0, Row(id=14, target=1, predicted_label=0, predicted_score=-0.13281741315104528, accuracy=0.7333333333333333, recall=0.0, precision=0.0, f1=0.0, auc=0.6363636363636364))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, Row(id=15, target=1, predicted_label=0, predicted_score=-0.17606284623641083, accuracy=0.75, recall=0.0, precision=0.0, f1=0.0, auc=0.6666666666666667))\n",
            "(0, Row(id=16, target=1, predicted_label=0, predicted_score=-0.1374089909516345, accuracy=0.7647058823529411, recall=0.0, precision=0.0, f1=0.0, auc=0.6538461538461539))\n",
            "(0, Row(id=17, target=4, predicted_label=0, predicted_score=-0.11195671475496366, accuracy=0.7222222222222222, recall=0.0, precision=0.0, f1=0.0, auc=0.6923076923076923))\n",
            "(0, Row(id=18, target=4, predicted_label=0, predicted_score=-0.052353477210396016, accuracy=0.6842105263157895, recall=0.0, precision=0.0, f1=0.0, auc=0.7307692307692307))\n",
            "(0, Row(id=19, target=1, predicted_label=0, predicted_score=-0.13749997611032588, accuracy=0.7, recall=0.0, precision=0.0, f1=0.0, auc=0.7261904761904762))\n",
            "(0, Row(id=20, target=1, predicted_label=1, predicted_score=0.0209395012825373, accuracy=0.6666666666666666, recall=0.0, precision=0.0, f1=0.0, auc=0.6777777777777778))\n",
            "(0, Row(id=21, target=1, predicted_label=0, predicted_score=-0.0639987362232497, accuracy=0.6818181818181818, recall=0.0, precision=0.0, f1=0.0, auc=0.65625))\n",
            "(0, Row(id=22, target=1, predicted_label=0, predicted_score=-0.08141426465773777, accuracy=0.6956521739130435, recall=0.0, precision=0.0, f1=0.0, auc=0.6372549019607843))\n",
            "(0, Row(id=23, target=1, predicted_label=0, predicted_score=-0.09036967232137483, accuracy=0.7083333333333334, recall=0.0, precision=0.0, f1=0.0, auc=0.6296296296296295))\n",
            "(0, Row(id=24, target=1, predicted_label=0, predicted_score=-0.1429488460342166, accuracy=0.72, recall=0.0, precision=0.0, f1=0.0, auc=0.631578947368421))\n",
            "(0, Row(id=25, target=1, predicted_label=0, predicted_score=-0.14139932188044052, accuracy=0.7307692307692307, recall=0.0, precision=0.0, f1=0.0, auc=0.6333333333333333))\n",
            "(0, Row(id=26, target=4, predicted_label=0, predicted_score=-0.1327632717666385, accuracy=0.7037037037037037, recall=0.0, precision=0.0, f1=0.0, auc=0.6214285714285714))\n",
            "(0, Row(id=27, target=1, predicted_label=0, predicted_score=-0.12492375119356569, accuracy=0.7142857142857143, recall=0.0, precision=0.0, f1=0.0, auc=0.6190476190476191))\n",
            "(0, Row(id=28, target=1, predicted_label=0, predicted_score=-0.08167180269559426, accuracy=0.7241379310344828, recall=0.0, precision=0.0, f1=0.0, auc=0.6038961038961039))\n",
            "(0, Row(id=29, target=1, predicted_label=0, predicted_score=-0.0512323097188892, accuracy=0.7333333333333333, recall=0.0, precision=0.0, f1=0.0, auc=0.5838509316770186))\n",
            "(0, Row(id=30, target=1, predicted_label=0, predicted_score=-0.15373161963239745, accuracy=0.7419354838709677, recall=0.0, precision=0.0, f1=0.0, auc=0.6011904761904762))\n",
            "(0, Row(id=31, target=1, predicted_label=0, predicted_score=-0.1579271779090749, accuracy=0.75, recall=0.0, precision=0.0, f1=0.0, auc=0.6171428571428572))\n",
            "(0, Row(id=32, target=1, predicted_label=0, predicted_score=-0.16137363554593392, accuracy=0.7575757575757576, recall=0.0, precision=0.0, f1=0.0, auc=0.6318681318681318))\n",
            "(0, Row(id=33, target=1, predicted_label=0, predicted_score=-0.15642152828436368, accuracy=0.7647058823529411, recall=0.0, precision=0.0, f1=0.0, auc=0.6455026455026456))\n",
            "(0, Row(id=34, target=1, predicted_label=0, predicted_score=-0.14774419806657202, accuracy=0.7714285714285715, recall=0.0, precision=0.0, f1=0.0, auc=0.653061224489796))\n",
            "(0, Row(id=35, target=4, predicted_label=0, predicted_score=-0.12301150976629877, accuracy=0.75, recall=0.0, precision=0.0, f1=0.0, auc=0.6473214285714286))\n",
            "(0, Row(id=36, target=1, predicted_label=0, predicted_score=-0.15423896058090336, accuracy=0.7567567567567568, recall=0.0, precision=0.0, f1=0.0, auc=0.6594827586206897))\n",
            "(0, Row(id=37, target=1, predicted_label=0, predicted_score=-0.1442376305613431, accuracy=0.7631578947368421, recall=0.0, precision=0.0, f1=0.0, auc=0.6625))\n",
            "(0, Row(id=38, target=1, predicted_label=0, predicted_score=-0.13640155278445576, accuracy=0.7692307692307693, recall=0.0, precision=0.0, f1=0.0, auc=0.6653225806451613))\n",
            "(0, Row(id=39, target=1, predicted_label=0, predicted_score=-0.16501209241270226, accuracy=0.775, recall=0.0, precision=0.0, f1=0.0, auc=0.67578125))\n",
            "(0, Row(id=40, target=1, predicted_label=0, predicted_score=-0.15136604252895336, accuracy=0.7804878048780488, recall=0.0, precision=0.0, f1=0.0, auc=0.6856060606060606))\n",
            "(0, Row(id=41, target=1, predicted_label=0, predicted_score=-0.11180355043552243, accuracy=0.7857142857142857, recall=0.0, precision=0.0, f1=0.0, auc=0.6764705882352942))\n",
            "(0, Row(id=42, target=1, predicted_label=0, predicted_score=-0.128872960226863, accuracy=0.7906976744186046, recall=0.0, precision=0.0, f1=0.0, auc=0.675))\n",
            "(0, Row(id=43, target=5, predicted_label=1, predicted_score=0.10248652979146256, accuracy=0.7954545454545454, recall=0.1111111111111111, precision=0.5, f1=0.18181818181818182, auc=0.711111111111111))\n",
            "(0, Row(id=44, target=5, predicted_label=1, predicted_score=0.06669936665015586, accuracy=0.8, recall=0.2, precision=0.6666666666666666, f1=0.3076923076923077, auc=0.74))\n",
            "(0, Row(id=45, target=1, predicted_label=0, predicted_score=-0.10614236991081122, accuracy=0.8043478260869565, recall=0.2, precision=0.6666666666666666, f1=0.3076923076923077, auc=0.7333333333333334))\n",
            "(0, Row(id=46, target=1, predicted_label=0, predicted_score=-0.15222836556041186, accuracy=0.8085106382978723, recall=0.2, precision=0.6666666666666666, f1=0.3076923076923077, auc=0.7405405405405405))\n",
            "(0, Row(id=47, target=1, predicted_label=0, predicted_score=-0.15200098550317004, accuracy=0.8125, recall=0.2, precision=0.6666666666666666, f1=0.3076923076923077, auc=0.7473684210526316))\n",
            "(0, Row(id=48, target=5, predicted_label=1, predicted_score=0.0814324341561703, accuracy=0.8163265306122449, recall=0.2727272727272727, precision=0.75, f1=0.4, auc=0.770334928229665))\n",
            "(0, Row(id=49, target=1, predicted_label=0, predicted_score=-0.12470733710129883, accuracy=0.82, recall=0.2727272727272727, precision=0.75, f1=0.4, auc=0.7692307692307694))\n",
            "(0, Row(id=50, target=1, predicted_label=0, predicted_score=-0.1495511680518793, accuracy=0.8235294117647058, recall=0.2727272727272727, precision=0.75, f1=0.4, auc=0.775))\n",
            "(0, Row(id=51, target=1, predicted_label=0, predicted_score=-0.17108347787964867, accuracy=0.8269230769230769, recall=0.2727272727272727, precision=0.75, f1=0.4, auc=0.7804878048780488))\n",
            "(0, Row(id=52, target=4, predicted_label=0, predicted_score=-0.07761099274644961, accuracy=0.8113207547169812, recall=0.25, precision=0.75, f1=0.375, auc=0.7886178861788617))\n",
            "(0, Row(id=53, target=1, predicted_label=0, predicted_score=-0.1343864916525121, accuracy=0.8148148148148148, recall=0.25, precision=0.75, f1=0.375, auc=0.7896825396825398))\n",
            "(0, Row(id=54, target=1, predicted_label=0, predicted_score=-0.02880208121352995, accuracy=0.8181818181818182, recall=0.25, precision=0.75, f1=0.375, auc=0.7771317829457365))\n",
            "(0, Row(id=55, target=1, predicted_label=0, predicted_score=-0.16065738948135289, accuracy=0.8214285714285714, recall=0.25, precision=0.75, f1=0.375, auc=0.7821969696969697))\n",
            "(0, Row(id=56, target=5, predicted_label=1, predicted_score=0.10990168370986952, accuracy=0.8245614035087719, recall=0.3076923076923077, precision=0.8, f1=0.4444444444444444, auc=0.798951048951049))\n",
            "(0, Row(id=57, target=1, predicted_label=0, predicted_score=-0.110734026971757, accuracy=0.8275862068965517, recall=0.3076923076923077, precision=0.8, f1=0.4444444444444444, auc=0.7948717948717949))\n",
            "(0, Row(id=58, target=5, predicted_label=1, predicted_score=0.05333677875197851, accuracy=0.8305084745762712, recall=0.35714285714285715, precision=0.8333333333333334, f1=0.5, auc=0.8095238095238095))\n",
            "(0, Row(id=59, target=4, predicted_label=0, predicted_score=-0.07570517594981274, accuracy=0.8166666666666667, recall=0.3333333333333333, precision=0.8333333333333334, f1=0.47619047619047616, auc=0.8133333333333335))\n",
            "(0, Row(id=60, target=4, predicted_label=1, predicted_score=0.014215735479134906, accuracy=0.819672131147541, recall=0.375, precision=0.8571428571428571, f1=0.5217391304347826, auc=0.8236111111111111))\n",
            "(0, Row(id=61, target=1, predicted_label=0, predicted_score=-0.1394847723920194, accuracy=0.8225806451612904, recall=0.375, precision=0.8571428571428571, f1=0.5217391304347826, auc=0.8247282608695652))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread wait_until_finish_read:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "Exception in thread run_worker_job-001[job]_ref_Environment_default_environment_1:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/apache_beam/runners/portability/portable_runner.py\", line 534, in read_messages\n",
            "    for message in self._message_stream:\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\", line 543, in __next__\n",
            "    return self._next()\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\", line 969, in _next\n",
            "    raise self\n",
            "grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:\n",
            "\tstatus = StatusCode.UNAVAILABLE\n",
            "\tdetails = \"Socket closed\"\n",
            "\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:127.0.0.1:38741 {grpc_message:\"Socket closed\", grpc_status:14, created_time:\"2025-05-08T01:06:12.753973698+00:00\"}\"\n",
            ">\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "Exception in thread read_state:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/apache_beam/runners/worker/sdk_worker.py\", line 268, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/apache_beam/runners/worker/sdk_worker.py\", line 1072, in pull_responses\n",
            "    for response in responses:\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\", line 543, in __next__\n",
            "    return self._next()\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\", line 969, in _next\n",
            "    raise self\n",
            "grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:\n",
            "\tstatus = StatusCode.UNAVAILABLE\n",
            "\tdetails = \"Socket closed\"\n",
            "\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:127.0.0.1:38741 {created_time:\"2025-05-08T01:06:12.753436635+00:00\", grpc_status:14, grpc_message:\"Socket closed\"}\"\n",
            ">\n",
            "ERROR:apache_beam.runners.worker.data_plane:Failed to read inputs in the data plane.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/apache_beam/runners/worker/data_plane.py\", line 704, in _read_inputs\n",
            "    for elements in elements_iterator:\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\", line 543, in __next__\n",
            "    return self._next()\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\", line 969, in _next\n",
            "    raise self\n",
            "grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:\n",
            "\tstatus = StatusCode.UNAVAILABLE\n",
            "\tdetails = \"Socket closed\"\n",
            "\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:127.0.0.1:38741 {grpc_message:\"Socket closed\", grpc_status:14, created_time:\"2025-05-08T01:06:12.757349769+00:00\"}\"\n",
            ">\n",
            "    for work_request in self._control_stub.Control(get_responses()):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\", line 543, in __next__\n",
            "    return self._next()\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\", line 969, in _next\n",
            "    raise self\n",
            "grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:\n",
            "\tstatus = StatusCode.UNAVAILABLE\n",
            "\tdetails = \"Socket closed\"\n",
            "\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:127.0.0.1:38741 {created_time:\"2025-05-08T01:06:12.757381694+00:00\", grpc_status:14, grpc_message:\"Socket closed\"}\"\n",
            ">\n",
            "Exception in thread read_grpc_client_inputs:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/apache_beam/runners/worker/data_plane.py\", line 721, in <lambda>\n",
            "    target=lambda: self._read_inputs(elements_iterator),\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/apache_beam/runners/worker/data_plane.py\", line 704, in _read_inputs\n",
            "    for elements in elements_iterator:\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\", line 543, in __next__\n",
            "    return self._next()\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\", line 969, in _next\n",
            "    raise self\n",
            "grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:\n",
            "\tstatus = StatusCode.UNAVAILABLE\n",
            "\tdetails = \"Socket closed\"\n",
            "\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:127.0.0.1:38741 {grpc_message:\"Socket closed\", grpc_status:14, created_time:\"2025-05-08T01:06:12.757349769+00:00\"}\"\n",
            ">\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-b6bae0913955>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m ])\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mbeam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m   _ = (p\n\u001b[1;32m     21\u001b[0m        \u001b[0;34m|\u001b[0m \u001b[0mSequenceToPeriodicStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/apache_beam/pipeline.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStandardOptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_wait_until_finish\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_until_finish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m           logging.info(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/apache_beam/runners/portability/portable_runner.py\u001b[0m in \u001b[0;36mwait_until_finish\u001b[0;34m(self, duration)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_observe_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_thread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_runtime_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/apache_beam/runners/portability/portable_runner.py\u001b[0m in \u001b[0;36m_observe_state\u001b[0;34m(self, message_thread)\u001b[0m\n\u001b[1;32m    573\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_observe_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_thread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mstate_response\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m         self._state = self.runner_api_state_to_pipeline_state(\n\u001b[1;32m    577\u001b[0m             state_response.state)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    958\u001b[0m                 )\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m             \u001b[0m_common\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_response_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_common.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(wait_fn, wait_complete_fn, timeout, spin_cb)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwait_complete_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0m_wait_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAXIMUM_WAIT_TIMEOUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspin_cb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_common.py\u001b[0m in \u001b[0;36m_wait_once\u001b[0;34m(wait_fn, timeout, spin_cb)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mspin_cb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m ):\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mwait_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspin_cb\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mspin_cb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/apache_beam/runners/portability/job_server.py\u001b[0m in \u001b[0;36m_sigint_handler\u001b[0;34m(self, sig, frame)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_sigint_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m       \u001b[0;31m# call original signal handler to handle sigint gracefully\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_sigint_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Alternative: Running the Pipeline with Dataflow Runner"
      ],
      "metadata": {
        "id": "I-6hza8-DcY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Environment Variables for Dataflow Runner\n",
        "TEMP_LOCATION = TEMP_ROOT + '/anomaly/iforest-notebook-' + SUFFIX + '/temp'\n",
        "STAGING_LOCATION = TEMP_ROOT + '/anomaly/iforest-notebook-' + SUFFIX + '/staging'"
      ],
      "metadata": {
        "id": "Gh-bU6vsD9vD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For running with dataflow runner\n",
        "!pip install 'apache_beam[gcp, interactive]=={BEAM_VERSION}' --quiet"
      ],
      "metadata": {
        "id": "0C0qur71DiN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running the pipeline on dataflow\n",
        "options = PipelineOptions([\n",
        "  \"--runner=DataflowRunner\",\n",
        "  \"--temp_location=\" + TEMP_LOCATION,\n",
        "  \"--staging_location=\" + STAGING_LOCATION,\n",
        "  \"--project=\" + PROJECT_ID,\n",
        "  \"--region=\" + REGION,\n",
        "  \"--extra_package=gs://shunping-test/anomaly-temp/pyod-2.0.3.tar.gz\",\n",
        "])\n",
        "\n",
        "with beam.Pipeline(options=options) as p:\n",
        "  _ = (p\n",
        "       | SequenceToPeriodicStream(rows, delay=1, repeat=True)\n",
        "       | beam.Map(lambda x: beam.Row(**x))\n",
        "       | beam.WithKeys(0)\n",
        "       | AnomalyDetection(detector=detector)\n",
        "       | beam.WindowInto(GlobalWindows()) # put everything into global window to compute overall auc\n",
        "       | beam.ParDo(ComputeMetrics(lambda x: 1 if x.target != 1 else 0))\n",
        "       | beam.LogElements()\n",
        "  )"
      ],
      "metadata": {
        "id": "-uspd0osDocV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}