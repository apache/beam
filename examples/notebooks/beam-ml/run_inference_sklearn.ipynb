{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title ###### Licensed to the Apache Software Foundation (ASF), Version 2.0 (the \"License\")\n",
        "\n",
        "# Licensed to the Apache Software Foundation (ASF) under one\n",
        "# or more contributor license agreements. See the NOTICE file\n",
        "# distributed with this work for additional information\n",
        "# regarding copyright ownership. The ASF licenses this file\n",
        "# to you under the Apache License, Version 2.0 (the\n",
        "# \"License\"); you may not use this file except in compliance\n",
        "# with the License. You may obtain a copy of the License at\n",
        "#\n",
        "#   http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing,\n",
        "# software distributed under the License is distributed on an\n",
        "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
        "# KIND, either express or implied. See the License for the\n",
        "# specific language governing permissions and limitations\n",
        "# under the License."
      ],
      "metadata": {
        "id": "C1rAsD2L-hSO",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6f8f3af-744e-4eaa-8a30-6d03e8e4d21e"
      },
      "source": [
        "# Apache Beam RunInference for scikit-learn\n",
        "\n",
        "<button>\n",
        "  <a href=\"https://beam.apache.org/documentation/sdks/python-machine-learning/\">\n",
        "    <img src=\"https://beam.apache.org/images/favicon.ico\" alt=\"Open the docs\" height=\"16\"/>\n",
        "    Beam RunInference\n",
        "  </a>\n",
        "</button>\n",
        "\n",
        "In this notebook, we walk through the use of the RunInference transform for [scikit-learn](https://scikit-learn.org/) also call sklearn.\n",
        "Beam [RunInference](https://beam.apache.org/releases/pydoc/current/apache_beam.ml.inference.base.html#apache_beam.ml.inference.base.RunInference) has implementations of it's [ModelHandler](https://beam.apache.org/releases/pydoc/current/apache_beam.ml.inference.base.html#apache_beam.ml.inference.base.ModelHandler) specifically for scikit-learn.\n",
        "\n",
        "Choose a model handler for your implementation:\n",
        "* The [numpy model handler](https://beam.apache.org/releases/pydoc/current/apache_beam.ml.inference.sklearn_inference.html#apache_beam.ml.inference.sklearn_inference.SklearnModelHandlerNumpy)\n",
        "* The [pandas dataframes model handler](https://beam.apache.org/releases/pydoc/current/apache_beam.ml.inference.sklearn_inference.html#apache_beam.ml.inference.sklearn_inference.SklearnModelHandlerNumpy)\n",
        "\n",
        "These ModelHandlers coupled with RunInference take care of batching, vectorization and optomizing predictions for you pipeline or model.\n",
        "\n",
        "This notebook illustrates common RunInference patterns such as the following:\n",
        "*   Generating predictions.\n",
        "*   Post processing results after RunInference.\n",
        "*   Inference with multiple models in the same pipeline.\n",
        "\n",
        "The linear regression models used in these samples are trained on data that correspondes to the 5 and 10 times table; that is,`y = 5x` and `y = 10x` respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "1. Install dependencies for beam.\n",
        "1. Authenticate with Google Cloud.\n",
        "1. Specify your project and bucket.  This will be needed to save and load models."
      ],
      "metadata": {
        "id": "zzwnMzzgdyPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-api-core --quiet\n",
        "!pip install google-cloud-pubsub google-cloud-bigquery-storage --quiet\n",
        "!pip install apache-beam[gcp,dataframe] --quiet"
      ],
      "metadata": {
        "id": "6vlKcT-Wev20"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32c9ba40-9396-48f4-9e7f-a2acced98bb2"
      },
      "source": [
        "## About scikit-learn Versions\n",
        "\n",
        "scikit-learn is a build-dependency of Apache Beam. If a different version of sklearn needs to be installed, use `%pip install scikit-learn==<version>`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "V0E35R5Ka2cE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "248458a6-cfd8-474d-ad0e-f37f7ae981ae"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Constants\n",
        "project = \"<your GCP project>\"\n",
        "bucket = \"<your GCP bucket>\"\n",
        "\n",
        "# set the project to avoid warnings.\n",
        "os.environ['GOOGLE_CLOUD_PROJECT'] = project\n",
        "\n",
        "save_model_dir_multiply_five = 'five_times_table_torch.pt'\n",
        "save_model_dir_multiply_ten = 'ten_times_table_torch.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "d6142b75-eef1-4e52-9fa4-fe02fe916b26"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from sklearn import linear_model\n",
        "from typing import Tuple\n",
        "\n",
        "import numpy as np\n",
        "import apache_beam as beam\n",
        "\n",
        "from apache_beam.ml.inference.sklearn_inference import ModelFileType\n",
        "from apache_beam.ml.inference.sklearn_inference import SklearnModelHandlerNumpy\n",
        "from apache_beam.ml.inference.base import KeyedModelHandler\n",
        "from apache_beam.ml.inference.base import PredictionResult\n",
        "from apache_beam.ml.inference.base import RunInference\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6695cd22-e0bf-438f-8223-4a93392e6616"
      },
      "source": [
        "## Create the Data and the scikit-learn Model.\n",
        "In this cell, we perform:\n",
        "1. Create the data to train the scikit-learn linear regression model.\n",
        "2. Train the linear regression model.\n",
        "3. Save the scikit-learn model using `pickle`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "c57843e8-f696-4196-ad39-827e34849976"
      },
      "outputs": [],
      "source": [
        "# Input data to train the sklearn model.\n",
        "x = np.arange(0, 100, dtype=np.float32).reshape(-1, 1)\n",
        "y = (x * 5).reshape(-1, 1)\n",
        "\n",
        "regression = linear_model.LinearRegression()\n",
        "regression.fit(x,y)\n",
        "\n",
        "sklearn_model_filename = 'sklearn_5x_model.pkl'\n",
        "with open(sklearn_model_filename, 'wb') as f:\n",
        "    pickle.dump(regression, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69008a3d-3d15-4643-828c-b0419b347d01"
      },
      "source": [
        "### scikit-learn RunInference pipeline.\n",
        "\n",
        "1. Define the scikit-learn model handler that accepts array_like object as input.\n",
        "2. Read the data from BigQuery.\n",
        "3. Use the scikit-learn trained model and the scikit-learn RunInference transform on unkeyed data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade google-cloud-bigquery --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEGaqpMVqgRP",
        "outputId": "1b4d9091-9d1a-4c44-e7ef-6353af7d2a65"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 211 kB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 76 kB 5.4 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.13.3 requires google-cloud-bigquery[bqstorage,pandas]<2.0.0dev,>=1.11.1, but you have google-cloud-bigquery 3.3.2 which is incompatible.\n",
            "google-cloud-storage 1.18.1 requires google-resumable-media<0.5.0dev,>=0.3.1, but you have google-resumable-media 2.3.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud config set project $project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xq5AKtRrqlUx",
        "outputId": "adccf042-9350-4d67-f605-1562b351b9b1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Populated BigQuery Table\n",
        "\n",
        "from google.cloud import bigquery\n",
        "\n",
        "client = bigquery.Client(project=project)\n",
        "\n",
        "# Make sure the dataset_id is unique in your project.\n",
        "dataset_id = '{project}.maths'.format(project=project)\n",
        "dataset = bigquery.Dataset(dataset_id)\n",
        "\n",
        "# Modify the location based on your project configuration.\n",
        "dataset.location = 'US'\n",
        "dataset = client.create_dataset(dataset, exists_ok=True)\n",
        "\n",
        "# Table name in the BigQuery dataset.\n",
        "table_name = 'maths_problems_1'\n",
        "\n",
        "query = \"\"\"\n",
        "    CREATE OR REPLACE TABLE\n",
        "      {project}.maths.{table} ( key STRING OPTIONS(description=\"A unique key for the maths problem\"),\n",
        "    value FLOAT64 OPTIONS(description=\"Our maths problem\" ) );\n",
        "    INSERT INTO maths.{table}\n",
        "    VALUES\n",
        "      (\"first_example\", 105.00),\n",
        "      (\"second_example\", 108.00),\n",
        "      (\"third_example\", 1000.00),\n",
        "      (\"fourth_example\", 1013.00)\n",
        "\"\"\".format(project=project, table=table_name)\n",
        "\n",
        "create_job = client.query(query)\n",
        "create_job.result()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCIjN__rpoVF",
        "outputId": "1b91ad1e-144f-4e5e-d941-0c82abdb4d51"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<google.cloud.bigquery.table._EmptyRowIterator at 0x7fec32790750>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "50a648a3-794a-4286-ab2b-fc0458db04ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9c942ad-b094-4940-929b-6217113cf873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PredictionResult(example=[105.0], inference=array([525.]))\n",
            "PredictionResult(example=[1000.0], inference=array([5000.]))\n",
            "PredictionResult(example=[108.0], inference=array([540.]))\n",
            "PredictionResult(example=[1013.0], inference=array([5065.]))\n"
          ]
        }
      ],
      "source": [
        "# SklearnModelHandlerNumpy accepts only unkeyed examples.\n",
        "# Use model_file_type=ModelFileType.JOBLIB if the model is seriazlized using joblib.\n",
        "sklearn_model_handler = SklearnModelHandlerNumpy(model_uri=sklearn_model_filename,\n",
        "                                                 model_file_type=ModelFileType.PICKLE) \n",
        "\n",
        "\n",
        "pipeline_options = PipelineOptions().from_dictionary(\n",
        "                                      {'temp_location':f'gs://{bucket}/tmp'})\n",
        "pipeline = beam.Pipeline(options=pipeline_options)\n",
        "\n",
        "# Define BigQuery table specification.\n",
        "table_name = 'maths_problems_1'\n",
        "table_spec = f'{project}:maths.{table_name}'\n",
        "\n",
        "with pipeline as p:\n",
        "  (\n",
        "      p \n",
        "      | \"ReadFromBQ\" >> beam.io.ReadFromBigQuery(table=table_spec)\n",
        "      | \"ExtractInputs\" >> beam.Map(lambda x: [x['value']]) \n",
        "      | \"RunInferenceSklearn\" >> RunInference(model_handler=sklearn_model_handler)\n",
        "      | beam.Map(print)\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33e901d6-ed06-4268-8a5f-685d31b5558f"
      },
      "source": [
        "### Sklearn RunInference on keyed inputs.\n",
        "1. Wrap the `SklearnModelHandlerNumpy` object around `KeyedModelHandler` to handle keyed data.\n",
        "2. Read the data from BigQuery.\n",
        "3. Use the Sklearn trained model and the Sklearn RunInference transform on a keyed data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "c212916d-b517-4589-ad15-a3a1df926fb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57a6ff62-dbd7-4b04-8129-5bffff956aa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('first_example', PredictionResult(example=[105.0], inference=array([525.])))\n",
            "('third_example', PredictionResult(example=[1000.0], inference=array([5000.])))\n",
            "('second_example', PredictionResult(example=[108.0], inference=array([540.])))\n",
            "('fourth_example', PredictionResult(example=[1013.0], inference=array([5065.])))\n"
          ]
        }
      ],
      "source": [
        "# Use model_file_type=ModelFileType.JOBLIB if the model is serialized using joblib.\n",
        "sklearn_model_handler = SklearnModelHandlerNumpy(model_uri=sklearn_model_filename,\n",
        "                                                 model_file_type=ModelFileType.PICKLE) \n",
        "keyed_sklearn_model_handler = KeyedModelHandler(sklearn_model_handler)\n",
        "\n",
        "pipeline_options = PipelineOptions().from_dictionary(\n",
        "                                      {'temp_location':f'gs://{bucket}/tmp'})\n",
        "pipeline = beam.Pipeline(options=pipeline_options)\n",
        "\n",
        "with pipeline as p:\n",
        "  (\n",
        "  p \n",
        "  | \"ReadFromBQ\" >> beam.io.ReadFromBigQuery(table=table_spec)\n",
        "  | \"ExtractInputs\" >> beam.Map(lambda x: (x['key'], [x['value']])) \n",
        "  | \"RunInferenceSklearn\" >> RunInference(model_handler=keyed_sklearn_model_handler)\n",
        "  | beam.Map(print)\n",
        "  )"
      ]
    }
  ]
}