{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fFjof1NgAJwu"
      },
      "outputs": [],
      "source": [
        "# @title ###### Licensed to the Apache Software Foundation (ASF), Version 2.0 (the \"License\")\n",
        "\n",
        "# Licensed to the Apache Software Foundation (ASF) under one\n",
        "# or more contributor license agreements. See the NOTICE file\n",
        "# distributed with this work for additional information\n",
        "# regarding copyright ownership. The ASF licenses this file\n",
        "# to you under the Apache License, Version 2.0 (the\n",
        "# \"License\"); you may not use this file except in compliance\n",
        "# with the License. You may obtain a copy of the License at\n",
        "#\n",
        "#   http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing,\n",
        "# software distributed under the License is distributed on an\n",
        "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
        "# KIND, either express or implied. See the License for the\n",
        "# specific language governing permissions and limitations\n",
        "# under the License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8xNRyZMW1yK"
      },
      "source": [
        "# Apache Beam RunInference with Vertex AI\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/apache/beam/blob/master/examples/notebooks/beam-ml/run_inference_vertex_ai.ipynb\"><img src=\"https://raw.githubusercontent.com/google/or-tools/main/tools/colab_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/apache/beam/blob/master/examples/notebooks/beam-ml/run_inference_vertex_ai.ipynb\"><img src=\"https://raw.githubusercontent.com/google/or-tools/main/tools/github_32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVCtGOKTHMm4"
      },
      "source": [
        "## Before you begin\n",
        "Set up your environment and download dependencies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDHPlMjZRuY0"
      },
      "source": [
        "### Install Apache Beam\n",
        "To use RunInference with the built-in Vertex AI model handler, install Apache Beam version 2.50.0 or later.\n",
        "\n",
        "**Note:** at time of writing 2.50.0 is in the release process and is not available, so this notebook uses a release candidate build."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jBakpNZnAhqk"
      },
      "outputs": [],
      "source": [
        "!pip install protobuf --quiet\n",
        "!pip install apache_beam[gcp,interactive]==2.50.0rc1 --quiet\n",
        "# Enforce shapely < 2.0.0 to avoid an issue with google.aiplatform\n",
        "!pip install shapely==1.7.1 --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X80jy3FqHjK4"
      },
      "source": [
        "### Authenticate with Google Cloud\n",
        "This notebook relies on having a Vertex AI endpoint deployed to Google Cloud. To use your Google Cloud account, authenticate this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Kz9sccyGBqz3"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40qtP6zJuMXm"
      },
      "source": [
        "### Import dependencies and set up your bucket\n",
        "Use the following code to import dependencies and to set up your Google Cloud Storage bucket.\n",
        "\n",
        "Replace `PROJECT_ID`, `LOCATION_NAME`, and `ENDPOINT_ID` with the ID of your project, the GCP region where your model is deployed, and the ID of your Vertex AI endpoint.\n",
        "\n",
        "**Important**: If an error occurs, restart your runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEle839_Akqx",
        "outputId": "52f54d2b-fd17-4c98-b2a2-3ba6987d1364"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-23 19:03:47.352583: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-23 19:03:48.877610: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from typing import Iterable\n",
        "from typing import List\n",
        "from typing import Tuple\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "import apache_beam as beam\n",
        "import tensorflow as tf\n",
        "from apache_beam.ml.inference.base import KeyedModelHandler\n",
        "from apache_beam.ml.inference.base import PredictionResult\n",
        "from apache_beam.ml.inference.base import RunInference\n",
        "from apache_beam.ml.inference.vertex_ai_inference import VertexAIModelHandlerJSON\n",
        "\n",
        "project = \"PROJECT_ID\"\n",
        "location = \"LOCATION_NAME\"\n",
        "endpoint_id = \"ENDPOINT_ID\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_a0-4Gb19cy"
      },
      "source": [
        "### Query your Endpoint\n",
        "\n",
        "This step checks that your model is deployed to your Vertex AI endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5XkIYXhJBFmS",
        "outputId": "71416e76-e6d1-483d-d8d8-bbeb901e6b62"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'hello_custom'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aiplatform.init(project=project, location=location)\n",
        "endpoint = aiplatform.Endpoint(endpoint_name=endpoint_id)\n",
        "# You can get more metadata if desired by removing [0].display_name\n",
        "endpoint.list_models()[0].display_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3BC2aY8cIMI"
      },
      "source": [
        "### Get and pre-process an example image\n",
        "\n",
        "This step shows how to preprocess an input to match what your model expects. We'll use an image of sunflowers to test the model and trim it to a 128x128 size to match the model's expectations and output the image as a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEXucyi2liij",
        "outputId": "edff91f6-eaf8-4cff-e881-ab8b60cc0fc8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-23 19:03:56.691395: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-23 19:03:56.728315: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-23 19:03:56.728545: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-23 19:03:56.729782: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-23 19:03:56.730077: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-23 19:03:56.730245: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-23 19:03:57.770023: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-23 19:03:57.770295: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-23 19:03:57.770455: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-23 19:03:57.770566: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-08-23 19:03:57.770600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13664 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
          ]
        }
      ],
      "source": [
        "IMG_WIDTH = 128\n",
        "IMG_URL = \"https://www.chicagobotanic.org/sites/default/files/images/sunflowers/sunflower_big1.jpg\"\n",
        "\n",
        "def download_image(image_url: str) -> bytes:\n",
        "  return requests.get(image_url).content\n",
        "\n",
        "def preprocess_image(data: bytes) -> List[float]:\n",
        "  \"\"\"Preprocess the image, resizing it and normalizing it before\n",
        "  converting to a list.\n",
        "  \"\"\"\n",
        "  image = tf.io.decode_jpeg(data, channels=3)\n",
        "  image = tf.image.resize_with_pad(image, IMG_WIDTH, IMG_WIDTH)\n",
        "  image = image / 255\n",
        "  return image.numpy().tolist()\n",
        "\n",
        "img = download_image(IMG_URL)\n",
        "example = preprocess_image(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a1zerXycQ0z"
      },
      "source": [
        "## Run the pipeline\n",
        "Use the following code to run the pipeline and get an image classification and a probability from the Vertex AI endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "St07XoibcQSb",
        "outputId": "7817aa2b-8edb-473c-e957-e446579e0dfe"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n        if (typeof window.interactive_beam_jquery == 'undefined') {\n          var jqueryScript = document.createElement('script');\n          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n          jqueryScript.type = 'text/javascript';\n          jqueryScript.onload = function() {\n            var datatableScript = document.createElement('script');\n            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n            datatableScript.type = 'text/javascript';\n            datatableScript.onload = function() {\n              window.interactive_beam_jquery = jQuery.noConflict(true);\n              window.interactive_beam_jquery(document).ready(function($){\n                \n              });\n            }\n            document.head.appendChild(datatableScript);\n          };\n          document.head.appendChild(jqueryScript);\n        } else {\n          window.interactive_beam_jquery(document).ready(function($){\n            \n          });\n        }"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sunflowers (0.999636769)\n"
          ]
        }
      ],
      "source": [
        "# Column labels for the output probabilities.\n",
        "COLUMNS = ['dandelion', 'daisy', 'tulips', 'sunflowers', 'roses']\n",
        "\n",
        "class PostProcessor(beam.DoFn):\n",
        "  def process(self, element: PredictionResult) -> Iterable[str]:\n",
        "    prediction_vals = element.inference\n",
        "    index = prediction_vals.index(max(prediction_vals))\n",
        "    yield str(COLUMNS[index]) + \" (\" + str(max(prediction_vals)) + \")\"\n",
        "\n",
        "model_handler = VertexAIModelHandlerJSON(endpoint_id=endpoint_id, project=project, location=location)\n",
        "\n",
        "with beam.Pipeline() as p:\n",
        "    _ = (p | beam.Create([example])\n",
        "           | RunInference(model_handler)\n",
        "           | beam.ParDo(PostProcessor())\n",
        "           | beam.Map(print)\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRLArcjOcYuO"
      },
      "source": [
        "## Use a keyed model handler\n",
        "To use a keyed model handler, use `KeyedModelHandler` with Vertex AI by using `VertexAIModelHandlerJSON`.\n",
        "\n",
        "By default, the `ModelHandler` does not expect a key.\n",
        "\n",
        "* If you know that keys are associated with your examples, use `beam.KeyedModelHandler` to wrap the model handler.\n",
        "* If you don't know whether keys are associated with your examples, use `beam.MaybeKeyedModelHandler`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6l9RwL2cAW3",
        "outputId": "ca431553-c560-49f3-fe44-4570ee1a6099"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://www.chicagobotanic.org/sites/default/files/images/sunflowers/sunflower_big1.jpg: sunflowers (0.999636769)\n"
          ]
        }
      ],
      "source": [
        "class PostProcessorKeyed(beam.DoFn):\n",
        "  def process(self, element: Tuple[str, PredictionResult]) -> Iterable[str]:\n",
        "    img_name, prediction_result = element\n",
        "    prediction_vals = prediction_result.inference\n",
        "    index = prediction_vals.index(max(prediction_vals))\n",
        "    yield img_name + \": \" + str(COLUMNS[index]) + \" (\" + str(\n",
        "        max(prediction_vals)) + \")\"\n",
        "\n",
        "keyed_model_handler = KeyedModelHandler(VertexAIModelHandlerJSON(endpoint_id=endpoint_id, project=project, location=location))\n",
        "with beam.Pipeline() as p:\n",
        "    _ = (p | 'CreateExamples' >> beam.Create([example])\n",
        "           | beam.Map(lambda image: (IMG_URL, image))\n",
        "           | RunInference(keyed_model_handler)\n",
        "           | beam.ParDo(PostProcessorKeyed())\n",
        "           | beam.Map(print)\n",
        "        )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
