{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/svetakvsundhar/beam/blob/healthcarenlp/examples/notebooks/healthcare/beam_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ###### Licensed to the Apache Software Foundation (ASF), Version 2.0 (the \"License\")\n",
        "\n",
        "# Licensed to the Apache Software Foundation (ASF) under one\n",
        "# or more contributor license agreements. See the NOTICE file\n",
        "# distributed with this work for additional information\n",
        "# regarding copyright ownership. The ASF licenses this file\n",
        "# to you under the Apache License, Version 2.0 (the\n",
        "# \"License\"); you may not use this file except in compliance\n",
        "# with the License. You may obtain a copy of the License at\n",
        "#\n",
        "#   http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing,\n",
        "# software distributed under the License is distributed on an\n",
        "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
        "# KIND, either express or implied. See the License for the\n",
        "# specific language governing permissions and limitations\n",
        "# under the License"
      ],
      "metadata": {
        "id": "lBuUTzxD2mvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Natural Language Processing Pipeline**\n",
        "\n",
        "**Note**: This example is used from [here](https://github.com/rasalt/healthcarenlp/blob/main/nlp_public.ipynb).\n",
        "\n",
        "\n",
        "\n",
        "This example demonstrates how to set up an Apache Beam pipeline that reads a file from [Google Cloud Storage](https://https://cloud.google.com/storage), and calls the [Google Cloud Healthcare NLP API](https://cloud.google.com/healthcare-api/docs/how-tos/nlp) to extract information from unstructured data. This application can be used in contexts such as reading scanned clinical documents and extracting structure from it.\n",
        "\n",
        "An Apache Beam pipeline is a pipeline that reads input data, transforms that data, and writes output data. It consists of PTransforms and PCollections. A PCollection represents a distributed data set that your Beam pipeline operates on. A PTransform represents a data processing operation, or a step, in your pipeline. It takes one or more PCollections as input, performs a processing function that you provide on the elements of that PCollection, and produces zero or more output PCollection objects.\n",
        "\n",
        "For details about Apache Beam pipelines, including PTransforms and PCollections, visit the [Beam Programming Guide](https://beam.apache.org/documentation/programming-guide/).\n",
        "\n",
        "You'll be able to use this notebook to explore the data in each PCollection."
      ],
      "metadata": {
        "id": "nEUAYCTx4Ijj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions\n",
        "1. Set the variables in the next cell based upon your project and preferences\n",
        "2. The files referred to in this notebook nlpsample*.csv are in the format with one\n",
        "blurb of clinical note."
      ],
      "metadata": {
        "id": "ZLBB0PTG5CHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install apache-beam[gcp]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7hq2sse8K4u",
        "outputId": "c6f559a6-1419-43f2-b88d-49fedca1c686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: apache-beam[gcp] in /usr/local/lib/python3.10/dist-packages (2.49.0)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (1.7)\n",
            "Requirement already satisfied: orjson<4.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (3.9.2)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (0.3.1.1)\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (2.2.1)\n",
            "Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (1.8.0)\n",
            "Requirement already satisfied: fasteners<1.0,>=0.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (0.18)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (1.56.0)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (2.7.0)\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (0.21.0)\n",
            "Requirement already satisfied: numpy<1.25.0,>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (1.22.4)\n",
            "Requirement already satisfied: objsize<0.7.0,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (0.6.1)\n",
            "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (4.4.1)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (1.22.3)\n",
            "Requirement already satisfied: protobuf<4.24.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (3.20.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (2022.7.1)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (2022.10.31)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (4.7.1)\n",
            "Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (0.21.0)\n",
            "Requirement already satisfied: pyarrow<12.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (9.0.0)\n",
            "Requirement already satisfied: cachetools<6,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (5.3.1)\n",
            "Requirement already satisfied: google-apitools<0.5.32,>=0.5.31 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (0.5.31)\n",
            "Requirement already satisfied: google-auth<3,>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (0.1.0)\n",
            "Requirement already satisfied: google-cloud-datastore<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (2.15.2)\n",
            "Requirement already satisfied: google-cloud-pubsub<3,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (2.18.0)\n",
            "Requirement already satisfied: google-cloud-pubsublite<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (1.8.3)\n",
            "Requirement already satisfied: google-cloud-bigquery<4,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (3.10.0)\n",
            "Requirement already satisfied: google-cloud-bigquery-storage<3,>=2.6.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (2.22.0)\n",
            "Requirement already satisfied: google-cloud-core<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (2.3.3)\n",
            "Requirement already satisfied: google-cloud-bigtable<3,>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (2.19.0)\n",
            "Requirement already satisfied: google-cloud-spanner<4,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (3.36.0)\n",
            "Requirement already satisfied: google-cloud-dlp<4,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (3.12.2)\n",
            "Requirement already satisfied: google-cloud-language<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (2.9.1)\n",
            "Requirement already satisfied: google-cloud-videointelligence<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (2.11.3)\n",
            "Requirement already satisfied: google-cloud-vision<4,>=2 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (3.4.4)\n",
            "Requirement already satisfied: google-cloud-recommendations-ai<0.11.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (0.10.4)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]) (1.28.0)\n",
            "Requirement already satisfied: oauth2client>=1.4.12 in /usr/local/lib/python3.10/dist-packages (from google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]) (4.1.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]) (1.16.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]) (4.9)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]) (2.11.1)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]) (23.1)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]) (1.10.2)\n",
            "Requirement already satisfied: shapely<2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]) (1.8.5.post1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4,>=2.0.0->apache-beam[gcp]) (2.5.0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigtable<3,>=2.19.0->apache-beam[gcp]) (0.12.6)\n",
            "Requirement already satisfied: grpcio-status>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]) (1.48.2)\n",
            "Requirement already satisfied: overrides<7.0.0,>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]) (6.5.0)\n",
            "Requirement already satisfied: sqlparse>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]) (0.4.4)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]) (0.6.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<0.23.0,>=0.8->apache-beam[gcp]) (3.1.0)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo<5.0.0,>=3.8.0->apache-beam[gcp]) (2.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]) (3.4)\n",
            "Requirement already satisfied: httpcore>=0.17.3 in /usr/local/lib/python3.10/dist-packages (from dnspython<3.0.0,>=1.16.0->pymongo<5.0.0,>=3.8.0->apache-beam[gcp]) (0.17.3)\n",
            "Requirement already satisfied: sniffio<2.0,>=1.1 in /usr/local/lib/python3.10/dist-packages (from dnspython<3.0.0,>=1.16.0->pymongo<5.0.0,>=3.8.0->apache-beam[gcp]) (1.3.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]) (1.59.1)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<4,>=2.0.0->apache-beam[gcp]) (1.5.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=1.4.12->google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]) (0.5.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore>=0.17.3->dnspython<3.0.0,>=1.16.0->pymongo<5.0.0,>=3.8.0->apache-beam[gcp]) (0.14.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore>=0.17.3->dnspython<3.0.0,>=1.16.0->pymongo<5.0.0,>=3.8.0->apache-beam[gcp]) (3.7.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore>=0.17.3->dnspython<3.0.0,>=1.16.0->pymongo<5.0.0,>=3.8.0->apache-beam[gcp]) (1.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that below **us-central1** is hardcoded as the location. This is because of the limited number of [locations](https://cloud.google.com/healthcare-api/docs/how-tos/nlp) the API currently supports."
      ],
      "metadata": {
        "id": "D7lJqW2PRFcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Change this variable to True if you want to debug the Interactive Runner Pipeline else it uses Dataflow\n",
        "debug = False\n",
        "DATASET=\"<YOUR_DATASET_NAME>\"\n",
        "TEMP_LOCATION=\"<YOUR_TEMP_LOCATION>\"\n",
        "PROJECT='<YOUR_PROJECT_ID>'\n",
        "LOCATION='us-central1'\n",
        "URL=f'https://healthcare.googleapis.com/v1/projects/{PROJECT}/locations/{LOCATION}/services/nlp:analyzeEntities'\n",
        "NLP_SERVICE=f'projects/{PROJECT}/locations/{LOCATION}/services/nlp'\n",
        "GCS_BUCKET=PROJECT"
      ],
      "metadata": {
        "id": "s9lhe5CZ5F3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BigQuery Setup**\n",
        "\n",
        "We will be using BigQuery to warehouse the structured data revealed in the output of the Healthcare NLP API. For this purpose, we create 3 tables to organize the data"
      ],
      "metadata": {
        "id": "DI_Qkyn75LO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "# Construct a BigQuery client object.\n",
        "\n",
        "TABLE_ENTITY=\"entity\"\n",
        "TABLE_REL=\"relations\"\n",
        "TABLE_ENTITYMENTIONS=\"entitymentions\"\n",
        "\n",
        "schemaEntity = [\n",
        "    bigquery.SchemaField(\"entityId\", \"STRING\", mode=\"NULLABLE\"),\n",
        "    bigquery.SchemaField(\"preferredTerm\", \"STRING\", mode=\"NULLABLE\"),\n",
        "    bigquery.SchemaField(\"vocabularyCodes\", \"STRING\", mode=\"REPEATED\"),\n",
        "]\n",
        "\n",
        "schemaRelations = [\n",
        "    bigquery.SchemaField(\"subjectId\", \"STRING\", mode=\"NULLABLE\"),\n",
        "    bigquery.SchemaField(\"objectId\", \"STRING\", mode=\"NULLABLE\"),\n",
        "    bigquery.SchemaField(\"confidence\", \"FLOAT64\", mode=\"NULLABLE\"),\n",
        "    bigquery.SchemaField(\"id\", \"STRING\", mode=\"NULLABLE\"),\n",
        "]\n",
        "\n",
        "schemaEntityMentions = [\n",
        "    bigquery.SchemaField(\"mentionId\", \"STRING\", mode=\"NULLABLE\"),\n",
        "    bigquery.SchemaField(\"type\", \"STRING\", mode=\"NULLABLE\"),\n",
        "    bigquery.SchemaField(\n",
        "        \"text\",\n",
        "        \"RECORD\",\n",
        "         mode=\"NULLABLE\",\n",
        "         fields=[\n",
        "             bigquery.SchemaField(\"content\", \"STRING\", mode=\"NULLABLE\"),\n",
        "             bigquery.SchemaField(\"beginOffset\", \"INTEGER\", mode=\"NULLABLE\"),\n",
        "         ],\n",
        "    ),\n",
        "    bigquery.SchemaField(\n",
        "        \"linkedEntities\",\n",
        "        \"RECORD\",\n",
        "         mode=\"REPEATED\",\n",
        "         fields=[\n",
        "             bigquery.SchemaField(\"entityId\", \"STRING\", mode=\"NULLABLE\"),\n",
        "         ],\n",
        "    ),\n",
        "    bigquery.SchemaField(\n",
        "        \"temporalAssessment\",\n",
        "        \"RECORD\",\n",
        "         mode=\"NULLABLE\",\n",
        "         fields=[\n",
        "             bigquery.SchemaField(\"value\", \"STRING\", mode=\"NULLABLE\"),\n",
        "             bigquery.SchemaField(\"confidence\", \"FLOAT64\", mode=\"NULLABLE\"),\n",
        "         ],\n",
        "    ),\n",
        "    bigquery.SchemaField(\n",
        "        \"certaintyAssessment\",\n",
        "        \"RECORD\",\n",
        "         mode=\"NULLABLE\",\n",
        "         fields=[\n",
        "             bigquery.SchemaField(\"value\", \"STRING\", mode=\"NULLABLE\"),\n",
        "             bigquery.SchemaField(\"confidence\", \"FLOAT64\", mode=\"NULLABLE\"),\n",
        "         ],\n",
        "    ),\n",
        "    bigquery.SchemaField(\n",
        "        \"subject\",\n",
        "        \"RECORD\",\n",
        "         mode=\"NULLABLE\",\n",
        "         fields=[\n",
        "             bigquery.SchemaField(\"value\", \"STRING\", mode=\"NULLABLE\"),\n",
        "             bigquery.SchemaField(\"confidence\", \"FLOAT64\", mode=\"NULLABLE\"),\n",
        "         ],\n",
        "    ),\n",
        "    bigquery.SchemaField(\"confidence\", \"FLOAT64\", mode=\"NULLABLE\"),\n",
        "    bigquery.SchemaField(\"id\", \"STRING\", mode=\"NULLABLE\")\n",
        "]\n",
        "\n",
        "client = bigquery.Client()\n",
        "\n",
        "# Create Table IDs\n",
        "table_ent = PROJECT+\".\"+DATASET+\".\"+TABLE_ENTITY\n",
        "table_rel = PROJECT+\".\"+DATASET+\".\"+TABLE_REL\n",
        "table_mentions = PROJECT+\".\"+DATASET+\".\"+TABLE_ENTITYMENTIONS\n",
        "\n",
        "# If table exists, delete the tables.\n",
        "client.delete_table(table_ent, not_found_ok=True)\n",
        "client.delete_table(table_rel, not_found_ok=True)\n",
        "client.delete_table(table_mentions, not_found_ok=True)\n",
        "\n",
        "# Create tables\n",
        "\n",
        "table = bigquery.Table(table_ent, schema=schemaEntity)\n",
        "table = client.create_table(table)  # Make an API request.\n",
        "\n",
        "print(\n",
        "    \"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id)\n",
        ")\n",
        "\n",
        "table = bigquery.Table(table_rel, schema=schemaRelations)\n",
        "table = client.create_table(table)  # Make an API request.\n",
        "print(\n",
        "    \"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id)\n",
        ")\n",
        "table = bigquery.Table(table_mentions, schema=schemaEntityMentions)\n",
        "table = client.create_table(table)  # Make an API request.\n",
        "print(\n",
        "    \"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZDqtFVE5Wd_",
        "outputId": "504a758e-6cf4-482e-a652-be46f8a36964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created table svetak-sandbox.sampledataset.entity\n",
            "Created table svetak-sandbox.sampledataset.relations\n",
            "Created table svetak-sandbox.sampledataset.entitymentions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pipeline Setup**\n",
        "\n",
        "For the purpose of experimenting, I have setup an interactiveRunner. But this should be changed to a DatafowRunner once you are comfortable with it"
      ],
      "metadata": {
        "id": "jc_iS_BP5aS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python's regular expression library\n",
        "import re\n",
        "from sys import argv\n",
        "# Beam and interactive Beam imports\n",
        "import apache_beam as beam\n",
        "from apache_beam.runners.interactive.interactive_runner import InteractiveRunner\n",
        "import apache_beam.runners.interactive.interactive_beam as ib\n",
        "\n",
        "#Reference https://cloud.google.com/dataflow/docs/guides/specifying-exec-params#python_1\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n",
        "if debug:\n",
        "    runnertype = \"InteractiveRunner\"\n",
        "else:\n",
        "    runnertype = \"DataflowRunner\"\n",
        "\n",
        "options = PipelineOptions(\n",
        "    flags=argv,\n",
        "    runner=runnertype,\n",
        "    project=PROJECT,\n",
        "    job_name=\"my-healthcare-nlp-job\",\n",
        "    temp_location=TEMP_LOCATION,\n",
        "    region=LOCATION)"
      ],
      "metadata": {
        "id": "07ct6kf55ihP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following defines a `PTransform` named `ReadLinesFromText`, that extracts lines from a file."
      ],
      "metadata": {
        "id": "dO1A9_WK5lb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReadLinesFromText(beam.PTransform):\n",
        "\n",
        "    def __init__(self, file_pattern):\n",
        "        self._file_pattern = file_pattern\n",
        "\n",
        "    def expand(self, pcoll):\n",
        "        return (pcoll.pipeline\n",
        "                | beam.io.ReadFromText(self._file_pattern))"
      ],
      "metadata": {
        "id": "t5iDRKMK5n_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following sets up an Apache Beam pipeline with the *Interactive Runner*. The *Interactive Runner* is the runner suitable for running in notebooks. A runner is an execution engine for Apache Beam pipelines."
      ],
      "metadata": {
        "id": "HI_HVB185sMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.auth import default\n",
        "\n",
        "credentials = default()"
      ],
      "metadata": {
        "id": "dMc10Dlgtp1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = beam.Pipeline(options = options)"
      ],
      "metadata": {
        "id": "7osCZ1om5ql0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following sets up a PTransform that extracts words from a Google Cloud Storage file that contains lines with each line containing a In our example, each line is a medical notes excerpt that will be passed through the Healthcare NLP API\n",
        "\n",
        "| is an overloaded operator that applies a PTransform to a PCollection to produce a new PCollection. Together with |, >> allows you to optionally name a PTransform.\n",
        "\n",
        "Usage: [PCollection] | [PTransform] or [PCollection] | [name] >> [PTransform]"
      ],
      "metadata": {
        "id": "EaF8NfC_521y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lines = p | 'read' >> ReadLinesFromText(GCS_BUCKET + \"nlpsample500.csv\")"
      ],
      "metadata": {
        "id": "2APAh6XQ6NYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if debug:\n",
        "    ib.show(lines)"
      ],
      "metadata": {
        "id": "NH_04EXw6P8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if debug:\n",
        "\n",
        "    from google.auth import compute_engine\n",
        "    credentials = compute_engine.Credentials()\n",
        "    response = {}\n",
        "    from google.auth.transport.requests import AuthorizedSession\n",
        "    authed_session = AuthorizedSession(credentials)\n",
        "\n",
        "    url = URL\n",
        "    value=\" operative suite and placed supine on the operating room table.  General endotracheal anesthesia was induced without incident.  The patient was then placed in a modified lithotomy position taking great care to pad all extremities.  TEDs and Venodynes were placed as prophylaxis against deep venous thrombosis.  Antibiotics were given for prophylaxis against surgical infection.,A 52-French bougie was placed in the proximal esophagus by Anesthesia, above the cardioesophageal junction.  A 2 cm midline incision was made at the junction of the upper two-thirds and lower one-third between the umbilicus and the xiphoid process.  The fascia was then cleared of subcutaneous tissue using a tonsil clamp.  A 1-2 cm incision was then made in the fascia gaining entry into the abdominal cavity without incident.  Two sutures of 0 Vicryl were then placed superiorly and inferiorly in the fascia, and then tied to the special 12 mm Hasson trocar fitted with a funnel-shaped adaptor in order to occlude the fascial opening.  Pneumoperitoneum was then established using carbon dioxide insufflation to a steady state of pressure of 16 mmHg.  A 30-degree laparoscope was inserted through this port and used to guide the remaining trocars.,The remaining trocars were then placed into the abdomen taking care to make the incisions along Langer's line, spreading the subcutaneous tissue with a tonsil clamp, and confirming the entry site by depressing the abdominal wall prior to insertion of the trocar.  A total of 4 other 10/11 mm trocars were placed.  Under direct vision 1 was inserted in the right upper quadrant at the midclavicular line, at a right supraumbilical position; another at the left upper quadrant at the midclavicular line, at a left supraumbilical position; 1 under the right costal margin in the anterior axillary line; and another laterally under the left costal margin on the anterior axillary line.  All of the trocars were placed without difficulty.  The patient was then placed in reverse Trendelenburg position.,The triangular ligament was taken down sharply, and the left lobe of the liver was retracted superolaterally using a fan retractor placed through the right lateral cannula.  The gastrohepatic ligament was then identified and incised in an avascular plane.  The dissection was carried anteromedially onto the phrenoesophageal membrane.  The phrenoesophageal membrane was divided on the anterior aspect of the hiatal orifice.  This incision was extended to the right to allow identification of the right crus.  Then along the inner side of the crus, the right esophageal wall was freed by dissecting the cleavage plane.,The liberation of the posterior aspect of the esophagus was started by extending the dissection the length of the right diaphragmatic crus.  The pars flaccida of the lesser omentum was opened, preserving the hepatic branches of the vagus nerve.  This allowed free access to the crura, left and right, and the right posterior aspect of the esophagus, and the posterior vagus nerve.,Attention was next turned to the left anterolateral aspect of the esophagus.  At its left border, the left crus was identified.  The dissection plane between it and the left aspect of the esophagus was freed.  The gastrophrenic ligament was incised, beginning the mobilization of the gastric pouch.  By dissecting the intramediastinal portion of the esophagus, we elongated the intra-abdominal segment of the esophagus and reduced the hiatal hernia.,The next step consisted of mobilization of the gastric pouch.  This required ligation and division of the gastrosplenic ligament and several short gastric vessels using the harmonic scalpel.  This dissection started on the stomach at the point where the vessels of the greater curvature turned towards the spleen, away from the gastroepiploic arcade.  The esophagus was lifted by a Babcock inserted through the left upper quadrant port.  Careful dissection of the mesoesophagus and the left crus revealed a cleavage plane between the crus and the posterior gastric wall.  Confirmation of having opened the correct plane was obtained by visualizing the spleen behind the esophagus.  A one-half inch Penrose drain was inserted around the esophagus and sewn to itself in order to facilitate retraction of the distal esophagus.  The retroesophageal channel was enlarged to allow easy passage of the antireflux valve.,The 52-French bougie was then carefully lowered into the proximal stomach, and the hiatal orifice was repaired.  Two interrupted 0 silk sutures were placed in the diaphragmatic crura to close the orifice.,The last part of the operation consisted of the passage and fixation of the antireflux valve.  With anterior retraction on the esophagus using the Penrose drain, a Babcock was passed behind the esophagus, from right to left.  It was used to grab the gastric pouch to the left of the esophagus and to pull it behind, forming the wrap.  The,52-French bougie was used to calibrate the external ring.  Marcaine 0.5% was injected 1 fingerbreadth anterior to the anterior superior iliac spine and around the wound for postanesthetic pain control.  The skin incision was approximated with skin staples.  A dressing was then applied.  All surgical counts were reported as correct.,Having tolerated the procedure well, the patient was subsequently taken to the recovery room in good and stable condition.\"\n",
        "\n",
        "    payload = {\n",
        "           'nlp_service': NLP_SERVICE,\n",
        "            'document_content': value\n",
        "    }\n",
        "    res = authed_session.post(url, data=payload)\n",
        "    response = res.json()\n",
        "    response['id'] = 2389\n",
        "\n",
        "    print(response)"
      ],
      "metadata": {
        "id": "L1_0oKEw6SWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InvokeNLP(beam.DoFn):\n",
        "\n",
        "    def process(self, element):\n",
        "      #  import requests\n",
        "        import uuid\n",
        "        from google.auth import compute_engine\n",
        "        credentials = compute_engine.Credentials()\n",
        "        from google.auth.transport.requests import AuthorizedSession\n",
        "        authed_session = AuthorizedSession(credentials)\n",
        "        url = URL\n",
        "        payload = {\n",
        "            'nlp_service': NLP_SERVICE,\n",
        "            'document_content': element\n",
        "        }\n",
        "        resp = authed_session.post(url, data=payload)\n",
        "        response = resp.json()\n",
        "        response['id'] = uuid.uuid4().hex[:8]\n",
        "        yield response\n",
        "\n",
        "class AnalyzeLines(beam.PTransform):\n",
        "    def expand(self, pcoll):\n",
        "        return (\n",
        "            pcoll\n",
        "            | \"Invoke NLP API\" >> beam.ParDo(InvokeNLP())\n",
        "        )"
      ],
      "metadata": {
        "id": "3ZJ-0dex9WE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from apache_beam import pvalue\n",
        "\n",
        "class getEntityMentions(beam.DoFn):\n",
        "    def process(self, element):\n",
        "        obj = {}\n",
        "        for e in element['entityMentions']:\n",
        "            e['id'] = element['id']\n",
        "            yield e\n",
        "\n",
        "class getRelationships(beam.DoFn):\n",
        "    def process(self, element):\n",
        "        obj = {}\n",
        "        id = element['id']\n",
        "        for e in element['relationships']:\n",
        "            obj = e\n",
        "            obj['id'] = id\n",
        "            yield obj\n",
        "\n",
        "class breakUpEntities(beam.DoFn):\n",
        "    def process(self, element):\n",
        "        for e in element['entities']:\n",
        "            print(e)\n",
        "            yield e"
      ],
      "metadata": {
        "id": "3KZgUv3d6haf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from apache_beam.io.gcp.internal.clients import bigquery\n",
        "\n",
        "\n",
        "table_spec = bigquery.TableReference(\n",
        "    projectId=PROJECT,\n",
        "    datasetId=DATASET,\n",
        "    tableId=TABLE_ENTITY)\n",
        "\n",
        "nlp_annotations = (lines\n",
        "                | \"Analyze\" >> AnalyzeLines()\n",
        "                  )\n"
      ],
      "metadata": {
        "id": "OkxgB2a-6iYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if debug:\n",
        "    ib.show(nlp_annotations) #, visualize_data=True)"
      ],
      "metadata": {
        "id": "zY-Nt3Y56laa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultsEntities = ( nlp_annotations\n",
        "                | \"Break\" >> beam.ParDo(breakUpEntities())\n",
        "                | \"WriteToBigQuery\" >> beam.io.WriteToBigQuery(\n",
        "                    table_spec,\n",
        "                    write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND,\n",
        "                    create_disposition=beam.io.BigQueryDisposition.CREATE_NEVER)\n",
        "                  )"
      ],
      "metadata": {
        "id": "Q9GIyLeS6oAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if debug:\n",
        "    ib.show(resultsEntities) #, visualize_data=True)"
      ],
      "metadata": {
        "id": "HM93OqSR6qbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_spec = bigquery.TableReference(\n",
        "    projectId=PROJECT,\n",
        "    datasetId=DATASET,\n",
        "    tableId=TABLE_REL)\n",
        "\n",
        "resultsRelationships = ( nlp_annotations\n",
        "                | \"GetRelationships\" >>  beam.ParDo(getRelationships())\n",
        "                | \"WriteToBigQuery\" >> beam.io.WriteToBigQuery(\n",
        "                    table_spec,\n",
        "                    write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND,\n",
        "                    create_disposition=beam.io.BigQueryDisposition.CREATE_NEVER)\n",
        "                  )"
      ],
      "metadata": {
        "id": "yOlHfkcT6s4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if debug:\n",
        "    ib.show(resultsRelationships) #, visualize_data=True)"
      ],
      "metadata": {
        "id": "mnkAtG3C9v9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_spec = bigquery.TableReference(\n",
        "    projectId=PROJECT,\n",
        "    datasetId=DATASET,\n",
        "    tableId=TABLE_ENTITYMENTIONS)\n",
        "\n",
        "resultsEntityMentions = ( nlp_annotations\n",
        "                | \"GetEntityMentions\" >> beam.ParDo(getEntityMentions())\n",
        "                | \"WriteToBigQuery\" >> beam.io.WriteToBigQuery(\n",
        "                    table_spec,\n",
        "                    write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND,\n",
        "                    create_disposition=beam.io.BigQueryDisposition.CREATE_NEVER)\n",
        "                  )"
      ],
      "metadata": {
        "id": "a6QxxnY890Za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if debug:\n",
        "    ib.show(resultsEntityMentions) #, visualize_data=True)"
      ],
      "metadata": {
        "id": "EySPNe-Q6vs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see the job graph for the pipeline by doing:"
      ],
      "metadata": {
        "id": "6rP2nO6Z60bt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ib.show_graph(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        },
        "id": "zQB5h1Zq6x8d",
        "outputId": "47a9d094-0e81-4ee8-c177-f5786cd7beea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <link rel=\"stylesheet\" href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css\" integrity=\"sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh\" crossorigin=\"anonymous\">\n",
              "            <div id=\"progress_indicator_c30a8fa9b3a0950abfbf3cabd172740a\">\n",
              "              <div class=\"spinner-border text-info\" role=\"status\"></div>\n",
              "              <span class=\"text-info\">Processing... show_graph</span>\n",
              "            </div>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
              "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
              " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
              "<!-- Generated by graphviz version 2.43.0 (0)\n",
              " -->\n",
              "<!-- Title: G Pages: 1 -->\n",
              "<svg width=\"481pt\" height=\"592pt\"\n",
              " viewBox=\"0.00 0.00 480.50 592.48\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
              "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 588.48)\">\n",
              "<title>G</title>\n",
              "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-588.48 476.5,-588.48 476.5,4 -4,4\"/>\n",
              "<!-- [31]: read -->\n",
              "<g id=\"node1\" class=\"node\">\n",
              "<title>[31]: read</title>\n",
              "<polygon fill=\"none\" stroke=\"blue\" points=\"180,-584.48 110,-584.48 110,-548.48 180,-548.48 180,-584.48\"/>\n",
              "<text text-anchor=\"middle\" x=\"145\" y=\"-562.78\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"blue\">[31]: read</text>\n",
              "</g>\n",
              "<!-- [32]: read -->\n",
              "<g id=\"node2\" class=\"node\">\n",
              "<title>[32]: read</title>\n",
              "<polygon fill=\"none\" stroke=\"blue\" points=\"268,-584.48 198,-584.48 198,-548.48 268,-548.48 268,-584.48\"/>\n",
              "<text text-anchor=\"middle\" x=\"233\" y=\"-562.78\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"blue\">[32]: read</text>\n",
              "</g>\n",
              "<!-- lines -->\n",
              "<g id=\"node3\" class=\"node\">\n",
              "<title>lines</title>\n",
              "<ellipse fill=\"none\" stroke=\"blue\" cx=\"233\" cy=\"-485.19\" rx=\"27.1\" ry=\"27.1\"/>\n",
              "<text text-anchor=\"middle\" x=\"233\" y=\"-481.49\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"blue\">lines</text>\n",
              "</g>\n",
              "<!-- [32]: read&#45;&gt;lines -->\n",
              "<g id=\"edge1\" class=\"edge\">\n",
              "<title>[32]: read&#45;&gt;lines</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M233,-548.28C233,-540.81 233,-531.77 233,-522.91\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"236.5,-522.72 233,-512.72 229.5,-522.72 236.5,-522.72\"/>\n",
              "</g>\n",
              "<!-- [37]: Analyze -->\n",
              "<g id=\"node4\" class=\"node\">\n",
              "<title>[37]: Analyze</title>\n",
              "<polygon fill=\"none\" stroke=\"blue\" points=\"278.5,-421.89 187.5,-421.89 187.5,-385.89 278.5,-385.89 278.5,-421.89\"/>\n",
              "<text text-anchor=\"middle\" x=\"233\" y=\"-400.19\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"blue\">[37]: Analyze</text>\n",
              "</g>\n",
              "<!-- lines&#45;&gt;[37]: Analyze -->\n",
              "<g id=\"edge2\" class=\"edge\">\n",
              "<title>lines&#45;&gt;[37]: Analyze</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M233,-457.78C233,-449.64 233,-440.65 233,-432.43\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"236.5,-432.2 233,-422.2 229.5,-432.2 236.5,-432.2\"/>\n",
              "</g>\n",
              "<!-- nlp_annotations -->\n",
              "<g id=\"node5\" class=\"node\">\n",
              "<title>nlp_annotations</title>\n",
              "<ellipse fill=\"none\" stroke=\"blue\" cx=\"233\" cy=\"-282.94\" rx=\"66.89\" ry=\"66.89\"/>\n",
              "<text text-anchor=\"middle\" x=\"233\" y=\"-279.24\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"blue\">nlp_annotations</text>\n",
              "</g>\n",
              "<!-- [37]: Analyze&#45;&gt;nlp_annotations -->\n",
              "<g id=\"edge3\" class=\"edge\">\n",
              "<title>[37]: Analyze&#45;&gt;nlp_annotations</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M233,-385.85C233,-378.65 233,-369.72 233,-360.16\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"236.5,-360.02 233,-350.02 229.5,-360.02 236.5,-360.02\"/>\n",
              "</g>\n",
              "<!-- [39]: Break -->\n",
              "<g id=\"node6\" class=\"node\">\n",
              "<title>[39]: Break</title>\n",
              "<polygon fill=\"none\" stroke=\"blue\" points=\"136.5,-180 57.5,-180 57.5,-144 136.5,-144 136.5,-180\"/>\n",
              "<text text-anchor=\"middle\" x=\"97\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"blue\">[39]: Break</text>\n",
              "</g>\n",
              "<!-- nlp_annotations&#45;&gt;[39]: Break -->\n",
              "<g id=\"edge4\" class=\"edge\">\n",
              "<title>nlp_annotations&#45;&gt;[39]: Break</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M182.75,-237.99C162.98,-220.7 141.06,-201.53 124.33,-186.9\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"126.4,-184.06 116.57,-180.11 121.79,-189.33 126.4,-184.06\"/>\n",
              "</g>\n",
              "<!-- [41]: GetRelationships -->\n",
              "<g id=\"node9\" class=\"node\">\n",
              "<title>[41]: GetRelationships</title>\n",
              "<polygon fill=\"none\" stroke=\"blue\" points=\"303,-180 163,-180 163,-144 303,-144 303,-180\"/>\n",
              "<text text-anchor=\"middle\" x=\"233\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"blue\">[41]: GetRelationships</text>\n",
              "</g>\n",
              "<!-- nlp_annotations&#45;&gt;[41]: GetRelationships -->\n",
              "<g id=\"edge5\" class=\"edge\">\n",
              "<title>nlp_annotations&#45;&gt;[41]: GetRelationships</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M233,-215.86C233,-206.85 233,-198.04 233,-190.28\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"236.5,-190.09 233,-180.09 229.5,-190.09 236.5,-190.09\"/>\n",
              "</g>\n",
              "<!-- [42]: GetEntityMentions -->\n",
              "<g id=\"node12\" class=\"node\">\n",
              "<title>[42]: GetEntityMentions</title>\n",
              "<polygon fill=\"none\" stroke=\"blue\" points=\"472.5,-180 321.5,-180 321.5,-144 472.5,-144 472.5,-180\"/>\n",
              "<text text-anchor=\"middle\" x=\"397\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"blue\">[42]: GetEntityMentions</text>\n",
              "</g>\n",
              "<!-- nlp_annotations&#45;&gt;[42]: GetEntityMentions -->\n",
              "<g id=\"edge6\" class=\"edge\">\n",
              "<title>nlp_annotations&#45;&gt;[42]: GetEntityMentions</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M287.15,-242.67C312.85,-224.03 342.69,-202.39 364.78,-186.37\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"367.1,-189.01 373.14,-180.31 362.99,-183.35 367.1,-189.01\"/>\n",
              "</g>\n",
              "<!-- pcoll6587 -->\n",
              "<g id=\"node7\" class=\"node\">\n",
              "<title>pcoll6587</title>\n",
              "<ellipse fill=\"none\" stroke=\"blue\" cx=\"81\" cy=\"-90\" rx=\"18\" ry=\"18\"/>\n",
              "</g>\n",
              "<!-- [39]: Break&#45;&gt;pcoll6587 -->\n",
              "<g id=\"edge7\" class=\"edge\">\n",
              "<title>[39]: Break&#45;&gt;pcoll6587</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M93.04,-143.7C91.24,-135.78 89.05,-126.23 87.04,-117.44\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"90.44,-116.59 84.8,-107.62 83.62,-118.15 90.44,-116.59\"/>\n",
              "</g>\n",
              "<!-- [39]: WriteToBigQuery -->\n",
              "<g id=\"node8\" class=\"node\">\n",
              "<title>[39]: WriteToBigQuery</title>\n",
              "<polygon fill=\"none\" stroke=\"blue\" points=\"144,-36 0,-36 0,0 144,0 144,-36\"/>\n",
              "<text text-anchor=\"middle\" x=\"72\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"blue\">[39]: WriteToBigQuery</text>\n",
              "</g>\n",
              "<!-- pcoll6587&#45;&gt;[39]: WriteToBigQuery -->\n",
              "<g id=\"edge8\" class=\"edge\">\n",
              "<title>pcoll6587&#45;&gt;[39]: WriteToBigQuery</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M78.82,-72.05C77.83,-64.35 76.63,-55.03 75.52,-46.36\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"78.97,-45.75 74.22,-36.28 72.02,-46.64 78.97,-45.75\"/>\n",
              "</g>\n",
              "<!-- pcoll6743 -->\n",
              "<g id=\"node10\" class=\"node\">\n",
              "<title>pcoll6743</title>\n",
              "<ellipse fill=\"none\" stroke=\"blue\" cx=\"233\" cy=\"-90\" rx=\"18\" ry=\"18\"/>\n",
              "</g>\n",
              "<!-- [41]: GetRelationships&#45;&gt;pcoll6743 -->\n",
              "<g id=\"edge9\" class=\"edge\">\n",
              "<title>[41]: GetRelationships&#45;&gt;pcoll6743</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M233,-143.7C233,-135.98 233,-126.71 233,-118.11\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"236.5,-118.1 233,-108.1 229.5,-118.1 236.5,-118.1\"/>\n",
              "</g>\n",
              "<!-- [41]: WriteToBigQuery -->\n",
              "<g id=\"node11\" class=\"node\">\n",
              "<title>[41]: WriteToBigQuery</title>\n",
              "<polygon fill=\"none\" stroke=\"blue\" points=\"306,-36 162,-36 162,0 306,0 306,-36\"/>\n",
              "<text text-anchor=\"middle\" x=\"234\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"blue\">[41]: WriteToBigQuery</text>\n",
              "</g>\n",
              "<!-- pcoll6743&#45;&gt;[41]: WriteToBigQuery -->\n",
              "<g id=\"edge10\" class=\"edge\">\n",
              "<title>pcoll6743&#45;&gt;[41]: WriteToBigQuery</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M233.25,-71.7C233.36,-63.98 233.49,-54.71 233.61,-46.11\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"237.11,-46.15 233.76,-36.1 230.11,-46.05 237.11,-46.15\"/>\n",
              "</g>\n",
              "<!-- pcoll1676 -->\n",
              "<g id=\"node13\" class=\"node\">\n",
              "<title>pcoll1676</title>\n",
              "<ellipse fill=\"none\" stroke=\"blue\" cx=\"397\" cy=\"-90\" rx=\"18\" ry=\"18\"/>\n",
              "</g>\n",
              "<!-- [42]: GetEntityMentions&#45;&gt;pcoll1676 -->\n",
              "<g id=\"edge11\" class=\"edge\">\n",
              "<title>[42]: GetEntityMentions&#45;&gt;pcoll1676</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M397,-143.7C397,-135.98 397,-126.71 397,-118.11\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"400.5,-118.1 397,-108.1 393.5,-118.1 400.5,-118.1\"/>\n",
              "</g>\n",
              "<!-- [42]: WriteToBigQuery -->\n",
              "<g id=\"node14\" class=\"node\">\n",
              "<title>[42]: WriteToBigQuery</title>\n",
              "<polygon fill=\"none\" stroke=\"blue\" points=\"469,-36 325,-36 325,0 469,0 469,-36\"/>\n",
              "<text text-anchor=\"middle\" x=\"397\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"blue\">[42]: WriteToBigQuery</text>\n",
              "</g>\n",
              "<!-- pcoll1676&#45;&gt;[42]: WriteToBigQuery -->\n",
              "<g id=\"edge12\" class=\"edge\">\n",
              "<title>pcoll1676&#45;&gt;[42]: WriteToBigQuery</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M397,-71.7C397,-63.98 397,-54.71 397,-46.11\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"400.5,-46.1 397,-36.1 393.5,-46.1 400.5,-46.1\"/>\n",
              "</g>\n",
              "</g>\n",
              "</svg>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "            $(\"#progress_indicator_c30a8fa9b3a0950abfbf3cabd172740a\").remove();\n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "            $(\"#progress_indicator_c30a8fa9b3a0950abfbf3cabd172740a\").remove();\n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = p.run()\n",
        "result.wait_until_finish()"
      ],
      "metadata": {
        "id": "_nbRHLhZ2Cb7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}