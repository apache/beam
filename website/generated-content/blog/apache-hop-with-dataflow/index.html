<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>Running Apache Hop visual pipelines with Google Cloud Dataflow</title><meta name=description content="Apache Beam is an open source, unified model and set of language-specific SDKs for defining and executing data processing workflows, and also data ingestion and integration flows, supporting Enterprise Integration Patterns (EIPs) and Domain Specific Languages (DSLs). Dataflow pipelines simplify the mechanics of large-scale batch and streaming data processing and can run on a number of runtimes like Apache Flink, Apache Spark, and Google Cloud Dataflow (a cloud service). Beam also brings DSL in different languages, allowing users to easily implement their data integration processes."><link href="https://fonts.googleapis.com/css?family=Roboto:100,300,400,500,700" rel=stylesheet><link rel=preload href=/scss/main.min.408fddfe3e8a45f87a5a8c9a839d77db667c1c534e5e5cd0d957ffc3dd6c14cf.css as=style><link href=/scss/main.min.408fddfe3e8a45f87a5a8c9a839d77db667c1c534e5e5cd0d957ffc3dd6c14cf.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-2.2.4.min.js></script><style>.body__contained img{max-width:100%}</style><script type=text/javascript src=/js/bootstrap.min.2979f9a6e32fc42c3e7406339ee9fe76b31d1b52059776a02b4a7fa6a4fd280a.js defer></script>
<script type=text/javascript src=/js/language-switch-v2.min.121952b7980b920320ab229551857669209945e39b05ba2b433a565385ca44c6.js defer></script>
<script type=text/javascript src=/js/fix-menu.min.039174b67107465f2090a493f91e126f7aa797f29420f9edab8a54d9dd4b3d2d.js defer></script>
<script type=text/javascript src=/js/section-nav.min.1405fd5e70fab5f6c54037c269b1d137487d8f3d1b3009032525f6db3fbce991.js defer></script>
<script type=text/javascript src=/js/page-nav.min.af231204c9c52c5089d53a4c02739eacbb7f939e3be1c6ffcc212e0ac4dbf879.js defer></script>
<script type=text/javascript src=/js/expandable-list.min.75a4526624a3b8898fe7fb9e3428c205b581f8b38c7926922467aef17eac69f2.js defer></script>
<script type=text/javascript src=/js/copy-to-clipboard.min.364c06423d7e8993fc42bb4abc38c03195bc8386db26d18774ce775d08d5b18d.js defer></script>
<script type=text/javascript src=/js/calendar.min.336664054fa0f52b08bbd4e3c59b5cb6d63dcfb2b4d602839746516b0817446b.js defer></script>
<script type=text/javascript src=/js/fix-playground-nested-scroll.min.0283f1037cb1b9d5074c6eaf041292b524a8148a7cdb803d5ccd6d1fc4eb3253.js defer></script>
<script type=text/javascript src=/js/anchor-content-jump-fix.min.22d3240f81632e4c11179b9d2aaf37a40da9414333c43aa97344e8b21a7df0e4.js defer></script>
<link rel=alternate type=application/rss+xml title="Apache Beam" href=/feed.xml><link rel=canonical href=/blog/apache-hop-with-dataflow/ data-proofer-ignore><link rel="shortcut icon" type=image/x-icon href=/images/favicon.ico><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.4.1/css/all.css integrity=sha384-5sAR7xN1Nv6T6+dT2mhtzEpVJvfS3NScPQTrOxhwjIuvcA67KV2R5Jz6kr4abQsz crossorigin=anonymous><link rel=stylesheet href=https://unpkg.com/swiper@8/swiper-bundle.min.css><script async src=https://platform.twitter.com/widgets.js></script>
<script>(function(e,t,n,s,o,i){e.hj=e.hj||function(){(e.hj.q=e.hj.q||[]).push(arguments)},e._hjSettings={hjid:2182187,hjsv:6},o=t.getElementsByTagName("head")[0],i=t.createElement("script"),i.async=1,i.src=n+e._hjSettings.hjid+s+e._hjSettings.hjsv,o.appendChild(i)})(window,document,"https://static.hotjar.com/c/hotjar-",".js?sv=")</script></head><body class=body><nav class="navigation-bar-mobile header navbar navbar-fixed-top"><div class=navbar-header><a href=/ class=navbar-brand><img alt=Brand style=height:46px;width:43px src=/images/beam_logo_navbar_mobile.png></a>
<a class=navbar-link href=/get-started/>Get Started</a>
<a class=navbar-link href=/documentation/>Documentation</a>
<button type=button class="navbar-toggle menu-open" aria-expanded=false aria-controls=navbar onclick=openMenu()>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button></div><div class="navbar-mask closed"></div><div id=navbar class="navbar-container closed"><button type=button class=navbar-toggle aria-expanded=false aria-controls=navbar id=closeMenu>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button><ul class="nav navbar-nav"><li><div class=searchBar-mobile><script>(function(){var t,n="012923275103528129024:4emlchv9wzi",e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src="https://cse.google.com/cse.js?cx="+n,t=document.getElementsByTagName("script")[0],t.parentNode.insertBefore(e,t)})()</script><gcse:search></gcse:search></div></li><li><a class=navbar-link href=/about>About</a></li><li><a class=navbar-link href=/get-started/>Get Started</a></li><li><span class=navbar-link>Documentation</span><ul><li><a href=/documentation/>General</a></li><li><a href=/documentation/sdks/java/>Languages</a></li><li><a href=/documentation/runners/capability-matrix/>Runners</a></li><li><a href=/documentation/io/connectors/>I/O Connectors</a></li></ul></li><li><a class=navbar-link href=/roadmap/>Roadmap</a></li><li><a class=navbar-link href=/community/>Community</a></li><li><a class=navbar-link href=/contribute/>Contribute</a></li><li><a class=navbar-link href=/blog/>Blog</a></li><li><a class=navbar-link href=/case-studies/>Case Studies</a></li></ul><ul class="nav navbar-nav navbar-right"><li><a href=https://github.com/apache/beam/edit/master/website/www/site/content/en/blog/apache-hop-with-dataflow.md data-proofer-ignore><svg xmlns="http://www.w3.org/2000/svg" width="25" height="24" fill="none" viewBox="0 0 25 24"><path stroke="#ff6d00" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.75" d="M4.543 20h4l10.5-10.5c.53-.53.828-1.25.828-2s-.298-1.47-.828-2-1.25-.828-2-.828-1.47.298-2 .828L4.543 16v4zm9.5-13.5 4 4"/></svg></a></li><li class=dropdown><a href=# class=dropdown-toggle id=apache-dropdown data-toggle=dropdown role=button aria-haspopup=true aria-expanded=false><img src=https://www.apache.org/foundation/press/kit/feather_small.png alt="Apache Logo" style=height:20px>
&nbsp;Apache
<span class=arrow-icon><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="none" viewBox="0 0 20 20"><circle cx="10" cy="10" r="10" fill="#ff6d00"/><path stroke="#fff" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8.535 5.28l4.573 4.818-4.573 4.403"/></svg></span></a><ul class="dropdown-menu dropdown-menu-right"><li><a target=_blank href=https://www.apache.org/>ASF Homepage</a></li><li><a target=_blank href=https://www.apache.org/licenses/>License</a></li><li><a target=_blank href=https://www.apache.org/security/>Security</a></li><li><a target=_blank href=https://www.apache.org/foundation/thanks.html>Thanks</a></li><li><a target=_blank href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a></li><li><a target=_blank href=https://www.apache.org/foundation/policies/conduct>Code of Conduct</a></li></ul></li></ul></div></nav><nav class=navigation-bar-desktop><a href=/ class=navbar-logo><img src=/images/beam_logo_navbar.png alt="Beam Logo"></a><div class=navbar-bar-left><div class=navbar-links><a class=navbar-link href=/about>About</a>
<a class=navbar-link href=/get-started/>Get Started</a><li class="dropdown navbar-dropdown navbar-dropdown-documentation"><a href=# class="dropdown-toggle navbar-link" role=button aria-haspopup=true aria-expanded=false>Documentation
<span><svg xmlns="http://www.w3.org/2000/svg" width="12" height="11" fill="none" viewBox="0 0 12 11"><path stroke="#ff6d00" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10.666 4.535 5.847 9.108 1.444 4.535"/></svg></span></a><ul class=dropdown-menu><li><a class=navbar-dropdown-menu-link href=/documentation/>General</a></li><li><a class=navbar-dropdown-menu-link href=/documentation/sdks/java/>Languages</a></li><li><a class=navbar-dropdown-menu-link href=/documentation/runners/capability-matrix/>Runners</a></li><li><a class=navbar-dropdown-menu-link href=/documentation/io/connectors/>I/O Connectors</a></li></ul></li><a class=navbar-link href=/roadmap/>Roadmap</a>
<a class=navbar-link href=/community/>Community</a>
<a class=navbar-link href=/contribute/>Contribute</a>
<a class=navbar-link href=/blog/>Blog</a>
<a class=navbar-link href=/case-studies/>Case Studies</a></div><div id=iconsBar><a type=button onclick=showSearch()><svg xmlns="http://www.w3.org/2000/svg" width="25" height="24" fill="none" viewBox="0 0 25 24"><path stroke="#ff6d00" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.75" d="M10.191 17c3.866.0 7-3.134 7-7s-3.134-7-7-7-7 3.134-7 7 3.134 7 7 7zm11 4-6-6"/></svg></a><a target=_blank href=https://github.com/apache/beam/edit/master/website/www/site/content/en/blog/apache-hop-with-dataflow.md data-proofer-ignore><svg xmlns="http://www.w3.org/2000/svg" width="25" height="24" fill="none" viewBox="0 0 25 24"><path stroke="#ff6d00" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.75" d="M4.543 20h4l10.5-10.5c.53-.53.828-1.25.828-2s-.298-1.47-.828-2-1.25-.828-2-.828-1.47.298-2 .828L4.543 16v4zm9.5-13.5 4 4"/></svg></a><li class="dropdown navbar-dropdown navbar-dropdown-apache"><a href=# class=dropdown-toggle role=button aria-haspopup=true aria-expanded=false><img src=https://www.apache.org/foundation/press/kit/feather_small.png alt="Apache Logo" style=height:20px>
&nbsp;Apache
<span class=arrow-icon><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="none" viewBox="0 0 20 20"><circle cx="10" cy="10" r="10" fill="#ff6d00"/><path stroke="#fff" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8.535 5.28l4.573 4.818-4.573 4.403"/></svg></span></a><ul class=dropdown-menu><li><a class=navbar-dropdown-menu-link target=_blank href=https://www.apache.org/>ASF Homepage</a></li><li><a class=navbar-dropdown-menu-link target=_blank href=https://www.apache.org/licenses/>License</a></li><li><a class=navbar-dropdown-menu-link target=_blank href=https://www.apache.org/security/>Security</a></li><li><a class=navbar-dropdown-menu-link target=_blank href=https://www.apache.org/foundation/thanks.html>Thanks</a></li><li><a class=navbar-dropdown-menu-link target=_blank href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a></li><li><a class=navbar-dropdown-menu-link target=_blank href=https://www.apache.org/foundation/policies/conduct>Code of Conduct</a></li></ul></li></div><div class="searchBar disappear"><script>(function(){var t,n="012923275103528129024:4emlchv9wzi",e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src="https://cse.google.com/cse.js?cx="+n,t=document.getElementsByTagName("script")[0],t.parentNode.insertBefore(e,t)})()</script><gcse:search></gcse:search>
<a type=button onclick=endSearch()><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25"><path stroke="#ff6d00" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.75" d="M21.122 20.827 4.727 4.432M21.122 4.43 4.727 20.827"/></svg></a></div></div></nav><div class=header-push></div><div class="top-banners swiper"><div class=swiper-wrapper><div class=swiper-slide><a href=https://tour.beam.apache.org><img class=banner-img-desktop src=/images/banners/tour-of-beam/tour-of-beam-desktop.png alt="Start Tour of Beam">
<img class=banner-img-mobile src=/images/banners/tour-of-beam/tour-of-beam-mobile.png alt="Start Tour of Beam"></a></div><div class=swiper-slide><a href=https://beam.apache.org/documentation/ml/overview/><img class=banner-img-desktop src=/images/banners/machine-learning/machine-learning-desktop.jpg alt="Machine Learning">
<img class=banner-img-mobile src=/images/banners/machine-learning/machine-learning-mobile.jpg alt="Machine Learning"></a></div></div><div class=swiper-pagination></div><div class=swiper-button-prev></div><div class=swiper-button-next></div></div><script src=/js/swiper-bundle.min.min.e0e8f81b0b15728d35ff73c07f42ddbb17a108d6f23df4953cb3e60df7ade675.js></script>
<script src=/js/sliders/top-banners.min.afa7d0a19acf7a3b28ca369490b3d401a619562a2a4c9612577be2f66a4b9855.js></script>
<script>function showSearch(){addPlaceholder();var e,t=document.querySelector(".searchBar");t.classList.remove("disappear"),e=document.querySelector("#iconsBar"),e.classList.add("disappear")}function addPlaceholder(){$("input:text").attr("placeholder","What are you looking for?")}function endSearch(){var e,t=document.querySelector(".searchBar");t.classList.add("disappear"),e=document.querySelector("#iconsBar"),e.classList.remove("disappear")}function blockScroll(){$("body").toggleClass("fixedPosition")}function openMenu(){addPlaceholder(),blockScroll()}</script><div class="body__contained center no__padding content-up"><article class=post itemscope itemtype=http://schema.org/BlogPosting><div class=post-content><div class=post-info><p>blog</p><p>2022/04/22</p></div><header class=post-header><h2 itemprop="name headline">Running Apache Hop visual pipelines with Google Cloud Dataflow</h1><div class=post-info><span>Israel Herraiz [<a href=https://twitter.com/herraiz>@herraiz</a>]</span></div></header><div class="arrow-list header-top-margin" itemprop=articleBody><h2 id=intro>Intro</h2><p>Apache Hop (<a href=https://hop.apache.org/>https://hop.apache.org/</a>) is a visual development environment for creating data pipelines using Apache Beam. You can run your Hop pipelines in Spark, Flink or Google Cloud Dataflow.</p><p>In this post, we will see how to install Hop, and we will run a sample pipeline in the cloud with Dataflow. To follow the steps given in this post, you should have a project in Google Cloud Platform, and you should have enough permissions to create a Google Cloud Storage bucket (or to use an existing one), as well as to run Dataflow jobs.</p><p>Once you have your Google Cloud project ready, you will need to <a href=https://cloud.google.com/sdk/docs/install>install the Google Cloud SDK</a> to trigger the Dataflow pipeline.</p><p>Also, don&rsquo;t forget to configure the Google Cloud SDK to use your account and your project.</p><h2 id=setup-and-local-execution>Setup and local execution</h2><p>You can run Apache Hop as a local application, or use <a href=https://hop.incubator.apache.org/manual/latest/hop-gui/hop-web.html>the Hop web version</a> from a Docker container. The instructions given in this post will work for the local application, as the authentication for Cloud Dataflow would be different if Hop is running in a container. All the rest of the instructions remain valid. The UI of Hop is exactly the same either running as a local app or in the web version.</p><p>Now it&rsquo;s time to download and install Apache Hop, following these <a href=https://hop.apache.org/manual/latest/getting-started/hop-download-install.html>instructions</a>.</p><p>For this post, I have used the binaries in the apache-hop-client package, version 1.2.0, released on March 7th, 2022.</p><p>After installing Hop, we are ready to start.</p><p>The Zip file contains a directory <code>config</code> where you will find some sample projects and some pipeline run configuration for Dataflow and other runners.</p><p>For this example, we are going to use the pipeline located in <code>config/projects/samples/beam/pipelines/input-process-output.hpl.</code></p><p>Let&rsquo;s start by opening Apache Hop. In the directory where you have unzipped the client, run</p><p><code>./hop/hop-gui.sh</code></p><p>(or <code>./hop/hop-gui.bat</code> if you are on Windows).</p><p>Once we are in Hop, let&rsquo;s open the pipeline.</p><p>We first switch from the project <code>default</code> to the project <code>samples</code>. Locate the <code>projects</code> box in the top left corner of the window, and select the project <code>samples</code>:</p><p><img class=center-block src=/images/blog/apache-hop/image18.png alt="Apache Hop projects"></p><p>Now we click the open button:</p><p><img class=center-block src=/images/blog/apache-hop/image4.png alt="Apache Hop open project"></p><p>Select the pipeline <code>input-process-output.hpl</code> in the <code>beam/pipelines</code> subdirectory:</p><p><img class=center-block src=/images/blog/apache-hop/image12.png alt="Apache Hop select pipeline"></p><p>You should see a graph like the following in the main window of Hop:</p><p><img class=center-block src=/images/blog/apache-hop/image17.png alt="Apache Hop main window"></p><p>This pipeline takes some customer data from a CSV file and filters out everything but the records with the column <code>stateCode</code> equal to <code>CA.</code></p><p>Then we select only some of the columns of the file, and the result is written to Google Cloud Storage.</p><p>It is always a good idea to test the pipeline locally before submitting it to Dataflow. In Apache Hop, you can preview the output of each transform. Let&rsquo;s have a look at the input <code>Customers</code>.</p><p>Click in the <code>Customers</code> input transform and then in <em>Preview Output</em> in the dialog box that opens after selecting the transform:</p><p><img class=center-block src=/images/blog/apache-hop/image10.png alt="Apache Hop Customers preview"></p><p>Now select the option <em>Quick launch</em> and you will see some of the input data:</p><p><img class=center-block src=/images/blog/apache-hop/image24.png alt="Apache Hop input data"></p><p>Click <em>Stop</em> when you finish reviewing the data.</p><p>If we repeat the process right after the <code>Only CA</code> transform, we will see that all the rows have the <code>stateCode</code> column equal to <code>CA</code>.</p><p>The next transform selects only some of the columns of the input data and reorders the columns. Let&rsquo;s have a look. Click the transform and then <em>Preview Output</em>:</p><p><img class=center-block src=/images/blog/apache-hop/image15.png alt="Apache Hop preview output"></p><p>Then click _Quick Launch _again, and you should see output like the following:</p><p><img class=center-block src=/images/blog/apache-hop/image8.png alt="Apache Hop output"></p><p>The column <code>id</code> is now the first, and we see only a subset of the input columns. This is how the data will look once the pipeline finishes writing the full output.</p><h2 id=using-the-beam-direct-runner>Using the Beam Direct Runner</h2><p>Let&rsquo;s run the pipeline. To run the pipeline, we need to specify a runner configuration. This is done through the Metadata tool of Apache Hop:</p><p><img class=center-block src=/images/blog/apache-hop/image6.png alt="Apache Hop runner configuration"></p><p>In the <code>samples</code> project, there are already several configurations created:</p><p><img class=center-block src=/images/blog/apache-hop/image9.png alt="Apache Hop configurations"></p><p>The <code>local</code> configuration is the one used to run the pipeline using Hop. For instance, this is the configuration that we used when we examined the previews of the output of different steps.</p><p>The <code>Direct</code> configuration uses the direct runner of Apache Beam. Let&rsquo;s examine what it looks like. There are two tabs in the Pipeline Run Configurations: main and variables.</p><p>For the direct runner, the main tab has the following options:</p><p><img class=center-block src=/images/blog/apache-hop/image28.png alt="Apache Hop direct runner"></p><p>We can change the number of workers settings to match our number of CPUs, or even limit it just to 1 so the pipeline does not consume a lot of resources.</p><p>In the variables tab, we find the configuration parameters for the pipeline itself (not for the runner): \</p><p><img class=center-block src=/images/blog/apache-hop/image14.png alt="Apache Hop variables tab"></p><p>For this pipeline, only the <code>DATA_INPUT</code> and <code>DATA_OUTPUT</code> variables are used. The <code>STATE_INPUT</code> is used in a different example.</p><p>If you go to the Beam transforms in the input and output nodes of the pipeline, you will see how these variables are used there:</p><p><img class=center-block src=/images/blog/apache-hop/image29.png alt="Apache Hop variables"></p><p><img class=center-block src=/images/blog/apache-hop/image11.png alt="Apache Hop variables"></p><p>Since those variables are correctly set up to point to the location of data in the samples project folder, let&rsquo;s try to run the pipeline using the Beam Direct Runner.</p><p>For that, we need to go back to the pipeline view (arrow button just above the Metadata tool), and click the run button (the small &ldquo;play&rdquo; button in the toolbar). Then choose the Direct pipeline run configuration, and click the <em>Launch</em> button:</p><p><img class=center-block src=/images/blog/apache-hop/image20.png alt="Apache Hop launch"></p><p>How do you know if the job has finished or not? You can check the logs at the bottom of the main window for that. You should see something like this:</p><p><img class=center-block src=/images/blog/apache-hop/image19.png alt="Apache Hop completed job"></p><p>If we go to the location set by <code>DATA_OUTPUT</code>, in our case <code>config/projects/samples/beam/output</code>, we should see some output files there. In my case, I see these files:</p><p><img class=center-block src=/images/blog/apache-hop/image26.png alt="Apache Hop output files"></p><p>The number of files depends on the number of workers that you have set in the run configuration.</p><p>Great, so the pipeline works locally. It is time to run it in the cloud!</p><h2 id=running-at-cloud-scale-with-dataflow>Running at cloud scale with Dataflow</h2><p>Let&rsquo;s have a look at the Dataflow Pipeline Run Configuration. Go to the metadata tool, then to Pipeline Run Configuration and select Dataflow:</p><p><img class=center-block src=/images/blog/apache-hop/image30.png alt="Apache Hop Pipeline Run Configuration"></p><p>We have again the Main and the Variables tab. We will need to change some values in both. Let&rsquo;s start with the Variables. Click the Variables tab, and you should see the following values:</p><p><img class=center-block src=/images/blog/apache-hop/image3.png alt="Apache Hop Variables tab"></p><p>Those are Google Cloud Storage (GCS) locations that belong to the author of that sample project. We need to change them to point to our own GCS bucket.</p><h2 id=project-setup-in-google-cloud>Project setup in Google Cloud</h2><p>But for that, we will have to create a bucket. For the next step, you need to make sure that you have configured gcloud (the Google Cloud SDK), and that you have managed to authenticate.</p><p>To double check, run the command <code>gcloud config list</code> and check if the account and the project look correct. If they do, let&rsquo;s triple check and run <code>gcloud auth login</code>. That should open a tab in your web browser, to do the authentication process. Once you have done that, you can interact with your project using the SDK.</p><p>For this example, I will use the region europe-west1 of GCP. Let&rsquo;s create a regional bucket there. In my case, I am using the name <code>ihr-apache-hop-blog</code> for the bucket name. Choose a different name for your bucket!</p><pre tabindex=0><code>gsutil mb -c regional -l europe-west1 gs://ihr-apache-hop-blog
</code></pre><p>Now let&rsquo;s upload the sample data to the GCS bucket, to test how the pipeline would run in Dataflow. Go to the same directory where you have all the hop files (the same directory that <code>hop-gui.sh</code> is in), and let&rsquo;s copy the data to GCS:</p><pre tabindex=0><code> gsutil cp config/projects/samples/beam/input/customers-noheader-1k.txt gs://ihr-apache-hop-blog/data/
</code></pre><p>Notice the final slash <code>/</code> in the path, indicating that you want to create a directory of name <code>data</code>, with all the contents.</p><p>To make sure that you have uploaded the data correctly, check the contents of that location:</p><pre tabindex=0><code>gsutil ls gs://ihr-apache-hop-blog/data/
</code></pre><p>You should see the file <code>customer-noheader-1k.txt</code> in that location.</p><p>Before we continue, make sure that Dataflow is enabled in your project, and that you have a service account ready to be used with Hop. Please check the instructions given at the documentation of Dataflow, in the <em><a href=https://cloud.google.com/dataflow/docs/quickstarts/create-pipeline-java#before-you-begin>Before you begin section</a></em> to see how to enable the API for Dataflow.</p><p>Now we need to make sure that Hop can use the necessary credentials for accessing Dataflow. In the Hop documentation, you will find that it recommends creating a service account, exporting a key for that service account, and setting the GOOGLE_APPLICATION_CREDENTIALS environment variable. This is also the method given in the above link.</p><p>Exporting the key of a service account is potentially dangerous, so we are going to use a different method, by leveraging the Google Cloud SDK. Run the following command:</p><pre tabindex=0><code>gcloud auth application-default login
</code></pre><p>That will open a tab in your web browser asking to confirm the authentication. Once you have confirmed, any application in your system that needs to access Google Cloud Platform will use those credentials for that access.</p><p>We need also to create a service account for the Dataflow job, with certain permissions. Create the service account with</p><pre tabindex=0><code>​​gcloud iam service-accounts create dataflow-hop-sa
</code></pre><p>And now we give permissions to this service account for Dataflow:</p><pre tabindex=0><code>gcloud projects add-iam-policy-binding ihr-hop-playground \
--member=&#34;serviceAccount:dataflow-hop-sa@ihr-hop-playground.iam.gserviceaccount.com&#34;\
 --role=&#34;roles/dataflow.worker&#34;
</code></pre><p>We also need to give additional permissions for Google Cloud Storage:</p><pre tabindex=0><code>gcloud projects add-iam-policy-binding ihr-hop-playground \
--member=&#34;serviceAccount:dataflow-hop-sa@ihr-hop-playground.iam.gserviceaccount.com&#34;\
 --role=&#34;roles/storage.admin&#34;
</code></pre><p>Make sure that you change the project id <code>ihr-hop-playground</code> to your own project id.</p><p>Now let&rsquo;s give permissions to our user to impersonate that service account. For that, go to <a href=https://console.cloud.google.com/iam-admin/serviceaccounts>Service Accounts in the Google Cloud Console</a> in your project, and click on the service account we have just created.</p><p>Click on the <em>Permissions</em> tab and then in the <em>Grant Access</em> button:</p><p><img class=center-block src=/images/blog/apache-hop/image21.png alt="Apache Hop Permissions"></p><p>Give your user the role <em>Service Account User</em>:</p><p><img class=center-block src=/images/blog/apache-hop/image13.png alt="Apache Hop Service Account User"></p><p>You are now all set to be able to run Dataflow with that service account and your user.</p><h2 id=updating-the-pipeline-run-configuration>Updating the Pipeline Run Configuration</h2><p>Before we can run a pipeline in Dataflow, we need to generate the JAR package for the pipeline code. For that, you have to go to the <em>Tools</em> menu (in the menu bar), and choose the option <em>Generate a Hop fat jar</em>. Click ok in the dialog, and then select a location and filename for the jar, and click <em>Save</em>:</p><p><img class=center-block src=/images/blog/apache-hop/image5.png alt="Apache Hop Tools menu"></p><p>It will take some minutes to generate the file:</p><p><img class=center-block src=/images/blog/apache-hop/image22.png alt="Apache Hop generate file"></p><p>We are ready to run the pipeline in Dataflow. Or almost :).</p><p>Go the pipeline editor, click the play button, and select <em>DataFlow</em> as Pipeline run configuration, and then click the play button on the right side:</p><p><img class=center-block src=/images/blog/apache-hop/image7.png alt="Apache Hop pipeline editor"></p><p>That will open the Dataflow Pipeline Run Configuration, where we can change the input variables, and other Dataflow settings.</p><p>Click on the <em>Variables</em> tab and modify only the <code>DATA_INPUT</code> and <code>DATA_OUTPUT</code> variables.</p><p><img class=center-block src=/images/blog/apache-hop/image2.png alt="Apache Hop Variables tab"></p><p>Notice that we also need to change the filename.</p><p>Let&rsquo;s go now to the <em>Main</em> tab, because there are some other options that we need to change there. We need to update:</p><ul><li>Project id</li><li>Service account</li><li>Staging location</li><li>Region</li><li>Temp location</li><li>Fat jar file location</li></ul><p>For project id, set your project id (the same one you see when you run <code>gcloud config list</code>).</p><p>For service account, use the address of the Service Account we have created. If you don&rsquo;t remember, you can find it under S<a href=https://console.cloud.google.com/iam-admin/serviceaccounts>ervice Accounts in the Google Cloud Console</a>.</p><p>For staging and temp locations, use the same bucket that we have just created. Change the bucket address in the paths, and leave the same &ldquo;binaries&rdquo; and &ldquo;tmp&rdquo; locations that are already set in the configuration.</p><p>For region, in this example we are using <code>europe-west1</code>.</p><p>Also, depending on your network configuration, you may want to check the box of &ldquo;Use Public IPs?&rdquo;, or alternatively leave it unchecked but enable Google Private Access in the regional subnetwork for europe-west1 in your project (for more details, please see <a href=https://cloud.google.com/vpc/docs/configure-private-google-access#enabling-pga>Configuring Private Google Access | VPC</a>). In this example, I will check the box for simplicity.</p><p>For the fat jar location, use the _Browse _button on the right side, and locate the JAR that we generated above. In summary, my <em>Main</em> options look like these (your project id and locations will be different):</p><p><img class=center-block src=/images/blog/apache-hop/image27.png alt="Apache Hop variables"></p><p>You may, of course, change any other option, depending on the specific settings that might be required for your project.</p><p>When you are ready, click on the _Ok _button and then <em>Launch</em> to trigger the pipeline.</p><p>In the logging window, you should see a line like the following:</p><p><img class=center-block src=/images/blog/apache-hop/image16.png alt="Apache Hop logging window"></p><h2 id=checking-the-job-in-dataflow>Checking the job in Dataflow</h2><p>If everything has gone well, you should now see a job running at <a href=https://console.cloud.google.com/dataflow/jobs>https://console.cloud.google.com/dataflow/jobs</a>.</p><p><img class=center-block src=/images/blog/apache-hop/image1.png alt="Dataflow job list"></p><p>If for some reason the job has failed, open the failed job page, check the _Logs _at the bottom, and click the error icon to find why the pipeline has failed. It is normally because we have set some wrong option in your configuration:</p><p><img class=center-block src=/images/blog/apache-hop/image25.png alt="Dataflow Logs"></p><p>When the pipeline starts running, you should see the graph of the pipeline in the job page:</p><p><img class=center-block src=/images/blog/apache-hop/image23.png alt="Dataflow pipeline graph"></p><p>When the job finishes, there should be a file in the output location. You can check it out with <code>gsutil</code></p><pre tabindex=0><code>% gsutil ls gs://ihr-apache-hop-blog/output
gs://ihr-apache-hop-blog/output/input-process-output-00000-of-00003.csv
gs://ihr-apache-hop-blog/output/input-process-output-00001-of-00003.csv
gs://ihr-apache-hop-blog/output/input-process-output-00002-of-00003.csv
</code></pre><p>In my case, the job has generated three files, but the actual number will vary from run to run.</p><p>Let&rsquo;s explore the first lines of those files:</p><pre tabindex=0><code>gsutil cat &#34;gs://ihr-apache-hop-blog/output/*csv&#34;| head
 12,wha-firstname,vnaov-name,egm-city,CALIFORNIA
 25,ayl-firstname,bwkoe-name,rtw-city,CALIFORNIA
 26,zio-firstname,rezku-name,nvt-city,CALIFORNIA
 44,rgh-firstname,wzkjq-name,hkm-city,CALIFORNIA
 135,ttv-firstname,eqley-name,trs-city,CALIFORNIA
 177,ahc-firstname,nltvw-name,uxf-city,CALIFORNIA
 181,kxv-firstname,bxerk-name,sek-city,CALIFORNIA
 272,wpy-firstname,qxjcn-name,rew-city,CALIFORNIA
 304,skq-firstname,cqapx-name,akw-city,CALIFORNIA
 308,sfu-firstname,ibfdt-name,kqf-city,CALIFORNIA
</code></pre><p>We can see that all the rows have CALIFORNIA as the state, that the output contains only the columns that we selected, and that the user id is the first column. The actual output you get will probably be different, as the order in which data is processed will not be the same in each run.</p><p>We have run this job with a small data sample, but we could have run the same job with an arbitrarily large input CSV. Dataflow would parallelize and process the data in chunks.</p><h2 id=conclusions>Conclusions</h2><p>Apache Hop is a visual development environment for Beam pipelines, that allows us to run the pipelines locally, inspect the data, debug, unit test and many other capabilities. Once we are happy with a pipeline that has run locally, we can deploy the same visual pipeline in the cloud by just setting the necessary parameters for using Dataflow.</p><p>If you want to know more about Apache Hop, don&rsquo;t miss <a href="https://www.youtube.com/watch?v=sZSIbcPtebI">the Beam Summit talk delivered by the author of Hop</a>, and don&rsquo;t forget to check out the <a href=https://hop.apache.org/manual/latest/getting-started/index.html>getting started guide</a>.</p></div></div><div class=blog-content><h2>Latest from the blog</h2></div><div class=posts-list><a class=post-card href=/blog/gsoc-25-yaml-user-accessibility/ data-categories="blog gsoc "><div class="post-info post-category"><p>blog & gsoc
                    
      </p><p>2025/09/23</p></div><div class=post><p class=post-title>Google Summer of Code 2025 - Beam YAML, Kafka and Iceberg User Accessibility</p><p class=post-info>Charles Nguyen</p></div></a><a class=post-card href=/blog/beam-2.68.0/ data-categories="blog release "><div class="post-info post-category"><p>blog & release
                    
   </p><p>2025/09/22</p></div><div class=post><p class=post-title>Apache Beam 2.68.0</p><p class=post-info>Vitalii Terentev</p></div></a><a class=post-card href=/blog/gsoc-25-infra/ data-categories="blog gsoc "><div class="post-info post-category"><p>blog & gsoc
                    
      </p><p>2025/09/15</p></div><div class=post><p class=post-title>Google Summer of Code 25 - Improving Apache Beam's Infrastructure</p><p class=post-info>Enrique Calderon</p></div></a></div></article></div><footer class=footer><div class=footer__contained><div class=footer__cols><div class="footer__cols__col footer__cols__col__logos"><div class=footer__cols__col__logo><img src=/images/beam_logo_circle.svg class=footer__logo alt="Beam logo"></div><div class=footer__cols__col__logo><img src=/images/apache_logo_circle.svg class=footer__logo alt="Apache logo"></div></div><div class=footer-wrapper><div class=wrapper-grid><div class=footer__cols__col><div class=footer__cols__col__title>Start</div><div class=footer__cols__col__link><a href=/get-started/beam-overview/>Overview</a></div><div class=footer__cols__col__link><a href=/get-started/quickstart-java/>Quickstart (Java)</a></div><div class=footer__cols__col__link><a href=/get-started/quickstart-py/>Quickstart (Python)</a></div><div class=footer__cols__col__link><a href=/get-started/quickstart-go/>Quickstart (Go)</a></div><div class=footer__cols__col__link><a href=/get-started/downloads/>Downloads</a></div></div><div class=footer__cols__col><div class=footer__cols__col__title>Docs</div><div class=footer__cols__col__link><a href=/documentation/programming-guide/>Concepts</a></div><div class=footer__cols__col__link><a href=/documentation/pipelines/design-your-pipeline/>Pipelines</a></div><div class=footer__cols__col__link><a href=/documentation/runners/capability-matrix/>Runners</a></div></div><div class=footer__cols__col><div class=footer__cols__col__title>Community</div><div class=footer__cols__col__link><a href=/contribute/>Contribute</a></div><div class=footer__cols__col__link><a href=https://projects.apache.org/committee.html?beam target=_blank>Team<img src=/images/external-link-icon.png width=14 height=14 alt="External link."></a></div><div class=footer__cols__col__link><a href=/community/presentation-materials/>Media</a></div><div class=footer__cols__col__link><a href=/community/in-person/>Events/Meetups</a></div><div class=footer__cols__col__link><a href=/community/contact-us/>Contact Us</a></div></div><div class=footer__cols__col><div class=footer__cols__col__title>Resources</div><div class=footer__cols__col__link><a href=/blog/>Blog</a></div><div class=footer__cols__col__link><a href=https://github.com/apache/beam>GitHub</a></div></div></div><div class=footer__bottom>&copy;
<a href=https://www.apache.org>The Apache Software Foundation</a>
| <a href=/privacy_policy>Privacy Policy</a>
| <a href=/feed.xml>RSS Feed</a><br><br>Apache Beam, Apache, Beam, the Beam logo, and the Apache feather logo are either registered trademarks or trademarks of The Apache Software Foundation. All other products or name brands are trademarks of their respective holders, including The Apache Software Foundation.</div></div><div class="footer__cols__col footer__cols__col__logos"><div class=footer__cols__col--group><div class=footer__cols__col__logo><a href=https://github.com/apache/beam><img src=/images/logos/social-icons/github-logo-150.png class=footer__logo alt="Github logo"></a></div><div class=footer__cols__col__logo><a href=https://www.linkedin.com/company/apache-beam/><img src=/images/logos/social-icons/linkedin-logo-150.png class=footer__logo alt="Linkedin logo"></a></div></div><div class=footer__cols__col--group><div class=footer__cols__col__logo><a href=https://twitter.com/apachebeam><img src=/images/logos/social-icons/twitter-logo-150.png class=footer__logo alt="Twitter logo"></a></div><div class=footer__cols__col__logo><a href=https://www.youtube.com/channel/UChNnb_YO_7B0HlW6FhAXZZQ><img src=/images/logos/social-icons/youtube-logo-150.png class=footer__logo alt="Youtube logo"></a></div></div></div></div></div></footer></body></html>