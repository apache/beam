<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>A review of input streaming connectors</title><meta name=description content="Apache Beam is an open source, unified model and set of language-specific SDKs for defining and executing data processing workflows, and also data ingestion and integration flows, supporting Enterprise Integration Patterns (EIPs) and Domain Specific Languages (DSLs). Dataflow pipelines simplify the mechanics of large-scale batch and streaming data processing and can run on a number of runtimes like Apache Flink, Apache Spark, and Google Cloud Dataflow (a cloud service). Beam also brings DSL in different languages, allowing users to easily implement their data integration processes."><link href="https://fonts.googleapis.com/css?family=Roboto:100,300,400" rel=stylesheet><link rel=preload href=/scss/main.min.7bfa213b38fe814e9a5d5af502d4d2e0d4e9e7dfe8a528843e32a858c6c92bc2.css as=style><link href=/scss/main.min.7bfa213b38fe814e9a5d5af502d4d2e0d4e9e7dfe8a528843e32a858c6c92bc2.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-2.2.4.min.js></script><style>.body__contained img{max-width:100%}</style><script src=/js/bootstrap.min.js></script><script src=/js/language-switch.js></script><script src=/js/fix-menu.js></script><script src=/js/section-nav.js></script><script src=/js/page-nav.js></script><link rel=alternate type=application/rss+xml title="Apache Beam" href=/feed.xml><link rel=canonical href=/blog/review-input-streaming-connectors/ data-proofer-ignore><link rel="shortcut icon" type=image/x-icon href=/images/favicon.ico><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.4.1/css/all.css integrity=sha384-5sAR7xN1Nv6T6+dT2mhtzEpVJvfS3NScPQTrOxhwjIuvcA67KV2R5Jz6kr4abQsz crossorigin=anonymous><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-73650088-1','auto');ga('send','pageview');</script></head><body class=body><nav class="header navbar navbar-fixed-top"><div class=navbar-header><button type=button class=navbar-toggle aria-expanded=false aria-controls=navbar>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span><span class=icon-bar></span><span class=icon-bar></span></button>
<a href=/ class=navbar-brand><img alt=Brand style=height:25px src=/images/beam_logo_navbar.png></a></div><div class="navbar-mask closed"></div><div id=navbar class="navbar-container closed"><ul class="nav navbar-nav"><li><a href=/get-started/beam-overview/>Get Started</a></li><li><a href=/documentation/>Documentation</a></li><li><a href=/documentation/sdks/java/>Languages</a></li><li><a href=/documentation/runners/capability-matrix/>RUNNERS</a></li><li><a href=/roadmap/>Roadmap</a></li><li><a href=/contribute/>Contribute</a></li><li><a href=/community/contact-us/>Community</a></li><li><a href=/blog/>Blog</a></li></ul><ul class="nav navbar-nav navbar-right"><li><div style=width:300px><script>(function(){var cx='012923275103528129024:4emlchv9wzi';var gcse=document.createElement('script');gcse.type='text/javascript';gcse.async=true;gcse.src='https://cse.google.com/cse.js?cx='+cx;var s=document.getElementsByTagName('script')[0];s.parentNode.insertBefore(gcse,s);})();</script><gcse:search></gcse:search></div></li><li class=dropdown><a href=# class=dropdown-toggle data-toggle=dropdown role=button aria-haspopup=true aria-expanded=false><img src=https://www.apache.org/foundation/press/kit/feather_small.png alt="Apache Logo" style=height:20px><span class=caret></span></a><ul class="dropdown-menu dropdown-menu-right"><li><a href=http://www.apache.org/>ASF Homepage</a></li><li><a href=http://www.apache.org/licenses/>License</a></li><li><a href=http://www.apache.org/security/>Security</a></li><li><a href=http://www.apache.org/foundation/thanks.html>Thanks</a></li><li><a href=http://www.apache.org/foundation/sponsorship.html>Sponsorship</a></li><li><a href=https://www.apache.org/foundation/policies/conduct>Code of Conduct</a></li></ul></li><li><a href=https://github.com/apache/beam/edit/master/website/www/site/content/en/blog/review-input-streaming-connectors.md data-proofer-ignore><i class="far fa-edit fa-lg" alt="Edit on GitHub" title="Edit on GitHub"></i></a></li></ul></div></nav><div class=body__contained><article class=post itemscope itemtype=http://schema.org/BlogPosting><header class=post-header><h1 class=post-title itemprop="name headline">A review of input streaming connectors</h1><p class=post-meta><time datetime=2018-08-20T00:00:01-08:00 itemprop=datePublished>Aug 20, 2018</time>
â€¢
Leonid Kuligin [<a href=https://twitter.com/lkulighin>@lkulighin</a>]
&
Julien Phalip [<a href=https://twitter.com/julienphalip>@julienphalip</a>]</p></header><div class=post-content itemprop=articleBody><p>In this post, you&rsquo;ll learn about the current state of support for input streaming connectors in <a href=/>Apache Beam</a>. For more context, you&rsquo;ll also learn about the corresponding state of support in <a href=https://spark.apache.org/>Apache Spark</a>.</p><p>With batch processing, you might load data from any source, including a database system. Even if there are no specific SDKs available for those database systems, you can often resort to using a <a href=https://en.wikipedia.org/wiki/Java_Database_Connectivity>JDBC</a> driver. With streaming, implementing a proper data pipeline is arguably more challenging as generally fewer source types are available. For that reason, this article particularly focuses on the streaming use case.</p><h2 id=connectors-for-java>Connectors for Java</h2><p>Beam has an official <a href=/documentation/sdks/java/>Java SDK</a> and has several execution engines, called <a href=/documentation/runners/capability-matrix/>runners</a>. In most cases it is fairly easy to transfer existing Beam pipelines written in Java or Scala to a Spark environment by using the <a href=/documentation/runners/spark/>Spark Runner</a>.</p><p>Spark is written in Scala and has a <a href=https://spark.apache.org/docs/latest/api/java/>Java API</a>. Spark&rsquo;s source code compiles to <a href=https://en.wikipedia.org/wiki/Java_(programming_language)#Java_JVM_and_Bytecode>Java bytecode</a> and the binaries are run by a <a href=https://en.wikipedia.org/wiki/Java_virtual_machine>Java Virtual Machine</a>. Scala code is interoperable with Java and therefore has native compatibility with Java libraries (and vice versa).</p><p>Spark offers two approaches to streaming: <a href=https://spark.apache.org/docs/latest/streaming-programming-guide.html>Discretized Streaming</a> (or DStreams) and <a href=https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html>Structured Streaming</a>. DStreams are a basic abstraction that represents a continuous series of <a href=https://spark.apache.org/docs/latest/rdd-programming-guide.html>Resilient Distributed Datasets</a> (or RDDs). Structured Streaming was introduced more recently (the alpha release came with Spark 2.1.0) and is based on a <a href=https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#programming-model>model</a> where live data is continuously appended to a table structure.</p><p>Spark Structured Streaming supports <a href=https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/streaming/DataStreamReader.html>file sources</a> (local filesystems and HDFS-compatible systems like Cloud Storage or S3) and <a href=https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html>Kafka</a> as streaming <a href=https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#input-sources>inputs</a>. Spark maintains built-in connectors for DStreams aimed at third-party services, such as Kafka or Flume, while other connectors are available through linking external dependencies, as shown in the table below.</p><p>Below are the main streaming input connectors for available for Beam and Spark DStreams in Java:</p><table class="table table-bordered"><tr><td></td><td></td><td><strong>Apache Beam</strong></td><td><strong>Apache Spark DStreams</strong></td></tr><tr><td rowspan=2>File Systems</td><td>Local<br>(Using the <code>file://</code> URI)</td><td><a href=https://beam.apache.org/releases/javadoc/2.23.0/org/apache/beam/sdk/io/TextIO.html>TextIO</a></td><td><a href=https://spark.apache.org/docs/latest/api/java/org/apache/spark/streaming/StreamingContext.html#textFileStream-java.lang.String->textFileStream</a><br>(Spark treats most Unix systems as HDFS-compatible, but the location should be accessible from all nodes)</td></tr><tr><td>HDFS<br>(Using the <code>hdfs://</code> URI)</td><td><a href=https://beam.apache.org/releases/javadoc/2.23.0/org/apache/beam/sdk/io/FileIO.html>FileIO</a> + <a href=https://beam.apache.org/releases/javadoc/2.23.0/org/apache/beam/sdk/io/hdfs/HadoopFileSystemOptions.html>HadoopFileSystemOptions</a></td><td><a href=https://spark.apache.org/docs/latest/api/java/org/apache/spark/streaming/util/HdfsUtils.html>HdfsUtils</a></td></tr><tr><td rowspan=2>Object Stores</td><td>Cloud Storage<br>(Using the <code>gs://</code> URI)</td><td><a href=https://beam.apache.org/releases/javadoc/2.23.0/org/apache/beam/sdk/io/FileIO.html>FileIO</a> + <a href=https://beam.apache.org/releases/javadoc/2.23.0/org/apache/beam/sdk/extensions/gcp/options/GcsOptions.html>GcsOptions</a></td><td rowspan=2><a href=https://spark.apache.org/docs/latest/api/java/org/apache/spark/SparkContext.html#hadoopConfiguration-->hadoopConfiguration</a>
and <a href=https://spark.apache.org/docs/latest/api/java/org/apache/spark/streaming/StreamingContext.html#textFileStream-java.lang.String->textFileStream</a></td></tr><tr><td>S3<br>(Using the <code>s3://</code> URI)</td><td><a href=https://beam.apache.org/releases/javadoc/2.23.0/org/apache/beam/sdk/io/FileIO.html>FileIO</a> + <a href=https://beam.apache.org/releases/javadoc/2.23.0/org/apache/beam/sdk/io/aws/options/S3Options.html>S3Options</a></td></tr><tr><td rowspan=3>Messaging Queues</td><td>Kafka</td><td><a href=https://beam.apache.org/releases/javadoc/2.23.0/org/apache/beam/sdk/io/kafka/KafkaIO.html>KafkaIO</a></td><td><a href=https://spark.apache.org/docs/latest/streaming-kafka-0-10-integration.html>spark-streaming-kafka</a></td></tr><tr><td>Kinesis</td><td><a href=https://beam.apache.org/releases/javadoc/2.23.0/org/apache/beam/sdk/io/kinesis/KinesisIO.html>KinesisIO</a></td><td><a href=https://spark.apache.org/docs/latest/streaming-kinesis-integration.html>spark-streaming-kinesis</a></td></tr><tr><td>Cloud Pub/Sub</td><td><a href=https://beam.apache.org/releases/javadoc/2.23.0/org/apache/beam/sdk/io/gcp/pubsub/PubsubIO.html>PubsubIO</a></td><td><a href=https://github.com/apache/bahir/tree/master/streaming-pubsub>spark-streaming-pubsub</a> from <a href=https://bahir.apache.org>Apache Bahir</a></td></tr><tr><td>Other</td><td>Custom receivers</td><td><a href=/documentation/io/developing-io-overview/>Read Transforms</a></td><td><a href=https://spark.apache.org/docs/latest/streaming-custom-receivers.html>receiverStream</a></td></tr></table><h2 id=connectors-for-python>Connectors for Python</h2><p>Beam has an official <a href=/documentation/sdks/python/>Python SDK</a> that currently supports a subset of the streaming features available in the Java SDK. Active development is underway to bridge the gap between the featuresets in the two SDKs. Currently for Python, the <a href=/documentation/runners/direct/>Direct Runner</a> and <a href=/documentation/runners/dataflow/>Dataflow Runner</a> are supported, and <a href=/documentation/sdks/python-streaming/>several streaming options</a> were introduced in beta in <a href=/blog/2018/06/26/beam-2.5.0.html>version 2.5.0</a>.</p><p>Spark also has a Python SDK called <a href=https://spark.apache.org/docs/latest/api/python/pyspark.html>PySpark</a>. As mentioned earlier, Scala code compiles to a bytecode that is executed by the JVM. PySpark uses <a href=https://www.py4j.org/>Py4J</a>, a library that enables Python programs to interact with the JVM and therefore access Java libraries, interact with Java objects, and register callbacks from Java. This allows PySpark to access native Spark objects like RDDs. Spark Structured Streaming supports <a href=https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.streaming.DataStreamReader>file sources</a> (local filesystems and HDFS-compatible systems like Cloud Storage or S3) and <a href=https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html>Kafka</a> as streaming inputs.</p><p>Below are the main streaming input connectors for available for Beam and Spark DStreams in Python:</p><table class="table table-bordered"><tr><td></td><td></td><td><strong>Apache Beam</strong></td><td><strong>Apache Spark DStreams</strong></td></tr><tr><td rowspan=2>File Systems</td><td>Local</td><td><a href=https://beam.apache.org/releases/pydoc/2.23.0/apache_beam.io.textio.html>io.textio</a></td><td><a href=https://spark.apache.org/docs/latest/api/python/pyspark.streaming.html#pyspark.streaming.StreamingContext.textFileStream>textFileStream</a></td></tr><tr><td>HDFS</td><td><a href=https://beam.apache.org/releases/pydoc/2.23.0/apache_beam.io.hadoopfilesystem.html>io.hadoopfilesystem</a></td><td><a href=https://spark.apache.org/docs/latest/api/java/org/apache/spark/SparkContext.html#hadoopConfiguration-->hadoopConfiguration</a> (Access through <code>sc._jsc</code> with Py4J)
and <a href=https://spark.apache.org/docs/latest/api/python/pyspark.streaming.html#pyspark.streaming.StreamingContext.textFileStream>textFileStream</a></td></tr><tr><td rowspan=2>Object stores</td><td>Google Cloud Storage</td><td><a href=https://beam.apache.org/releases/pydoc/2.23.0/apache_beam.io.gcp.gcsio.html>io.gcp.gcsio</a></td><td rowspan=2><a href=https://spark.apache.org/docs/latest/api/python/pyspark.streaming.html#pyspark.streaming.StreamingContext.textFileStream>textFileStream</a></td></tr><tr><td>S3</td><td>N/A</td></tr><tr><td rowspan=3>Messaging Queues</td><td>Kafka</td><td>N/A</td><td><a href=https://spark.apache.org/docs/latest/api/python/pyspark.streaming.html#pyspark.streaming.kafka.KafkaUtils>KafkaUtils</a></td></tr><tr><td>Kinesis</td><td>N/A</td><td><a href=https://spark.apache.org/docs/latest/api/python/pyspark.streaming.html#module-pyspark.streaming.kinesis>KinesisUtils</a></td></tr><tr><td>Cloud Pub/Sub</td><td><a href=https://beam.apache.org/releases/pydoc/2.23.0/apache_beam.io.gcp.pubsub.html>io.gcp.pubsub</a></td><td>N/A</td></tr><tr><td>Other</td><td>Custom receivers</td><td><a href=/documentation/sdks/python-custom-io/>BoundedSource and RangeTracker</a></td><td>N/A</td></tr></table><h2 id=connectors-for-other-languages>Connectors for other languages</h2><h3 id=scala>Scala</h3><p>Since Scala code is interoperable with Java and therefore has native compatibility with Java libraries (and vice versa), you can use the same Java connectors described above in your Scala programs. Apache Beam also has a <a href=https://github.com/spotify/scio>Scala API</a> open-sourced <a href=https://labs.spotify.com/2017/10/16/big-data-processing-at-spotify-the-road-to-scio-part-1/>by Spotify</a>.</p><h3 id=go>Go</h3><p>A <a href=/documentation/sdks/go/>Go SDK</a> for Apache Beam is under active development. It is currently experimental and is not recommended for production. Spark does not have an official Go SDK.</p><h3 id=r>R</h3><p>Apache Beam does not have an official R SDK. Spark Structured Streaming is supported by an <a href=https://spark.apache.org/docs/latest/sparkr.html#structured-streaming>R SDK</a>, but only for <a href=https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#input-sources>file sources</a> as a streaming input.</p><h2 id=next-steps>Next steps</h2><p>We hope this article inspired you to try new and interesting ways of connecting streaming sources to your Beam pipelines!</p><p>Check out the following links for further information:</p><ul><li>See a full list of all built-in and in-progress <a href=/documentation/io/built-in/>I/O Transforms</a> for Apache Beam.</li><li>Learn about some Apache Beam mobile gaming pipeline <a href=/get-started/mobile-gaming-example/>examples</a>.</li></ul></div></article></div><footer class=footer><div class=footer__contained><div class=footer__cols><div class=footer__cols__col><div class=footer__cols__col__logo><img src=/images/beam_logo_circle.svg class=footer__logo alt="Beam logo"></div><div class=footer__cols__col__logo><img src=/images/apache_logo_circle.svg class=footer__logo alt="Apache logo"></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Start</div><div class=footer__cols__col__link><a href=/get-started/beam-overview/>Overview</a></div><div class=footer__cols__col__link><a href=/get-started/quickstart-java/>Quickstart (Java)</a></div><div class=footer__cols__col__link><a href=/get-started/quickstart-py/>Quickstart (Python)</a></div><div class=footer__cols__col__link><a href=/get-started/quickstart-go/>Quickstart (Go)</a></div><div class=footer__cols__col__link><a href=/get-started/downloads/>Downloads</a></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Docs</div><div class=footer__cols__col__link><a href=/documentation/programming-guide/>Concepts</a></div><div class=footer__cols__col__link><a href=/documentation/pipelines/design-your-pipeline/>Pipelines</a></div><div class=footer__cols__col__link><a href=/documentation/runners/capability-matrix/>Runners</a></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Community</div><div class=footer__cols__col__link><a href=/contribute/>Contribute</a></div><div class=footer__cols__col__link><a href=https://projects.apache.org/committee.html?beam target=_blank>Team<img src=/images/external-link-icon.png width=14 height=14 alt="External link."></a></div><div class=footer__cols__col__link><a href=/community/presentation-materials/>Media</a></div><div class=footer__cols__col__link><a href=/community/in-person/>Events/Meetups</a></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Resources</div><div class=footer__cols__col__link><a href=/blog/>Blog</a></div><div class=footer__cols__col__link><a href=/community/contact-us/>Contact Us</a></div><div class=footer__cols__col__link><a href=https://github.com/apache/beam>GitHub</a></div></div></div></div><div class=footer__bottom>&copy;
<a href=http://www.apache.org>The Apache Software Foundation</a>
| <a href=/privacy_policy>Privacy Policy</a>
| <a href=/feed.xml>RSS Feed</a><br><br>Apache Beam, Apache, Beam, the Beam logo, and the Apache feather logo are either registered trademarks or trademarks of The Apache Software Foundation. All other products or name brands are trademarks of their respective holders, including The Apache Software Foundation.</div></footer></body></html>