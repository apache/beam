<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Apache Beam – gsoc</title><link>/categories/gsoc/</link><description>Recent content in gsoc on Apache Beam</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Tue, 23 Sep 2025 00:00:00 -0400</lastBuildDate><atom:link href="/categories/gsoc/index.xml" rel="self" type="application/rss+xml"/><item><title>Blog: Google Summer of Code 2025 - Beam YAML, Kafka and Iceberg User Accessibility</title><link>/blog/gsoc-25-yaml-user-accessibility/</link><pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate><guid>/blog/gsoc-25-yaml-user-accessibility/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;p>The relatively new Beam YAML SDK was introduced in the spirit of making data processing easy,
but it has gained little adoption for complex ML tasks and hasn’t been widely used with
&lt;a href="beam.apache.org/documentation/io/managed-io/">Managed I/O&lt;/a> such as Kafka and Iceberg.
As part of Google Summer of Code 2025, new illustrative, production-ready pipeline examples
of ML use cases with Kafka and Iceberg data sources using the YAML SDK have been developed
to address this adoption gap.&lt;/p>
&lt;h2 id="context">Context&lt;/h2>
&lt;p>The YAML SDK was introduced in Spring 2024 as Beam’s first no-code SDK. It follows a declarative approach
of defining a data processing pipeline using a YAML DSL, as opposed to other programming language specific SDKs.
At the time, it had few meaningful examples and documentation to go along with it. Key missing examples
were ML workflows and integration with the Kafka and Iceberg Managed I/O. Foundational work had already been done
to add support for ML capabilities as well as Kafka and Iceberg IO connectors in the YAML SDK, but there were no
end-to-end examples demonstrating their usage.&lt;/p>
&lt;p>Beam, as well as Kafka and Iceberg, are mainstream big data technologies but they also have a learning curve.
The overall theme of the project is to help democratize data processing for scientists and analysts who traditionally
don’t have a strong background in software engineering. They can now refer to these meaningful examples as the starting point,
helping them onboard faster and be more productive when authoring ML/data pipelines to their use cases with Beam and its YAML DSL.&lt;/p>
&lt;h2 id="contributions">Contributions&lt;/h2>
&lt;p>The data pipelines/workflows developed are production-ready: Kafka and Iceberg data sources are set up on GCP,
and the data used are raw public datasets. The pipelines are tested end-to-end on Google Cloud Dataflow and
are also unit tested to ensure correct transformation logic.&lt;/p>
&lt;p>Delivered pipelines/workflows, each with documentation as README.md, address 4 main ML use cases below:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>Streaming Classification Inference&lt;/strong>: A streaming ML pipeline that demonstrates Beam YAML capability to perform
classification inference on a stream of incoming data from Kafka. The overall workflow also includes
DistilBERT model deployment and serving on Google Cloud Vertex AI where the pipeline can access for remote inferences.
The pipeline is applied to a sentiment analysis task on a stream of YouTube comments, preprocessing data and classifying
whether a comment is positive or negative. See &lt;a href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/yaml/examples/transforms/ml/sentiment_analysis/streaming_sentiment_analysis.yaml">pipeline&lt;/a> and &lt;a href="https://github.com/apache/beam/tree/master/sdks/python/apache_beam/yaml/examples/transforms/ml/sentiment_analysis">documentation&lt;/a>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Streaming Regression Inference&lt;/strong>: A streaming ML pipeline that demonstrates Beam YAML capability to perform
regression inference on a stream of incoming data from Kafka. The overall workflow also includes
custom model training, deployment and serving on Google Cloud Vertex AI where the pipeline can access for remote inferences.
The pipeline is applied to a regression task on a stream of taxi rides, preprocessing data and predicting the fare amount
for every ride. See &lt;a href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/yaml/examples/transforms/ml/taxi_fare/streaming_taxifare_prediction.yaml">pipeline&lt;/a> and &lt;a href="https://github.com/apache/beam/tree/master/sdks/python/apache_beam/yaml/examples/transforms/ml/taxi_fare">documentation&lt;/a>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Batch Anomaly Detection&lt;/strong>: A ML workflow that demonstrates ML-specific transformations
and reading from/writing to Iceberg IO. The workflow contains unsupervised model training and several pipelines that leverage
Iceberg for storing results, BigQuery for storing vector embeddings and MLTransform for computing embeddings to demonstrate
an end-to-end anomaly detection workflow on a dataset of system logs. See &lt;a href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/yaml/examples/transforms/ml/log_analysis/batch_log_analysis.sh">workflow&lt;/a> and &lt;a href="https://github.com/apache/beam/tree/master/sdks/python/apache_beam/yaml/examples/transforms/ml/log_analysis">documentation&lt;/a>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Feature Engineering &amp;amp; Model Evaluation&lt;/strong>: A ML workflow that demonstrates Beam YAML capability to do feature engineering
which is subsequently used for model evaluation, and its integration with Iceberg IO. The workflow contains model training
and several pipelines, showcasing an end-to-end Fraud Detection MLOps solution that generates features and evaluates models
to detect credit card transaction frauds. See &lt;a href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/yaml/examples/transforms/ml/fraud_detection/fraud_detection_mlops_beam_yaml_sdk.ipynb">workflow&lt;/a> and &lt;a href="https://github.com/apache/beam/tree/master/sdks/python/apache_beam/yaml/examples/transforms/ml/fraud_detection">documentation&lt;/a>.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="challenges">Challenges&lt;/h2>
&lt;p>The main challenge of the project was a lack of previous YAML pipeline examples and good documentation to rely on.
Unlike the Python or Java SDKs where there are already many notebooks and end-to-end examples demonstrating various use cases,
the examples for YAML SDK only involved simple transformations such as filter, group by, etc. More complex transforms like
&lt;code>MLTransform&lt;/code> and &lt;code>ReadFromIceberg&lt;/code> had no examples and requires configurations that didn&amp;rsquo;t have clear API reference at the time.
As a result, there were a lot of deep dives into the actual implementation of the PTransforms across YAML, Python and Java SDKs to
understand the error messages and how to correctly use the transforms.&lt;/p>
&lt;p>Another challenge was writing unit tests for the pipeline to ensure that the pipeline’s logic is correct.
It was a learning curve to understand how the existing test suite is set up and how it can be used to write unit tests for
the data pipelines. A lot of time was spent on properly writing mocks for the pipeline&amp;rsquo;s sources and sinks, as well as for the
transforms that require external services such as Vertex AI.&lt;/p>
&lt;h2 id="conclusion--personal-thoughts">Conclusion &amp;amp; Personal Thoughts&lt;/h2>
&lt;p>These production-ready pipelines demonstrate the potential of Beam YAML SDK to author complex ML workflows
that interact with Iceberg and Kafka. The examples are a nice addition to Beam, especially with Beam 3.0.0 milestones
coming up where low-code/no-code, ML capabilities and Managed I/O are focused on.&lt;/p>
&lt;p>I had an amazing time working with the big data technologies Beam, Iceberg, and Kafka as well as many Google Cloud services
(Dataflow, Vertex AI and Google Kubernetes Engine, to name a few). I’ve always wanted to work more in the ML space, and this
experience has been a great growth opportunity for me. Google Summer of Code this year has been selective, and the project&amp;rsquo;s success
would not have been possible without the support of my mentor, Chamikara Jayalath. It&amp;rsquo;s been a pleasure working closely
with him and the broader Beam community to contribute to this open-source project that has a meaningful impact on the
data engineering community.&lt;/p>
&lt;p>My advice for future Google Summer of Code participants is to first and foremost research and choose a project that aligns closely
with your interest. Most importantly, spend a lot of time making yourself visible and writing a good proposal when the program
is opened for applications. Being visible (e.g. by sharing your proposal, or generally any ideas and questions on the project&amp;rsquo;s
communication channel early on) makes it more likely for you to be selected; and a good proposal not only will make you even
more likely to be in the program, but also give you a lot of confidence when contributing to and completing the project.&lt;/p>
&lt;h2 id="references">References&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://summerofcode.withgoogle.com/programs/2025/projects/f4kiDdus">Google Summer of Code Project Listing&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.google.com/document/d/1MSAVF6X9ggtVZbqz8YJGmMgkolR_dve0Lr930cByyac/edit?usp=sharing">Google Summer of Code Final Report&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Blog: Google Summer of Code 25 - Improving Apache Beam's Infrastructure</title><link>/blog/gsoc-25-infra/</link><pubDate>Mon, 15 Sep 2025 00:00:00 -0600</pubDate><guid>/blog/gsoc-25-infra/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;p>I loved contributing to Apache Beam during Google Summer of Code 2025. I worked on improving the infrastructure of Apache Beam, which included enhancing the CI/CD pipelines, automating various tasks, and improving the overall developer experience.&lt;/p>
&lt;h2 id="motivation">Motivation&lt;/h2>
&lt;p>Since I was in high school, I have been fascinated by computers, but when I discovered Open Source, I was amazed by the idea of people from all around the world collaborating to build software that anyone can use, just for the love of it. I started participating in open source communities, and I found it to be a great way to learn and grow as a developer.&lt;/p>
&lt;p>When I heard about Google Summer of Code, I saw it as an opportunity to take my open source contributions to the next level. The idea of working on a real-world project while being mentored by experienced developers sounded like an amazing opportunity. I heard about Apache Beam from another contributor and ex-GSoC participant, and I was immediately drawn to the project, specifically on the infrastructure side of things, as I have a strong interest in DevOps and automation.&lt;/p>
&lt;h2 id="the-challenge">The Challenge&lt;/h2>
&lt;p>When searching for a project, I was told that Apache Beam&amp;rsquo;s infrastructure had several areas that could be improved. I was excited because the ideas were focused on improving the developer experience, and creating tools that could benefit not only Beam&amp;rsquo;s developers but also the wider open source community.&lt;/p>
&lt;p>There were four main challenges:&lt;/p>
&lt;ol>
&lt;li>Automating the cleanup of unused cloud resources to reduce costs and improve resource management.&lt;/li>
&lt;li>Implementing a system for managing permissions through Git, allowing for better tracking and auditing of changes.&lt;/li>
&lt;li>Creating a tool for rotating service account keys to enhance security.&lt;/li>
&lt;li>Developing a security monitoring system to detect and respond to potential threats.&lt;/li>
&lt;/ol>
&lt;h2 id="the-solution">The Solution&lt;/h2>
&lt;p>I worked closely with my mentor to break down and define each challenge into manageable tasks, creating a plan for the summer. I started by taking a look at the current state of the infrastructure, after which I began working on each challenge one by one.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>Automating the cleanup of unused cloud resources:&lt;/strong> We noticed that some resources in the GCP project, especially Pub/Sub topics created for testing, were often forgotten, leading to unnecessary costs. Since the infrastructure is primarily for testing and development, there&amp;rsquo;s no need to keep unused resources. I developed a Python script that identifies and removes stale Pub/Sub topics that have existed for too long. This tool is now scheduled to run periodically via a GitHub Actions workflow to keep the project tidy and cost-effective.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Implementing a system for managing permissions through Git:&lt;/strong> This was more challenging, as it required a good understanding of both GCP IAM and the existing workflow. After some investigation, I learned that the current process was mostly manual and error-prone. The task involved creating a more automated and reliable system. This was achieved by using Terraform to define the desired state of IAM roles and permissions in code, which allows for better tracking and auditing of changes. This also included some custom roles, but that is still a work in progress.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Creating a tool for rotating service account keys:&lt;/strong> Key rotation is a security practice that we don&amp;rsquo;t always follow, but it is essential to ensure that service account keys are not compromised. I noticed that GCP had some APIs that could help with this, but the rotation process itself was not automated. So I wrote a Python script that automates the rotation of GCP service account keys, enhancing the security of service account credentials.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Developing a security monitoring system:&lt;/strong> To keep track of incorrect usage and potential threats, I built a log analysis tool that monitors GCP audit logs for suspicious activity, collecting and parsing logs to identify potential security threats, delivering email alerts when something unusual is detected.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>As an extra, and after noticing that some of these tools and policies could be ignored by developers, we also came up with the idea of an enforcement module to ensure the usage of these new tools and policies. This module would be integrated into the CI/CD pipeline, checking for compliance with the new infrastructure policies and notifying developers of any violations.&lt;/p>
&lt;h2 id="the-impact">The Impact&lt;/h2>
&lt;p>The tools developed during this project will have an impact on the Apache Beam community and the wider open source community. The automation of resource cleanup will help reduce costs and improve resource management, while the permission management system will provide better tracking and auditing of changes. The service account key rotation tool will enhance security, and the security monitoring system will help detect and respond to potential threats.&lt;/p>
&lt;h2 id="wrap-up">Wrap Up&lt;/h2>
&lt;p>This project has been an incredible learning experience for me. I have gained a better understanding of how GCP works, as well as how to use Terraform and GitHub Actions. I have also learned a lot about security best practices and how to implement them in a real-world project.&lt;/p>
&lt;p>I also learned a lot about working in an open source community, having direct communication with such experienced developers, and the importance of collaboration and communication in a distributed team. I am grateful for the opportunity to work on such an important project and to contribute to the Apache Beam community.&lt;/p>
&lt;p>Finally, a special thanks to my mentor, Pablo Estrada, for his guidance and support throughout the summer. I am grateful not only for his amazing technical skills but especially for his patience and encouragement on my journey contributing to open source.&lt;/p>
&lt;p>You can find my final report &lt;a href="https://gist.github.com/ksobrenat32/b028b8303393afbe73a8fc5e17daff90">here&lt;/a> if you want to take a look at the details of my work.&lt;/p>
&lt;h2 id="advice-for-future-participants">Advice for Future Participants&lt;/h2>
&lt;p>If you are considering participating in Google Summer of Code, my advice would be to choose an area you are passionate about; this will make any coding challenge easier to overcome. Also, don&amp;rsquo;t be afraid to ask questions and seek help from your mentors and the community. At the start, I made that mistake, and I learned that asking for help is a sign of strength, not weakness.&lt;/p>
&lt;p>Finally, make sure to manage your time effectively and stay organized (keeping a progress journal is a great idea). GSoC is a great opportunity to learn and grow as a developer, but it can also be time-consuming, so it&amp;rsquo;s important to stay focused and on track.&lt;/p></description></item><item><title>Blog: Google Summer of Code '19</title><link>/blog/gsoc-19/</link><pubDate>Wed, 04 Sep 2019 00:00:01 -0800</pubDate><guid>/blog/gsoc-19/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;p>Google Summer of Code was an amazing learning experience for me.
I contributed to open source, learned about Apache Beam’s internals and worked with the best engineers in the world.&lt;/p>
&lt;h2 id="motivation">Motivation&lt;/h2>
&lt;p>Two of my friends had participated in GSoC in 2018. I was intrigued by their experience.
The idea of working on open-source software that could potentially be used by developers across the world, while being mentored by the best people in a field was exciting!
So, I decided to give Google Summer of Code a shot this year.&lt;/p>
&lt;h2 id="what-is-google-summer-of-code">What is Google Summer of Code?&lt;/h2>
&lt;p>&lt;a href="https://summerofcode.withgoogle.com/">Google Summer of Code&lt;/a> is a global program hosted by Google focused on introducing students to open source software development.
Students work on a 3 month programming project with an open source organization during their break from university.&lt;/p>
&lt;h2 id="why-apache-beam">Why Apache Beam?&lt;/h2>
&lt;p>While interning at &lt;a href="https://atlan.com/">Atlan&lt;/a>, I discovered the field of Data Engineering. I found the challenges and the discussions of the engineers there interesting. While researching for my internship project, I came across the Streaming Systems book. It introduced me to the unified model of Apache Beam for Batch and Streaming Systems, which I was fascinated by.
I wanted to explore Data Engineering, so for GSoC, I wanted to work on a project in that field. Towards the end of my internship, I started contributing to Apache Airflow(very cool project) and Apache Beam, hoping one of them would participate in GSoC. I got lucky!&lt;/p>
&lt;p>&lt;a href="https://youtu.be/U2eWLb-LD44">Also, Spotify’s Discover Weekly uses Apache Beam!&lt;/a>&lt;/p>
&lt;h2 id="preparation">Preparation&lt;/h2>
&lt;p>I had already read the &lt;a href="http://streamingsystems.net/">Streaming Systems book&lt;/a>. So, I had an idea of the concepts that Beam is built on, but had never actually used Beam.
Before actually submitting a proposal, I went through a bunch of resources to make sure I had a concrete understanding of Beam.
I read the &lt;a href="https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101">Streaming 101&lt;/a> and &lt;a href="https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-102">Streaming 102&lt;/a> blogs by Tyler Akidau. They are the perfect introduction to Beam’s unified model for Batch and Streaming.
In addition, I watched all Beam talks on YouTube. You can find them on the &lt;a href="/get-started/resources/videos-and-podcasts/">Beam Website&lt;/a>.
Beam has really good documentation. The &lt;a href="/documentation/programming-guide/">Programming Guide&lt;/a> lays out all of Beam’s concepts really well. &lt;a href="/documentation/runtime/model">Beam’s execution model&lt;/a> is also documented well and is a must-read to understand how Beam processes data.
&lt;a href="https://www.waitingforcode.com/apache-beam">waitingforcode.com&lt;/a> also has good blog posts about Beam concepts.
To get a better sense of the Beam codebase, I played around with it and worked on some PRs to understand Beam better and got familiar with the test suite and workflows.&lt;/p>
&lt;h2 id="gsoc-journey">GSoC Journey&lt;/h2>
&lt;p>GSoC has 2 phases. The first is the Community Bonding period in which students get familiar with the project and the community. The other is the actual Coding Period in which students work on their projects. Since the Coding Period has three evaluations spaced out by a month, I divided my project into three parts focusing on the implementation, tests, and documentation or improvements.&lt;/p>
&lt;h3 id="project">Project&lt;/h3>
&lt;p>My project(&lt;a href="https://issues.apache.org/jira/browse/BEAM-6611">BEAM-6611&lt;/a>) added support for File Loads method of inserting data into BigQuery for streaming pipelines. It builds on PR - &lt;a href="https://github.com/apache/beam/pull/7655">#7655&lt;/a> for &lt;a href="https://issues.apache.org/jira/browse/BEAM-6553">BEAM-6553&lt;/a> that added support in the Python SDK for writing to BigQuery using File Loads method for Batch pipelines. Streaming pipelines with non-default Windowing, Triggering and Accumulation mode can write data to BigQuery using file loads method. In case of failure, the pipeline will fail atomically. This means that each record will be loaded into BigQuery at-most-once.
You can find my proposal &lt;a href="https://docs.google.com/document/d/15Peyd3Z_wu5rvGWw8lMLpZuTyyreM_JOAEFFWvF97YY/edit?usp=sharing">here&lt;/a>.&lt;/p>
&lt;h3 id="community-bonding">Community Bonding&lt;/h3>
&lt;p>When GSoC started, my semester end exams had not yet finished. As a result, I couldn’t get much done. I worked on three PTransforms for the Python SDK - Latest, WithKeys and Reify.&lt;/p>
&lt;h3 id="coding-period-i">Coding Period I&lt;/h3>
&lt;p>In this period, I wrote some Integration Tests for the BigQuery sink using Streaming Inserts in streaming mode. I worked on a failing integration test for my project. I also finished the implementation of my project. But, one PostCommit test didn’t pass. I realized that the matcher for the Integration Test that queried BigQuery for the results was intended to be used in Batch mode. So, I wrote a version of the matcher to work in streaming mode.&lt;/p>
&lt;h3 id="coding-period-ii">Coding Period II&lt;/h3>
&lt;p>Even after I had added the matcher for streaming mode, the PostComit tests did not pass. A test was being run even though it was not specified. I isolated the failure to a &lt;a href="https://nose.readthedocs.io/en/latest/doc_tests/test_multiprocess/multiprocess.html#other-differences-in-test-running">limitation&lt;/a> of the multiprocess plugin for &lt;a href="https://nose.readthedocs.io/en/latest/">nose(a Python test framework)&lt;/a> due to which it found more tests than had been specified. It took me a while to figure this out. In this period, changes for my project got merged.
I also worked on small issues related to testing.&lt;/p>
&lt;p>This period was marked by a few exciting events:&lt;/p>
&lt;ul>
&lt;li>Ending up in the top #100 contributors to apache/beam.&lt;/li>
&lt;li>My first ever PR Review on an open source project.&lt;/li>
&lt;/ul>
&lt;img src="https://pbs.twimg.com/media/D_XNSC-UIAUmswG?format=png&amp;name=small" alt="Weird flex but ok" />
&lt;h3 id="coding-period-iii">Coding Period III&lt;/h3>
&lt;p>This was the final coding period before the program ended. Since my project was merged earlier than expected, my mentor suggested another issue(&lt;a href="https://issues.apache.org/jira/browse/BEAM-7742">BEAM-7742&lt;/a>) in the same area - BigQueryIO, that I found interesting. So, I worked on partitioning written files in BigQuery to ensure that all load jobs triggered adhere to the load job size limitations specified for BigQuery.
While working on my project, I was using a pipeline that uses PubSub as a source and BigQuery as a sink to validate my changes. My mentor suggested we add them to the Beam test suite as it would be the ultimate test for BigQueryIO. I also worked on adding this test to Beam.&lt;/p>
&lt;p>You can find the list of PRs I worked on &lt;a href="https://github.com/apache/beam/pulls?utf8=%E2%9C%93&amp;amp;q=is%3Apr+author%3Attanay">here&lt;/a>.&lt;/p>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>GSoC has been a lesson in discipline and goal-setting for me. Deciding what I wanted to work on and how much I wanted to get done each week was an important lesson.
I had never worked remotely, so this was a new experience. Although I struggled with it initially, I appreciate the flexibility that it comes with.
I also had a lot of fun learning about Apache Beam’s internals, and other tools in the same ecosystem.
This was also the first time I had written code with a test-first approach.&lt;/p>
&lt;p>I thank my mentor - Pablo Estrada, Apache Beam, The Apache Software Foundation and Google Summer of Code for this opportunity. I am also grateful to my mentor for helping me with everything I needed and more, and the Apache Beam community for being supportive and encouraging.&lt;/p>
&lt;p>With the right effort, perseverance, conviction, and a plan, anything is possible. Anything.&lt;/p></description></item></channel></rss>