<!--
 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at
   http://www.apache.org/licenses/LICENSE-2.0
 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License. See accompanying LICENSE file.
-->
<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Apache Beam</title>
    <description>Apache Beam is an open source, unified model and set of language-specific SDKs for defining and executing data processing workflows, and also data ingestion and integration flows, supporting Enterprise Integration Patterns (EIPs) and Domain Specific Languages (DSLs). Dataflow pipelines simplify the mechanics of large-scale batch and streaming data processing and can run on a number of runtimes like Apache Flink, Apache Spark, and Google Cloud Dataflow (a cloud service). Beam also brings DSL in different languages, allowing users to easily implement their data integration processes.
</description>
    <link>https://beam.apache.org/</link>
    <atom:link href="https://beam.apache.org/feed.xml" rel="self" type="application/rss+xml"/>
    <generator>Jekyll v3.2.0</generator>
    
      <item>
        <title>Beam Summit Europe 2018</title>
        <description>&lt;!--
Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;

&lt;p&gt;With a growing community of contributors and users, the Apache Beam project is organising the first European Beam Summit.&lt;/p&gt;

&lt;p&gt;We are happy to invite you to this event, which will take place in &lt;strong&gt;London&lt;/strong&gt; on &lt;strong&gt;October 1st and 2nd of 2018&lt;/strong&gt;. &lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/Facebook-AD.png&quot; alt=&quot;Beam Summit Europe 2018 flyer&quot; height=&quot;360&quot; width=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;what-is-the-beam-summit-2018&quot;&gt;What is the Beam Summit 2018?&lt;/h3&gt;
&lt;p&gt;The summit is a 2 day, multi-track event.&lt;/p&gt;

&lt;p&gt;During the first day we’ll host sessions to share use cases from companies using Apache Beam, community driven talks, and a session to discuss the project’s roadmap (from the main partners in the project as well as all users planning to contribute to the project and wanting to share their plans). We’ll also have break-out sessions that will allow cross team collaboration in multiple sub-topics.&lt;/p&gt;

&lt;p&gt;The second day will be a “hands-on” day. We will offer an introductory session to Apache Beam. Additionally, we’ll host an advanced track for more advanced users with open-table discussions about more complex and newer Apache Beam features.&lt;/p&gt;

&lt;p&gt;The agenda will grow and be communicated in the coming month, keep an eye on the page.&lt;/p&gt;

&lt;h3 id=&quot;event-details&quot;&gt;Event Details&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Venue&lt;/strong&gt;: &lt;a href=&quot;https://goo.gl/maps/LAC4haDzSzR2&quot;&gt;Level39, One Canada Square, Canary Wharf, London E14 5AB&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Dates&lt;/strong&gt;: 1-2 October 2018&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;how-do-i-register&quot;&gt;How do I register?&lt;/h3&gt;
&lt;p&gt;You can register for free on the &lt;a href=&quot;https://www.eventbrite.com/e/beam-summit-london-2018-tickets-49100625292#tickets&quot;&gt;Eventbrite registration page&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;i-am-interested-in-speaking-how-do-i-propose-my-session&quot;&gt;I am interested in speaking, how do I propose my session?&lt;/h3&gt;
&lt;p&gt;With this we are also launching a Call for Papers in case you want to secure a slot for one of the sessions. Please fill out the &lt;a href=&quot;https://goo.gl/forms/nrZOCC1JwEfLtKfA2&quot;&gt;CfP form&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;id-love-to-get-involved-as-a-volunteer-or-sponsor&quot;&gt;I’d love to get involved as a volunteer or sponsor&lt;/h3&gt;
&lt;p&gt;Furthermore, in order to keep this event free, we are looking for people to help out at and/or sponsor some parts of the conference. If you (or your company) are interested to help out, please reach out to: &lt;a href=&quot;mailto:baetensmatthias@gmail.com&quot;&gt;baetensmatthias@gmail.com&lt;/a&gt; or &lt;a href=&quot;mailto:alex@vanboxel.be&quot;&gt;alex@vanboxel.be&lt;/a&gt;. You can find more info in the &lt;a href=&quot;https://drive.google.com/file/d/1RnZ52rGaB6BR-EKneBcabdMcg9Pl7z9M&quot;&gt;sponsor booklet&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thanks, and we hope to see you at the event! 
The Events &amp;amp; Meetups Group&lt;/p&gt;
</description>
        <pubDate>Tue, 21 Aug 2018 01:00:01 -0700</pubDate>
        <link>https://beam.apache.org/blog/2018/08/21/beam-summit-europe.html</link>
        <guid isPermaLink="true">https://beam.apache.org/blog/2018/08/21/beam-summit-europe.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>A review of input streaming connectors</title>
        <description>&lt;!--
Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;

&lt;p&gt;In this post, you’ll learn about the current state of support for input streaming connectors in &lt;a href=&quot;/&quot;&gt;Apache Beam&lt;/a&gt;. For more context, you’ll also learn about the corresponding state of support in &lt;a href=&quot;https://spark.apache.org/&quot;&gt;Apache Spark&lt;/a&gt;.&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;With batch processing, you might load data from any source, including a database system. Even if there are no specific SDKs available for those database systems, you can often resort to using a &lt;a href=&quot;https://en.wikipedia.org/wiki/Java_Database_Connectivity&quot;&gt;JDBC&lt;/a&gt; driver. With streaming, implementing a proper data pipeline is arguably more challenging as generally fewer source types are available. For that reason, this article particularly focuses on the streaming use case.&lt;/p&gt;

&lt;h2 id=&quot;connectors-for-java&quot;&gt;Connectors for Java&lt;/h2&gt;

&lt;p&gt;Beam has an official &lt;a href=&quot;/documentation/sdks/java/&quot;&gt;Java SDK&lt;/a&gt; and has several execution engines, called &lt;a href=&quot;/documentation/runners/capability-matrix/&quot;&gt;runners&lt;/a&gt;. In most cases it is fairly easy to transfer existing Beam pipelines written in Java or Scala to a Spark environment by using the &lt;a href=&quot;/documentation/runners/spark/&quot;&gt;Spark Runner&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Spark is written in Scala and has a &lt;a href=&quot;https://spark.apache.org/docs/latest/api/java/&quot;&gt;Java API&lt;/a&gt;. Spark’s source code compiles to &lt;a href=&quot;https://en.wikipedia.org/wiki/Java_(programming_language)#Java_JVM_and_Bytecode&quot;&gt;Java bytecode&lt;/a&gt; and the binaries are run by a &lt;a href=&quot;https://en.wikipedia.org/wiki/Java_virtual_machine&quot;&gt;Java Virtual Machine&lt;/a&gt;. Scala code is interoperable with Java and therefore has native compatibility with Java libraries (and vice versa).&lt;/p&gt;

&lt;p&gt;Spark offers two approaches to streaming: &lt;a href=&quot;https://spark.apache.org/docs/latest/streaming-programming-guide.html&quot;&gt;Discretized Streaming&lt;/a&gt; (or DStreams) and &lt;a href=&quot;https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html&quot;&gt;Structured Streaming&lt;/a&gt;. DStreams are a basic abstraction that represents a continuous series of &lt;a href=&quot;https://spark.apache.org/docs/latest/rdd-programming-guide.html&quot;&gt;Resilient Distributed Datasets&lt;/a&gt; (or RDDs). Structured Streaming was introduced more recently (the alpha release came with Spark 2.1.0) and is based on a &lt;a href=&quot;https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#programming-model&quot;&gt;model&lt;/a&gt; where live data is continuously appended to a table structure.&lt;/p&gt;

&lt;p&gt;Spark Structured Streaming supports &lt;a href=&quot;https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/streaming/DataStreamReader.html&quot;&gt;file sources&lt;/a&gt; (local filesystems and HDFS-compatible systems like Cloud Storage or S3) and &lt;a href=&quot;https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html&quot;&gt;Kafka&lt;/a&gt; as streaming &lt;a href=&quot;https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#input-sources&quot;&gt;inputs&lt;/a&gt;. Spark maintains built-in connectors for DStreams aimed at third-party services, such as Kafka or Flume, while other connectors are available through linking external dependencies, as shown in the table below.&lt;/p&gt;

&lt;p&gt;Below are the main streaming input connectors for available for Beam and Spark DStreams in Java:&lt;/p&gt;

&lt;table class=&quot;table table-bordered&quot;&gt;
  &lt;tr&gt;
   &lt;td&gt;
   &lt;/td&gt;
   &lt;td&gt;
   &lt;/td&gt;
   &lt;td&gt;&lt;strong&gt;Apache Beam&lt;/strong&gt;
   &lt;/td&gt;
   &lt;td&gt;&lt;strong&gt;Apache Spark DStreams&lt;/strong&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td rowspan=&quot;2&quot;&gt;File Systems
   &lt;/td&gt;
   &lt;td&gt;Local&lt;br /&gt;(Using the &lt;code&gt;file://&lt;/code&gt; URI)
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;/documentation/sdks/javadoc/2.6.0/org/apache/beam/sdk/io/TextIO.html&quot;&gt;TextIO&lt;/a&gt;
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;https://spark.apache.org/docs/latest/api/java/org/apache/spark/streaming/StreamingContext.html#textFileStream-java.lang.String-&quot;&gt;textFileStream&lt;/a&gt;&lt;br /&gt;(Spark treats most Unix systems as HDFS-compatible, but the location should be accessible from all nodes)
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;HDFS&lt;br /&gt;(Using the &lt;code&gt;hdfs://&lt;/code&gt; URI)
   &lt;/td&gt;
    &lt;td&gt;&lt;a href=&quot;/documentation/sdks/javadoc/2.6.0/org/apache/beam/sdk/io/FileIO.html&quot;&gt;FileIO&lt;/a&gt; + &lt;a href=&quot;/documentation/sdks/javadoc/2.6.0/org/apache/beam/sdk/io/hdfs/HadoopFileSystemOptions.html&quot;&gt;HadoopFileSystemOptions&lt;/a&gt;
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;https://spark.apache.org/docs/latest/api/java/org/apache/spark/streaming/util/HdfsUtils.html&quot;&gt;HdfsUtils&lt;/a&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td rowspan=&quot;2&quot;&gt;Object Stores
   &lt;/td&gt;
   &lt;td&gt;Cloud Storage&lt;br /&gt;(Using the &lt;code&gt;gs://&lt;/code&gt; URI)
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;/documentation/sdks/javadoc/2.6.0/org/apache/beam/sdk/io/FileIO.html&quot;&gt;FileIO&lt;/a&gt; + &lt;a href=&quot;/documentation/sdks/javadoc/2.6.0/org/apache/beam/sdk/extensions/gcp/options/GcsOptions.html&quot;&gt;GcsOptions&lt;/a&gt;
   &lt;/td&gt;
   &lt;td rowspan=&quot;2&quot;&gt;&lt;a href=&quot;https://spark.apache.org/docs/latest/api/java/org/apache/spark/SparkContext.html#hadoopConfiguration--&quot;&gt;hadoopConfiguration&lt;/a&gt;
and &lt;a href=&quot;https://spark.apache.org/docs/latest/api/java/org/apache/spark/streaming/StreamingContext.html#textFileStream-java.lang.String-&quot;&gt;textFileStream&lt;/a&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;S3&lt;br /&gt;(Using the &lt;code&gt;s3://&lt;/code&gt; URI)
   &lt;/td&gt;
    &lt;td&gt;&lt;a href=&quot;/documentation/sdks/javadoc/2.6.0/org/apache/beam/sdk/io/FileIO.html&quot;&gt;FileIO&lt;/a&gt; + &lt;a href=&quot;/documentation/sdks/javadoc/2.6.0/org/apache/beam/sdk/io/aws/options/S3Options.html&quot;&gt;S3Options&lt;/a&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td rowspan=&quot;3&quot;&gt;Messaging Queues
   &lt;/td&gt;
   &lt;td&gt;Kafka
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;/documentation/sdks/javadoc/2.6.0/org/apache/beam/sdk/io/kafka/KafkaIO.html&quot;&gt;KafkaIO&lt;/a&gt;
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;https://spark.apache.org/docs/latest/streaming-kafka-0-10-integration.html&quot;&gt;spark-streaming-kafka&lt;/a&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;Kinesis
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;/documentation/sdks/javadoc/2.6.0/org/apache/beam/sdk/io/kinesis/KinesisIO.html&quot;&gt;KinesisIO&lt;/a&gt;
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;https://spark.apache.org/docs/latest/streaming-kinesis-integration.html&quot;&gt;spark-streaming-kinesis&lt;/a&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;Cloud Pub/Sub
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;/documentation/sdks/javadoc/2.6.0/org/apache/beam/sdk/io/gcp/pubsub/PubsubIO.html&quot;&gt;PubsubIO&lt;/a&gt;
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/bahir/tree/master/streaming-pubsub&quot;&gt;spark-streaming-pubsub&lt;/a&gt; from &lt;a href=&quot;http://bahir.apache.org&quot;&gt;Apache Bahir&lt;/a&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;Other
   &lt;/td&gt;
   &lt;td&gt;Custom receivers
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;/documentation/io/authoring-overview/#read-transforms&quot;&gt;Read Transforms&lt;/a&gt;
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;https://spark.apache.org/docs/latest/streaming-custom-receivers.html&quot;&gt;receiverStream&lt;/a&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;h2 id=&quot;connectors-for-python&quot;&gt;Connectors for Python&lt;/h2&gt;

&lt;p&gt;Beam has an official &lt;a href=&quot;/documentation/sdks/python/&quot;&gt;Python SDK&lt;/a&gt; that currently supports a subset of the streaming features available in the Java SDK. Active development is underway to bridge the gap between the featuresets in the two SDKs. Currently for Python, the &lt;a href=&quot;/documentation/runners/direct/&quot;&gt;Direct Runner&lt;/a&gt; and &lt;a href=&quot;/documentation/runners/dataflow/&quot;&gt;Dataflow Runner&lt;/a&gt; are supported, and &lt;a href=&quot;/documentation/sdks/python-streaming/&quot;&gt;several streaming options&lt;/a&gt; were introduced in beta in &lt;a href=&quot;/blog/2018/06/26/beam-2.5.0.html&quot;&gt;version 2.5.0&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Spark also has a Python SDK called &lt;a href=&quot;http://spark.apache.org/docs/latest/api/python/pyspark.html&quot;&gt;PySpark&lt;/a&gt;. As mentioned earlier, Scala code compiles to a bytecode that is executed by the JVM. PySpark uses &lt;a href=&quot;https://www.py4j.org/&quot;&gt;Py4J&lt;/a&gt;, a library that enables Python programs to interact with the JVM and therefore access Java libraries, interact with Java objects, and register callbacks from Java. This allows PySpark to access native Spark objects like RDDs. Spark Structured Streaming supports &lt;a href=&quot;http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.streaming.DataStreamReader&quot;&gt;file sources&lt;/a&gt; (local filesystems and HDFS-compatible systems like Cloud Storage or S3) and &lt;a href=&quot;https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html&quot;&gt;Kafka&lt;/a&gt; as streaming inputs.&lt;/p&gt;

&lt;p&gt;Below are the main streaming input connectors for available for Beam and Spark DStreams in Python:&lt;/p&gt;

&lt;table class=&quot;table table-bordered&quot;&gt;
  &lt;tr&gt;
   &lt;td&gt;
   &lt;/td&gt;
   &lt;td&gt;
   &lt;/td&gt;
   &lt;td&gt;&lt;strong&gt;Apache Beam&lt;/strong&gt;
   &lt;/td&gt;
   &lt;td&gt;&lt;strong&gt;Apache Spark DStreams&lt;/strong&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td rowspan=&quot;2&quot;&gt;File Systems
   &lt;/td&gt;
   &lt;td&gt;Local
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;/documentation/sdks/pydoc/2.6.0/apache_beam.io.textio.html&quot;&gt;io.textio&lt;/a&gt;
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;http://spark.apache.org/docs/latest/api/python/pyspark.streaming.html#pyspark.streaming.StreamingContext.textFileStream&quot;&gt;textFileStream&lt;/a&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;HDFS
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;/documentation/sdks/pydoc/2.6.0/apache_beam.io.hadoopfilesystem.html&quot;&gt;io.hadoopfilesystem&lt;/a&gt;
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;https://spark.apache.org/docs/latest/api/java/org/apache/spark/SparkContext.html#hadoopConfiguration--&quot;&gt;hadoopConfiguration&lt;/a&gt; (Access through &lt;code&gt;sc._jsc&lt;/code&gt; with Py4J)
and &lt;a href=&quot;http://spark.apache.org/docs/latest/api/python/pyspark.streaming.html#pyspark.streaming.StreamingContext.textFileStream&quot;&gt;textFileStream&lt;/a&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td rowspan=&quot;2&quot;&gt;Object stores
   &lt;/td&gt;
   &lt;td&gt;Google Cloud Storage
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;/documentation/sdks/pydoc/2.6.0/apache_beam.io.gcp.gcsio.html&quot;&gt;io.gcp.gcsio&lt;/a&gt;
   &lt;/td&gt;
   &lt;td rowspan=&quot;2&quot;&gt;&lt;a href=&quot;http://spark.apache.org/docs/latest/api/python/pyspark.streaming.html#pyspark.streaming.StreamingContext.textFileStream&quot;&gt;textFileStream&lt;/a&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;S3
   &lt;/td&gt;
   &lt;td&gt;N/A
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td rowspan=&quot;3&quot;&gt;Messaging Queues
   &lt;/td&gt;
   &lt;td&gt;Kafka
   &lt;/td&gt;
   &lt;td&gt;N/A
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;http://spark.apache.org/docs/latest/api/python/pyspark.streaming.html#pyspark.streaming.kafka.KafkaUtils&quot;&gt;KafkaUtils&lt;/a&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;Kinesis
   &lt;/td&gt;
   &lt;td&gt;N/A
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;http://spark.apache.org/docs/latest/api/python/pyspark.streaming.html#module-pyspark.streaming.kinesis&quot;&gt;KinesisUtils&lt;/a&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;Cloud Pub/Sub
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;/documentation/sdks/pydoc/2.6.0/apache_beam.io.gcp.pubsub.html&quot;&gt;io.gcp.pubsub&lt;/a&gt;
   &lt;/td&gt;
   &lt;td&gt;N/A
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;Other
   &lt;/td&gt;
   &lt;td&gt;Custom receivers
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;/documentation/sdks/python-custom-io/&quot;&gt;BoundedSource and RangeTracker&lt;/a&gt;
   &lt;/td&gt;
   &lt;td&gt;N/A
   &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;h2 id=&quot;connectors-for-other-languages&quot;&gt;Connectors for other languages&lt;/h2&gt;

&lt;h3 id=&quot;scala&quot;&gt;Scala&lt;/h3&gt;

&lt;p&gt;Since Scala code is interoperable with Java and therefore has native compatibility with Java libraries (and vice versa), you can use the same Java connectors described above in your Scala programs. Apache Beam also has a &lt;a href=&quot;https://github.com/spotify/scio&quot;&gt;Scala API&lt;/a&gt; open-sourced &lt;a href=&quot;https://labs.spotify.com/2017/10/16/big-data-processing-at-spotify-the-road-to-scio-part-1/&quot;&gt;by Spotify&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;go&quot;&gt;Go&lt;/h3&gt;

&lt;p&gt;A &lt;a href=&quot;/documentation/sdks/go/&quot;&gt;Go SDK&lt;/a&gt; for Apache Beam is under active development. It is currently experimental and is not recommended for production. Spark does not have an official Go SDK.&lt;/p&gt;

&lt;h3 id=&quot;r&quot;&gt;R&lt;/h3&gt;

&lt;p&gt;Apache Beam does not have an official R SDK. Spark Structured Streaming is supported by an &lt;a href=&quot;https://spark.apache.org/docs/latest/sparkr.html#structured-streaming&quot;&gt;R SDK&lt;/a&gt;, but only for &lt;a href=&quot;https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#input-sources&quot;&gt;file sources&lt;/a&gt; as a streaming input.&lt;/p&gt;

&lt;h2 id=&quot;next-steps&quot;&gt;Next steps&lt;/h2&gt;

&lt;p&gt;We hope this article inspired you to try new and interesting ways of connecting streaming sources to your Beam pipelines!&lt;/p&gt;

&lt;p&gt;Check out the following links for further information:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;See a full list of all built-in and in-progress &lt;a href=&quot;/documentation/io/built-in/&quot;&gt;I/O Transforms&lt;/a&gt; for Apache Beam.&lt;/li&gt;
  &lt;li&gt;Learn about some Apache Beam mobile gaming pipeline &lt;a href=&quot;/get-started/mobile-gaming-example/&quot;&gt;examples&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Mon, 20 Aug 2018 01:00:01 -0700</pubDate>
        <link>https://beam.apache.org/blog/2018/08/20/review-input-streaming-connectors.html</link>
        <guid isPermaLink="true">https://beam.apache.org/blog/2018/08/20/review-input-streaming-connectors.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Apache Beam 2.6.0</title>
        <description>&lt;!--
Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;

&lt;p&gt;We are glad to present the new 2.6.0 release of Beam.
This release includes multiple fixes and new functionality, such as new features in SQL and portability.&lt;!--more--&gt;
We also spent a significant amount of time automating the release and fixing continuous integration. For more information, check the
&lt;a href=&quot;https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12319527&amp;amp;version=12343392&quot;&gt;release notes&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;new-features--improvements&quot;&gt;New Features / Improvements&lt;/h2&gt;

&lt;h3 id=&quot;grpcprotobuf-shading&quot;&gt;gRPC/Protobuf shading&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;gRPC/protobuf&lt;/code&gt; is now shaded in the majority of Apache Beam
Java modules. A few modules which expose &lt;code class=&quot;highlighter-rouge&quot;&gt;gRPC/protobuf&lt;/code&gt; on the
API surface still maintain a direct dependency.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;beam-sql&quot;&gt;Beam SQL&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Added support for the &lt;code class=&quot;highlighter-rouge&quot;&gt;EXISTS&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;LIKE&lt;/code&gt; operators.&lt;/li&gt;
  &lt;li&gt;Implemented &lt;code class=&quot;highlighter-rouge&quot;&gt;SUM()&lt;/code&gt; aggregations.&lt;/li&gt;
  &lt;li&gt;Fixed issues with the &lt;code class=&quot;highlighter-rouge&quot;&gt;CASE&lt;/code&gt; expression.&lt;/li&gt;
  &lt;li&gt;Added support for date comparisons.&lt;/li&gt;
  &lt;li&gt;Added unbounded data support to &lt;code class=&quot;highlighter-rouge&quot;&gt;LIMIT&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;portability&quot;&gt;Portability&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Shared libraries for supporting timers and user state
are now available for runner integration.&lt;/li&gt;
  &lt;li&gt;Added a Universal Local Runner, which works on a single machine using portability and containerized SDK harnesses.&lt;/li&gt;
  &lt;li&gt;The Flink Runner now accepts jobs using the Job API.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ios&quot;&gt;IOs&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Bounded &lt;code class=&quot;highlighter-rouge&quot;&gt;SplittableDoFn&lt;/code&gt; (SDF) support is now available in all
runners (SDF is the new I/O connector API).&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;HBaseIO&lt;/code&gt; is the first I/O supporting Bounded SDF (using
&lt;code class=&quot;highlighter-rouge&quot;&gt;readAll&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;sdks&quot;&gt;SDKs&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Improved Python &lt;code class=&quot;highlighter-rouge&quot;&gt;AvroIO&lt;/code&gt; performance.&lt;/li&gt;
  &lt;li&gt;Python &lt;code class=&quot;highlighter-rouge&quot;&gt;AvroIO&lt;/code&gt; has a &lt;code class=&quot;highlighter-rouge&quot;&gt;use_fastavro&lt;/code&gt; option that uses
&lt;code class=&quot;highlighter-rouge&quot;&gt;fastavro&lt;/code&gt; instead of &lt;code class=&quot;highlighter-rouge&quot;&gt;apache/avro&lt;/code&gt;, for a
&lt;a href=&quot;https://gist.github.com/ryan-williams/ede5ae61605e7ba6aa655071858ef52b&quot;&gt;3-6x speedup&lt;/a&gt;!&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;other&quot;&gt;Other&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Updated various dependency versions.&lt;/li&gt;
  &lt;li&gt;Improvements to stability, performance, and documentation.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;list-of-contributors&quot;&gt;List of Contributors&lt;/h2&gt;

&lt;p&gt;According to git shortlog, the following 39 people contributed
to the 2.6.0 release. Thank you to all contributors!&lt;/p&gt;

&lt;p&gt;Ahmet Altay, Alan Myrvold, Alexey Romanenko, Andrew Pilloud,
Ankur Goenka, Boyuan Zhang, Charles Chen, cclauss,
Daniel Oliveira, Elliott Brossard, Eric Beach,
Etienne Chauchot, Eugene Kirpichov, Henning Rohde,
Ismaël Mejía, Kai Jiang, Kasia, Kenneth Knowles, Luis Osa,
Lukasz Cwik, Maria Garcia Herrero, Mark Liu, Matthias Feys,
Pablo Estrada, Rafael Fernandez, Reuven Lax, Robert Bradshaw,
Robert Burke, Robin Qiu, Ryan Williams, Scott Wegner, Rui Weng,
Sergei Lebedev, Sindy Li, Thomas Weise, Udi Meiri,
Valentyn Tymofieiev, XuMingmin, and Yifan Zou.&lt;/p&gt;
</description>
        <pubDate>Fri, 10 Aug 2018 01:00:01 -0700</pubDate>
        <link>https://beam.apache.org/blog/2018/08/10/beam-2.6.0.html</link>
        <guid isPermaLink="true">https://beam.apache.org/blog/2018/08/10/beam-2.6.0.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Apache Beam 2.5.0</title>
        <description>&lt;!--
Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;

&lt;p&gt;We are glad to present the new 2.5.0 release of Beam. This release includes
multiple fixes and new functionalities. &lt;!--more--&gt; For more information
please check the detailed release notes.&lt;/p&gt;

&lt;h1 id=&quot;new-features--improvements&quot;&gt;New Features / Improvements&lt;/h1&gt;

&lt;h2 id=&quot;go-sdk-support&quot;&gt;Go SDK support&lt;/h2&gt;
&lt;p&gt;The Go SDK has been officially accepted into the project, after an incubation period and community effort. Go pipelines run on Dataflow runner. More details are &lt;a href=&quot;https://beam.apache.org/documentation/sdks/go/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;parquet-support&quot;&gt;Parquet support&lt;/h2&gt;
&lt;p&gt;Support for Apache Parquet format was added. It uses Parquet 1.10 release which, thanks to AvroParquerWriter’s API changes, allows FileIO.Sink implementation.&lt;/p&gt;

&lt;h2 id=&quot;performanceintegration-tests&quot;&gt;Performance/Integration Tests&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Added new integration tests - HCatalogIOIT (Hive), HBaseIOIT, ParquetIOIT (with the IO itself, local filesystem, HDFS)&lt;/li&gt;
  &lt;li&gt;Multinode (3 data node) HDFS cluster is used for running tests on HDFS.&lt;/li&gt;
  &lt;li&gt;Several improvements on performance tests running and results analysis.&lt;/li&gt;
  &lt;li&gt;Scaled up Kubernetes cluster from 1 to 3 nodes.&lt;/li&gt;
  &lt;li&gt;Added metrics in Spark streaming.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;internal-build-system-migrated-to-gradle&quot;&gt;Internal Build System: Migrated to Gradle&lt;/h2&gt;
&lt;p&gt;After a months-long community effort, the internal Beam build has been migrated from Maven to Gradle. The new build system was chosen because of dependency-driven build support, incremental build/test, and support for non-Java languages.&lt;/p&gt;

&lt;h2 id=&quot;nexmark-improvements&quot;&gt;Nexmark Improvements&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Kafka support as a source/sink for events and results.&lt;/li&gt;
  &lt;li&gt;Translation of some queries to Beam SQL.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;beam-sql&quot;&gt;Beam SQL&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Support for MAP, ROW, ARRAY data types&lt;/li&gt;
  &lt;li&gt;Support UNNEST on array fields&lt;/li&gt;
  &lt;li&gt;Improved optimizations&lt;/li&gt;
  &lt;li&gt;Upgrade Calcite to 1.16&lt;/li&gt;
  &lt;li&gt;Support SQL on POJOs via automatic conversion&lt;/li&gt;
  &lt;li&gt;Schema moved into core Beam&lt;/li&gt;
  &lt;li&gt;UDAFs can be indirect suclasses of CombineFn&lt;/li&gt;
  &lt;li&gt;Many other small bugfixes&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;portability&quot;&gt;Portability&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Common shared code related to supporting portable execution for runners.&lt;/li&gt;
  &lt;li&gt;Python SDK supporting side inputs over the portability APIs.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;extract-metrics-in-a-runner-agnostic-way&quot;&gt;Extract metrics in a runner agnostic way&lt;/h2&gt;
&lt;p&gt;Metrics are pushed by the runners to configurable sinks (Http REST sink available). It is already enabled in Flink and Spark runner, work is in progress for Dataflow.&lt;/p&gt;

&lt;h1 id=&quot;miscellaneous-fixes&quot;&gt;Miscellaneous Fixes&lt;/h1&gt;

&lt;h2 id=&quot;sdks&quot;&gt;SDKs&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Implemented HDFS FileSystem for Python SDK.&lt;/li&gt;
  &lt;li&gt;Python SDK adds support for side inputs for streaming execution.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;runners&quot;&gt;Runners&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Updated Spark runner to Spark version 2.3.1&lt;/li&gt;
  &lt;li&gt;Fixed issue with late elements windowed into expired fixed windows get dropped in Directrunner.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ios&quot;&gt;IOs&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;CassandraIO gained a better split algorithm based on overlapping regions.&lt;/li&gt;
  &lt;li&gt;ElasticsearchIO supports partial updates.&lt;/li&gt;
  &lt;li&gt;ElasticsearchIO allows to pass id, type and index per document.&lt;/li&gt;
  &lt;li&gt;SolrIO supports a more robust retry on write strategy.&lt;/li&gt;
  &lt;li&gt;S3 FileSystem supports encryption (SSE-S3, SSE-C and SSE-KMS).&lt;/li&gt;
  &lt;li&gt;Improved connection management in JdbcIO.&lt;/li&gt;
  &lt;li&gt;Added support the element timestamps while publishing to Kafka.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;other&quot;&gt;Other&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Use Java ErrorProne for static analysis.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;list-of-contributors&quot;&gt;List of Contributors&lt;/h1&gt;

&lt;p&gt;According to git shortlog, the following 84 people contributed to the 2.5.0 release. Thank you to all contributors!&lt;/p&gt;

&lt;p&gt;Ahmet Altay, Alan Myrvold, Alex Amato, Alex Van Boxel, Alexander Dejanovski, Alexey Romanenko, Aljoscha Krettek, ananvay, Andreas Ehrencrona, Andrew Pilloud, Ankur Goenka, Anton Kedin, arkash, Austin Bennett, Axel Magnuson, Ben Chambers, Ben Sidhom, Bill Neubauer, Boyuan Zhang, Braden Bassingthwaite, Cade Markegard, cclauss, Chamikara Jayalath, Charles Chen, Chuan Yu Foo, Cody Schroeder, Colm O hEigeartaigh, Daniel Oliveira, Dariusz Aniszewski, David Cavazos, Dawid Wysakowicz, Eric Roshan-Eisner, Etienne Chauchot, Eugene Kirpichov, Flavio Fiszman, Geet Kumar, GlennAmmons, Grzegorz Kołakowski, Henning Rohde, Innocent Djiofack, Ismaël Mejía, Jack Hsueh, Jason Kuster, Javier Antonio Gonzalez Trejo, Jean-Baptiste Onofré, Kai Jiang, Kamil Szewczyk, Katarzyna Kucharczyk, Kenneth Jung, Kenneth Knowles, Kevin Peterson, Lukasz Cwik, Łukasz Gajowy, Mairbek Khadikov, Manu Zhang, Maria Garcia Herrero, Marian Dvorsky, Mark Liu, Matthias Feys, Matthias Wessendorf, mingmxu, Nathan Howell, Pablo Estrada, Paul Gerver, Raghu Angadi, rarokni, Reuven Lax, Rezan Achmad, Robbe Sneyders, Robert Bradshaw, Robert Burke, Romain Manni-Bucau, Sam Waggoner, Sam Whittle, Scott Wegner, Stephan Hoyer, Thomas Groh, Thomas Weise, Tim Robertson, Udi Meiri, Valentyn Tymofieiev, XuMingmin, Yifan Zou, Yunqing Zhou&lt;/p&gt;
</description>
        <pubDate>Tue, 26 Jun 2018 01:00:01 -0700</pubDate>
        <link>https://beam.apache.org/blog/2018/06/26/beam-2.5.0.html</link>
        <guid isPermaLink="true">https://beam.apache.org/blog/2018/06/26/beam-2.5.0.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Apache Beam 2.3.0</title>
        <description>&lt;!--
Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;

&lt;p&gt;We are glad to present the new 2.3.0 release of Beam. This release includes
multiple fixes and new functionalities. &lt;!--more--&gt; For more information
please check the detailed release notes.&lt;/p&gt;

&lt;h1 id=&quot;new-features--improvements&quot;&gt;New Features / Improvements&lt;/h1&gt;

&lt;h2 id=&quot;beam-moves-to-java-8&quot;&gt;Beam moves to Java 8&lt;/h2&gt;

&lt;p&gt;The supported version of Java for Beam is now Java 8. The code and examples have
been refactored to use multiple of the advantages of the language, e.g. lambdas,
streams, improved type inference, etc.&lt;/p&gt;

&lt;h2 id=&quot;spark-runner-is-now-based-on-spark-2x&quot;&gt;Spark runner is now based on Spark 2.x&lt;/h2&gt;

&lt;p&gt;Spark runner moves forward into the Spark 2.x development line, this would allow
to benefit of improved performance, as well as open the runner for future
compatibility with the Structured Streaming APIs. Notice that support for Spark
1.x is finished with this release.&lt;/p&gt;

&lt;h2 id=&quot;amazon-web-services-s3-filesystem-support&quot;&gt;Amazon Web Services S3 Filesystem support&lt;/h2&gt;

&lt;p&gt;Beam already supported AWS S3 via HadoopFileSystem, but this version brings a
native implementation with the corresponding performance advantages of the S3
filesystem.&lt;/p&gt;

&lt;h2 id=&quot;general-purpose-writing-to-files&quot;&gt;General-purpose writing to files&lt;/h2&gt;

&lt;p&gt;This release contains a new transform, FileIO.write() / writeDynamic() that
implements a general-purpose fluent and Java8-friendly API for writing to files
using a FileIO.Sink. This API has similar capabilities to DynamicDestinations
APIs from Beam 2.2 but is much easier to use and extend. The DynamicDestinations
APIs for writing to files are deprecated by it, as is FileBasedSink.&lt;/p&gt;

&lt;h2 id=&quot;splittable-dofn-support-on-the-python-sdk&quot;&gt;Splittable DoFn support on the Python SDK&lt;/h2&gt;

&lt;p&gt;This release adds the Splittable DoFn API for Python SDK and adds Splittable
DoFn support for Python streaming DirectRunner.&lt;/p&gt;

&lt;h2 id=&quot;portability&quot;&gt;Portability&lt;/h2&gt;

&lt;p&gt;Progress continues to being able to execute Python on runners other then Google
Cloud Dataflow and the Go SDK on any runner.&lt;/p&gt;

&lt;h1 id=&quot;miscellaneous-fixes&quot;&gt;Miscellaneous Fixes&lt;/h1&gt;

&lt;h2 id=&quot;sdks&quot;&gt;SDKs&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;MapElements and FlatMapElements support using side inputs using the new
interface Contextful.Fn. For library authors, this interface is the
recommended choice for user-code callbacks that may use side inputs.&lt;/li&gt;
  &lt;li&gt;Introduces the family of Reify transforms for converting between explicit and
implicit representations of various Beam entities.&lt;/li&gt;
  &lt;li&gt;Introduces two transforms for approximate sketching of data: Count-Min Sketch
(approximate element frequency estimation) and HyperLogLog (approximate
cardinality estimation).&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;runners&quot;&gt;Runners&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Staging files on Dataflow shows progress&lt;/li&gt;
  &lt;li&gt;Flink runner is based now on Flink version 1.4.0&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ios&quot;&gt;IOs&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;BigtableIO now supports ValueProvider configuration&lt;/li&gt;
  &lt;li&gt;BigQueryIO supports writing bounded collections to tables with partition
decorators&lt;/li&gt;
  &lt;li&gt;KafkaIO moves to version 1.0 (it is still backwards compatible with versions &amp;gt;= 0.9.x.x)&lt;/li&gt;
  &lt;li&gt;Added IO source for VCF files (Python)&lt;/li&gt;
  &lt;li&gt;Added support for backoff on deadlocks in JdbcIO.write() and connection
improvement&lt;/li&gt;
  &lt;li&gt;Improved performance of KinesisIO.read()&lt;/li&gt;
  &lt;li&gt;Many improvements to TikaIO&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;list-of-contributors&quot;&gt;List of Contributors&lt;/h1&gt;

&lt;p&gt;According to git shortlog, the following 78 people contributed to the 2.3.0 release. Thank you to all contributors!&lt;/p&gt;

&lt;p&gt;Ahmet Altay, Alan Myrvold, Alex Amato, Alexey Romanenko, Ankur Goenka, Anton Kedin, Arnaud Fournier, Asha Rostamianfar, Ben Chambers, Ben Sidhom, Bill Neubauer, Brian Foo, cclauss, Chamikara Jayalath, Charles Chen, Colm O hEigeartaigh, Daniel Oliveira, Dariusz Aniszewski, David Cavazos, David Sabater, David Sabater Dinter, Dawid Wysakowicz, Dmytro Ivanov, Etienne Chauchot, Eugene Kirpichov, Exprosed, Grzegorz Kołakowski, Henning Rohde, Holden Karau, Huygaa Batsaikhan, Ilya Figotin, Innocent Djiofack, Ismaël Mejía, Itamar Ostricher, Jacky, Jacob Marble, James Xu, Jean-Baptiste Onofré, Jeremie Lenfant-Engelmann, Kamil Szewczyk, Kenneth Knowles, Lukasz Cwik, Łukasz Gajowy, Luke Zhu, Mairbek Khadikov, María García Herrero, Marian Dvorsky, Mark Liu, melissa, Miles Saul, mingmxu, Motty Gruda, nerdynick, Neville Li, Nigel Kilmer, Pablo, Pawel Kaczmarczyk, Petr Shevtsov, Rafal Wojdyla, Raghu Angadi, Robert Bradshaw, Robert Burke, Romain Manni-Bucau, Ryan Niemocienski, Ryan Skraba, Sam Whittle, Scott Wegner, Shashank Prabhakara, Solomon Duskis, Thomas Groh, Thomas Weise, Udi Meiri, Valentyn Tymofieiev, wtanaka.com, XuMingmin, zhouhai02, Zohar Yahav, 琨瑜.&lt;/p&gt;

</description>
        <pubDate>Mon, 19 Feb 2018 00:00:01 -0800</pubDate>
        <link>https://beam.apache.org/blog/2018/02/19/beam-2.3.0.html</link>
        <guid isPermaLink="true">https://beam.apache.org/blog/2018/02/19/beam-2.3.0.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Apache Beam: A Look Back at 2017</title>
        <description>&lt;!--
Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;

&lt;p&gt;On January 10, 2017, Apache Beam got &lt;a href=&quot;/blog/2017/01/10/beam-graduates.html&quot;&gt;promoted&lt;/a&gt;
as a Top-Level Apache Software Foundation project. It was an important milestone
that validated the value of the project, legitimacy of its community, and
heralded its growing adoption. In the past year, Apache Beam has been on a
phenomenal growth trajectory, with significant growth in its community and
feature set. Let us walk you through some of the notable achievements.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;use-cases&quot;&gt;Use cases&lt;/h2&gt;

&lt;p&gt;First, lets take a glimpse at how Beam was used in 2017. Apache Beam being a
unified framework for batch and stream processing, enables a very wide spectrum
of diverse use cases. Here are some use cases that exemplify the versatility of
Beam.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-block&quot; src=&quot;/images/blog/2017-look-back/timeline.png&quot; alt=&quot;Use Cases&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;community-growth&quot;&gt;Community growth&lt;/h2&gt;

&lt;p&gt;In 2017, Apache Beam had 174 contributors worldwide, from many different
organizations. As an Apache project, we are proud to count 18 PMC members and
31 committers. The community had 7 releases in 2017, each bringing a rich set of
new features and fixes.&lt;/p&gt;

&lt;p&gt;The most obvious and encouraging sign of the growth of Apache Beam’s community,
and validation of its core value proposition of portability, is the addition of
significant new &lt;a href=&quot;/documentation/runners/capability-matrix/&quot;&gt;runners&lt;/a&gt;
(i.e. execution engines). We entered 2017 with Apache Flink, Apache Spark 1.x,
Google Cloud Dataflow, Apache Apex, and Apache Gearpump. In 2017, the following
new and updated runners were developed:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Apache Spark 2.x update&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.ibm.com/blogs/bluemix/2017/10/streaming-analytics-updates-ibm-streams-runner-apache-beam-2-0/&quot;&gt;IBM Streams runner&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;MapReduce runner&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://jstorm.io/&quot;&gt;JStorm runner&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In addition to runners, Beam added new IO connectors, some notable ones being
the Cassandra, MQTT, AMQP, HBase/HCatalog, JDBC, Solr, Tika, Redis, and
ElasticSearch connectors. Beam’s IO connectors make it possible to read from or
write to data sources/sinks even when they are not natively supported by the
underlying execution engine. Beam also provides fully pluggable filesystem
support, allowing us to support and extend our coverage to HDFS, S3, Azure
Storage, and Google Storage. We continue to add new IO connectors and
filesystems to extend the Beam use cases.&lt;/p&gt;

&lt;p&gt;A particularly telling sign of the maturity of an open source community is when
it is able to collaborate with multiple other open source communities, and
mutually improve the state of the art. Over the past few months, the Beam,
Calcite, and Flink communities have come together to define a robust &lt;a href=&quot;https://docs.google.com/document/d/1wrla8mF_mmq-NW9sdJHYVgMyZsgCmHumJJ5f5WUzTiM/edit&quot;&gt;spec&lt;/a&gt;
for Streaming SQL, with engineers from over four organizations contributing to
it. If, like us, you are excited by the prospect of improving the state of
streaming SQL, please join us!&lt;/p&gt;

&lt;p&gt;In addition to SQL, new XML and JSON based declarative DSLs are also in PoC.&lt;/p&gt;

&lt;h2 id=&quot;continued-innovation&quot;&gt;Continued innovation&lt;/h2&gt;

&lt;p&gt;Innovation is important to the success on any open source project, and Beam has
a rich history of bringing innovative new ideas to the open source community.
Apache Beam was the first to introduce some seminal concepts in the world of
big-data processing:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Unified batch and streaming SDK that enables users to author big-data jobs
without having to learn multiple disparate SDKs/APIs.&lt;/li&gt;
  &lt;li&gt;Cross-Engine Portability: Giving enterprises the confidence that workloads
authored today will not have to be re-written when open source engines become
outdated and are supplanted by newer ones.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101&quot;&gt;Semantics&lt;/a&gt;
essential for reasoning about unbounded unordered data, and achieving
consistent and correct output from a streaming job.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In 2017, the pace of innovation continued. The following capabilities were
introduced:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Cross-Language Portability framework, and a &lt;a href=&quot;https://golang.org/&quot;&gt;Go&lt;/a&gt; SDK
developed with it.&lt;/li&gt;
  &lt;li&gt;Dynamically Shardable IO (SplittableDoFn)&lt;/li&gt;
  &lt;li&gt;Support for schemas in PCollection, allowing us to extend the runner
capabilities.&lt;/li&gt;
  &lt;li&gt;Extensions addressing new use cases such as machine learning, and new data
formats.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;areas-of-improvement&quot;&gt;Areas of improvement&lt;/h2&gt;

&lt;p&gt;Any retrospective view of a project is incomplete without an honest assessment
of areas of improvement. Two aspects stand out:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Helping runners showcase their individual strengths. After all, portability
does not imply homogeneity. Different runners have different areas in which
they excel, and we need to do a better job of helping them highlight their
strengths.&lt;/li&gt;
  &lt;li&gt;Based on the previous point, helping customers make a more informed decision
when they select a runner or migrate from one to another.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In 2018, we aim to take proactive steps to improve the above aspects.&lt;/p&gt;

&lt;h2 id=&quot;ethos-of-the-project-and-its-community&quot;&gt;Ethos of the project and its community&lt;/h2&gt;

&lt;p&gt;The world of batch and stream big-data processing today is reminiscent of the
&lt;a href=&quot;https://en.wikipedia.org/wiki/Tower_of_Babel&quot;&gt;Tower of Babel&lt;/a&gt; parable: a
slowdown of progress because different communities spoke different languages.
Similarly, today there are multiple disparate big-data SDKs/APIs, each with
their own distinct terminology to describe similar concepts. The side effect is
user confusion and slower adoption.&lt;/p&gt;

&lt;p&gt;The Apache Beam project aims to provide an industry standard portable SDK that
will:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Benefit users by providing &lt;strong&gt;&lt;em&gt;innovation with stability&lt;/em&gt;&lt;/strong&gt;: The separation of
SDK and engine enables healthy competition between runners, without requiring
users to constantly learn new SDKs/APIs and rewrite their workloads to
benefit from new innovation.&lt;/li&gt;
  &lt;li&gt;Benefit big-data engines by &lt;strong&gt;&lt;em&gt;growing the pie for everyone&lt;/em&gt;&lt;/strong&gt;: Making it
easier for users to author, maintain, upgrade and migrate their big-data
workloads will lead to significant growth in the number of production
big-data deployments.&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Tue, 09 Jan 2018 00:00:01 -0800</pubDate>
        <link>https://beam.apache.org/blog/2018/01/09/beam-a-look-back.html</link>
        <guid isPermaLink="true">https://beam.apache.org/blog/2018/01/09/beam-a-look-back.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Timely (and Stateful) Processing with Apache Beam</title>
        <description>&lt;!--
Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;

&lt;p&gt;In a &lt;a href=&quot;/blog/2017/02/13/stateful-processing.html&quot;&gt;prior blog
post&lt;/a&gt;, I
introduced the basics of stateful processing in Apache Beam, focusing on the
addition of state to per-element processing. So-called &lt;em&gt;timely&lt;/em&gt; processing
complements stateful processing in Beam by letting you set timers to request a
(stateful) callback at some point in the future.&lt;/p&gt;

&lt;p&gt;What can you do with timers in Beam? Here are some examples:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;You can output data buffered in state after some amount of processing time.&lt;/li&gt;
  &lt;li&gt;You can take special action when the watermark estimates that you have
received all data up to a specified point in event time.&lt;/li&gt;
  &lt;li&gt;You can author workflows with timeouts that alter state and emit output in
response to the absence of additional input for some period of time.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These are just a few possibilities. State and timers together form a powerful
programming paradigm for fine-grained control to express a huge variety of
workflows.  Stateful and timely processing in Beam is portable across data
processing engines and integrated with Beam’s unified model of event time
windowing in both streaming and batch processing.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;what-is-stateful-and-timely-processing&quot;&gt;What is stateful and timely processing?&lt;/h2&gt;

&lt;p&gt;In my prior post, I developed an understanding of stateful processing largely
by contrast with associative, commutative combiners. In this post, I’ll
emphasize a perspective that I had mentioned only briefly: that elementwise
processing with access to per-key-and-window state and timers represents a
fundamental pattern for “embarrassingly parallel” computation, distinct from
the others in Beam.&lt;/p&gt;

&lt;p&gt;In fact, stateful and timely computation is the low-level computational pattern
that underlies the others. Precisely because it is lower level, it allows you
to really micromanage your computations to unlock new use cases and new
efficiencies. This incurs the complexity of manually managing your state and
timers - it isn’t magic! Let’s first look again at the two primary
computational patterns in Beam.&lt;/p&gt;

&lt;h3 id=&quot;element-wise-processing-pardo-map-etc&quot;&gt;Element-wise processing (ParDo, Map, etc)&lt;/h3&gt;

&lt;p&gt;The most elementary embarrassingly parallel pattern is just using a bunch of
computers to apply the same function to every input element of a massive
collection. In Beam, per-element processing like this is expressed as a basic
&lt;code class=&quot;highlighter-rouge&quot;&gt;ParDo&lt;/code&gt; - analogous to “Map” from MapReduce - which is like an enhanced “map”,
“flatMap”, etc, from functional programming.&lt;/p&gt;

&lt;p&gt;The following diagram illustrates per-element processing. Input elements are
squares, output elements are triangles. The colors of the elements represent
their key, which will matter later. Each input element maps to the
corresponding output element(s) completely independently. Processing may be
distributed across computers in any way, yielding essentially limitless
parallelism.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-block&quot; src=&quot;/images/blog/timely-processing/ParDo.png&quot; alt=&quot;ParDo offers limitless parallelism&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This pattern is obvious, exists in all data-parallel paradigms, and has
a simple stateless implementation. Every input element can be processed
independently or in arbitrary bundles. Balancing the work between computers is
actually the hard part, and can be addressed by splitting, progress estimation,
work-stealing, etc.&lt;/p&gt;

&lt;h3 id=&quot;per-key-and-window-aggregation-combine-reduce-groupbykey-etc&quot;&gt;Per-key (and window) aggregation (Combine, Reduce, GroupByKey, etc.)&lt;/h3&gt;

&lt;p&gt;The other embarassingly parallel design pattern at the heart of Beam is per-key
(and window) aggregation. Elements sharing a key are colocated and then
combined using some associative and commutative operator. In Beam this is
expressed as a &lt;code class=&quot;highlighter-rouge&quot;&gt;GroupByKey&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;Combine.perKey&lt;/code&gt;, and corresponds to the shuffle
and “Reduce” from MapReduce.  It is sometimes helpful to think of per-key
&lt;code class=&quot;highlighter-rouge&quot;&gt;Combine&lt;/code&gt; as the fundamental operation, and raw &lt;code class=&quot;highlighter-rouge&quot;&gt;GroupByKey&lt;/code&gt; as a combiner that
just concatenates input elements. The communication pattern for the input
elements is the same, modulo some optimizations possible for &lt;code class=&quot;highlighter-rouge&quot;&gt;Combine&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;In the illustration here, recall that the color of each element represents the
key. So all of the red squares are routed to the same location where they are
aggregated and the red triangle is the output.  Likewise for the yellow and
green squares, etc. In a real application, you may have millions of keys, so
the parallelism is still massive.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-block&quot; src=&quot;/images/blog/timely-processing/CombinePerKey.png&quot; alt=&quot;Gathering elements per key then combining them&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The underlying data processing engine will, at some level of abstraction, use
state to perform this aggregation across all the elements arriving for a key.
In particular, in a streaming execution, the aggregation process may need to
wait for more data to arrive or for the watermark to estimate that all input
for an event time window is complete. This requires some way to store the
intermediate aggregation between input elements as well a way to a receive a
callback when it is time to emit the result. As a result, the &lt;em&gt;execution&lt;/em&gt; of
per key aggregation by a stream processing engine fundamentally involves state
and timers.&lt;/p&gt;

&lt;p&gt;However, &lt;em&gt;your&lt;/em&gt; code is just a declarative expression of the aggregation
operator.  The runner can choose a variety of ways to execute your operator. 
I went over this in detail in &lt;a href=&quot;/blog/2017/02/13/stateful-processing.html&quot;&gt;my prior post focused on state alone&lt;/a&gt;. Since you do not
observe elements in any defined order, nor manipulate mutable state or timers
directly, I call this neither stateful nor timely processing.&lt;/p&gt;

&lt;h3 id=&quot;per-key-and-window-stateful-timely-processing&quot;&gt;Per-key-and-window stateful, timely processing&lt;/h3&gt;

&lt;p&gt;Both &lt;code class=&quot;highlighter-rouge&quot;&gt;ParDo&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;Combine.perKey&lt;/code&gt; are standard patterns for parallelism that go
back decades. When implementing these in a massive-scale distributed data
processing engine, we can highlight a few characteristics that are particularly
important.&lt;/p&gt;

&lt;p&gt;Let us consider these characteristics of &lt;code class=&quot;highlighter-rouge&quot;&gt;ParDo&lt;/code&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;You write single-threaded code to process one element.&lt;/li&gt;
  &lt;li&gt;Elements are processed in arbitrary order with no dependencies
or interaction between processing of elements.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And these characteristics for &lt;code class=&quot;highlighter-rouge&quot;&gt;Combine.perKey&lt;/code&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Elements for a common key and window are gathered together.&lt;/li&gt;
  &lt;li&gt;A user-defined operator is applied to those elements.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Combining some of the characteristics of unrestricted parallel mapping and
per-key-and-window combination, we can discern a megaprimitive from which we
build stateful and timely processing:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Elements for a common key and window are gathered together.&lt;/li&gt;
  &lt;li&gt;Elements are processed in arbitrary order.&lt;/li&gt;
  &lt;li&gt;You write single-threaded code to process one element or timer, possibly
accessing state or setting timers.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the illustration below, the red squares are gathered and fed one by one to
the stateful, timely, &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt;. As each element is processed, the &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; has
access to state (the color-partitioned cylinder on the right) and can set
timers to receive callbacks (the colorful clocks on the left).&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-block&quot; src=&quot;/images/blog/timely-processing/StateAndTimers.png&quot; alt=&quot;Gathering elements per key then timely, stateful processing&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So that is the abstract notion of per-key-and-window stateful, timely
processing in Apache Beam. Now let’s see what it looks like to write code that
accesses state, sets timers, and receives callbacks.&lt;/p&gt;

&lt;h2 id=&quot;example-batched-rpc&quot;&gt;Example: Batched RPC&lt;/h2&gt;

&lt;p&gt;To demonstrate stateful and timely processing, let’s work through a concrete
example, with code.&lt;/p&gt;

&lt;p&gt;Suppose you are writing a system to analyze events.  You have a ton of data
coming in and you need to enrich each event by RPC to an external system. You
can’t just issue an RPC per event.  Not only would this be terrible for
performance, but it would also likely blow your quota with the external system.
So you’d like to gather a number of events, make one RPC for them all, and then
output all the enriched events.&lt;/p&gt;

&lt;h3 id=&quot;state&quot;&gt;State&lt;/h3&gt;

&lt;p&gt;Let’s set up the state we need to track batches of elements. As each element
comes in, we will write the element to a buffer while tracking the number of
elements we have buffered. Here are the state cells in code:&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DoFn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Event&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EnrichedEvent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

  &lt;span class=&quot;nd&quot;&gt;@StateId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;buffer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StateSpec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BagState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Event&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bufferedEvents&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StateSpecs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;bag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;

  &lt;span class=&quot;nd&quot;&gt;@StateId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;count&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StateSpec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ValueState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;countState&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StateSpecs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;

  &lt;span class=&quot;err&quot;&gt;…&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TBD&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;…&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# State and timers are not yet supported in Beam's Python SDK.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Follow https://issues.apache.org/jira/browse/BEAM-2687 for updates.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Walking through the code, we have:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The state cell &lt;code class=&quot;highlighter-rouge&quot;&gt;&quot;buffer&quot;&lt;/code&gt; is an unordered bag of buffered events.&lt;/li&gt;
  &lt;li&gt;The state cell &lt;code class=&quot;highlighter-rouge&quot;&gt;&quot;count&quot;&lt;/code&gt; tracks how many events have been buffered.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Next, as a recap of reading and writing state, let’s write our &lt;code class=&quot;highlighter-rouge&quot;&gt;@ProcessElement&lt;/code&gt;
method. We will choose a limit on the size of the buffer, &lt;code class=&quot;highlighter-rouge&quot;&gt;MAX_BUFFER_SIZE&lt;/code&gt;. If
our buffer reaches this size, we will perform a single RPC to enrich all the
events, and output.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DoFn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Event&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EnrichedEvent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

  &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MAX_BUFFER_SIZE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;nd&quot;&gt;@StateId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;buffer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StateSpec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BagState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Event&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bufferedEvents&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StateSpecs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;bag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;

  &lt;span class=&quot;nd&quot;&gt;@StateId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;count&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StateSpec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ValueState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;countState&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StateSpecs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;

  &lt;span class=&quot;nd&quot;&gt;@ProcessElement&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;process&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;ProcessContext&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nd&quot;&gt;@StateId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;buffer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BagState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Event&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bufferState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nd&quot;&gt;@StateId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;count&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ValueState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;countState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;firstNonNull&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;countState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;countState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;bufferState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;element&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MAX_BUFFER_SIZE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EnrichedEvent&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enrichedEvent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enrichEvents&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bufferState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;enrichedEvent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;bufferState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;clear&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;countState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;clear&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;err&quot;&gt;…&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TBD&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;…&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# State and timers are not yet supported in Beam's Python SDK.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Follow https://issues.apache.org/jira/browse/BEAM-2687 for updates.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Here is an illustration to accompany the code:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-block&quot; src=&quot;/images/blog/timely-processing/BatchedRpcState.png&quot; alt=&quot;Batching elements in state, then performing RPCs&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The blue box is the &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;The yellow box within it is the &lt;code class=&quot;highlighter-rouge&quot;&gt;@ProcessElement&lt;/code&gt; method.&lt;/li&gt;
  &lt;li&gt;Each input event is a red square - this diagram just shows the activity for
a single key, represented by the color red. Your &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; will run the same
workflow in parallel for all keys which are perhaps user IDs.&lt;/li&gt;
  &lt;li&gt;Each input event is written to the buffer as a red triangle, representing
the fact that you might actually buffer more than just the raw input, even
though this code doesn’t.&lt;/li&gt;
  &lt;li&gt;The external service is drawn as a cloud. When there are enough buffered
events, the &lt;code class=&quot;highlighter-rouge&quot;&gt;@ProcessElement&lt;/code&gt; method reads the events from state and issues
a single RPC.&lt;/li&gt;
  &lt;li&gt;Each output enriched event is drawn as a red circle. To consumers of this
output, it looks just like an element-wise operation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So far, we have only used state, but not timers. You may have noticed that
there is a problem - there will usually be data left in the buffer. If no more
input arrives, that data will never be processed. In Beam, every window has
some point in event time when any further input for the window is considered
too late and is discarded. At this point, we say that the window has “expired”.
Since no further input can arrive to access the state for that window, the
state is also discarded. For our example, we need to ensure that all leftover
events are output when the window expires.&lt;/p&gt;

&lt;h3 id=&quot;event-time-timers&quot;&gt;Event Time Timers&lt;/h3&gt;

&lt;p&gt;An event time timer requests a call back when the watermark for an input
&lt;code class=&quot;highlighter-rouge&quot;&gt;PCollection&lt;/code&gt; reaches some threshold. In other words, you can use an event time
timer to take action at a specific moment in event time - a particular point of
completeness for a &lt;code class=&quot;highlighter-rouge&quot;&gt;PCollection&lt;/code&gt; - such as when a window expires.&lt;/p&gt;

&lt;p&gt;For our example, let us add an event time timer so that when the window expires,
any events remaining in the buffer are processed.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DoFn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Event&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EnrichedEvent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;err&quot;&gt;…&lt;/span&gt;

  &lt;span class=&quot;nd&quot;&gt;@TimerId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;expiry&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TimerSpec&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;expirySpec&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TimerSpecs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;timer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TimeDomain&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;EVENT_TIME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;

  &lt;span class=&quot;nd&quot;&gt;@ProcessElement&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;process&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;ProcessContext&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;BoundedWindow&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nd&quot;&gt;@StateId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;buffer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BagState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Event&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bufferState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nd&quot;&gt;@StateId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;count&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ValueState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;countState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nd&quot;&gt;@TimerId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;expiry&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Timer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;expiryTimer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;expiryTimer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;window&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;maxTimestamp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;plus&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;allowedLateness&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;

    &lt;span class=&quot;err&quot;&gt;…&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;same&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logic&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;above&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;…&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;nd&quot;&gt;@OnTimer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;expiry&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;onExpiry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;OnTimerContext&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nd&quot;&gt;@StateId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;buffer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BagState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Event&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bufferState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bufferState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;isEmpty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EnrichedEvent&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enrichedEvent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enrichEvents&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bufferState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;enrichedEvent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# State and timers are not yet supported in Beam's Python SDK.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Follow https://issues.apache.org/jira/browse/BEAM-2687 for updates.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Let’s unpack the pieces of this snippet:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;We declare an event time timer with &lt;code class=&quot;highlighter-rouge&quot;&gt;@TimerId(&quot;expiry&quot;)&lt;/code&gt;. We will use the
identifier &lt;code class=&quot;highlighter-rouge&quot;&gt;&quot;expiry&quot;&lt;/code&gt; to identify the timer for setting the callback time as
well as receiving the callback.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The variable &lt;code class=&quot;highlighter-rouge&quot;&gt;expiryTimer&lt;/code&gt;, annotated with &lt;code class=&quot;highlighter-rouge&quot;&gt;@TimerId&lt;/code&gt;, is set to the value
&lt;code class=&quot;highlighter-rouge&quot;&gt;TimerSpecs.timer(TimeDomain.EVENT_TIME)&lt;/code&gt;, indicating that we want a
callback according to the event time watermark of the input elements.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In the &lt;code class=&quot;highlighter-rouge&quot;&gt;@ProcessElement&lt;/code&gt; element we annotate a parameter &lt;code class=&quot;highlighter-rouge&quot;&gt;@TimerId(&quot;expiry&quot;)
Timer&lt;/code&gt;. The Beam runner automatically provides this &lt;code class=&quot;highlighter-rouge&quot;&gt;Timer&lt;/code&gt; parameter by which
we can set (and reset) the timer. It is inexpensive to reset a timer
repeatedly, so we simply set it on every element.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;We define the &lt;code class=&quot;highlighter-rouge&quot;&gt;onExpiry&lt;/code&gt; method, annotated with &lt;code class=&quot;highlighter-rouge&quot;&gt;@OnTimer(&quot;expiry&quot;)&lt;/code&gt;, that
performs a final event enrichment RPC and outputs the result. The Beam runner
delivers the callback to this method by matching its identifier.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Illustrating this logic, we have the diagram below:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-block&quot; src=&quot;/images/blog/timely-processing/BatchedRpcExpiry.png&quot; alt=&quot;Batched RPCs with window expiration&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Both the &lt;code class=&quot;highlighter-rouge&quot;&gt;@ProcessElement&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;@OnTimer(&quot;expiry&quot;)&lt;/code&gt; methods perform the same
access to buffered state, perform the same batched RPC, and output enriched
elements.&lt;/p&gt;

&lt;p&gt;Now, if we are executing this in a streaming real-time manner, we might still
have unbounded latency for particular buffered data. If the watermark is advancing
very slowly, or event time windows are chosen to be quite large, then a lot of
time might pass before output is emitted based either on enough elements or
window expiration. We can also use timers to limit the amount of wall-clock
time, aka processing time, before we process buffered elements. We can choose
some reasonable amount of time so that even though we are issuing RPCs that are
not as large as they might be, it is still few enough RPCs to avoid blowing our
quota with the external service.&lt;/p&gt;

&lt;h3 id=&quot;processing-time-timers&quot;&gt;Processing Time Timers&lt;/h3&gt;

&lt;p&gt;A timer in processing time (time as it passes while your pipeline is executing)
is intuitively simple: you want to wait a certain amount of time and then
receive a call back.&lt;/p&gt;

&lt;p&gt;To put the finishing touches on our example, we will set a processing time
timer as soon as any data is buffered. We track whether or not the timer has
been set so we don’t continually reset it. When an element arrives, if the
timer has not been set, then we set it for the current moment plus
&lt;code class=&quot;highlighter-rouge&quot;&gt;MAX_BUFFER_DURATION&lt;/code&gt;. After the allotted processing time has passed, a
callback will fire and enrich and emit any buffered elements.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DoFn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Event&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EnrichedEvent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;err&quot;&gt;…&lt;/span&gt;

  &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Duration&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MAX_BUFFER_DURATION&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Duration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;standardSeconds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;

  &lt;span class=&quot;nd&quot;&gt;@TimerId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;stale&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TimerSpec&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;staleSpec&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TimerSpecs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;timer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TimeDomain&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;PROCESSING_TIME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;

  &lt;span class=&quot;nd&quot;&gt;@ProcessElement&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;process&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;ProcessContext&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;BoundedWindow&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nd&quot;&gt;@StateId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;count&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ValueState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;countState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nd&quot;&gt;@StateId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;buffer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BagState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Event&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bufferState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nd&quot;&gt;@TimerId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;stale&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Timer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;staleTimer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nd&quot;&gt;@TimerId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;expiry&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Timer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;expiryTimer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;staleTimerSet&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;firstNonNull&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;staleSetState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;firstNonNull&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;countState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;staleTimer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MAX_BUFFER_DURATION&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setRelative&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;err&quot;&gt;…&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;same&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;processing&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logic&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;above&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;…&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;nd&quot;&gt;@OnTimer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;stale&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;onStale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;OnTimerContext&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nd&quot;&gt;@StateId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;buffer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BagState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Event&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bufferState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nd&quot;&gt;@StateId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;count&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ValueState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;countState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bufferState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;isEmpty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EnrichedEvent&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enrichedEvent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enrichEvents&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bufferState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;enrichedEvent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;bufferState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;clear&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;countState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;clear&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;err&quot;&gt;…&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;same&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;expiry&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;above&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;…&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# State and timers are not yet supported in Beam's Python SDK.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Follow https://issues.apache.org/jira/browse/BEAM-2687 for updates.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Here is an illustration of the final code:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-block&quot; src=&quot;/images/blog/timely-processing/BatchedRpcStale.png&quot; alt=&quot;Batching elements in state, then performing RPCs&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Recapping the entirety of the logic:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;As events arrive at &lt;code class=&quot;highlighter-rouge&quot;&gt;@ProcessElement&lt;/code&gt; they are buffered in state.&lt;/li&gt;
  &lt;li&gt;If the size of the buffer exceeds a maximum, the events are enriched and output.&lt;/li&gt;
  &lt;li&gt;If the buffer fills too slowly and the events get stale before the maximum is reached,
a timer causes a callback which enriches the buffered events and outputs.&lt;/li&gt;
  &lt;li&gt;Finally, as any window is expiring, any events buffered in that window are
processed and output prior to the state for that window being discarded.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the end, we have a full example that uses state and timers to explicitly
manage the low-level details of a performance-sensitive transform in Beam. As
we added more and more features, our &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; actually became pretty large. That
is a normal characteristic of stateful, timely processing. You are really
digging in and managing a lot of details that are handled automatically when
you express your logic using Beam’s higher-level APIs. What you gain from this
extra effort is an ability to tackle use cases and achieve efficiencies that
may not have been possible otherwise.&lt;/p&gt;

&lt;h2 id=&quot;state-and-timers-in-beams-unified-model&quot;&gt;State and Timers in Beam’s Unified Model&lt;/h2&gt;

&lt;p&gt;Beam’s unified model for event time across streaming and batch processing has
novel implications for state and timers. Usually, you don’t need to do anything
for your stateful and timely &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; to work well in the Beam model. But it will
help to be aware of the considerations below, especially if you have used
similar features before outside of Beam.&lt;/p&gt;

&lt;h3 id=&quot;event-time-windowing-just-works&quot;&gt;Event Time Windowing “Just Works”&lt;/h3&gt;

&lt;p&gt;One of the raisons d’etre for Beam is correct processing of out-of-order event
data, which is almost all event data. Beam’s solution to out-of-order data is
event time windowing, where windows in event time yield correct results no
matter what windowing a user chooses or what order the events come in.&lt;/p&gt;

&lt;p&gt;If you write a stateful, timely transform, it should work no matter how the
surrounding pipeline chooses to window event time. If the pipeline chooses
fixed windows of one hour (sometimes called tumbling windows) or windows of 30
minutes sliding by 10 minutes, the stateful, timely transform should
transparently work correctly.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-block&quot; src=&quot;/images/blog/timely-processing/WindowingChoices.png&quot; alt=&quot;Two windowing strategies for the same stateful and timely transform&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This works in Beam automatically, because state and timers are partitioned per
key and window. Within each key and window, the stateful, timely processing is
essentially independent.  As an added benefit, the passing of event time (aka
advancement of the watermark) allows automatic release of unreachable state
when a window expires, so you often don’t have to worry about evicting old
state.&lt;/p&gt;

&lt;h3 id=&quot;unified-real-time-and-historical-processing&quot;&gt;Unified real-time and historical processing&lt;/h3&gt;

&lt;p&gt;A second tenet of Beam’s semantic model is that processing must be unified
between batch and streaming. One important use case for this unification
is the ability to apply the same logic to a stream of events in real time and
to archived storage of the same events.&lt;/p&gt;

&lt;p&gt;A common characteristic of archived data is that it may arrive radically out of
order. The sharding of archived files often results in a totally different
ordering for processing than events coming in near-real-time. The data will
also all be all available and hence delivered instantaneously from the point of
view of your pipeline. Whether running experiments on past data or reprocessing
past results to fix a data processing bug, it is critically important that your
processing logic be applicable to archived events just as easily as incoming
near-real-time data.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-block&quot; src=&quot;/images/blog/timely-processing/UnifiedModel.png&quot; alt=&quot;Unified stateful processing over streams and file archives&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It is (deliberately) possible to write a stateful and timely DoFn that delivers
results that depend on ordering or delivery timing, so in this sense there is
additional burden on you, the &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; author, to ensure that this nondeterminism
falls within documented allowances.&lt;/p&gt;

&lt;h2 id=&quot;go-use-it&quot;&gt;Go use it!&lt;/h2&gt;

&lt;p&gt;I’ll end this post in the same way I ended the last. I hope you will go try out
Beam with stateful, timely processing. If it opens up new possibilities for
you, then great! If not, we want to hear about it. Since this is a new feature,
please check the &lt;a href=&quot;/documentation/runners/capability-matrix/&quot;&gt;capability matrix&lt;/a&gt; to see the level of support for
your preferred Beam backend(s).&lt;/p&gt;

&lt;p&gt;And please do join the Beam community at
&lt;a href=&quot;/get-started/support&quot;&gt;user@beam.apache.org&lt;/a&gt; and follow
&lt;a href=&quot;https://twitter.com/ApacheBeam&quot;&gt;@ApacheBeam&lt;/a&gt; on Twitter.&lt;/p&gt;
</description>
        <pubDate>Mon, 28 Aug 2017 01:00:01 -0700</pubDate>
        <link>https://beam.apache.org/blog/2017/08/28/timely-processing.html</link>
        <guid isPermaLink="true">https://beam.apache.org/blog/2017/08/28/timely-processing.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Powerful and modular IO connectors with Splittable DoFn in Apache Beam</title>
        <description>&lt;!--
Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;

&lt;p&gt;One of the most important parts of the Apache Beam ecosystem is its quickly
growing set of connectors that allow Beam pipelines to read and write data to
various data storage systems (“IOs”). Currently, Beam ships &lt;a href=&quot;/documentation/io/built-in/&quot;&gt;over 20 IO
connectors&lt;/a&gt; with many more in
active development. As user demands for IO connectors grew, our work on
improving the related Beam APIs (in particular, the Source API) produced an
unexpected result: a generalization of Beam’s most basic primitive, &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt;.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;connectors-as-mini-pipelines&quot;&gt;Connectors as mini-pipelines&lt;/h2&gt;

&lt;p&gt;One of the main reasons for this vibrant IO connector ecosystem is that
developing a basic IO is relatively straightforward: many connector
implementations are simply mini-pipelines (composite &lt;code class=&quot;highlighter-rouge&quot;&gt;PTransform&lt;/code&gt;s) made of the
basic Beam &lt;code class=&quot;highlighter-rouge&quot;&gt;ParDo&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;GroupByKey&lt;/code&gt; primitives. For example,
&lt;code class=&quot;highlighter-rouge&quot;&gt;ElasticsearchIO.write()&lt;/code&gt;
&lt;a href=&quot;https://github.com/apache/beam/blob/f7e8f886c91ea9d0b51e00331eeb4484e2f6e000/sdks/java/io/elasticsearch/src/main/java/org/apache/beam/sdk/io/elasticsearch/ElasticsearchIO.java#L783&quot;&gt;expands&lt;/a&gt;
into a single &lt;code class=&quot;highlighter-rouge&quot;&gt;ParDo&lt;/code&gt; with some batching for performance; &lt;code class=&quot;highlighter-rouge&quot;&gt;JdcbIO.read()&lt;/code&gt;
&lt;a href=&quot;https://github.com/apache/beam/blob/f7e8f886c91ea9d0b51e00331eeb4484e2f6e000/sdks/java/io/jdbc/src/main/java/org/apache/beam/sdk/io/jdbc/JdbcIO.java#L329&quot;&gt;expands&lt;/a&gt;
into &lt;code class=&quot;highlighter-rouge&quot;&gt;Create.of(query)&lt;/code&gt;, a reshuffle to &lt;a href=&quot;https://cloud.google.com/dataflow/service/dataflow-service-desc#preventing-fusion&quot;&gt;prevent
fusion&lt;/a&gt;,
and &lt;code class=&quot;highlighter-rouge&quot;&gt;ParDo(execute sub-query)&lt;/code&gt;.  Some IOs
&lt;a href=&quot;https://github.com/apache/beam/blob/8503adbbc3a590cd0dc2939f6a45d335682a9442/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIO.java#L1139&quot;&gt;construct&lt;/a&gt;
considerably more complicated pipelines.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-block&quot; src=&quot;/images/blog/splittable-do-fn/jdbcio-expansion.png&quot; alt=&quot;Expansion of the JdbcIO.read() composite transform&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This “mini-pipeline” approach is flexible, modular, and generalizes to data
sources that read from a dynamically computed &lt;code class=&quot;highlighter-rouge&quot;&gt;PCollection&lt;/code&gt; of locations, such
as
&lt;a href=&quot;https://github.com/apache/beam/blob/f7e8f886c91ea9d0b51e00331eeb4484e2f6e000/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/spanner/SpannerIO.java#L222&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SpannerIO.readAll()&lt;/code&gt;&lt;/a&gt;
which reads the results of a &lt;code class=&quot;highlighter-rouge&quot;&gt;PCollection&lt;/code&gt; of queries from Cloud Spanner,
compared to
&lt;a href=&quot;https://github.com/apache/beam/blob/f7e8f886c91ea9d0b51e00331eeb4484e2f6e000/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/spanner/SpannerIO.java#L318&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SpannerIO.read()&lt;/code&gt;&lt;/a&gt;
which executes a single query. We believe such dynamic data sources are a very
useful capability, often overlooked by other data processing frameworks.&lt;/p&gt;

&lt;h2 id=&quot;when-pardo-and-groupbykey-are-not-enough&quot;&gt;When ParDo and GroupByKey are not enough&lt;/h2&gt;

&lt;p&gt;Despite the flexibility of &lt;code class=&quot;highlighter-rouge&quot;&gt;ParDo&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;GroupByKey&lt;/code&gt; and their derivatives, in some
cases building an efficient IO connector requires extra capabilities.&lt;/p&gt;

&lt;p&gt;For example, imagine reading files using the sequence &lt;code class=&quot;highlighter-rouge&quot;&gt;ParDo(filepattern →
expand into files)&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;ParDo(filename → read records)&lt;/code&gt;, or reading a Kafka topic
using &lt;code class=&quot;highlighter-rouge&quot;&gt;ParDo(topic → list partitions)&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;ParDo(topic, partition → read
records)&lt;/code&gt;. This approach has two big issues:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;In the file example, some files might be much larger than others, so the
second &lt;code class=&quot;highlighter-rouge&quot;&gt;ParDo&lt;/code&gt; may have very long individual &lt;code class=&quot;highlighter-rouge&quot;&gt;@ProcessElement&lt;/code&gt; calls. As a
result, the pipeline can suffer from poor performance due to stragglers.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In the Kafka example, implementing the second &lt;code class=&quot;highlighter-rouge&quot;&gt;ParDo&lt;/code&gt; is &lt;em&gt;simply impossible&lt;/em&gt;
with a regular &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt;, because it would need to output an infinite number of
records per each input element &lt;code class=&quot;highlighter-rouge&quot;&gt;topic, partition&lt;/code&gt; &lt;em&gt;(&lt;a href=&quot;/blog/2017/02/13/stateful-processing.html&quot;&gt;stateful processing&lt;/a&gt; comes close, but it
has other limitations that make it insufficient for this task&lt;/em&gt;).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;beam-source-api&quot;&gt;Beam Source API&lt;/h2&gt;

&lt;p&gt;Apache Beam historically provides a Source API
(&lt;a href=&quot;/documentation/sdks/javadoc/2.6.0/org/apache/beam/sdk/io/BoundedSource.html&quot;&gt;BoundedSource&lt;/a&gt;
and
&lt;a href=&quot;/documentation/sdks/javadoc/2.6.0/org/apache/beam/sdk/io/UnboundedSource.html&quot;&gt;UnboundedSource&lt;/a&gt;) which does
not have these limitations and allows development of efficient data sources for
batch and streaming systems. Pipelines use this API via the
&lt;a href=&quot;/documentation/sdks/javadoc/2.6.0/org/apache/beam/sdk/io/Read.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Read.from(Source)&lt;/code&gt;&lt;/a&gt; built-in &lt;code class=&quot;highlighter-rouge&quot;&gt;PTransform&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The Source API is largely similar to that of most other data processing
frameworks, and allows the system to read data in parallel using multiple
workers, as well as checkpoint and resume reading from an unbounded data source.
Additionally, the Beam
&lt;a href=&quot;/documentation/sdks/javadoc/2.6.0/org/apache/beam/sdk/io/BoundedSource.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;BoundedSource&lt;/code&gt;&lt;/a&gt;
API provides advanced features such as progress reporting and &lt;a href=&quot;/blog/2016/05/18/splitAtFraction-method.html&quot;&gt;dynamic
rebalancing&lt;/a&gt;
(which together enable autoscaling), and
&lt;a href=&quot;/documentation/sdks/javadoc/2.6.0/org/apache/beam/sdk/io/UnboundedSource.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;UnboundedSource&lt;/code&gt;&lt;/a&gt; supports
reporting the source’s watermark and backlog &lt;em&gt;(until SDF, we believed that
“batch” and “streaming” data sources are fundamentally different and thus
require fundamentally different APIs)&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Unfortunately, these features come at a price. Coding against the Source API
involves a lot of boilerplate and is error-prone, and it does not compose well
with the rest of the Beam model because a &lt;code class=&quot;highlighter-rouge&quot;&gt;Source&lt;/code&gt; can appear only at the root
of a pipeline. For example:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Using the Source API, it is not possible to read a &lt;code class=&quot;highlighter-rouge&quot;&gt;PCollection&lt;/code&gt; of
filepatterns.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A &lt;code class=&quot;highlighter-rouge&quot;&gt;Source&lt;/code&gt; can not read a side input, or wait on another pipeline step to
produce the data.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A &lt;code class=&quot;highlighter-rouge&quot;&gt;Source&lt;/code&gt; can not emit an additional output (for example, records that failed to
parse) and so on.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The Source API is not composable even with itself. For example, suppose Alice
implements an unbounded &lt;code class=&quot;highlighter-rouge&quot;&gt;Source&lt;/code&gt; that watches a directory for new matching
files, and Bob implements an unbounded &lt;code class=&quot;highlighter-rouge&quot;&gt;Source&lt;/code&gt; that tails a file. The Source
API does not let them simply chain the sources together and obtain a &lt;code class=&quot;highlighter-rouge&quot;&gt;Source&lt;/code&gt;
that returns new records in new log files in a directory (a very common user
request). Instead, such a source would have to be developed mostly from
scratch, and our experience shows that a full-featured monolithic
implementation of such a &lt;code class=&quot;highlighter-rouge&quot;&gt;Source&lt;/code&gt; is incredibly difficult and error-prone.&lt;/p&gt;

&lt;p&gt;Another class of issues with the &lt;code class=&quot;highlighter-rouge&quot;&gt;Source&lt;/code&gt; API comes from its strict
bounded/unbounded dichotomy:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;It is difficult or impossible to reuse code between seemingly very similar
bounded and unbounded sources, for example, the &lt;code class=&quot;highlighter-rouge&quot;&gt;BoundedSource&lt;/code&gt; that generates
a sequence &lt;code class=&quot;highlighter-rouge&quot;&gt;[a, b)&lt;/code&gt; and the &lt;code class=&quot;highlighter-rouge&quot;&gt;UnboundedSource&lt;/code&gt; that generates a sequence &lt;code class=&quot;highlighter-rouge&quot;&gt;[a,
inf)&lt;/code&gt; &lt;a href=&quot;https://github.com/apache/beam/blob/master/sdks/java/core/src/main/java/org/apache/beam/sdk/io/CountingSource.java&quot;&gt;don’t share any
code&lt;/a&gt;
in the Beam Java SDK.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;It is not clear how to classify the ingestion of a very large and
continuously growing dataset. Ingesting its “already available” part seems to
require a &lt;code class=&quot;highlighter-rouge&quot;&gt;BoundedSource&lt;/code&gt;: the runner could benefit from knowing its size, and
could perform dynamic rebalancing. However, ingesting the continuously arriving
new data seems to require an &lt;code class=&quot;highlighter-rouge&quot;&gt;UnboundedSource&lt;/code&gt; for providing watermarks. From
this angle, the &lt;code class=&quot;highlighter-rouge&quot;&gt;Source&lt;/code&gt; API has &lt;a href=&quot;https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101&quot;&gt;the same issues as Lambda
Architecture&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;About two years ago we began thinking about how to address the limitations of
the Source API, and ended up, surprisingly, addressing the limitations of
&lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; instead.&lt;/p&gt;

&lt;h2 id=&quot;enter-splittable-dofn&quot;&gt;Enter Splittable DoFn&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://s.apache.org/splittable-do-fn&quot;&gt;Splittable DoFn&lt;/a&gt; (SDF) is a
generalization of &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; that gives it the core capabilities of &lt;code class=&quot;highlighter-rouge&quot;&gt;Source&lt;/code&gt; while
retaining &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt;’s syntax, flexibility, modularity, and ease of coding.  As a
result, it becomes possible to develop more powerful IO connectors than before,
with shorter, simpler, more reusable code.&lt;/p&gt;

&lt;p&gt;Note that, unlike &lt;code class=&quot;highlighter-rouge&quot;&gt;Source&lt;/code&gt;, SDF &lt;em&gt;does not&lt;/em&gt; have distinct bounded/unbounded APIs,
just as regular &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt;s don’t: there is only one API, which covers both of these
use cases and anything in between. Thus, SDF closes the final gap in the unified
batch/streaming programming model of Apache Beam.&lt;/p&gt;

&lt;p&gt;When reading the explanation of SDF below, keep in mind the running example of a
&lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; that takes a filename as input and outputs the records in that file.
People familiar with the &lt;code class=&quot;highlighter-rouge&quot;&gt;Source&lt;/code&gt; API may find it useful to think of SDF as a
way to read a &lt;code class=&quot;highlighter-rouge&quot;&gt;PCollection&lt;/code&gt; of sources, treating the source itself as just
another piece of data in the pipeline &lt;em&gt;(this, in fact, was one of the early
design iterations among the work that led to creation of SDF)&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;The two aspects where &lt;code class=&quot;highlighter-rouge&quot;&gt;Source&lt;/code&gt; has an advantage over a regular &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Splittability:&lt;/strong&gt; applying a &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; to a single element is &lt;em&gt;monolithic&lt;/em&gt;, but
reading from a &lt;code class=&quot;highlighter-rouge&quot;&gt;Source&lt;/code&gt; is &lt;em&gt;non-monolithic&lt;/em&gt;. The whole &lt;code class=&quot;highlighter-rouge&quot;&gt;Source&lt;/code&gt; doesn’t have to
be read at once; rather, it is read in parts, called &lt;em&gt;bundles&lt;/em&gt;. For example, a
large file is usually read in several bundles, each reading some sub-range of
offsets within the file. Likewise, a Kafka topic (which, of course, can never
be read “fully”) is read over an infinite number of bundles, each reading some
finite number of elements.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Interaction with the runner:&lt;/strong&gt; runners apply a &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; to a single element as
a “black box”, but interact quite richly with &lt;code class=&quot;highlighter-rouge&quot;&gt;Source&lt;/code&gt;. &lt;code class=&quot;highlighter-rouge&quot;&gt;Source&lt;/code&gt; provides the
runner with information such as its estimated size (or its generalization,
“backlog”), progress through reading the bundle, watermarks etc. The runner
uses this information to tune the execution and control the breakdown of the
&lt;code class=&quot;highlighter-rouge&quot;&gt;Source&lt;/code&gt; into bundles. For example, a slowly progressing large bundle of a file
may be &lt;a href=&quot;https://cloud.google.com/blog/big-data/2016/05/no-shard-left-behind-dynamic-work-rebalancing-in-google-cloud-dataflow&quot;&gt;dynamically
split&lt;/a&gt;
by a batch-focused runner before it becomes a straggler, and a latency-focused
streaming runner may control how many elements it reads from a source in each
bundle to optimize for latency vs. per-bundle overhead.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;non-monolithic-element-processing-with-restrictions&quot;&gt;Non-monolithic element processing with restrictions&lt;/h3&gt;

&lt;p&gt;Splittable &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; supports &lt;code class=&quot;highlighter-rouge&quot;&gt;Source&lt;/code&gt;-like features by allowing the processing of
a single element to be non-monolithic.&lt;/p&gt;

&lt;p&gt;The processing of one element by an SDF is decomposed into a (potentially
infinite) number of &lt;em&gt;restrictions&lt;/em&gt;, each describing some part of the work to be
done for the whole element. The input to an SDF’s &lt;code class=&quot;highlighter-rouge&quot;&gt;@ProcessElement&lt;/code&gt; call is a
pair of an element and a restriction (compared to a regular &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt;, which takes
just the element).&lt;/p&gt;

&lt;p&gt;Processing of every element starts by creating an &lt;em&gt;initial restriction&lt;/em&gt; that
describes the entire work, and the initial restriction is then split further
into sub-restrictions which must logically add up to the original. For example,
for a splittable &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; called &lt;code class=&quot;highlighter-rouge&quot;&gt;ReadFn&lt;/code&gt; that takes a filename and outputs
records in the file, the restriction may be a pair of starting and ending byte
offset, and &lt;code class=&quot;highlighter-rouge&quot;&gt;ReadFn&lt;/code&gt; may interpret it as &lt;em&gt;read records whose starting offsets
are in the given range&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-block&quot; src=&quot;/images/blog/splittable-do-fn/restrictions.png&quot; alt=&quot;Specifying parts of work for an element using restrictions&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The idea of restrictions provides non-monolithic execution - the first
ingredient for parity with &lt;code class=&quot;highlighter-rouge&quot;&gt;Source&lt;/code&gt;. The other ingredient is &lt;em&gt;interaction with
the runner&lt;/em&gt;: the runner has access to the restriction of each active
&lt;code class=&quot;highlighter-rouge&quot;&gt;@ProcessElement&lt;/code&gt; call of an SDF, can inquire about the progress of the call,
and most importantly, can &lt;em&gt;split&lt;/em&gt; the restriction while it is being processed
(hence the name &lt;em&gt;Splittable DoFn&lt;/em&gt;).&lt;/p&gt;

&lt;p&gt;Splitting produces a &lt;em&gt;primary&lt;/em&gt; and &lt;em&gt;residual&lt;/em&gt; restriction that add up to the
original restriction being split: the current &lt;code class=&quot;highlighter-rouge&quot;&gt;@ProcessElement&lt;/code&gt; call keeps
processing the primary, and the residual will be processed by another
&lt;code class=&quot;highlighter-rouge&quot;&gt;@ProcessElement&lt;/code&gt; call. For example, a runner may schedule the residual to be
processed in parallel on another worker.&lt;/p&gt;

&lt;p&gt;Splitting of a running &lt;code class=&quot;highlighter-rouge&quot;&gt;@ProcessElement&lt;/code&gt; call has two critically important uses:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Supporting infinite work per element.&lt;/strong&gt; A restriction is, in general, not
required to describe a finite amount of work. For example, reading from a Kafka
topic starting from offset &lt;em&gt;100&lt;/em&gt; can be represented by the
restriction &lt;em&gt;[100, inf)&lt;/em&gt;. A &lt;code class=&quot;highlighter-rouge&quot;&gt;@ProcessElement&lt;/code&gt; call processing this
entire restriction would, of course, never complete. However, while such a call
runs, a runner can split the restriction into a &lt;em&gt;finite&lt;/em&gt; primary &lt;em&gt;[100, 150)&lt;/em&gt;
(letting the current call complete this part) and an &lt;em&gt;infinite&lt;/em&gt; residual &lt;em&gt;[150,
inf)&lt;/em&gt; to be processed later, effectively checkpointing and resuming the call;
this can be repeated forever.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img class=&quot;center-block&quot; src=&quot;/images/blog/splittable-do-fn/kafka-splitting.png&quot; alt=&quot;Splitting an infinite restriction into a finite primary and infinite residual&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Dynamic rebalancing.&lt;/strong&gt; When a (typically batch-focused) runner detects that
a &lt;code class=&quot;highlighter-rouge&quot;&gt;@ProcessElement&lt;/code&gt; call is going to take too long and become a straggler, it
can split the restriction in some proportion so that the primary is short enough
to not be a straggler, and can schedule the residual in parallel on another
worker. For details, see &lt;a href=&quot;https://cloud.google.com/blog/big-data/2016/05/no-shard-left-behind-dynamic-work-rebalancing-in-google-cloud-dataflow&quot;&gt;No Shard Left
Behind&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Logically, the execution of an SDF on an element works according to the
following diagram, where “magic” stands for the runner-specific ability to split
the restrictions and schedule processing of residuals.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-block&quot; src=&quot;/images/blog/splittable-do-fn/transform-expansion.png&quot; alt=&quot;Execution of an SDF - pairing with a restriction, splitting     restrictions, processing element/restriction pairs&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This diagram emphasizes that splittability is an implementation detail of the
particular &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt;: a splittable &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; still looks like a &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&amp;lt;A, B&amp;gt;&lt;/code&gt; to its
user, and can be applied via a &lt;code class=&quot;highlighter-rouge&quot;&gt;ParDo&lt;/code&gt; to a &lt;code class=&quot;highlighter-rouge&quot;&gt;PCollection&amp;lt;A&amp;gt;&lt;/code&gt; producing a
&lt;code class=&quot;highlighter-rouge&quot;&gt;PCollection&amp;lt;B&amp;gt;&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&quot;which-dofns-need-to-be-splittable&quot;&gt;Which DoFns need to be splittable&lt;/h3&gt;

&lt;p&gt;Note that decomposition of an element into element/restriction pairs is not
automatic or “magical”: SDF is a new API for &lt;em&gt;authoring&lt;/em&gt; a &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt;, rather than a
new way to &lt;em&gt;execute&lt;/em&gt; an existing &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt;. When making a &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; splittable, the
author needs to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Consider the structure of the work it does for every element.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Come up with a scheme for describing parts of this work using restrictions.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Write code for creating the initial restriction, splitting it, and executing
an element/restriction pair.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;An overwhelming majority of &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt;s found in user pipelines do not need to be
made splittable: SDF is an advanced, powerful API, primarily targeting authors
of new IO connectors &lt;em&gt;(though it has interesting non-IO applications as well:
see &lt;a href=&quot;http://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv&quot;&gt;Non-IO examples&lt;/a&gt;)&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;execution-of-a-restriction-and-data-consistency&quot;&gt;Execution of a restriction and data consistency&lt;/h3&gt;

&lt;p&gt;One of the most important parts of the Splittable &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; design is related to
how it achieves data consistency while splitting. For example, while the runner
is preparing to split the restriction of an active &lt;code class=&quot;highlighter-rouge&quot;&gt;@ProcessElement&lt;/code&gt; call, how
can it be sure that the call has not concurrently progressed past the point of
splitting?&lt;/p&gt;

&lt;p&gt;This is achieved by requiring the processing of a restriction to follow a
certain pattern. We think of a restriction as a sequence of &lt;em&gt;blocks&lt;/em&gt; -
elementary indivisible units of work, identified by a &lt;em&gt;position&lt;/em&gt;. A
&lt;code class=&quot;highlighter-rouge&quot;&gt;@ProcessElement&lt;/code&gt; call processes the blocks one by one, first &lt;em&gt;claiming&lt;/em&gt; the
block’s position to atomically check if it’s still within the range of the
restriction, until the whole restriction is processed.&lt;/p&gt;

&lt;p&gt;The diagram below illustrates this for &lt;code class=&quot;highlighter-rouge&quot;&gt;ReadFn&lt;/code&gt; (a splittable &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; that reads
Avro files) processing the element &lt;code class=&quot;highlighter-rouge&quot;&gt;foo.avro&lt;/code&gt; with restriction &lt;code class=&quot;highlighter-rouge&quot;&gt;[30, 70)&lt;/code&gt;. This
&lt;code class=&quot;highlighter-rouge&quot;&gt;@ProcessElement&lt;/code&gt; call scans the Avro file for &lt;a href=&quot;https://avro.apache.org/docs/current/spec.html#Object+Container+Files&quot;&gt;data
blocks&lt;/a&gt;
starting from offset &lt;code class=&quot;highlighter-rouge&quot;&gt;30&lt;/code&gt; and claims the position of each block in this range.
If a block is claimed successfully, then the call outputs all records in this
data block, otherwise, it terminates.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-block&quot; src=&quot;/images/blog/splittable-do-fn/blocks.png&quot; alt=&quot;Processing a restriction by claiming blocks inside it&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For more details, see &lt;a href=&quot;http://s.apache.org/splittable-do-fn#heading=h.vjs7pzbb7kw&quot;&gt;Restrictions, blocks and
positions&lt;/a&gt; in the
design proposal document.&lt;/p&gt;

&lt;h3 id=&quot;code-example&quot;&gt;Code example&lt;/h3&gt;

&lt;p&gt;Let us look at some examples of SDF code. The examples use the Beam Java SDK,
which &lt;a href=&quot;https://github.com/apache/beam/blob/f7e8f886c91ea9d0b51e00331eeb4484e2f6e000/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/DoFn.java#L527&quot;&gt;represents splittable
&lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt;s&lt;/a&gt;
as part of the flexible &lt;a href=&quot;http://s.apache.org/a-new-dofn&quot;&gt;annotation-based
&lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt;&lt;/a&gt; machinery, and the &lt;a href=&quot;https://s.apache.org/splittable-do-fn-python&quot;&gt;proposed SDF syntax
for Python&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;A splittable &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; is a &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; - no new base class needed. Any SDF derives
from the &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; class and has a &lt;code class=&quot;highlighter-rouge&quot;&gt;@ProcessElement&lt;/code&gt; method.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;@ProcessElement&lt;/code&gt; method takes an additional
&lt;a href=&quot;https://github.com/apache/beam/blob/f7e8f886c91ea9d0b51e00331eeb4484e2f6e000/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/splittabledofn/RestrictionTracker.java&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;RestrictionTracker&lt;/code&gt;&lt;/a&gt;
parameter that gives access to the current restriction in addition to the
current element.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;An SDF needs to define a &lt;code class=&quot;highlighter-rouge&quot;&gt;@GetInitialRestriction&lt;/code&gt; method that can create a
restriction describing the complete work for a given element.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;There are several less important optional methods, such as
&lt;code class=&quot;highlighter-rouge&quot;&gt;@SplitRestriction&lt;/code&gt; for pre-splitting the initial restriction into several
smaller restrictions, and a few others.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The “Hello World” of SDF is a counter, which takes pairs &lt;em&gt;(x, N)&lt;/em&gt; as input and
produces pairs &lt;em&gt;(x, 0), (x, 1), …, (x, N-1)&lt;/em&gt; as output.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;CountFn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DoFn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;KV&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;KV&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nd&quot;&gt;@ProcessElement&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;process&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ProcessContext&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OffsetRangeTracker&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tracker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tracker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;currentRestriction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getFrom&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tracker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;tryClaim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;KV&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;of&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;element&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getKey&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;nd&quot;&gt;@GetInitialRestriction&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OffsetRange&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;getInitialRange&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;KV&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;element&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;OffsetRange&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;element&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;PCollection&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;KV&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;…&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;PCollection&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;KV&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ParDo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;of&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CountFn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;());&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;CountFn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DoFn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;process&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;element&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tracker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DoFn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RestrictionTrackerParam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;xrange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tracker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;current_restriction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()):&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tracker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;try_claim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;element&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;
        
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_initial_restriction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;element&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;element&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This short &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; subsumes the functionality of
&lt;a href=&quot;https://github.com/apache/beam/blob/master/sdks/java/core/src/main/java/org/apache/beam/sdk/io/CountingSource.java&quot;&gt;CountingSource&lt;/a&gt;,
but is more flexible: &lt;code class=&quot;highlighter-rouge&quot;&gt;CountingSource&lt;/code&gt; generates only one sequence specified at
pipeline construction time, while this &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; can generate a dynamic family of
sequences, one per element in the input collection (it does not matter whether
the input collection is bounded or unbounded).&lt;/p&gt;

&lt;p&gt;However, the &lt;code class=&quot;highlighter-rouge&quot;&gt;Source&lt;/code&gt;-specific capabilities of &lt;code class=&quot;highlighter-rouge&quot;&gt;CountingSource&lt;/code&gt; are still
available in &lt;code class=&quot;highlighter-rouge&quot;&gt;CountFn&lt;/code&gt;. For example, if a sequence has a lot of elements, a
batch-focused runner can still apply dynamic rebalancing to it and generate
different subranges of the sequence in parallel by splitting the &lt;code class=&quot;highlighter-rouge&quot;&gt;OffsetRange&lt;/code&gt;.
Likewise, a streaming-focused runner can use the same splitting logic to
checkpoint and resume the generation of the sequence even if it is, for
practical purposes, infinite (for example, when applied to a &lt;code class=&quot;highlighter-rouge&quot;&gt;KV(...,
Long.MAX_VALUE)&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;A slightly more complex example is the &lt;code class=&quot;highlighter-rouge&quot;&gt;ReadFn&lt;/code&gt; considered above, which reads
data from Avro files and illustrates the idea of &lt;em&gt;blocks&lt;/em&gt;: we provide pseudocode
to illustrate the approach.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ReadFn&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DoFn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AvroRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nd&quot;&gt;@ProcessElement&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;process&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ProcessContext&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OffsetRangeTracker&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tracker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AvroReader&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Avro&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;// Seek to the first block starting at or after the start offset.&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;reader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;seek&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tracker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;currentRestriction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getFrom&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;readNextBlock&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;// Claim the position of the current Avro block&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tracker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;tryClaim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;currentBlockOffset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;c1&quot;&gt;// Out of range of the current restriction - we're done.&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;// Emit all records in this block&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AvroRecord&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;currentBlock&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;nd&quot;&gt;@GetInitialRestriction&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;OffsetRange&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;getInitialRestriction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;OffsetRange&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;File&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AvroReader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DoFn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;process&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tracker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DoFn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RestrictionTrackerParam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fileio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ChannelFactory&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stop&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tracker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;current_restriction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
      &lt;span class=&quot;c&quot;&gt;# Seek to the first block starting at or after the start offset.&lt;/span&gt;
      &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seek&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AvroUtils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_next_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# Claim the position of the current Avro block&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tracker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;try_claim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()):&lt;/span&gt;
          &lt;span class=&quot;c&quot;&gt;# Out of range of the current restriction - we're done.&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# Emit all records in this block&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;records&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AvroUtils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_next_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_initial_restriction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fileio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ChannelFactory&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size_in_bytes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This hypothetical &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; reads records from a single Avro file. Notably missing
is the code for expanding a filepattern: it no longer needs to be part of this
&lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt;! Instead, the SDK includes a
&lt;a href=&quot;https://github.com/apache/beam/blob/master/sdks/java/core/src/main/java/org/apache/beam/sdk/io/FileIO.java&quot;&gt;FileIO.matchAll()&lt;/a&gt;
transform for expanding a filepattern into a &lt;code class=&quot;highlighter-rouge&quot;&gt;PCollection&lt;/code&gt; of filenames, and
different file format IOs can reuse the same transform, reading the files with
different &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt;s.&lt;/p&gt;

&lt;p&gt;This example demonstrates the benefits of increased modularity allowed by SDF:
&lt;code class=&quot;highlighter-rouge&quot;&gt;FileIO.matchAll()&lt;/code&gt; supports continuous ingestion of new files in streaming
pipelines using &lt;code class=&quot;highlighter-rouge&quot;&gt;.continuously()&lt;/code&gt;, and this functionality becomes automatically
available to various file format IOs. For example,
&lt;code class=&quot;highlighter-rouge&quot;&gt;TextIO.read().watchForNewFiles()&lt;/code&gt; &lt;a href=&quot;https://github.com/apache/beam/blob/3bd68ecfd7d576d78e02deb0476e549f11e1b5ef/sdks/java/core/src/main/java/org/apache/beam/sdk/io/TextIO.java#L486&quot;&gt;uses &lt;code class=&quot;highlighter-rouge&quot;&gt;FileIO.matchAll()&lt;/code&gt; under the
hood)&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;current-status&quot;&gt;Current status&lt;/h2&gt;

&lt;p&gt;Splittable &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; is a major new API, and its delivery and widespread adoption
involves a lot of work in different parts of the Apache Beam ecosystem.  Some
of that work is already complete and provides direct benefit to users via new
IO connectors. However, a large amount of work is in progress or planned.&lt;/p&gt;

&lt;p&gt;As of August 2017, SDF is available for use in the Beam Java Direct runner and
Dataflow Streaming runner, and implementation is in progress in the Flink and
Apex runners; see &lt;a href=&quot;/documentation/runners/capability-matrix/&quot;&gt;capability matrix&lt;/a&gt; for the current status. Support
for SDF in the Python SDK is &lt;a href=&quot;https://s.apache.org/splittable-do-fn-python&quot;&gt;in active
development&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Several SDF-based transforms and IO connectors are available for Beam users at
HEAD and will be included in Beam 2.2.0. &lt;code class=&quot;highlighter-rouge&quot;&gt;TextIO&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;AvroIO&lt;/code&gt; finally provide
continuous ingestion of files (one of the most frequently requested features)
via &lt;code class=&quot;highlighter-rouge&quot;&gt;.watchForNewFiles()&lt;/code&gt; which is backed by the utility transforms
&lt;code class=&quot;highlighter-rouge&quot;&gt;FileIO.matchAll().continuously()&lt;/code&gt; and the more general
&lt;a href=&quot;https://github.com/apache/beam/blob/f7e8f886c91ea9d0b51e00331eeb4484e2f6e000/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Watch.java&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Watch.growthOf()&lt;/code&gt;&lt;/a&gt;.
These utility transforms are also independently useful for “power user” use
cases.&lt;/p&gt;

&lt;p&gt;To enable more flexible use cases for IOs currently based on the Source API, we
will change them to use SDF. This transition is &lt;a href=&quot;http://s.apache.org/textio-sdf&quot;&gt;pioneered by
TextIO&lt;/a&gt; and involves temporarily &lt;a href=&quot;http://s.apache.org/sdf-via-source&quot;&gt;executing SDF
via the Source API&lt;/a&gt; to support runners
lacking the ability to run SDF directly.&lt;/p&gt;

&lt;p&gt;In addition to enabling new IOs, work on SDF has influenced our thinking about
other parts of the Beam programming model:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;SDF unified the final remaining part of the Beam programming model that was
not batch/streaming agnostic (the &lt;code class=&quot;highlighter-rouge&quot;&gt;Source&lt;/code&gt; API). This led us to consider use
cases that cannot be described as purely batch or streaming (for example,
ingesting a large amount of historical data and carrying on with more data
arriving in real time) and to develop a &lt;a href=&quot;http://s.apache.org/beam-fn-api-progress-reporting&quot;&gt;unified notion of “progress” and
“backlog”&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The &lt;a href=&quot;http://s.apache.org/beam-fn-api&quot;&gt;Fn API&lt;/a&gt; - the foundation of Beam’s
future support for cross-language pipelines - uses SDF as &lt;em&gt;the only&lt;/em&gt; concept
representing data ingestion.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Implementation of SDF has lead to &lt;a href=&quot;https://lists.apache.org/thread.html/86831496a08fe148e3b982cdb904f828f262c0b571543a9fed7b915d@%3Cdev.beam.apache.org%3E&quot;&gt;formalizing pipeline termination
semantics&lt;/a&gt;
and making it consistent between runners.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;SDF set a new standard for how modular IO connectors can be, inspiring
creation of similar APIs for some non-SDF-based connectors (for example,
&lt;code class=&quot;highlighter-rouge&quot;&gt;SpannerIO.readAll()&lt;/code&gt; and the
&lt;a href=&quot;https://issues.apache.org/jira/browse/BEAM-2706&quot;&gt;planned&lt;/a&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;JdbcIO.readAll()&lt;/code&gt;).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;call-to-action&quot;&gt;Call to action&lt;/h2&gt;

&lt;p&gt;Apache Beam thrives on having a large community of contributors. Here are some
ways you can get involved in the SDF effort and help make the Beam IO connector
ecosystem more modular:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Use the currently available SDF-based IO connectors, provide feedback, file
bugs, and suggest or implement improvements.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Propose or develop a new IO connector based on SDF.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Implement or improve support for SDF in your favorite runner.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Subscribe and contribute to the occasional SDF-related discussions on
&lt;a href=&quot;mailto:user@beam.apache.org&quot;&gt;user@beam.apache.org&lt;/a&gt; (mailing list for Beam
users) and &lt;a href=&quot;mailto:dev@beam.apache.org&quot;&gt;dev@beam.apache.org&lt;/a&gt; (mailing list for
Beam developers)!&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 16 Aug 2017 01:00:01 -0700</pubDate>
        <link>https://beam.apache.org/blog/2017/08/16/splittable-do-fn.html</link>
        <guid isPermaLink="true">https://beam.apache.org/blog/2017/08/16/splittable-do-fn.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Apache Beam publishes the first stable release</title>
        <description>&lt;!--
Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;

&lt;p&gt;The Apache Beam community is pleased to &lt;a href=&quot;https://blogs.apache.org/foundation/entry/the-apache-software-foundation-announces12&quot;&gt;announce the availability of version 2.0.0&lt;/a&gt;. This is the first stable release of Apache Beam, signifying a statement from the community that it intends to maintain API stability with all releases for the foreseeable future, and making Beam suitable for enterprise deployment.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;This first stable release is the third important milestone for the Apache Beam community. Beam joined the Apache Incubator in February 2016 and graduated as a top-level project of The Apache Software Foundation in December. Through these fifteen months of concentrated effort, a slightly chaotic codebase, merged from multiple organizations, has been developed into a generalized framework for data processing that is truly engine- and environment-independent. Apache Beam has evolved and improved through three incubating and three post-incubation releases, culminating in the stable release announced today as version 2.0.0.&lt;/p&gt;

&lt;p&gt;In the five months since graduation, Apache Beam has seen a significant growth, both in terms of adoption and community contribution. Apache Beam is &lt;a href=&quot;https://blogs.apache.org/foundation/entry/the-apache-software-foundation-announces12&quot;&gt;in use&lt;/a&gt; at Google Cloud, PayPal, and Talend, among others.&lt;/p&gt;

&lt;p&gt;Apache Beam, version 2.0.0 improves user experience across the project, focusing on seamless portability across execution environments, including engines, operating systems, on-premise clusters, cloud providers, and data storage systems. Other highlights include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;API stability and future compatibility within this major version.&lt;/li&gt;
  &lt;li&gt;Stateful data processing paradigms that unlock efficient, data-dependent computations.&lt;/li&gt;
  &lt;li&gt;Support for user-extensible file systems, with built-in support for Hadoop Distributed File System, among others.&lt;/li&gt;
  &lt;li&gt;A metrics subsystem for deeper insight into pipeline execution.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Many contributors made this release possible, by participating in different roles: contributing code, writing documentation, testing release candidates, supporting users, or helping in some other way. The following is a partial list of contributors – 76 individuals contributed code to the project since the previous release, assembled from source history:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ahmet Altay&lt;/li&gt;
  &lt;li&gt;Eric Anderson&lt;/li&gt;
  &lt;li&gt;Raghu Angadi&lt;/li&gt;
  &lt;li&gt;Sourabh Bajaj&lt;/li&gt;
  &lt;li&gt;Péter Gergő Barna&lt;/li&gt;
  &lt;li&gt;Chen Bin&lt;/li&gt;
  &lt;li&gt;Davor Bonaci&lt;/li&gt;
  &lt;li&gt;Robert Bradshaw&lt;/li&gt;
  &lt;li&gt;Ben Chambers&lt;/li&gt;
  &lt;li&gt;Etienne Chauchot&lt;/li&gt;
  &lt;li&gt;Chang Chen&lt;/li&gt;
  &lt;li&gt;Charles Chen&lt;/li&gt;
  &lt;li&gt;Craig Citro&lt;/li&gt;
  &lt;li&gt;Lukasz Cwik&lt;/li&gt;
  &lt;li&gt;Márton Elek&lt;/li&gt;
  &lt;li&gt;Pablo Estrada&lt;/li&gt;
  &lt;li&gt;Josh Forman-Gornall&lt;/li&gt;
  &lt;li&gt;Maria García Herrero&lt;/li&gt;
  &lt;li&gt;Jins George&lt;/li&gt;
  &lt;li&gt;Damien Gouyette&lt;/li&gt;
  &lt;li&gt;Thomas Groh&lt;/li&gt;
  &lt;li&gt;Dan Halperin&lt;/li&gt;
  &lt;li&gt;Pei He&lt;/li&gt;
  &lt;li&gt;Hadar Hod&lt;/li&gt;
  &lt;li&gt;Chamikara Jayalath&lt;/li&gt;
  &lt;li&gt;Rekha Joshi&lt;/li&gt;
  &lt;li&gt;Uwe Jugel&lt;/li&gt;
  &lt;li&gt;Sung Junyoung&lt;/li&gt;
  &lt;li&gt;Holden Karau&lt;/li&gt;
  &lt;li&gt;Vikas Kedigehalli&lt;/li&gt;
  &lt;li&gt;Eugene Kirpichov&lt;/li&gt;
  &lt;li&gt;Tibor Kiss&lt;/li&gt;
  &lt;li&gt;Kenneth Knowles&lt;/li&gt;
  &lt;li&gt;Vassil Kolarov&lt;/li&gt;
  &lt;li&gt;Chinmay Kolhatkar&lt;/li&gt;
  &lt;li&gt;Aljoscha Krettek&lt;/li&gt;
  &lt;li&gt;Dipti Kulkarni&lt;/li&gt;
  &lt;li&gt;Radhika Kulkarni&lt;/li&gt;
  &lt;li&gt;Jason Kuster&lt;/li&gt;
  &lt;li&gt;Reuven Lax&lt;/li&gt;
  &lt;li&gt;Stas Levin&lt;/li&gt;
  &lt;li&gt;Julien Lhermitte&lt;/li&gt;
  &lt;li&gt;Jingsong Li&lt;/li&gt;
  &lt;li&gt;Neville Li&lt;/li&gt;
  &lt;li&gt;Mark Liu&lt;/li&gt;
  &lt;li&gt;Michael Luckey&lt;/li&gt;
  &lt;li&gt;Andrew Martin&lt;/li&gt;
  &lt;li&gt;Ismaël Mejía&lt;/li&gt;
  &lt;li&gt;Devon Meunier&lt;/li&gt;
  &lt;li&gt;Neda Mirian&lt;/li&gt;
  &lt;li&gt;Anil Muppalla&lt;/li&gt;
  &lt;li&gt;Gergely Novak&lt;/li&gt;
  &lt;li&gt;Jean-Baptiste Onofré&lt;/li&gt;
  &lt;li&gt;Melissa Pashniak&lt;/li&gt;
  &lt;li&gt;peay&lt;/li&gt;
  &lt;li&gt;David Rieber&lt;/li&gt;
  &lt;li&gt;Rahul Sabbineni&lt;/li&gt;
  &lt;li&gt;Kobi Salant&lt;/li&gt;
  &lt;li&gt;Amit Sela&lt;/li&gt;
  &lt;li&gt;Mark Shalda&lt;/li&gt;
  &lt;li&gt;Stephen Sisk&lt;/li&gt;
  &lt;li&gt;Yuya Tajima&lt;/li&gt;
  &lt;li&gt;Wesley Tanaka&lt;/li&gt;
  &lt;li&gt;JiJun Tang&lt;/li&gt;
  &lt;li&gt;Valentyn Tymofieiev&lt;/li&gt;
  &lt;li&gt;David Volquartz&lt;/li&gt;
  &lt;li&gt;Huafeng Wang&lt;/li&gt;
  &lt;li&gt;Thomas Weise&lt;/li&gt;
  &lt;li&gt;Rafal Wojdyla&lt;/li&gt;
  &lt;li&gt;Yangping Wu&lt;/li&gt;
  &lt;li&gt;wyp&lt;/li&gt;
  &lt;li&gt;James Xu&lt;/li&gt;
  &lt;li&gt;Mingmin Xu&lt;/li&gt;
  &lt;li&gt;Ted Yu&lt;/li&gt;
  &lt;li&gt;Borisa Zivkovic&lt;/li&gt;
  &lt;li&gt;Aviem Zur&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Apache Beam, version 2.0.0, is making its debut at Apache: Big Data, taking place this week in Miami, FL, with four sessions featuring Apache Beam. Apache Beam will also be highlighted at numerous face-to-face meetups and conferences, including the Future of Data San Jose meetup, Strata Data Conference London, Berlin Buzzwords, and DataWorks Summit San Jose.&lt;/p&gt;

&lt;p&gt;We’d like to invite everyone to try out Apache Beam today and consider joining our vibrant community. We welcome feedback, contribution and participation through our mailing lists, issue tracker, pull requests, and events.&lt;/p&gt;
</description>
        <pubDate>Wed, 17 May 2017 01:00:01 -0700</pubDate>
        <link>https://beam.apache.org/blog/2017/05/17/beam-first-stable-release.html</link>
        <guid isPermaLink="true">https://beam.apache.org/blog/2017/05/17/beam-first-stable-release.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Python SDK released in Apache Beam 0.6.0</title>
        <description>&lt;!--
Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;

&lt;p&gt;Apache Beam’s latest release, version &lt;a href=&quot;/get-started/downloads/&quot;&gt;0.6.0&lt;/a&gt;, introduces a new SDK – this time, for the Python programming language. The Python SDK joins the Java SDK as the second implementation of the Beam programming model.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;The Python SDK incorporates all of the main concepts of the Beam model, including ParDo, GroupByKey, Windowing, and others. It features extensible IO APIs for writing bounded sources and sinks, and provides built-in implementation for reading and writing Text, Avro, and TensorFlow record files, as well as connectors to Google BigQuery and Google Cloud Datastore.&lt;/p&gt;

&lt;p&gt;There are two runners capable of executing pipelines written with the Python SDK today: &lt;a href=&quot;/documentation/runners/direct/&quot;&gt;Direct Runner&lt;/a&gt; and &lt;a href=&quot;/documentation/runners/dataflow/&quot;&gt;Dataflow Runner&lt;/a&gt;, both of which are currently limited to batch execution only. Upcoming features will shortly bring the benefits of the Python SDK to additional runners.&lt;/p&gt;

&lt;h4 id=&quot;try-the-apache-beam-python-sdk&quot;&gt;Try the Apache Beam Python SDK&lt;/h4&gt;

&lt;p&gt;If you would like to try out the Python SDK, a good place to start is the &lt;a href=&quot;/get-started/quickstart-py/&quot;&gt;Quickstart&lt;/a&gt;. After that, you can take a look at additional &lt;a href=&quot;https://github.com/apache/beam/tree/v0.6.0/sdks/python/apache_beam/examples&quot;&gt;examples&lt;/a&gt;, and deep dive into the &lt;a href=&quot;/documentation/sdks/pydoc/&quot;&gt;API reference&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Let’s take a look at a quick example together. First, install the &lt;code class=&quot;highlighter-rouge&quot;&gt;apache-beam&lt;/code&gt; package from PyPI and start your Python interpreter.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ pip install apache-beam
$ python
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;We will harness the power of Apache Beam to estimate Pi in honor of the recently passed Pi Day.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import random
import apache_beam as beam

def run_trials(count):
  &quot;&quot;&quot;Throw darts into unit square and count how many fall into unit circle.&quot;&quot;&quot;
  inside = 0
  for _ in xrange(count):
    x, y = random.uniform(0, 1), random.uniform(0, 1)
    inside += 1 if x*x + y*y &amp;lt;= 1.0 else 0
  return count, inside

def combine_results(results):
  &quot;&quot;&quot;Given all the trial results, estimate pi.&quot;&quot;&quot;
  total, inside = sum(r[0] for r in results), sum(r[1] for r in results)
  return total, inside, 4 * float(inside) / total if total &amp;gt; 0 else 0

p = beam.Pipeline()
(p | beam.Create([500] * 10)  # Create 10 experiments with 500 samples each.
   | beam.Map(run_trials)     # Run experiments in parallel.
   | beam.CombineGlobally(combine_results)      # Combine the results.
   | beam.io.WriteToText('./pi_estimate.txt'))  # Write PI estimate to a file.

p.run()
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This example estimates Pi by throwing random darts into the unit square and keeping track of the fraction of those darts that fell into the unit circle (see the full &lt;a href=&quot;https://github.com/apache/beam/blob/v0.6.0/sdks/python/apache_beam/examples/complete/estimate_pi.py&quot;&gt;example&lt;/a&gt; for details). If you are curious, you can check the result of our estimation by looking at the output file.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ cat pi_estimate.txt*
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;roadmap&quot;&gt;Roadmap&lt;/h4&gt;

&lt;p&gt;The first thing on the Python SDK’s roadmap is to address two of its limitations. First, the existing runners are currently limited to bounded PCollections, and we are looking forward to extending the SDK to support unbounded PCollections (“streaming”). Additionally, we are working on extending support to more Apache Beam runners, and the upcoming Fn API will do the heavy lifting.&lt;/p&gt;

&lt;p&gt;Both of these improvements will enable the Python SDK to fulfill the mission of Apache Beam: a unified programming model for batch and streaming data processing that can run on any execution engine.&lt;/p&gt;

&lt;h4 id=&quot;join-us&quot;&gt;Join us!&lt;/h4&gt;

&lt;p&gt;Please consider joining us, whether as a user or a contributor, as we work towards our first release with API stability. If you’d like to try out Apache Beam today, check out the latest &lt;a href=&quot;/get-started/downloads/&quot;&gt;0.6.0&lt;/a&gt; release. We welcome contributions and participation from anyone through our mailing lists, issue tracker, pull requests, and events.&lt;/p&gt;
</description>
        <pubDate>Thu, 16 Mar 2017 01:00:01 -0700</pubDate>
        <link>https://beam.apache.org/blog/2017/03/16/python-sdk-release.html</link>
        <guid isPermaLink="true">https://beam.apache.org/blog/2017/03/16/python-sdk-release.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
  </channel>
</rss>
