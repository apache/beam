<!--
 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at
   http://www.apache.org/licenses/LICENSE-2.0
 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License. See accompanying LICENSE file.
-->
<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Apache Beam</title>
    <description>Apache Beam is an open source, unified model and set of language-specific SDKs for defining and executing data processing workflows, and also data ingestion and integration flows, supporting Enterprise Integration Patterns (EIPs) and Domain Specific Languages (DSLs). Dataflow pipelines simplify the mechanics of large-scale batch and streaming data processing and can run on a number of runtimes like Apache Flink, Apache Spark, and Google Cloud Dataflow (a cloud service). Beam also brings DSL in different languages, allowing users to easily implement their data integration processes.
</description>
    <link>https://beam.apache.org/</link>
    <atom:link href="https://beam.apache.org/feed.xml" rel="self" type="application/rss+xml"/>
    <generator>Jekyll v3.2.0</generator>
    
      <item>
        <title>Inaugural edition of the Beam Summit Europe 2018 - aftermath</title>
        <description>&lt;!--
Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;

&lt;p&gt;Almost 1 month ago, we had the pleasure to welcome the Beam community at Level39 in London for the inaugural edition of the Beam Summit London Summit. &lt;!--more--&gt;&lt;/p&gt;

&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Day 1 of the first Beam Summit London going full speed ahead! Sessions by &lt;a href=&quot;https://twitter.com/SkyUK?ref_src=twsrc%5Etfw&quot;&gt;@SkyUK&lt;/a&gt; &lt;a href=&quot;https://twitter.com/GCPcloud?ref_src=twsrc%5Etfw&quot;&gt;@GCPcloud&lt;/a&gt; &lt;a href=&quot;https://twitter.com/Talend?ref_src=twsrc%5Etfw&quot;&gt;@Talend&lt;/a&gt; &lt;a href=&quot;https://twitter.com/PlantixApp?ref_src=twsrc%5Etfw&quot;&gt;@PlantixApp&lt;/a&gt; and more! &lt;a href=&quot;https://twitter.com/hashtag/ApacheBeam?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#ApacheBeam&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hashtag/apachebeamlondon?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#apachebeamlondon&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hashtag/l39?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#l39&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hashtag/level39?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#level39&lt;/a&gt; &lt;a href=&quot;https://twitter.com/ApacheBeam?ref_src=twsrc%5Etfw&quot;&gt;@ApacheBeam&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hashtag/summit?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#summit&lt;/a&gt; &lt;a href=&quot;https://t.co/aEESFnbgxT&quot;&gt;pic.twitter.com/aEESFnbgxT&lt;/a&gt;&lt;/p&gt;&amp;mdash; Matthias Baetens üåÜ (@matthiasbaetens) &lt;a href=&quot;https://twitter.com/matthiasbaetens/status/1046756260996149248?ref_src=twsrc%5Etfw&quot;&gt;October 1, 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;h2 id=&quot;first-edition&quot;&gt;First edition!&lt;/h2&gt;

&lt;p&gt;This first edition of the summit was a free event, with over 125 RSVPs. We had two days of content; day one was focused on the roadmap of the project, the ASF and use cases from companies that use Beam. The second day was divided into tracks (a beginner and an advanced track). Those presentations &amp;amp; workshops were organised for the more than &lt;strong&gt;80 attendees&lt;/strong&gt; - and next to that there were several other activities like discussions, a brainstorm session, a UX booth and a signing session. We were able to offer the attendees &lt;strong&gt;17 sessions&lt;/strong&gt; from a great line-up of companies: 
Google, Spotify, Talend, Sky, Amazon, Data Artisans, Datatonic, Vente Exclusive, ML6, Flumaion, Plantix, Polidea, Seznam and more!&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h4 id=&quot;topics-included-using-python-to-run-beam-on-flink&quot;&gt;Topics included using Python to run Beam on Flink:&lt;/h4&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;nl&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Don&amp;#39;t miss &lt;a href=&quot;https://twitter.com/snntrable?ref_src=twsrc%5Etfw&quot;&gt;@snntrable&lt;/a&gt;&amp;#39;s session at Beam Sumit London, Oct. 2, 2018, about &lt;a href=&quot;https://twitter.com/hashtag/Python?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#Python&lt;/a&gt; Streaming Pipelines with &lt;a href=&quot;https://twitter.com/ApacheBeam?ref_src=twsrc%5Etfw&quot;&gt;@ApacheBeam&lt;/a&gt; and &lt;a href=&quot;https://twitter.com/ApacheFlink?ref_src=twsrc%5Etfw&quot;&gt;@ApacheFlink&lt;/a&gt;! Register here: &lt;a href=&quot;https://t.co/wblzUeiTIg&quot;&gt;https://t.co/wblzUeiTIg&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hashtag/streamprocessing?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#streamprocessing&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hashtag/BigData?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#BigData&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hashtag/MachineLearning?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#MachineLearning&lt;/a&gt; &lt;a href=&quot;https://t.co/7Ph51WqspW&quot;&gt;pic.twitter.com/7Ph51WqspW&lt;/a&gt;&lt;/p&gt;&amp;mdash; data Artisans (@dataArtisans) &lt;a href=&quot;https://twitter.com/dataArtisans/status/1044967266817847296?ref_src=twsrc%5Etfw&quot;&gt;26 september 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h4 id=&quot;ml-with-beam-with-the-tensorflow-transform-integration&quot;&gt;ML with Beam with the TensorFlow transform integration:&lt;/h4&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;nl&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Such a great pleasure to listen to the talk by &lt;a href=&quot;https://twitter.com/FsMatt?ref_src=twsrc%5Etfw&quot;&gt;@FsMatt&lt;/a&gt; on TensorFlow transform at the &lt;a href=&quot;https://twitter.com/hashtag/BeamSummit?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#BeamSummit&lt;/a&gt;!  &lt;a href=&quot;https://twitter.com/ApacheBeam?ref_src=twsrc%5Etfw&quot;&gt;@ApacheBeam&lt;/a&gt; &lt;a href=&quot;https://twitter.com/TensorFlow?ref_src=twsrc%5Etfw&quot;&gt;@TensorFlow&lt;/a&gt; &lt;a href=&quot;https://twitter.com/Level39CW?ref_src=twsrc%5Etfw&quot;&gt;@Level39CW&lt;/a&gt; &lt;br /&gt;&lt;br /&gt;Check the code for his demo at &lt;a href=&quot;https://t.co/8IS41A2aF2&quot;&gt;https://t.co/8IS41A2aF2&lt;/a&gt; &lt;a href=&quot;https://t.co/UWytiudmRO&quot;&gt;https://t.co/UWytiudmRO&lt;/a&gt;&lt;/p&gt;&amp;mdash; datatonic (@teamdatatonic) &lt;a href=&quot;https://twitter.com/teamdatatonic/status/1047126173493469184?ref_src=twsrc%5Etfw&quot;&gt;2 oktober 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h4 id=&quot;the-portability-layer-was-a-big-topic&quot;&gt;The portability layer was a big topic:&lt;/h4&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;nl&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Excellent talk by &lt;a href=&quot;https://twitter.com/stadtlegende?ref_src=twsrc%5Etfw&quot;&gt;@stadtlegende&lt;/a&gt; on adding portability to &lt;a href=&quot;https://twitter.com/hashtag/ApacheBeam?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#ApacheBeam&lt;/a&gt;, awesome milestone and next step to make the Apache Beam vision become a reality! &lt;a href=&quot;https://t.co/M9jERlTeAE&quot;&gt;pic.twitter.com/M9jERlTeAE&lt;/a&gt;&lt;/p&gt;&amp;mdash; Matthias Feys (@FsMatt) &lt;a href=&quot;https://twitter.com/FsMatt/status/1047105336841244673?ref_src=twsrc%5Etfw&quot;&gt;2 oktober 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h4 id=&quot;as-well-as-a-session-on-how-to-build-your-own-sdk&quot;&gt;As well as a session on how to build your own SDK:&lt;/h4&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;nl&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Robert Bredshaw explains how to build a new &lt;a href=&quot;https://twitter.com/ApacheBeam?ref_src=twsrc%5Etfw&quot;&gt;@ApacheBeam&lt;/a&gt; SDK.&lt;a href=&quot;https://twitter.com/hashtag/BeamSummit?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#BeamSummit&lt;/a&gt; &lt;a href=&quot;https://t.co/Bj84GJimdo&quot;&gt;pic.twitter.com/Bj84GJimdo&lt;/a&gt;&lt;/p&gt;&amp;mdash; Maximilian Michels üßó (@stadtlegende) &lt;a href=&quot;https://twitter.com/stadtlegende/status/1047139320195366912?ref_src=twsrc%5Etfw&quot;&gt;2 oktober 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;h2 id=&quot;presentations&quot;&gt;Presentations&lt;/h2&gt;
&lt;p&gt;In the aftermath of the Summit, you can check the presentations of all the sessions.&lt;/p&gt;

&lt;h3 id=&quot;day-1-use-cases&quot;&gt;Day 1: Use cases&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://drive.google.com/open?id=1hyHw7RVpFrFpli3vLt6JGBHrEm4BcgF-5nRdH1ZE8qo&quot;&gt;Day 1 - Session 1 - Large scale stream analytics with Apache Beam at Sky&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://drive.google.com/open?id=1MxYrFDVoVFsrzbTtmr18zcbPFUU4nSdi&quot;&gt;Day 1 - Session 2 - Running Quantitative Analytics with Apache Beam&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://drive.google.com/open?id=0B4bFLXEWuluSdVBJSnZrbTZjSGFHbnd4cExYOGZQU2hmY3lF&quot;&gt;Day 1 - Session 3 - Talend Data Streams: Building Big Data pipelines with Apache Beam&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://drive.google.com/open?id=1-GIUVn9QBtg6t-O8uINDkMO4PyZSU_HAEjMWuUHiYY4&quot;&gt;Day 1 - Session 4 - Lesson Learned from Migrating to Apache Beam for Geo-Data Visualisation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;day-2-beginners-track&quot;&gt;Day 2: Beginners track&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://drive.google.com/open?id=1ntQEDhb8gkxof4uFftxWTOfN39laUDZU7IDHTPKWrcQ&quot;&gt;Day 2 - Beginner - Session 1 - Development Environment with Apache Beam&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://drive.google.com/open?id=0B4bFLXEWuluSWWJBWXV3ZTdseWpJN1o5UFdpSzV4Qi1sSGU0&quot;&gt;Day 2 - Beginner - Session 2 - Towards Portability and Beyond&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://drive.google.com/open?id=0B4bFLXEWuluSLTd6TFlYdFZZYjBTOFZQV3MxZzlPLWROWjZv&quot;&gt;Day 2 - Beginner - Session 3 - Python Streaming Pipelines with Beam on Flink&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://drive.google.com/open?id=0B4bFLXEWuluSMEV1a1cwM3ozeWQ4TkxlS0tFcnNtRGNGcjJ3&quot;&gt;Day 2 - Beginner - Session 4 - How runners execute a Beam pipeline&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://drive.google.com/open?id=1QyqO8zJ3fIWD5DTnr1JNCEbm2dS15c1c02fI8zD-zqY&quot;&gt;Day 2 - Beginner - Session 5 - IO Integration Testing framework in Apache Beam&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;day-2-advanced-track&quot;&gt;Day 2: Advanced track&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://drive.google.com/open?id=1Kr1skutObtDil2CExSQUb5rCVwZQm1m2lpmuAXFCE5I&quot;&gt;Day 2 - Advanced - Session 1 -  Pre-processing for TensorFlow pipelines with Apache Beam &amp;amp;  tf.Transform&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://drive.google.com/open?id=11x7gtuAxg76nOQKaB0YOwcvzS4TUeWONTU1ZQK0LsX8&quot;&gt;Day 2 - Advanced - Session 2 - Streaming data into BigQuery: schema generation with Protobuf&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://drive.google.com/open?id=1cgQGBIXaACSwbYu_w3AkvvTdsCfeXAS1tBvQ77eVn74&quot;&gt;Day 2 - Advanced - Session 3 - Implementing a SplittableParDo&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.google.com/presentation/d/1F02Lwnqm9H3cGqDQhIZ3gbftyLQSnVMRxX69H_d04OE/edit?usp=sharing&quot;&gt;Day 2 - Advanced - Session 4 - Big Data on Google Cloud with Scala and Scio&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://drive.google.com/open?id=1D1ajcKoOR5OzehPwONdHLSzpO4PZOsLk&quot;&gt;Day 2 - Advanced - Session 5 - Landuse Classification of Satellite Imagery&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://drive.google.com/open?id=1aFH6lhnVIq4Alu-_HItQ0QOddEPJQRqI5jV_t0o3CYI&quot;&gt;Day 2 - Advanced - Session 6 - Java 8 DSL for Beam SDK&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://drive.google.com/open?id=1AkU-QXSflau-RSeolB4TSLy0_mg0xwb398Czw7aqVGw&quot;&gt;Day 2  - Advanced - Session 7 - So, You Want to Write a Beam SDK?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;recordings&quot;&gt;Recordings&lt;/h2&gt;
&lt;p&gt;In case you prefer rewatching the recorded talks together with those slides, we are also happy to share the recordings of the majority of the sessions:&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/videoseries?list=PL4dEBWmGSIU_9JTGnkGVg6-BwaV0FMxyJ&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;h3 id=&quot;day-1-use-cases-1&quot;&gt;Day 1: Use cases&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://youtu.be/En0FrjvNr3M&quot;&gt;Day 1 - Session 1 - Large scale stream analytics with Apache Beam at Sky&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://youtu.be/6yDEOUophuw&quot;&gt;Day 1 - Session 2 - Running Quantitative Analytics with Apache Beam&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://youtu.be/1AlEGUtiQek&quot;&gt;Day 1 - Session 3 - Talend Data Streams: Building Big Data pipelines with Apache Beam&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://youtu.be/GBKqw03doHE&quot;&gt;Day 1 - Session 4 - Lesson Learned from Migrating to Apache Beam for Geo-Data Visualisation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;day-2-advanced-track-1&quot;&gt;Day 2: Advanced track&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://youtu.be/L-k6-3ApXR4&quot;&gt;Day 2 - Advanced - Session 1 -  Pre-processing for TensorFlow pipelines with Apache Beam &amp;amp;  tf.Transform&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://youtu.be/ctN5U_Ke8uk&quot;&gt;Day 2 - Advanced - Session 2 - Streaming data into BigQuery: schema generation with Protobuf&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://youtu.be/jU6EmPyKefg&quot;&gt;Day 2 - Advanced - Session 3 - Implementing a SplittableParDo&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://youtu.be/F0n9sqj1_NQ&quot;&gt;Day 2 - Advanced - Session 4 - Big Data on Google Cloud with Scala and Scio&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://youtu.be/s-IR2eFe4B4&quot;&gt;Day 2 - Advanced - Session 5 - Landuse Classification of Satellite Imagery&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://youtu.be/ott1e_CnZ04&quot;&gt;Day 2 - Advanced - Session 6 - Java 8 DSL for Beam SDK&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://youtu.be/VsGQ2LFeTHY&quot;&gt;Day 2  - Advanced - Session 7 - So, You Want to Write a Beam SDK?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;wrapping-up&quot;&gt;Wrapping up&lt;/h2&gt;

&lt;p&gt;We are also gathering feedback and thoughts on the Summit - please add your thoughts and discussions to the &lt;a href=&quot;https://lists.apache.org/thread.html/aa1306da25029dff12a49ba3ce63f2caf6a5f8ba73eda879c8403f3f@%3Cdev.beam.apache.org%3E&quot;&gt;topic on the mailing list&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Overall, we hope our attendees enjoyed this first edition of our summit and want to thank &lt;strong&gt;our sponsors Google, Datatonic, Vente-Exclusive&lt;/strong&gt; to make this possible.&lt;/p&gt;

&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;nl&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Wrapping up the first day of the &lt;a href=&quot;https://twitter.com/hashtag/BeamSummit?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#BeamSummit&lt;/a&gt;. Excellent view from the &lt;a href=&quot;https://twitter.com/hashtag/level39?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#level39&lt;/a&gt; venue. Very happy with the line up. &lt;a href=&quot;https://t.co/7FhokKbQY5&quot;&gt;pic.twitter.com/7FhokKbQY5&lt;/a&gt;&lt;/p&gt;&amp;mdash; Alex Van Boxel (@alexvb) &lt;a href=&quot;https://twitter.com/alexvb/status/1046803829650608129?ref_src=twsrc%5Etfw&quot;&gt;1 oktober 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

</description>
        <pubDate>Wed, 31 Oct 2018 01:00:01 -0700</pubDate>
        <link>https://beam.apache.org/blog/2018/10/31/beam-summit-aftermath.html</link>
        <guid isPermaLink="true">https://beam.apache.org/blog/2018/10/31/beam-summit-aftermath.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Apache Beam 2.8.0</title>
        <description>&lt;!--
Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;

&lt;p&gt;We are happy to present the new 2.8.0 release of Beam. This release includes both improvements and new functionality.
See the &lt;a href=&quot;/get-started/downloads/#280-2018-10-26&quot;&gt;download page&lt;/a&gt; for this release.&lt;!--more--&gt;
For more information on changes in 2.8.0, check out the
&lt;a href=&quot;https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12319527&amp;amp;version=12343985&quot;&gt;detailed release notes&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;new-features--improvements&quot;&gt;New Features / Improvements&lt;/h2&gt;

&lt;h2 id=&quot;known-issues&quot;&gt;Known Issues&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/BEAM-4783&quot;&gt;BEAM-4783&lt;/a&gt; Performance degradations in certain situations when Spark runner is used.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dependency-upgrades&quot;&gt;Dependency Upgrades&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Elastic Search dependency upgraded to 6.3.2&lt;/li&gt;
  &lt;li&gt;google-cloud-pubsub dependency upgraded to 0.35.4&lt;/li&gt;
  &lt;li&gt;google-api-client dependency upgraded to 1.24.1&lt;/li&gt;
  &lt;li&gt;Updated Flink Runner to 1.5.3&lt;/li&gt;
  &lt;li&gt;Updated Spark runner to Spark version 2.3.2&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;sdks&quot;&gt;SDKs&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Python SDK added support for user state and timers.&lt;/li&gt;
  &lt;li&gt;Go SDK added support for side inputs.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;portability&quot;&gt;Portability&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://beam.apache.org/roadmap/portability/#python-on-flink&quot;&gt;Python on Flink MVP&lt;/a&gt; completed.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ios&quot;&gt;I/Os&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Fixes to RedisIO non-prefix read operations.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;miscellaneous-fixes&quot;&gt;Miscellaneous Fixes&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Several bug fixes and performance improvements.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;list-of-contributors&quot;&gt;List of Contributors&lt;/h2&gt;

&lt;p&gt;According to git shortlog, the following people contributed
to the 2.8.0 release. Thank you to all contributors!&lt;/p&gt;

&lt;p&gt;Adam Horky, Ahmet Altay, Alan Myrvold, Aleksandr Kokhaniukov,
Alex Amato, Alexey Romanenko, Aljoscha Krettek, Andrew Fulton,
Andrew Pilloud, Ankur Goenka, Anton Kedin, Babu, Batkhuyag Batsaikhan, Ben Song,
Bingfeng Shu, Boyuan Zhang, Chamikara Jayalath, Charles Chen,
Christian Schneider, Cody Schroeder, Colm O hEigeartaigh, Daniel Mills,
Daniel Oliveira, Dat Tran, David Moravek, Dusan Rychnovsky, Etienne Chauchot,
Eugene Kirpichov, Gleb Kanterov, Heejong Lee, Henning Rohde, Isma√´l Mej√≠a,
Jan Lukavsk√Ω, Jaromir Vanek, Jean-Baptiste Onofr√©, Jeff Klukas, Joar Wandborg,
Jozef Vilcek, Julien Phalip, Julien Tournay, Juta, J√°ra Vanƒõk,
Katarzyna Kucharczyk, Kengo Seki, Kenneth Knowles, Kevin Si, Kirill Kozlov,
Kyle Winkelman, Logan HAUSPIE, Lukasz Cwik, Manu Zhang, Mark Liu,
Matthias Baetens, Matthias Feys, Maximilian Michels, Melissa Pashniak,
Micah Wylde, Michael Luckey, Mike Pedersen, Mikhail Gryzykhin, Novotnik,
Petr, Ondrej Kvasnicka, Pablo Estrada, PaulVelthuis93, Pavel Slechta,
Rafael Fern√°ndez, Raghu Angadi, Renat, Reuven Lax, Robbe Sneyders,
Robert Bradshaw, Robert Burke, Rodrigo Benenson, Rong Ou, Ruoyun Huang,
Ryan Williams, Sam Rohde, Scott Wegner, Shinsuke Sugaya, Shnitz, Simon P,
Sindy Li, Stephen Lumenta, Stijn Decubber, Thomas Weise, Tomas Novak,
Tomas Roos, Udi Meiri, Vaclav Plajt, Valentyn Tymofieiev, Vitalii Tverdokhlib,
Xinyu Liu, XuMingmin, Yifan Zou, Yuan, Yueyang Qiu, aalbatross, amaliujia,
cclauss, connelloG, daidokoro, deepyaman, djhworld, flyisland, huygaa11,
jasonkuster, jglezt, kkpoon, mareksimunek, nielm, svXaverius, timrobertson100,
vaclav.plajt@gmail.com, vitaliytv, vvarma, xiliu, xinyuiscool, xitep,
≈Åukasz Gajowy.&lt;/p&gt;
</description>
        <pubDate>Mon, 29 Oct 2018 01:00:01 -0700</pubDate>
        <link>https://beam.apache.org/blog/2018/10/29/beam-2.8.0.html</link>
        <guid isPermaLink="true">https://beam.apache.org/blog/2018/10/29/beam-2.8.0.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Apache Beam 2.7.0</title>
        <description>&lt;!--
Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;

&lt;p&gt;We are happy to present the new 2.7.0 release of Beam. This release includes both improvements and new functionality.
See the &lt;a href=&quot;/get-started/downloads/#270-lts-2018-10-02&quot;&gt;download page&lt;/a&gt; for this release.&lt;!--more--&gt;
For more information on changes in 2.7.0, check out the
&lt;a href=&quot;https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12319527&amp;amp;version=12343654&quot;&gt;detailed release notes&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;new-features--improvements&quot;&gt;New Features / Improvements&lt;/h2&gt;

&lt;h3 id=&quot;new-ios&quot;&gt;New I/Os&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;KuduIO&lt;/li&gt;
  &lt;li&gt;Amazon SNS sink&lt;/li&gt;
  &lt;li&gt;Amazon SqsIO&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dependency-upgrades&quot;&gt;Dependency Upgrades&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Apache Calcite dependency upgraded to 1.17.0&lt;/li&gt;
  &lt;li&gt;Apache Derby dependency upgraded to 10.14.2.0&lt;/li&gt;
  &lt;li&gt;Apache HTTP components upgraded (see release notes).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;portability&quot;&gt;Portability&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Experimental support for Python on local Flink runner for simple
examples, see latest information here:
/contribute/portability/#status.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;miscellaneous-fixes&quot;&gt;Miscellaneous Fixes&lt;/h2&gt;

&lt;h3 id=&quot;ios&quot;&gt;I/Os&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;KinesisIO, fixed dependency issue&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;list-of-contributors&quot;&gt;List of Contributors&lt;/h2&gt;

&lt;p&gt;According to git shortlog, the following 72 people contributed
to the 2.7.0 release. Thank you to all contributors!&lt;/p&gt;

&lt;p&gt;Ahmet Altay, Alan Myrvold, Alexey Romanenko, Aljoscha Krettek,
Andrew Pilloud, Ankit Jhalaria, Ankur Goenka, Anton Kedin, Boyuan
Zhang, Carl McGraw, Carlos Alonso, cclauss, Chamikara Jayalath,
Charles Chen, Cory Brzycki, Daniel Oliveira, Dariusz Aniszewski,
devinduan, Eric Beach, Etienne Chauchot, Eugene Kirpichov, Garrett
Jones, Gene Peters, Gleb Kanterov, Henning Rohde, Henry Suryawirawan,
Holden Karau, Huygaa Batsaikhan, Isma√´l Mej√≠a, Jason Kuster, Jean-
Baptiste Onofr√©, Joachim van der Herten, Jozef Vilcek, jxlewis, Kai
Jiang, Katarzyna Kucharczyk, Kenn Knowles, Krzysztof Trubalski, Kyle
Winkelman, Leen Toelen, Luis Enrique Ort√≠z Ramirez, Lukasz Cwik,
≈Åukasz Gajowy, Luke Cwik, Mark Liu, Matthias Feys, Maximilian Michels,
Melissa Pashniak, Mikhail Gryzykhin, Mikhail Sokolov, mingmxu, Norbert
Chen, Pablo Estrada, Prateek Chanda, Raghu Angadi, Ravi Pathak, Reuven
Lax, Robert Bradshaw, Robert Burke, Rui Wang, Ryan Williams, Sindy Li,
Thomas Weise, Tim Robertson, Tormod Haavi, Udi Meiri, Vaclav Plajt,
Valentyn Tymofieiev, xiliu, XuMingmin, Yifan Zou, Yueyang Qiu.&lt;/p&gt;
</description>
        <pubDate>Wed, 03 Oct 2018 01:00:01 -0700</pubDate>
        <link>https://beam.apache.org/blog/2018/10/03/beam-2.7.0.html</link>
        <guid isPermaLink="true">https://beam.apache.org/blog/2018/10/03/beam-2.7.0.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Beam Summit Europe 2018</title>
        <description>&lt;!--
Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;

&lt;p&gt;With a growing community of contributors and users, the Apache Beam project is organising the first European Beam Summit.&lt;/p&gt;

&lt;p&gt;We are happy to invite you to this event, which will take place in &lt;strong&gt;London&lt;/strong&gt; on &lt;strong&gt;October 1st and 2nd of 2018&lt;/strong&gt;. &lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/Facebook-AD.png&quot; alt=&quot;Beam Summit Europe 2018 flyer&quot; height=&quot;360&quot; width=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;what-is-the-beam-summit-2018&quot;&gt;What is the Beam Summit 2018?&lt;/h3&gt;
&lt;p&gt;The summit is a 2 day, multi-track event.&lt;/p&gt;

&lt;p&gt;During the first day we‚Äôll host sessions to share use cases from companies using Apache Beam, community driven talks, and a session to discuss the project‚Äôs roadmap (from the main partners in the project as well as all users planning to contribute to the project and wanting to share their plans). We‚Äôll also have break-out sessions that will allow cross team collaboration in multiple sub-topics.&lt;/p&gt;

&lt;p&gt;The second day will be a ‚Äúhands-on‚Äù day. We will offer an introductory session to Apache Beam. Additionally, we‚Äôll host an advanced track for more advanced users with open-table discussions about more complex and newer Apache Beam features.&lt;/p&gt;

&lt;p&gt;The agenda will grow and be communicated in the coming month, keep an eye on the page.&lt;/p&gt;

&lt;h3 id=&quot;event-details&quot;&gt;Event Details&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Venue&lt;/strong&gt;: &lt;a href=&quot;https://goo.gl/maps/LAC4haDzSzR2&quot;&gt;Level39, One Canada Square, Canary Wharf, London E14 5AB&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Dates&lt;/strong&gt;: 1-2 October 2018&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;how-do-i-register&quot;&gt;How do I register?&lt;/h3&gt;
&lt;p&gt;You can register for free on the &lt;a href=&quot;https://www.eventbrite.com/e/beam-summit-london-2018-tickets-49100625292#tickets&quot;&gt;Eventbrite registration page&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;i-am-interested-in-speaking-how-do-i-propose-my-session&quot;&gt;I am interested in speaking, how do I propose my session?&lt;/h3&gt;
&lt;p&gt;With this we are also launching a Call for Papers in case you want to secure a slot for one of the sessions. Please fill out the &lt;a href=&quot;https://goo.gl/forms/nrZOCC1JwEfLtKfA2&quot;&gt;CfP form&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;id-love-to-get-involved-as-a-volunteer-or-sponsor&quot;&gt;I‚Äôd love to get involved as a volunteer or sponsor&lt;/h3&gt;
&lt;p&gt;Furthermore, in order to keep this event free, we are looking for people to help out at and/or sponsor some parts of the conference. If you (or your company) are interested to help out, please reach out to: &lt;a href=&quot;mailto:baetensmatthias@gmail.com&quot;&gt;baetensmatthias@gmail.com&lt;/a&gt; or &lt;a href=&quot;mailto:alex@vanboxel.be&quot;&gt;alex@vanboxel.be&lt;/a&gt;. You can find more info in the &lt;a href=&quot;https://drive.google.com/file/d/1RnZ52rGaB6BR-EKneBcabdMcg9Pl7z9M&quot;&gt;sponsor booklet&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thanks, and we hope to see you at the event! 
The Events &amp;amp; Meetups Group&lt;/p&gt;
</description>
        <pubDate>Tue, 21 Aug 2018 01:00:01 -0700</pubDate>
        <link>https://beam.apache.org/blog/2018/08/21/beam-summit-europe.html</link>
        <guid isPermaLink="true">https://beam.apache.org/blog/2018/08/21/beam-summit-europe.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>A review of input streaming connectors</title>
        <description>&lt;!--
Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;

&lt;p&gt;In this post, you‚Äôll learn about the current state of support for input streaming connectors in &lt;a href=&quot;/&quot;&gt;Apache Beam&lt;/a&gt;. For more context, you‚Äôll also learn about the corresponding state of support in &lt;a href=&quot;https://spark.apache.org/&quot;&gt;Apache Spark&lt;/a&gt;.&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;With batch processing, you might load data from any source, including a database system. Even if there are no specific SDKs available for those database systems, you can often resort to using a &lt;a href=&quot;https://en.wikipedia.org/wiki/Java_Database_Connectivity&quot;&gt;JDBC&lt;/a&gt; driver. With streaming, implementing a proper data pipeline is arguably more challenging as generally fewer source types are available. For that reason, this article particularly focuses on the streaming use case.&lt;/p&gt;

&lt;h2 id=&quot;connectors-for-java&quot;&gt;Connectors for Java&lt;/h2&gt;

&lt;p&gt;Beam has an official &lt;a href=&quot;/documentation/sdks/java/&quot;&gt;Java SDK&lt;/a&gt; and has several execution engines, called &lt;a href=&quot;/documentation/runners/capability-matrix/&quot;&gt;runners&lt;/a&gt;. In most cases it is fairly easy to transfer existing Beam pipelines written in Java or Scala to a Spark environment by using the &lt;a href=&quot;/documentation/runners/spark/&quot;&gt;Spark Runner&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Spark is written in Scala and has a &lt;a href=&quot;https://spark.apache.org/docs/latest/api/java/&quot;&gt;Java API&lt;/a&gt;. Spark‚Äôs source code compiles to &lt;a href=&quot;https://en.wikipedia.org/wiki/Java_(programming_language)#Java_JVM_and_Bytecode&quot;&gt;Java bytecode&lt;/a&gt; and the binaries are run by a &lt;a href=&quot;https://en.wikipedia.org/wiki/Java_virtual_machine&quot;&gt;Java Virtual Machine&lt;/a&gt;. Scala code is interoperable with Java and therefore has native compatibility with Java libraries (and vice versa).&lt;/p&gt;

&lt;p&gt;Spark offers two approaches to streaming: &lt;a href=&quot;https://spark.apache.org/docs/latest/streaming-programming-guide.html&quot;&gt;Discretized Streaming&lt;/a&gt; (or DStreams) and &lt;a href=&quot;https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html&quot;&gt;Structured Streaming&lt;/a&gt;. DStreams are a basic abstraction that represents a continuous series of &lt;a href=&quot;https://spark.apache.org/docs/latest/rdd-programming-guide.html&quot;&gt;Resilient Distributed Datasets&lt;/a&gt; (or RDDs). Structured Streaming was introduced more recently (the alpha release came with Spark 2.1.0) and is based on a &lt;a href=&quot;https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#programming-model&quot;&gt;model&lt;/a&gt; where live data is continuously appended to a table structure.&lt;/p&gt;

&lt;p&gt;Spark Structured Streaming supports &lt;a href=&quot;https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/streaming/DataStreamReader.html&quot;&gt;file sources&lt;/a&gt; (local filesystems and HDFS-compatible systems like Cloud Storage or S3) and &lt;a href=&quot;https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html&quot;&gt;Kafka&lt;/a&gt; as streaming &lt;a href=&quot;https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#input-sources&quot;&gt;inputs&lt;/a&gt;. Spark maintains built-in connectors for DStreams aimed at third-party services, such as Kafka or Flume, while other connectors are available through linking external dependencies, as shown in the table below.&lt;/p&gt;

&lt;p&gt;Below are the main streaming input connectors for available for Beam and Spark DStreams in Java:&lt;/p&gt;

&lt;table class=&quot;table table-bordered&quot;&gt;
  &lt;tr&gt;
   &lt;td&gt;
   &lt;/td&gt;
   &lt;td&gt;
   &lt;/td&gt;
   &lt;td&gt;&lt;strong&gt;Apache Beam&lt;/strong&gt;
   &lt;/td&gt;
   &lt;td&gt;&lt;strong&gt;Apache Spark DStreams&lt;/strong&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td rowspan=&quot;2&quot;&gt;File Systems
   &lt;/td&gt;
   &lt;td&gt;Local&lt;br /&gt;(Using the &lt;code&gt;file://&lt;/code&gt; URI)
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;https://beam.apache.org/releases/javadoc/2.9.0/org/apache/beam/sdk/io/TextIO.html&quot;&gt;TextIO&lt;/a&gt;
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;https://spark.apache.org/docs/latest/api/java/org/apache/spark/streaming/StreamingContext.html#textFileStream-java.lang.String-&quot;&gt;textFileStream&lt;/a&gt;&lt;br /&gt;(Spark treats most Unix systems as HDFS-compatible, but the location should be accessible from all nodes)
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;HDFS&lt;br /&gt;(Using the &lt;code&gt;hdfs://&lt;/code&gt; URI)
   &lt;/td&gt;
    &lt;td&gt;&lt;a href=&quot;https://beam.apache.org/releases/javadoc/2.9.0/org/apache/beam/sdk/io/FileIO.html&quot;&gt;FileIO&lt;/a&gt; + &lt;a href=&quot;https://beam.apache.org/releases/javadoc/2.9.0/org/apache/beam/sdk/io/hdfs/HadoopFileSystemOptions.html&quot;&gt;HadoopFileSystemOptions&lt;/a&gt;
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;https://spark.apache.org/docs/latest/api/java/org/apache/spark/streaming/util/HdfsUtils.html&quot;&gt;HdfsUtils&lt;/a&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td rowspan=&quot;2&quot;&gt;Object Stores
   &lt;/td&gt;
   &lt;td&gt;Cloud Storage&lt;br /&gt;(Using the &lt;code&gt;gs://&lt;/code&gt; URI)
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;https://beam.apache.org/releases/javadoc/2.9.0/org/apache/beam/sdk/io/FileIO.html&quot;&gt;FileIO&lt;/a&gt; + &lt;a href=&quot;https://beam.apache.org/releases/javadoc/2.9.0/org/apache/beam/sdk/extensions/gcp/options/GcsOptions.html&quot;&gt;GcsOptions&lt;/a&gt;
   &lt;/td&gt;
   &lt;td rowspan=&quot;2&quot;&gt;&lt;a href=&quot;https://spark.apache.org/docs/latest/api/java/org/apache/spark/SparkContext.html#hadoopConfiguration--&quot;&gt;hadoopConfiguration&lt;/a&gt;
and &lt;a href=&quot;https://spark.apache.org/docs/latest/api/java/org/apache/spark/streaming/StreamingContext.html#textFileStream-java.lang.String-&quot;&gt;textFileStream&lt;/a&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;S3&lt;br /&gt;(Using the &lt;code&gt;s3://&lt;/code&gt; URI)
   &lt;/td&gt;
    &lt;td&gt;&lt;a href=&quot;https://beam.apache.org/releases/javadoc/2.9.0/org/apache/beam/sdk/io/FileIO.html&quot;&gt;FileIO&lt;/a&gt; + &lt;a href=&quot;https://beam.apache.org/releases/javadoc/2.9.0/org/apache/beam/sdk/io/aws/options/S3Options.html&quot;&gt;S3Options&lt;/a&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td rowspan=&quot;3&quot;&gt;Messaging Queues
   &lt;/td&gt;
   &lt;td&gt;Kafka
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;https://beam.apache.org/releases/javadoc/2.9.0/org/apache/beam/sdk/io/kafka/KafkaIO.html&quot;&gt;KafkaIO&lt;/a&gt;
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;https://spark.apache.org/docs/latest/streaming-kafka-0-10-integration.html&quot;&gt;spark-streaming-kafka&lt;/a&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;Kinesis
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;https://beam.apache.org/releases/javadoc/2.9.0/org/apache/beam/sdk/io/kinesis/KinesisIO.html&quot;&gt;KinesisIO&lt;/a&gt;
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;https://spark.apache.org/docs/latest/streaming-kinesis-integration.html&quot;&gt;spark-streaming-kinesis&lt;/a&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;Cloud Pub/Sub
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;https://beam.apache.org/releases/javadoc/2.9.0/org/apache/beam/sdk/io/gcp/pubsub/PubsubIO.html&quot;&gt;PubsubIO&lt;/a&gt;
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/bahir/tree/master/streaming-pubsub&quot;&gt;spark-streaming-pubsub&lt;/a&gt; from &lt;a href=&quot;http://bahir.apache.org&quot;&gt;Apache Bahir&lt;/a&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;Other
   &lt;/td&gt;
   &lt;td&gt;Custom receivers
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;/documentation/io/authoring-overview/#read-transforms&quot;&gt;Read Transforms&lt;/a&gt;
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;https://spark.apache.org/docs/latest/streaming-custom-receivers.html&quot;&gt;receiverStream&lt;/a&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;h2 id=&quot;connectors-for-python&quot;&gt;Connectors for Python&lt;/h2&gt;

&lt;p&gt;Beam has an official &lt;a href=&quot;/documentation/sdks/python/&quot;&gt;Python SDK&lt;/a&gt; that currently supports a subset of the streaming features available in the Java SDK. Active development is underway to bridge the gap between the featuresets in the two SDKs. Currently for Python, the &lt;a href=&quot;/documentation/runners/direct/&quot;&gt;Direct Runner&lt;/a&gt; and &lt;a href=&quot;/documentation/runners/dataflow/&quot;&gt;Dataflow Runner&lt;/a&gt; are supported, and &lt;a href=&quot;/documentation/sdks/python-streaming/&quot;&gt;several streaming options&lt;/a&gt; were introduced in beta in &lt;a href=&quot;/blog/2018/06/26/beam-2.5.0.html&quot;&gt;version 2.5.0&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Spark also has a Python SDK called &lt;a href=&quot;http://spark.apache.org/docs/latest/api/python/pyspark.html&quot;&gt;PySpark&lt;/a&gt;. As mentioned earlier, Scala code compiles to a bytecode that is executed by the JVM. PySpark uses &lt;a href=&quot;https://www.py4j.org/&quot;&gt;Py4J&lt;/a&gt;, a library that enables Python programs to interact with the JVM and therefore access Java libraries, interact with Java objects, and register callbacks from Java. This allows PySpark to access native Spark objects like RDDs. Spark Structured Streaming supports &lt;a href=&quot;http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.streaming.DataStreamReader&quot;&gt;file sources&lt;/a&gt; (local filesystems and HDFS-compatible systems like Cloud Storage or S3) and &lt;a href=&quot;https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html&quot;&gt;Kafka&lt;/a&gt; as streaming inputs.&lt;/p&gt;

&lt;p&gt;Below are the main streaming input connectors for available for Beam and Spark DStreams in Python:&lt;/p&gt;

&lt;table class=&quot;table table-bordered&quot;&gt;
  &lt;tr&gt;
   &lt;td&gt;
   &lt;/td&gt;
   &lt;td&gt;
   &lt;/td&gt;
   &lt;td&gt;&lt;strong&gt;Apache Beam&lt;/strong&gt;
   &lt;/td&gt;
   &lt;td&gt;&lt;strong&gt;Apache Spark DStreams&lt;/strong&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td rowspan=&quot;2&quot;&gt;File Systems
   &lt;/td&gt;
   &lt;td&gt;Local
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;https://beam.apache.org/releases/pydoc/2.9.0/apache_beam.io.textio.html&quot;&gt;io.textio&lt;/a&gt;
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;http://spark.apache.org/docs/latest/api/python/pyspark.streaming.html#pyspark.streaming.StreamingContext.textFileStream&quot;&gt;textFileStream&lt;/a&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;HDFS
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;https://beam.apache.org/releases/pydoc/2.9.0/apache_beam.io.hadoopfilesystem.html&quot;&gt;io.hadoopfilesystem&lt;/a&gt;
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;https://spark.apache.org/docs/latest/api/java/org/apache/spark/SparkContext.html#hadoopConfiguration--&quot;&gt;hadoopConfiguration&lt;/a&gt; (Access through &lt;code&gt;sc._jsc&lt;/code&gt; with Py4J)
and &lt;a href=&quot;http://spark.apache.org/docs/latest/api/python/pyspark.streaming.html#pyspark.streaming.StreamingContext.textFileStream&quot;&gt;textFileStream&lt;/a&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td rowspan=&quot;2&quot;&gt;Object stores
   &lt;/td&gt;
   &lt;td&gt;Google Cloud Storage
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;https://beam.apache.org/releases/pydoc/2.9.0/apache_beam.io.gcp.gcsio.html&quot;&gt;io.gcp.gcsio&lt;/a&gt;
   &lt;/td&gt;
   &lt;td rowspan=&quot;2&quot;&gt;&lt;a href=&quot;http://spark.apache.org/docs/latest/api/python/pyspark.streaming.html#pyspark.streaming.StreamingContext.textFileStream&quot;&gt;textFileStream&lt;/a&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;S3
   &lt;/td&gt;
   &lt;td&gt;N/A
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td rowspan=&quot;3&quot;&gt;Messaging Queues
   &lt;/td&gt;
   &lt;td&gt;Kafka
   &lt;/td&gt;
   &lt;td&gt;N/A
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;http://spark.apache.org/docs/latest/api/python/pyspark.streaming.html#pyspark.streaming.kafka.KafkaUtils&quot;&gt;KafkaUtils&lt;/a&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;Kinesis
   &lt;/td&gt;
   &lt;td&gt;N/A
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;http://spark.apache.org/docs/latest/api/python/pyspark.streaming.html#module-pyspark.streaming.kinesis&quot;&gt;KinesisUtils&lt;/a&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;Cloud Pub/Sub
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;https://beam.apache.org/releases/pydoc/2.9.0/apache_beam.io.gcp.pubsub.html&quot;&gt;io.gcp.pubsub&lt;/a&gt;
   &lt;/td&gt;
   &lt;td&gt;N/A
   &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;Other
   &lt;/td&gt;
   &lt;td&gt;Custom receivers
   &lt;/td&gt;
   &lt;td&gt;&lt;a href=&quot;/documentation/sdks/python-custom-io/&quot;&gt;BoundedSource and RangeTracker&lt;/a&gt;
   &lt;/td&gt;
   &lt;td&gt;N/A
   &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;h2 id=&quot;connectors-for-other-languages&quot;&gt;Connectors for other languages&lt;/h2&gt;

&lt;h3 id=&quot;scala&quot;&gt;Scala&lt;/h3&gt;

&lt;p&gt;Since Scala code is interoperable with Java and therefore has native compatibility with Java libraries (and vice versa), you can use the same Java connectors described above in your Scala programs. Apache Beam also has a &lt;a href=&quot;https://github.com/spotify/scio&quot;&gt;Scala API&lt;/a&gt; open-sourced &lt;a href=&quot;https://labs.spotify.com/2017/10/16/big-data-processing-at-spotify-the-road-to-scio-part-1/&quot;&gt;by Spotify&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;go&quot;&gt;Go&lt;/h3&gt;

&lt;p&gt;A &lt;a href=&quot;/documentation/sdks/go/&quot;&gt;Go SDK&lt;/a&gt; for Apache Beam is under active development. It is currently experimental and is not recommended for production. Spark does not have an official Go SDK.&lt;/p&gt;

&lt;h3 id=&quot;r&quot;&gt;R&lt;/h3&gt;

&lt;p&gt;Apache Beam does not have an official R SDK. Spark Structured Streaming is supported by an &lt;a href=&quot;https://spark.apache.org/docs/latest/sparkr.html#structured-streaming&quot;&gt;R SDK&lt;/a&gt;, but only for &lt;a href=&quot;https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#input-sources&quot;&gt;file sources&lt;/a&gt; as a streaming input.&lt;/p&gt;

&lt;h2 id=&quot;next-steps&quot;&gt;Next steps&lt;/h2&gt;

&lt;p&gt;We hope this article inspired you to try new and interesting ways of connecting streaming sources to your Beam pipelines!&lt;/p&gt;

&lt;p&gt;Check out the following links for further information:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;See a full list of all built-in and in-progress &lt;a href=&quot;/documentation/io/built-in/&quot;&gt;I/O Transforms&lt;/a&gt; for Apache Beam.&lt;/li&gt;
  &lt;li&gt;Learn about some Apache Beam mobile gaming pipeline &lt;a href=&quot;/get-started/mobile-gaming-example/&quot;&gt;examples&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Mon, 20 Aug 2018 01:00:01 -0700</pubDate>
        <link>https://beam.apache.org/blog/2018/08/20/review-input-streaming-connectors.html</link>
        <guid isPermaLink="true">https://beam.apache.org/blog/2018/08/20/review-input-streaming-connectors.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Apache Beam 2.6.0</title>
        <description>&lt;!--
Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;

&lt;p&gt;We are glad to present the new 2.6.0 release of Beam.
This release includes multiple fixes and new functionality, such as new features in SQL and portability.&lt;!--more--&gt;
We also spent a significant amount of time automating the release and fixing continuous integration. For more information, check the
&lt;a href=&quot;https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12319527&amp;amp;version=12343392&quot;&gt;release notes&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;new-features--improvements&quot;&gt;New Features / Improvements&lt;/h2&gt;

&lt;h3 id=&quot;grpcprotobuf-shading&quot;&gt;gRPC/Protobuf shading&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;gRPC/protobuf&lt;/code&gt; is now shaded in the majority of Apache Beam
Java modules. A few modules which expose &lt;code class=&quot;highlighter-rouge&quot;&gt;gRPC/protobuf&lt;/code&gt; on the
API surface still maintain a direct dependency.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;beam-sql&quot;&gt;Beam SQL&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Added support for the &lt;code class=&quot;highlighter-rouge&quot;&gt;EXISTS&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;LIKE&lt;/code&gt; operators.&lt;/li&gt;
  &lt;li&gt;Implemented &lt;code class=&quot;highlighter-rouge&quot;&gt;SUM()&lt;/code&gt; aggregations.&lt;/li&gt;
  &lt;li&gt;Fixed issues with the &lt;code class=&quot;highlighter-rouge&quot;&gt;CASE&lt;/code&gt; expression.&lt;/li&gt;
  &lt;li&gt;Added support for date comparisons.&lt;/li&gt;
  &lt;li&gt;Added unbounded data support to &lt;code class=&quot;highlighter-rouge&quot;&gt;LIMIT&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;portability&quot;&gt;Portability&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Shared libraries for supporting timers and user state
are now available for runner integration.&lt;/li&gt;
  &lt;li&gt;Added a Universal Local Runner, which works on a single machine using portability and containerized SDK harnesses.&lt;/li&gt;
  &lt;li&gt;The Flink Runner now accepts jobs using the Job API.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ios&quot;&gt;IOs&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Bounded &lt;code class=&quot;highlighter-rouge&quot;&gt;SplittableDoFn&lt;/code&gt; (SDF) support is now available in all
runners (SDF is the new I/O connector API).&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;HBaseIO&lt;/code&gt; is the first I/O supporting Bounded SDF (using
&lt;code class=&quot;highlighter-rouge&quot;&gt;readAll&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;sdks&quot;&gt;SDKs&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Improved Python &lt;code class=&quot;highlighter-rouge&quot;&gt;AvroIO&lt;/code&gt; performance.&lt;/li&gt;
  &lt;li&gt;Python &lt;code class=&quot;highlighter-rouge&quot;&gt;AvroIO&lt;/code&gt; has a &lt;code class=&quot;highlighter-rouge&quot;&gt;use_fastavro&lt;/code&gt; option that uses
&lt;code class=&quot;highlighter-rouge&quot;&gt;fastavro&lt;/code&gt; instead of &lt;code class=&quot;highlighter-rouge&quot;&gt;apache/avro&lt;/code&gt;, for a
&lt;a href=&quot;https://gist.github.com/ryan-williams/ede5ae61605e7ba6aa655071858ef52b&quot;&gt;3-6x speedup&lt;/a&gt;!&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;other&quot;&gt;Other&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Updated various dependency versions.&lt;/li&gt;
  &lt;li&gt;Improvements to stability, performance, and documentation.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;list-of-contributors&quot;&gt;List of Contributors&lt;/h2&gt;

&lt;p&gt;According to git shortlog, the following 39 people contributed
to the 2.6.0 release. Thank you to all contributors!&lt;/p&gt;

&lt;p&gt;Ahmet Altay, Alan Myrvold, Alexey Romanenko, Andrew Pilloud,
Ankur Goenka, Boyuan Zhang, Charles Chen, cclauss,
Daniel Oliveira, Elliott Brossard, Eric Beach,
Etienne Chauchot, Eugene Kirpichov, Henning Rohde,
Isma√´l Mej√≠a, Kai Jiang, Kasia, Kenneth Knowles, Luis Osa,
Lukasz Cwik, Maria Garcia Herrero, Mark Liu, Matthias Feys,
Pablo Estrada, Rafael Fernandez, Reuven Lax, Robert Bradshaw,
Robert Burke, Robin Qiu, Ryan Williams, Scott Wegner, Rui Weng,
Sergei Lebedev, Sindy Li, Thomas Weise, Udi Meiri,
Valentyn Tymofieiev, XuMingmin, and Yifan Zou.&lt;/p&gt;
</description>
        <pubDate>Fri, 10 Aug 2018 01:00:01 -0700</pubDate>
        <link>https://beam.apache.org/blog/2018/08/10/beam-2.6.0.html</link>
        <guid isPermaLink="true">https://beam.apache.org/blog/2018/08/10/beam-2.6.0.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Apache Beam 2.5.0</title>
        <description>&lt;!--
Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;

&lt;p&gt;We are glad to present the new 2.5.0 release of Beam. This release includes
multiple fixes and new functionalities. &lt;!--more--&gt; For more information
please check the detailed release notes.&lt;/p&gt;

&lt;h1 id=&quot;new-features--improvements&quot;&gt;New Features / Improvements&lt;/h1&gt;

&lt;h2 id=&quot;go-sdk-support&quot;&gt;Go SDK support&lt;/h2&gt;
&lt;p&gt;The Go SDK has been officially accepted into the project, after an incubation period and community effort. Go pipelines run on Dataflow runner. More details are &lt;a href=&quot;/documentation/sdks/go/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;parquet-support&quot;&gt;Parquet support&lt;/h2&gt;
&lt;p&gt;Support for Apache Parquet format was added. It uses Parquet 1.10 release which, thanks to AvroParquerWriter‚Äôs API changes, allows FileIO.Sink implementation.&lt;/p&gt;

&lt;h2 id=&quot;performanceintegration-tests&quot;&gt;Performance/Integration Tests&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Added new integration tests - HCatalogIOIT (Hive), HBaseIOIT, ParquetIOIT (with the IO itself, local filesystem, HDFS)&lt;/li&gt;
  &lt;li&gt;Multinode (3 data node) HDFS cluster is used for running tests on HDFS.&lt;/li&gt;
  &lt;li&gt;Several improvements on performance tests running and results analysis.&lt;/li&gt;
  &lt;li&gt;Scaled up Kubernetes cluster from 1 to 3 nodes.&lt;/li&gt;
  &lt;li&gt;Added metrics in Spark streaming.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;internal-build-system-migrated-to-gradle&quot;&gt;Internal Build System: Migrated to Gradle&lt;/h2&gt;
&lt;p&gt;After a months-long community effort, the internal Beam build has been migrated from Maven to Gradle. The new build system was chosen because of dependency-driven build support, incremental build/test, and support for non-Java languages.&lt;/p&gt;

&lt;h2 id=&quot;nexmark-improvements&quot;&gt;Nexmark Improvements&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Kafka support as a source/sink for events and results.&lt;/li&gt;
  &lt;li&gt;Translation of some queries to Beam SQL.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;beam-sql&quot;&gt;Beam SQL&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Support for MAP, ROW, ARRAY data types&lt;/li&gt;
  &lt;li&gt;Support UNNEST on array fields&lt;/li&gt;
  &lt;li&gt;Improved optimizations&lt;/li&gt;
  &lt;li&gt;Upgrade Calcite to 1.16&lt;/li&gt;
  &lt;li&gt;Support SQL on POJOs via automatic conversion&lt;/li&gt;
  &lt;li&gt;Schema moved into core Beam&lt;/li&gt;
  &lt;li&gt;UDAFs can be indirect suclasses of CombineFn&lt;/li&gt;
  &lt;li&gt;Many other small bugfixes&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;portability&quot;&gt;Portability&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Common shared code related to supporting portable execution for runners.&lt;/li&gt;
  &lt;li&gt;Python SDK supporting side inputs over the portability APIs.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;extract-metrics-in-a-runner-agnostic-way&quot;&gt;Extract metrics in a runner agnostic way&lt;/h2&gt;
&lt;p&gt;Metrics are pushed by the runners to configurable sinks (Http REST sink available). It is already enabled in Flink and Spark runner, work is in progress for Dataflow.&lt;/p&gt;

&lt;h1 id=&quot;miscellaneous-fixes&quot;&gt;Miscellaneous Fixes&lt;/h1&gt;

&lt;h2 id=&quot;sdks&quot;&gt;SDKs&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Implemented HDFS FileSystem for Python SDK.&lt;/li&gt;
  &lt;li&gt;Python SDK adds support for side inputs for streaming execution.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;runners&quot;&gt;Runners&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Updated Spark runner to Spark version 2.3.1&lt;/li&gt;
  &lt;li&gt;Fixed issue with late elements windowed into expired fixed windows get dropped in Directrunner.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ios&quot;&gt;IOs&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;CassandraIO gained a better split algorithm based on overlapping regions.&lt;/li&gt;
  &lt;li&gt;ElasticsearchIO supports partial updates.&lt;/li&gt;
  &lt;li&gt;ElasticsearchIO allows to pass id, type and index per document.&lt;/li&gt;
  &lt;li&gt;SolrIO supports a more robust retry on write strategy.&lt;/li&gt;
  &lt;li&gt;S3 FileSystem supports encryption (SSE-S3, SSE-C and SSE-KMS).&lt;/li&gt;
  &lt;li&gt;Improved connection management in JdbcIO.&lt;/li&gt;
  &lt;li&gt;Added support the element timestamps while publishing to Kafka.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;other&quot;&gt;Other&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Use Java ErrorProne for static analysis.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;list-of-contributors&quot;&gt;List of Contributors&lt;/h1&gt;

&lt;p&gt;According to git shortlog, the following 84 people contributed to the 2.5.0 release. Thank you to all contributors!&lt;/p&gt;

&lt;p&gt;Ahmet Altay, Alan Myrvold, Alex Amato, Alex Van Boxel, Alexander Dejanovski, Alexey Romanenko, Aljoscha Krettek, ananvay, Andreas Ehrencrona, Andrew Pilloud, Ankur Goenka, Anton Kedin, arkash, Austin Bennett, Axel Magnuson, Ben Chambers, Ben Sidhom, Bill Neubauer, Boyuan Zhang, Braden Bassingthwaite, Cade Markegard, cclauss, Chamikara Jayalath, Charles Chen, Chuan Yu Foo, Cody Schroeder, Colm O hEigeartaigh, Daniel Oliveira, Dariusz Aniszewski, David Cavazos, Dawid Wysakowicz, Eric Roshan-Eisner, Etienne Chauchot, Eugene Kirpichov, Flavio Fiszman, Geet Kumar, GlennAmmons, Grzegorz Ko≈Çakowski, Henning Rohde, Innocent Djiofack, Isma√´l Mej√≠a, Jack Hsueh, Jason Kuster, Javier Antonio Gonzalez Trejo, Jean-Baptiste Onofr√©, Kai Jiang, Kamil Szewczyk, Katarzyna Kucharczyk, Kenneth Jung, Kenneth Knowles, Kevin Peterson, Lukasz Cwik, ≈Åukasz Gajowy, Mairbek Khadikov, Manu Zhang, Maria Garcia Herrero, Marian Dvorsky, Mark Liu, Matthias Feys, Matthias Wessendorf, mingmxu, Nathan Howell, Pablo Estrada, Paul Gerver, Raghu Angadi, rarokni, Reuven Lax, Rezan Achmad, Robbe Sneyders, Robert Bradshaw, Robert Burke, Romain Manni-Bucau, Sam Waggoner, Sam Whittle, Scott Wegner, Stephan Hoyer, Thomas Groh, Thomas Weise, Tim Robertson, Udi Meiri, Valentyn Tymofieiev, XuMingmin, Yifan Zou, Yunqing Zhou&lt;/p&gt;
</description>
        <pubDate>Tue, 26 Jun 2018 01:00:01 -0700</pubDate>
        <link>https://beam.apache.org/blog/2018/06/26/beam-2.5.0.html</link>
        <guid isPermaLink="true">https://beam.apache.org/blog/2018/06/26/beam-2.5.0.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Apache Beam 2.3.0</title>
        <description>&lt;!--
Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;

&lt;p&gt;We are glad to present the new 2.3.0 release of Beam. This release includes
multiple fixes and new functionalities. &lt;!--more--&gt; For more information
please check the detailed release notes.&lt;/p&gt;

&lt;h1 id=&quot;new-features--improvements&quot;&gt;New Features / Improvements&lt;/h1&gt;

&lt;h2 id=&quot;beam-moves-to-java-8&quot;&gt;Beam moves to Java 8&lt;/h2&gt;

&lt;p&gt;The supported version of Java for Beam is now Java 8. The code and examples have
been refactored to use multiple of the advantages of the language, e.g. lambdas,
streams, improved type inference, etc.&lt;/p&gt;

&lt;h2 id=&quot;spark-runner-is-now-based-on-spark-2x&quot;&gt;Spark runner is now based on Spark 2.x&lt;/h2&gt;

&lt;p&gt;Spark runner moves forward into the Spark 2.x development line, this would allow
to benefit of improved performance, as well as open the runner for future
compatibility with the Structured Streaming APIs. Notice that support for Spark
1.x is finished with this release.&lt;/p&gt;

&lt;h2 id=&quot;amazon-web-services-s3-filesystem-support&quot;&gt;Amazon Web Services S3 Filesystem support&lt;/h2&gt;

&lt;p&gt;Beam already supported AWS S3 via HadoopFileSystem, but this version brings a
native implementation with the corresponding performance advantages of the S3
filesystem.&lt;/p&gt;

&lt;h2 id=&quot;general-purpose-writing-to-files&quot;&gt;General-purpose writing to files&lt;/h2&gt;

&lt;p&gt;This release contains a new transform, FileIO.write() / writeDynamic() that
implements a general-purpose fluent and Java8-friendly API for writing to files
using a FileIO.Sink. This API has similar capabilities to DynamicDestinations
APIs from Beam 2.2 but is much easier to use and extend. The DynamicDestinations
APIs for writing to files are deprecated by it, as is FileBasedSink.&lt;/p&gt;

&lt;h2 id=&quot;splittable-dofn-support-on-the-python-sdk&quot;&gt;Splittable DoFn support on the Python SDK&lt;/h2&gt;

&lt;p&gt;This release adds the Splittable DoFn API for Python SDK and adds Splittable
DoFn support for Python streaming DirectRunner.&lt;/p&gt;

&lt;h2 id=&quot;portability&quot;&gt;Portability&lt;/h2&gt;

&lt;p&gt;Progress continues to being able to execute Python on runners other then Google
Cloud Dataflow and the Go SDK on any runner.&lt;/p&gt;

&lt;h1 id=&quot;miscellaneous-fixes&quot;&gt;Miscellaneous Fixes&lt;/h1&gt;

&lt;h2 id=&quot;sdks&quot;&gt;SDKs&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;MapElements and FlatMapElements support using side inputs using the new
interface Contextful.Fn. For library authors, this interface is the
recommended choice for user-code callbacks that may use side inputs.&lt;/li&gt;
  &lt;li&gt;Introduces the family of Reify transforms for converting between explicit and
implicit representations of various Beam entities.&lt;/li&gt;
  &lt;li&gt;Introduces two transforms for approximate sketching of data: Count-Min Sketch
(approximate element frequency estimation) and HyperLogLog (approximate
cardinality estimation).&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;runners&quot;&gt;Runners&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Staging files on Dataflow shows progress&lt;/li&gt;
  &lt;li&gt;Flink runner is based now on Flink version 1.4.0&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ios&quot;&gt;IOs&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;BigtableIO now supports ValueProvider configuration&lt;/li&gt;
  &lt;li&gt;BigQueryIO supports writing bounded collections to tables with partition
decorators&lt;/li&gt;
  &lt;li&gt;KafkaIO moves to version 1.0 (it is still backwards compatible with versions &amp;gt;= 0.9.x.x)&lt;/li&gt;
  &lt;li&gt;Added IO source for VCF files (Python)&lt;/li&gt;
  &lt;li&gt;Added support for backoff on deadlocks in JdbcIO.write() and connection
improvement&lt;/li&gt;
  &lt;li&gt;Improved performance of KinesisIO.read()&lt;/li&gt;
  &lt;li&gt;Many improvements to TikaIO&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;list-of-contributors&quot;&gt;List of Contributors&lt;/h1&gt;

&lt;p&gt;According to git shortlog, the following 78 people contributed to the 2.3.0 release. Thank you to all contributors!&lt;/p&gt;

&lt;p&gt;Ahmet Altay, Alan Myrvold, Alex Amato, Alexey Romanenko, Ankur Goenka, Anton Kedin, Arnaud Fournier, Asha Rostamianfar, Ben Chambers, Ben Sidhom, Bill Neubauer, Brian Foo, cclauss, Chamikara Jayalath, Charles Chen, Colm O hEigeartaigh, Daniel Oliveira, Dariusz Aniszewski, David Cavazos, David Sabater, David Sabater Dinter, Dawid Wysakowicz, Dmytro Ivanov, Etienne Chauchot, Eugene Kirpichov, Exprosed, Grzegorz Ko≈Çakowski, Henning Rohde, Holden Karau, Huygaa Batsaikhan, Ilya Figotin, Innocent Djiofack, Isma√´l Mej√≠a, Itamar Ostricher, Jacky, Jacob Marble, James Xu, Jean-Baptiste Onofr√©, Jeremie Lenfant-Engelmann, Kamil Szewczyk, Kenneth Knowles, Lukasz Cwik, ≈Åukasz Gajowy, Luke Zhu, Mairbek Khadikov, Mar√≠a Garc√≠a Herrero, Marian Dvorsky, Mark Liu, melissa, Miles Saul, mingmxu, Motty Gruda, nerdynick, Neville Li, Nigel Kilmer, Pablo, Pawel Kaczmarczyk, Petr Shevtsov, Rafal Wojdyla, Raghu Angadi, Robert Bradshaw, Robert Burke, Romain Manni-Bucau, Ryan Niemocienski, Ryan Skraba, Sam Whittle, Scott Wegner, Shashank Prabhakara, Solomon Duskis, Thomas Groh, Thomas Weise, Udi Meiri, Valentyn Tymofieiev, wtanaka.com, XuMingmin, zhouhai02, Zohar Yahav, Áê®Áëú.&lt;/p&gt;

</description>
        <pubDate>Mon, 19 Feb 2018 00:00:01 -0800</pubDate>
        <link>https://beam.apache.org/blog/2018/02/19/beam-2.3.0.html</link>
        <guid isPermaLink="true">https://beam.apache.org/blog/2018/02/19/beam-2.3.0.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Apache Beam: A Look Back at 2017</title>
        <description>&lt;!--
Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;

&lt;p&gt;On January 10, 2017, Apache Beam got &lt;a href=&quot;/blog/2017/01/10/beam-graduates.html&quot;&gt;promoted&lt;/a&gt;
as a Top-Level Apache Software Foundation project. It was an important milestone
that validated the value of the project, legitimacy of its community, and
heralded its growing adoption. In the past year, Apache Beam has been on a
phenomenal growth trajectory, with significant growth in its community and
feature set. Let us walk you through some of the notable achievements.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;use-cases&quot;&gt;Use cases&lt;/h2&gt;

&lt;p&gt;First, lets take a glimpse at how Beam was used in 2017. Apache Beam being a
unified framework for batch and stream processing, enables a very wide spectrum
of diverse use cases. Here are some use cases that exemplify the versatility of
Beam.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-block&quot; src=&quot;/images/blog/2017-look-back/timeline.png&quot; alt=&quot;Use Cases&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;community-growth&quot;&gt;Community growth&lt;/h2&gt;

&lt;p&gt;In 2017, Apache Beam had 174 contributors worldwide, from many different
organizations. As an Apache project, we are proud to count 18 PMC members and
31 committers. The community had 7 releases in 2017, each bringing a rich set of
new features and fixes.&lt;/p&gt;

&lt;p&gt;The most obvious and encouraging sign of the growth of Apache Beam‚Äôs community,
and validation of its core value proposition of portability, is the addition of
significant new &lt;a href=&quot;/documentation/runners/capability-matrix/&quot;&gt;runners&lt;/a&gt;
(i.e. execution engines). We entered 2017 with Apache Flink, Apache Spark 1.x,
Google Cloud Dataflow, Apache Apex, and Apache Gearpump. In 2017, the following
new and updated runners were developed:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Apache Spark 2.x update&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.ibm.com/blogs/bluemix/2017/10/streaming-analytics-updates-ibm-streams-runner-apache-beam-2-0/&quot;&gt;IBM Streams runner&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;MapReduce runner&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://jstorm.io/&quot;&gt;JStorm runner&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In addition to runners, Beam added new IO connectors, some notable ones being
the Cassandra, MQTT, AMQP, HBase/HCatalog, JDBC, Solr, Tika, Redis, and
ElasticSearch connectors. Beam‚Äôs IO connectors make it possible to read from or
write to data sources/sinks even when they are not natively supported by the
underlying execution engine. Beam also provides fully pluggable filesystem
support, allowing us to support and extend our coverage to HDFS, S3, Azure
Storage, and Google Storage. We continue to add new IO connectors and
filesystems to extend the Beam use cases.&lt;/p&gt;

&lt;p&gt;A particularly telling sign of the maturity of an open source community is when
it is able to collaborate with multiple other open source communities, and
mutually improve the state of the art. Over the past few months, the Beam,
Calcite, and Flink communities have come together to define a robust &lt;a href=&quot;https://docs.google.com/document/d/1wrla8mF_mmq-NW9sdJHYVgMyZsgCmHumJJ5f5WUzTiM/edit&quot;&gt;spec&lt;/a&gt;
for Streaming SQL, with engineers from over four organizations contributing to
it. If, like us, you are excited by the prospect of improving the state of
streaming SQL, please join us!&lt;/p&gt;

&lt;p&gt;In addition to SQL, new XML and JSON based declarative DSLs are also in PoC.&lt;/p&gt;

&lt;h2 id=&quot;continued-innovation&quot;&gt;Continued innovation&lt;/h2&gt;

&lt;p&gt;Innovation is important to the success on any open source project, and Beam has
a rich history of bringing innovative new ideas to the open source community.
Apache Beam was the first to introduce some seminal concepts in the world of
big-data processing:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Unified batch and streaming SDK that enables users to author big-data jobs
without having to learn multiple disparate SDKs/APIs.&lt;/li&gt;
  &lt;li&gt;Cross-Engine Portability: Giving enterprises the confidence that workloads
authored today will not have to be re-written when open source engines become
outdated and are supplanted by newer ones.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101&quot;&gt;Semantics&lt;/a&gt;
essential for reasoning about unbounded unordered data, and achieving
consistent and correct output from a streaming job.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In 2017, the pace of innovation continued. The following capabilities were
introduced:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Cross-Language Portability framework, and a &lt;a href=&quot;https://golang.org/&quot;&gt;Go&lt;/a&gt; SDK
developed with it.&lt;/li&gt;
  &lt;li&gt;Dynamically Shardable IO (SplittableDoFn)&lt;/li&gt;
  &lt;li&gt;Support for schemas in PCollection, allowing us to extend the runner
capabilities.&lt;/li&gt;
  &lt;li&gt;Extensions addressing new use cases such as machine learning, and new data
formats.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;areas-of-improvement&quot;&gt;Areas of improvement&lt;/h2&gt;

&lt;p&gt;Any retrospective view of a project is incomplete without an honest assessment
of areas of improvement. Two aspects stand out:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Helping runners showcase their individual strengths. After all, portability
does not imply homogeneity. Different runners have different areas in which
they excel, and we need to do a better job of helping them highlight their
strengths.&lt;/li&gt;
  &lt;li&gt;Based on the previous point, helping customers make a more informed decision
when they select a runner or migrate from one to another.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In 2018, we aim to take proactive steps to improve the above aspects.&lt;/p&gt;

&lt;h2 id=&quot;ethos-of-the-project-and-its-community&quot;&gt;Ethos of the project and its community&lt;/h2&gt;

&lt;p&gt;The world of batch and stream big-data processing today is reminiscent of the
&lt;a href=&quot;https://en.wikipedia.org/wiki/Tower_of_Babel&quot;&gt;Tower of Babel&lt;/a&gt; parable: a
slowdown of progress because different communities spoke different languages.
Similarly, today there are multiple disparate big-data SDKs/APIs, each with
their own distinct terminology to describe similar concepts. The side effect is
user confusion and slower adoption.&lt;/p&gt;

&lt;p&gt;The Apache Beam project aims to provide an industry standard portable SDK that
will:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Benefit users by providing &lt;strong&gt;&lt;em&gt;innovation with stability&lt;/em&gt;&lt;/strong&gt;: The separation of
SDK and engine enables healthy competition between runners, without requiring
users to constantly learn new SDKs/APIs and rewrite their workloads to
benefit from new innovation.&lt;/li&gt;
  &lt;li&gt;Benefit big-data engines by &lt;strong&gt;&lt;em&gt;growing the pie for everyone&lt;/em&gt;&lt;/strong&gt;: Making it
easier for users to author, maintain, upgrade and migrate their big-data
workloads will lead to significant growth in the number of production
big-data deployments.&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Tue, 09 Jan 2018 00:00:01 -0800</pubDate>
        <link>https://beam.apache.org/blog/2018/01/09/beam-a-look-back.html</link>
        <guid isPermaLink="true">https://beam.apache.org/blog/2018/01/09/beam-a-look-back.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Timely (and Stateful) Processing with Apache Beam</title>
        <description>&lt;!--
Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;

&lt;p&gt;In a &lt;a href=&quot;/blog/2017/02/13/stateful-processing.html&quot;&gt;prior blog
post&lt;/a&gt;, I
introduced the basics of stateful processing in Apache Beam, focusing on the
addition of state to per-element processing. So-called &lt;em&gt;timely&lt;/em&gt; processing
complements stateful processing in Beam by letting you set timers to request a
(stateful) callback at some point in the future.&lt;/p&gt;

&lt;p&gt;What can you do with timers in Beam? Here are some examples:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;You can output data buffered in state after some amount of processing time.&lt;/li&gt;
  &lt;li&gt;You can take special action when the watermark estimates that you have
received all data up to a specified point in event time.&lt;/li&gt;
  &lt;li&gt;You can author workflows with timeouts that alter state and emit output in
response to the absence of additional input for some period of time.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These are just a few possibilities. State and timers together form a powerful
programming paradigm for fine-grained control to express a huge variety of
workflows.  Stateful and timely processing in Beam is portable across data
processing engines and integrated with Beam‚Äôs unified model of event time
windowing in both streaming and batch processing.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;what-is-stateful-and-timely-processing&quot;&gt;What is stateful and timely processing?&lt;/h2&gt;

&lt;p&gt;In my prior post, I developed an understanding of stateful processing largely
by contrast with associative, commutative combiners. In this post, I‚Äôll
emphasize a perspective that I had mentioned only briefly: that elementwise
processing with access to per-key-and-window state and timers represents a
fundamental pattern for ‚Äúembarrassingly parallel‚Äù computation, distinct from
the others in Beam.&lt;/p&gt;

&lt;p&gt;In fact, stateful and timely computation is the low-level computational pattern
that underlies the others. Precisely because it is lower level, it allows you
to really micromanage your computations to unlock new use cases and new
efficiencies. This incurs the complexity of manually managing your state and
timers - it isn‚Äôt magic! Let‚Äôs first look again at the two primary
computational patterns in Beam.&lt;/p&gt;

&lt;h3 id=&quot;element-wise-processing-pardo-map-etc&quot;&gt;Element-wise processing (ParDo, Map, etc)&lt;/h3&gt;

&lt;p&gt;The most elementary embarrassingly parallel pattern is just using a bunch of
computers to apply the same function to every input element of a massive
collection. In Beam, per-element processing like this is expressed as a basic
&lt;code class=&quot;highlighter-rouge&quot;&gt;ParDo&lt;/code&gt; - analogous to ‚ÄúMap‚Äù from MapReduce - which is like an enhanced ‚Äúmap‚Äù,
‚ÄúflatMap‚Äù, etc, from functional programming.&lt;/p&gt;

&lt;p&gt;The following diagram illustrates per-element processing. Input elements are
squares, output elements are triangles. The colors of the elements represent
their key, which will matter later. Each input element maps to the
corresponding output element(s) completely independently. Processing may be
distributed across computers in any way, yielding essentially limitless
parallelism.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-block&quot; src=&quot;/images/blog/timely-processing/ParDo.png&quot; alt=&quot;ParDo offers limitless parallelism&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This pattern is obvious, exists in all data-parallel paradigms, and has
a simple stateless implementation. Every input element can be processed
independently or in arbitrary bundles. Balancing the work between computers is
actually the hard part, and can be addressed by splitting, progress estimation,
work-stealing, etc.&lt;/p&gt;

&lt;h3 id=&quot;per-key-and-window-aggregation-combine-reduce-groupbykey-etc&quot;&gt;Per-key (and window) aggregation (Combine, Reduce, GroupByKey, etc.)&lt;/h3&gt;

&lt;p&gt;The other embarassingly parallel design pattern at the heart of Beam is per-key
(and window) aggregation. Elements sharing a key are colocated and then
combined using some associative and commutative operator. In Beam this is
expressed as a &lt;code class=&quot;highlighter-rouge&quot;&gt;GroupByKey&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;Combine.perKey&lt;/code&gt;, and corresponds to the shuffle
and ‚ÄúReduce‚Äù from MapReduce.  It is sometimes helpful to think of per-key
&lt;code class=&quot;highlighter-rouge&quot;&gt;Combine&lt;/code&gt; as the fundamental operation, and raw &lt;code class=&quot;highlighter-rouge&quot;&gt;GroupByKey&lt;/code&gt; as a combiner that
just concatenates input elements. The communication pattern for the input
elements is the same, modulo some optimizations possible for &lt;code class=&quot;highlighter-rouge&quot;&gt;Combine&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;In the illustration here, recall that the color of each element represents the
key. So all of the red squares are routed to the same location where they are
aggregated and the red triangle is the output.  Likewise for the yellow and
green squares, etc. In a real application, you may have millions of keys, so
the parallelism is still massive.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-block&quot; src=&quot;/images/blog/timely-processing/CombinePerKey.png&quot; alt=&quot;Gathering elements per key then combining them&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The underlying data processing engine will, at some level of abstraction, use
state to perform this aggregation across all the elements arriving for a key.
In particular, in a streaming execution, the aggregation process may need to
wait for more data to arrive or for the watermark to estimate that all input
for an event time window is complete. This requires some way to store the
intermediate aggregation between input elements as well a way to a receive a
callback when it is time to emit the result. As a result, the &lt;em&gt;execution&lt;/em&gt; of
per key aggregation by a stream processing engine fundamentally involves state
and timers.&lt;/p&gt;

&lt;p&gt;However, &lt;em&gt;your&lt;/em&gt; code is just a declarative expression of the aggregation
operator.  The runner can choose a variety of ways to execute your operator. 
I went over this in detail in &lt;a href=&quot;/blog/2017/02/13/stateful-processing.html&quot;&gt;my prior post focused on state alone&lt;/a&gt;. Since you do not
observe elements in any defined order, nor manipulate mutable state or timers
directly, I call this neither stateful nor timely processing.&lt;/p&gt;

&lt;h3 id=&quot;per-key-and-window-stateful-timely-processing&quot;&gt;Per-key-and-window stateful, timely processing&lt;/h3&gt;

&lt;p&gt;Both &lt;code class=&quot;highlighter-rouge&quot;&gt;ParDo&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;Combine.perKey&lt;/code&gt; are standard patterns for parallelism that go
back decades. When implementing these in a massive-scale distributed data
processing engine, we can highlight a few characteristics that are particularly
important.&lt;/p&gt;

&lt;p&gt;Let us consider these characteristics of &lt;code class=&quot;highlighter-rouge&quot;&gt;ParDo&lt;/code&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;You write single-threaded code to process one element.&lt;/li&gt;
  &lt;li&gt;Elements are processed in arbitrary order with no dependencies
or interaction between processing of elements.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And these characteristics for &lt;code class=&quot;highlighter-rouge&quot;&gt;Combine.perKey&lt;/code&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Elements for a common key and window are gathered together.&lt;/li&gt;
  &lt;li&gt;A user-defined operator is applied to those elements.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Combining some of the characteristics of unrestricted parallel mapping and
per-key-and-window combination, we can discern a megaprimitive from which we
build stateful and timely processing:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Elements for a common key and window are gathered together.&lt;/li&gt;
  &lt;li&gt;Elements are processed in arbitrary order.&lt;/li&gt;
  &lt;li&gt;You write single-threaded code to process one element or timer, possibly
accessing state or setting timers.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the illustration below, the red squares are gathered and fed one by one to
the stateful, timely, &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt;. As each element is processed, the &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; has
access to state (the color-partitioned cylinder on the right) and can set
timers to receive callbacks (the colorful clocks on the left).&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-block&quot; src=&quot;/images/blog/timely-processing/StateAndTimers.png&quot; alt=&quot;Gathering elements per key then timely, stateful processing&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So that is the abstract notion of per-key-and-window stateful, timely
processing in Apache Beam. Now let‚Äôs see what it looks like to write code that
accesses state, sets timers, and receives callbacks.&lt;/p&gt;

&lt;h2 id=&quot;example-batched-rpc&quot;&gt;Example: Batched RPC&lt;/h2&gt;

&lt;p&gt;To demonstrate stateful and timely processing, let‚Äôs work through a concrete
example, with code.&lt;/p&gt;

&lt;p&gt;Suppose you are writing a system to analyze events.  You have a ton of data
coming in and you need to enrich each event by RPC to an external system. You
can‚Äôt just issue an RPC per event.  Not only would this be terrible for
performance, but it would also likely blow your quota with the external system.
So you‚Äôd like to gather a number of events, make one RPC for them all, and then
output all the enriched events.&lt;/p&gt;

&lt;h3 id=&quot;state&quot;&gt;State&lt;/h3&gt;

&lt;p&gt;Let‚Äôs set up the state we need to track batches of elements. As each element
comes in, we will write the element to a buffer while tracking the number of
elements we have buffered. Here are the state cells in code:&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DoFn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Event&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EnrichedEvent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

  &lt;span class=&quot;nd&quot;&gt;@StateId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;buffer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StateSpec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BagState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Event&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bufferedEvents&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StateSpecs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;bag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;

  &lt;span class=&quot;nd&quot;&gt;@StateId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;count&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StateSpec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ValueState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;countState&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StateSpecs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;

  &lt;span class=&quot;err&quot;&gt;‚Ä¶&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TBD&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;‚Ä¶&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# State and timers are not yet supported in Beam's Python SDK.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Follow https://issues.apache.org/jira/browse/BEAM-2687 for updates.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Walking through the code, we have:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The state cell &lt;code class=&quot;highlighter-rouge&quot;&gt;&quot;buffer&quot;&lt;/code&gt; is an unordered bag of buffered events.&lt;/li&gt;
  &lt;li&gt;The state cell &lt;code class=&quot;highlighter-rouge&quot;&gt;&quot;count&quot;&lt;/code&gt; tracks how many events have been buffered.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Next, as a recap of reading and writing state, let‚Äôs write our &lt;code class=&quot;highlighter-rouge&quot;&gt;@ProcessElement&lt;/code&gt;
method. We will choose a limit on the size of the buffer, &lt;code class=&quot;highlighter-rouge&quot;&gt;MAX_BUFFER_SIZE&lt;/code&gt;. If
our buffer reaches this size, we will perform a single RPC to enrich all the
events, and output.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DoFn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Event&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EnrichedEvent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

  &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MAX_BUFFER_SIZE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;nd&quot;&gt;@StateId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;buffer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StateSpec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BagState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Event&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bufferedEvents&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StateSpecs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;bag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;

  &lt;span class=&quot;nd&quot;&gt;@StateId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;count&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StateSpec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ValueState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;countState&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StateSpecs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;

  &lt;span class=&quot;nd&quot;&gt;@ProcessElement&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;process&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;ProcessContext&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nd&quot;&gt;@StateId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;buffer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BagState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Event&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bufferState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nd&quot;&gt;@StateId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;count&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ValueState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;countState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;firstNonNull&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;countState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;countState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;bufferState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;element&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MAX_BUFFER_SIZE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EnrichedEvent&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enrichedEvent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enrichEvents&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bufferState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;enrichedEvent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;bufferState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;clear&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;countState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;clear&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;err&quot;&gt;‚Ä¶&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TBD&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;‚Ä¶&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# State and timers are not yet supported in Beam's Python SDK.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Follow https://issues.apache.org/jira/browse/BEAM-2687 for updates.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Here is an illustration to accompany the code:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-block&quot; src=&quot;/images/blog/timely-processing/BatchedRpcState.png&quot; alt=&quot;Batching elements in state, then performing RPCs&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The blue box is the &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;The yellow box within it is the &lt;code class=&quot;highlighter-rouge&quot;&gt;@ProcessElement&lt;/code&gt; method.&lt;/li&gt;
  &lt;li&gt;Each input event is a red square - this diagram just shows the activity for
a single key, represented by the color red. Your &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; will run the same
workflow in parallel for all keys which are perhaps user IDs.&lt;/li&gt;
  &lt;li&gt;Each input event is written to the buffer as a red triangle, representing
the fact that you might actually buffer more than just the raw input, even
though this code doesn‚Äôt.&lt;/li&gt;
  &lt;li&gt;The external service is drawn as a cloud. When there are enough buffered
events, the &lt;code class=&quot;highlighter-rouge&quot;&gt;@ProcessElement&lt;/code&gt; method reads the events from state and issues
a single RPC.&lt;/li&gt;
  &lt;li&gt;Each output enriched event is drawn as a red circle. To consumers of this
output, it looks just like an element-wise operation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So far, we have only used state, but not timers. You may have noticed that
there is a problem - there will usually be data left in the buffer. If no more
input arrives, that data will never be processed. In Beam, every window has
some point in event time when any further input for the window is considered
too late and is discarded. At this point, we say that the window has ‚Äúexpired‚Äù.
Since no further input can arrive to access the state for that window, the
state is also discarded. For our example, we need to ensure that all leftover
events are output when the window expires.&lt;/p&gt;

&lt;h3 id=&quot;event-time-timers&quot;&gt;Event Time Timers&lt;/h3&gt;

&lt;p&gt;An event time timer requests a call back when the watermark for an input
&lt;code class=&quot;highlighter-rouge&quot;&gt;PCollection&lt;/code&gt; reaches some threshold. In other words, you can use an event time
timer to take action at a specific moment in event time - a particular point of
completeness for a &lt;code class=&quot;highlighter-rouge&quot;&gt;PCollection&lt;/code&gt; - such as when a window expires.&lt;/p&gt;

&lt;p&gt;For our example, let us add an event time timer so that when the window expires,
any events remaining in the buffer are processed.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DoFn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Event&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EnrichedEvent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;err&quot;&gt;‚Ä¶&lt;/span&gt;

  &lt;span class=&quot;nd&quot;&gt;@TimerId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;expiry&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TimerSpec&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;expirySpec&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TimerSpecs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;timer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TimeDomain&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;EVENT_TIME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;

  &lt;span class=&quot;nd&quot;&gt;@ProcessElement&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;process&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;ProcessContext&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;BoundedWindow&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nd&quot;&gt;@StateId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;buffer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BagState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Event&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bufferState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nd&quot;&gt;@StateId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;count&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ValueState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;countState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nd&quot;&gt;@TimerId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;expiry&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Timer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;expiryTimer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;expiryTimer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;window&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;maxTimestamp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;plus&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;allowedLateness&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;

    &lt;span class=&quot;err&quot;&gt;‚Ä¶&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;same&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logic&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;above&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;‚Ä¶&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;nd&quot;&gt;@OnTimer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;expiry&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;onExpiry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;OnTimerContext&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nd&quot;&gt;@StateId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;buffer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BagState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Event&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bufferState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bufferState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;isEmpty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EnrichedEvent&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enrichedEvent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enrichEvents&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bufferState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;enrichedEvent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# State and timers are not yet supported in Beam's Python SDK.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Follow https://issues.apache.org/jira/browse/BEAM-2687 for updates.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Let‚Äôs unpack the pieces of this snippet:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;We declare an event time timer with &lt;code class=&quot;highlighter-rouge&quot;&gt;@TimerId(&quot;expiry&quot;)&lt;/code&gt;. We will use the
identifier &lt;code class=&quot;highlighter-rouge&quot;&gt;&quot;expiry&quot;&lt;/code&gt; to identify the timer for setting the callback time as
well as receiving the callback.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The variable &lt;code class=&quot;highlighter-rouge&quot;&gt;expiryTimer&lt;/code&gt;, annotated with &lt;code class=&quot;highlighter-rouge&quot;&gt;@TimerId&lt;/code&gt;, is set to the value
&lt;code class=&quot;highlighter-rouge&quot;&gt;TimerSpecs.timer(TimeDomain.EVENT_TIME)&lt;/code&gt;, indicating that we want a
callback according to the event time watermark of the input elements.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In the &lt;code class=&quot;highlighter-rouge&quot;&gt;@ProcessElement&lt;/code&gt; element we annotate a parameter &lt;code class=&quot;highlighter-rouge&quot;&gt;@TimerId(&quot;expiry&quot;)
Timer&lt;/code&gt;. The Beam runner automatically provides this &lt;code class=&quot;highlighter-rouge&quot;&gt;Timer&lt;/code&gt; parameter by which
we can set (and reset) the timer. It is inexpensive to reset a timer
repeatedly, so we simply set it on every element.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;We define the &lt;code class=&quot;highlighter-rouge&quot;&gt;onExpiry&lt;/code&gt; method, annotated with &lt;code class=&quot;highlighter-rouge&quot;&gt;@OnTimer(&quot;expiry&quot;)&lt;/code&gt;, that
performs a final event enrichment RPC and outputs the result. The Beam runner
delivers the callback to this method by matching its identifier.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Illustrating this logic, we have the diagram below:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-block&quot; src=&quot;/images/blog/timely-processing/BatchedRpcExpiry.png&quot; alt=&quot;Batched RPCs with window expiration&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Both the &lt;code class=&quot;highlighter-rouge&quot;&gt;@ProcessElement&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;@OnTimer(&quot;expiry&quot;)&lt;/code&gt; methods perform the same
access to buffered state, perform the same batched RPC, and output enriched
elements.&lt;/p&gt;

&lt;p&gt;Now, if we are executing this in a streaming real-time manner, we might still
have unbounded latency for particular buffered data. If the watermark is advancing
very slowly, or event time windows are chosen to be quite large, then a lot of
time might pass before output is emitted based either on enough elements or
window expiration. We can also use timers to limit the amount of wall-clock
time, aka processing time, before we process buffered elements. We can choose
some reasonable amount of time so that even though we are issuing RPCs that are
not as large as they might be, it is still few enough RPCs to avoid blowing our
quota with the external service.&lt;/p&gt;

&lt;h3 id=&quot;processing-time-timers&quot;&gt;Processing Time Timers&lt;/h3&gt;

&lt;p&gt;A timer in processing time (time as it passes while your pipeline is executing)
is intuitively simple: you want to wait a certain amount of time and then
receive a call back.&lt;/p&gt;

&lt;p&gt;To put the finishing touches on our example, we will set a processing time
timer as soon as any data is buffered. We track whether or not the timer has
been set so we don‚Äôt continually reset it. When an element arrives, if the
timer has not been set, then we set it for the current moment plus
&lt;code class=&quot;highlighter-rouge&quot;&gt;MAX_BUFFER_DURATION&lt;/code&gt;. After the allotted processing time has passed, a
callback will fire and enrich and emit any buffered elements.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DoFn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Event&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EnrichedEvent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;err&quot;&gt;‚Ä¶&lt;/span&gt;

  &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Duration&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MAX_BUFFER_DURATION&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Duration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;standardSeconds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;

  &lt;span class=&quot;nd&quot;&gt;@TimerId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;stale&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TimerSpec&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;staleSpec&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TimerSpecs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;timer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TimeDomain&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;PROCESSING_TIME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;

  &lt;span class=&quot;nd&quot;&gt;@ProcessElement&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;process&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;ProcessContext&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;BoundedWindow&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nd&quot;&gt;@StateId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;count&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ValueState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;countState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nd&quot;&gt;@StateId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;buffer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BagState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Event&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bufferState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nd&quot;&gt;@TimerId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;stale&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Timer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;staleTimer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nd&quot;&gt;@TimerId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;expiry&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Timer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;expiryTimer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;staleTimerSet&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;firstNonNull&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;staleSetState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;firstNonNull&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;countState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;staleTimer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MAX_BUFFER_DURATION&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setRelative&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;err&quot;&gt;‚Ä¶&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;same&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;processing&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logic&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;above&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;‚Ä¶&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;nd&quot;&gt;@OnTimer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;stale&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;onStale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;OnTimerContext&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nd&quot;&gt;@StateId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;buffer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BagState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Event&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bufferState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nd&quot;&gt;@StateId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;count&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ValueState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;countState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bufferState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;isEmpty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EnrichedEvent&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enrichedEvent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enrichEvents&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bufferState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;enrichedEvent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;bufferState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;clear&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;countState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;clear&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;err&quot;&gt;‚Ä¶&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;same&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;expiry&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;above&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;‚Ä¶&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# State and timers are not yet supported in Beam's Python SDK.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Follow https://issues.apache.org/jira/browse/BEAM-2687 for updates.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Here is an illustration of the final code:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-block&quot; src=&quot;/images/blog/timely-processing/BatchedRpcStale.png&quot; alt=&quot;Batching elements in state, then performing RPCs&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Recapping the entirety of the logic:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;As events arrive at &lt;code class=&quot;highlighter-rouge&quot;&gt;@ProcessElement&lt;/code&gt; they are buffered in state.&lt;/li&gt;
  &lt;li&gt;If the size of the buffer exceeds a maximum, the events are enriched and output.&lt;/li&gt;
  &lt;li&gt;If the buffer fills too slowly and the events get stale before the maximum is reached,
a timer causes a callback which enriches the buffered events and outputs.&lt;/li&gt;
  &lt;li&gt;Finally, as any window is expiring, any events buffered in that window are
processed and output prior to the state for that window being discarded.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the end, we have a full example that uses state and timers to explicitly
manage the low-level details of a performance-sensitive transform in Beam. As
we added more and more features, our &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; actually became pretty large. That
is a normal characteristic of stateful, timely processing. You are really
digging in and managing a lot of details that are handled automatically when
you express your logic using Beam‚Äôs higher-level APIs. What you gain from this
extra effort is an ability to tackle use cases and achieve efficiencies that
may not have been possible otherwise.&lt;/p&gt;

&lt;h2 id=&quot;state-and-timers-in-beams-unified-model&quot;&gt;State and Timers in Beam‚Äôs Unified Model&lt;/h2&gt;

&lt;p&gt;Beam‚Äôs unified model for event time across streaming and batch processing has
novel implications for state and timers. Usually, you don‚Äôt need to do anything
for your stateful and timely &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; to work well in the Beam model. But it will
help to be aware of the considerations below, especially if you have used
similar features before outside of Beam.&lt;/p&gt;

&lt;h3 id=&quot;event-time-windowing-just-works&quot;&gt;Event Time Windowing ‚ÄúJust Works‚Äù&lt;/h3&gt;

&lt;p&gt;One of the raisons d‚Äôetre for Beam is correct processing of out-of-order event
data, which is almost all event data. Beam‚Äôs solution to out-of-order data is
event time windowing, where windows in event time yield correct results no
matter what windowing a user chooses or what order the events come in.&lt;/p&gt;

&lt;p&gt;If you write a stateful, timely transform, it should work no matter how the
surrounding pipeline chooses to window event time. If the pipeline chooses
fixed windows of one hour (sometimes called tumbling windows) or windows of 30
minutes sliding by 10 minutes, the stateful, timely transform should
transparently work correctly.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-block&quot; src=&quot;/images/blog/timely-processing/WindowingChoices.png&quot; alt=&quot;Two windowing strategies for the same stateful and timely transform&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This works in Beam automatically, because state and timers are partitioned per
key and window. Within each key and window, the stateful, timely processing is
essentially independent.  As an added benefit, the passing of event time (aka
advancement of the watermark) allows automatic release of unreachable state
when a window expires, so you often don‚Äôt have to worry about evicting old
state.&lt;/p&gt;

&lt;h3 id=&quot;unified-real-time-and-historical-processing&quot;&gt;Unified real-time and historical processing&lt;/h3&gt;

&lt;p&gt;A second tenet of Beam‚Äôs semantic model is that processing must be unified
between batch and streaming. One important use case for this unification
is the ability to apply the same logic to a stream of events in real time and
to archived storage of the same events.&lt;/p&gt;

&lt;p&gt;A common characteristic of archived data is that it may arrive radically out of
order. The sharding of archived files often results in a totally different
ordering for processing than events coming in near-real-time. The data will
also all be all available and hence delivered instantaneously from the point of
view of your pipeline. Whether running experiments on past data or reprocessing
past results to fix a data processing bug, it is critically important that your
processing logic be applicable to archived events just as easily as incoming
near-real-time data.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-block&quot; src=&quot;/images/blog/timely-processing/UnifiedModel.png&quot; alt=&quot;Unified stateful processing over streams and file archives&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It is (deliberately) possible to write a stateful and timely DoFn that delivers
results that depend on ordering or delivery timing, so in this sense there is
additional burden on you, the &lt;code class=&quot;highlighter-rouge&quot;&gt;DoFn&lt;/code&gt; author, to ensure that this nondeterminism
falls within documented allowances.&lt;/p&gt;

&lt;h2 id=&quot;go-use-it&quot;&gt;Go use it!&lt;/h2&gt;

&lt;p&gt;I‚Äôll end this post in the same way I ended the last. I hope you will go try out
Beam with stateful, timely processing. If it opens up new possibilities for
you, then great! If not, we want to hear about it. Since this is a new feature,
please check the &lt;a href=&quot;/documentation/runners/capability-matrix/&quot;&gt;capability matrix&lt;/a&gt; to see the level of support for
your preferred Beam backend(s).&lt;/p&gt;

&lt;p&gt;And please do join the Beam community at
&lt;a href=&quot;/get-started/support&quot;&gt;user@beam.apache.org&lt;/a&gt; and follow
&lt;a href=&quot;https://twitter.com/ApacheBeam&quot;&gt;@ApacheBeam&lt;/a&gt; on Twitter.&lt;/p&gt;
</description>
        <pubDate>Mon, 28 Aug 2017 01:00:01 -0700</pubDate>
        <link>https://beam.apache.org/blog/2017/08/28/timely-processing.html</link>
        <guid isPermaLink="true">https://beam.apache.org/blog/2017/08/28/timely-processing.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
  </channel>
</rss>
