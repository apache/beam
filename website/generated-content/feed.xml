<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Apache Beam</title><description>Apache Beam is an open source, unified model and set of language-specific SDKs for defining and executing data processing workflows, and also data ingestion and integration flows, supporting Enterprise Integration Patterns (EIPs) and Domain Specific Languages (DSLs). Dataflow pipelines simplify the mechanics of large-scale batch and streaming data processing and can run on a number of runtimes like Apache Flink, Apache Spark, and Google Cloud Dataflow (a cloud service). Beam also brings DSL in different languages, allowing users to easily implement their data integration processes.</description><link>/</link><generator>Hugo -- gohugo.io</generator><item><title>Google Summer of Code 2025 - Beam YAML, Kafka and Iceberg User Accessibility</title><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;p>The relatively new Beam YAML SDK was introduced in the spirit of making data processing easy,
but it has gained little adoption for complex ML tasks and hasn’t been widely used with
&lt;a href="beam.apache.org/documentation/io/managed-io/">Managed I/O&lt;/a> such as Kafka and Iceberg.
As part of Google Summer of Code 2025, new illustrative, production-ready pipeline examples
of ML use cases with Kafka and Iceberg data sources using the YAML SDK have been developed
to address this adoption gap.&lt;/p>
&lt;h2 id="context">Context&lt;/h2>
&lt;p>The YAML SDK was introduced in Spring 2024 as Beam’s first no-code SDK. It follows a declarative approach
of defining a data processing pipeline using a YAML DSL, as opposed to other programming language specific SDKs.
At the time, it had few meaningful examples and documentation to go along with it. Key missing examples
were ML workflows and integration with the Kafka and Iceberg Managed I/O. Foundational work had already been done
to add support for ML capabilities as well as Kafka and Iceberg IO connectors in the YAML SDK, but there were no
end-to-end examples demonstrating their usage.&lt;/p>
&lt;p>Beam, as well as Kafka and Iceberg, are mainstream big data technologies but they also have a learning curve.
The overall theme of the project is to help democratize data processing for scientists and analysts who traditionally
don’t have a strong background in software engineering. They can now refer to these meaningful examples as the starting point,
helping them onboard faster and be more productive when authoring ML/data pipelines to their use cases with Beam and its YAML DSL.&lt;/p>
&lt;h2 id="contributions">Contributions&lt;/h2>
&lt;p>The data pipelines/workflows developed are production-ready: Kafka and Iceberg data sources are set up on GCP,
and the data used are raw public datasets. The pipelines are tested end-to-end on Google Cloud Dataflow and
are also unit tested to ensure correct transformation logic.&lt;/p>
&lt;p>Delivered pipelines/workflows, each with documentation as README.md, address 4 main ML use cases below:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>Streaming Classification Inference&lt;/strong>: A streaming ML pipeline that demonstrates Beam YAML capability to perform
classification inference on a stream of incoming data from Kafka. The overall workflow also includes
DistilBERT model deployment and serving on Google Cloud Vertex AI where the pipeline can access for remote inferences.
The pipeline is applied to a sentiment analysis task on a stream of YouTube comments, preprocessing data and classifying
whether a comment is positive or negative. See &lt;a href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/yaml/examples/transforms/ml/sentiment_analysis/streaming_sentiment_analysis.yaml">pipeline&lt;/a> and &lt;a href="https://github.com/apache/beam/tree/master/sdks/python/apache_beam/yaml/examples/transforms/ml/sentiment_analysis">documentation&lt;/a>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Streaming Regression Inference&lt;/strong>: A streaming ML pipeline that demonstrates Beam YAML capability to perform
regression inference on a stream of incoming data from Kafka. The overall workflow also includes
custom model training, deployment and serving on Google Cloud Vertex AI where the pipeline can access for remote inferences.
The pipeline is applied to a regression task on a stream of taxi rides, preprocessing data and predicting the fare amount
for every ride. See &lt;a href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/yaml/examples/transforms/ml/taxi_fare/streaming_taxifare_prediction.yaml">pipeline&lt;/a> and &lt;a href="https://github.com/apache/beam/tree/master/sdks/python/apache_beam/yaml/examples/transforms/ml/taxi_fare">documentation&lt;/a>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Batch Anomaly Detection&lt;/strong>: A ML workflow that demonstrates ML-specific transformations
and reading from/writing to Iceberg IO. The workflow contains unsupervised model training and several pipelines that leverage
Iceberg for storing results, BigQuery for storing vector embeddings and MLTransform for computing embeddings to demonstrate
an end-to-end anomaly detection workflow on a dataset of system logs. See &lt;a href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/yaml/examples/transforms/ml/log_analysis/batch_log_analysis.sh">workflow&lt;/a> and &lt;a href="https://github.com/apache/beam/tree/master/sdks/python/apache_beam/yaml/examples/transforms/ml/log_analysis">documentation&lt;/a>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Feature Engineering &amp;amp; Model Evaluation&lt;/strong>: A ML workflow that demonstrates Beam YAML capability to do feature engineering
which is subsequently used for model evaluation, and its integration with Iceberg IO. The workflow contains model training
and several pipelines, showcasing an end-to-end Fraud Detection MLOps solution that generates features and evaluates models
to detect credit card transaction frauds. See &lt;a href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/yaml/examples/transforms/ml/fraud_detection/fraud_detection_mlops_beam_yaml_sdk.ipynb">workflow&lt;/a> and &lt;a href="https://github.com/apache/beam/tree/master/sdks/python/apache_beam/yaml/examples/transforms/ml/fraud_detection">documentation&lt;/a>.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="challenges">Challenges&lt;/h2>
&lt;p>The main challenge of the project was a lack of previous YAML pipeline examples and good documentation to rely on.
Unlike the Python or Java SDKs where there are already many notebooks and end-to-end examples demonstrating various use cases,
the examples for YAML SDK only involved simple transformations such as filter, group by, etc. More complex transforms like
&lt;code>MLTransform&lt;/code> and &lt;code>ReadFromIceberg&lt;/code> had no examples and requires configurations that didn&amp;rsquo;t have clear API reference at the time.
As a result, there were a lot of deep dives into the actual implementation of the PTransforms across YAML, Python and Java SDKs to
understand the error messages and how to correctly use the transforms.&lt;/p>
&lt;p>Another challenge was writing unit tests for the pipeline to ensure that the pipeline’s logic is correct.
It was a learning curve to understand how the existing test suite is set up and how it can be used to write unit tests for
the data pipelines. A lot of time was spent on properly writing mocks for the pipeline&amp;rsquo;s sources and sinks, as well as for the
transforms that require external services such as Vertex AI.&lt;/p>
&lt;h2 id="conclusion--personal-thoughts">Conclusion &amp;amp; Personal Thoughts&lt;/h2>
&lt;p>These production-ready pipelines demonstrate the potential of Beam YAML SDK to author complex ML workflows
that interact with Iceberg and Kafka. The examples are a nice addition to Beam, especially with Beam 3.0.0 milestones
coming up where low-code/no-code, ML capabilities and Managed I/O are focused on.&lt;/p>
&lt;p>I had an amazing time working with the big data technologies Beam, Iceberg, and Kafka as well as many Google Cloud services
(Dataflow, Vertex AI and Google Kubernetes Engine, to name a few). I’ve always wanted to work more in the ML space, and this
experience has been a great growth opportunity for me. Google Summer of Code this year has been selective, and the project&amp;rsquo;s success
would not have been possible without the support of my mentor, Chamikara Jayalath. It&amp;rsquo;s been a pleasure working closely
with him and the broader Beam community to contribute to this open-source project that has a meaningful impact on the
data engineering community.&lt;/p>
&lt;p>My advice for future Google Summer of Code participants is to first and foremost research and choose a project that aligns closely
with your interest. Most importantly, spend a lot of time making yourself visible and writing a good proposal when the program
is opened for applications. Being visible (e.g. by sharing your proposal, or generally any ideas and questions on the project&amp;rsquo;s
communication channel early on) makes it more likely for you to be selected; and a good proposal not only will make you even
more likely to be in the program, but also give you a lot of confidence when contributing to and completing the project.&lt;/p>
&lt;h2 id="references">References&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://summerofcode.withgoogle.com/programs/2025/projects/f4kiDdus">Google Summer of Code Project Listing&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.google.com/document/d/1MSAVF6X9ggtVZbqz8YJGmMgkolR_dve0Lr930cByyac/edit?usp=sharing">Google Summer of Code Final Report&lt;/a>&lt;/li>
&lt;/ul></description><link>/blog/gsoc-25-yaml-user-accessibility/</link><pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate><guid>/blog/gsoc-25-yaml-user-accessibility/</guid><category>blog</category><category>gsoc</category></item><item><title>Apache Beam 2.68.0</title><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;p>We are happy to present the new 2.68.0 release of Beam.
This release includes both improvements and new functionality.
See the &lt;a href="/get-started/downloads/#2680-2025-09-??">download page&lt;/a> for this release.&lt;/p>
&lt;p>For more information on changes in 2.68.0, check out the &lt;a href="https://github.com/apache/beam/milestone/36?closed=1">detailed release notes&lt;/a>.&lt;/p>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>[Python] Prism runner now enabled by default for most Python pipelines using the direct runner (&lt;a href="https://github.com/apache/beam/pull/34612">#34612&lt;/a>). This may break some tests, see &lt;a href="https://github.com/apache/beam/pull/34612">https://github.com/apache/beam/pull/34612&lt;/a> for details on how to handle issues.&lt;/li>
&lt;/ul>
&lt;h3 id="ios">I/Os&lt;/h3>
&lt;ul>
&lt;li>Upgraded Iceberg dependency to 1.9.2 (&lt;a href="https://github.com/apache/beam/pull/35981">#35981&lt;/a>)&lt;/li>
&lt;/ul>
&lt;h3 id="new-features--improvements">New Features / Improvements&lt;/h3>
&lt;ul>
&lt;li>BigtableRead Connector for BeamYaml added with new Config Param (&lt;a href="https://github.com/apache/beam/pull/35696">#35696&lt;/a>)&lt;/li>
&lt;li>MongoDB Java driver upgraded from 3.12.11 to 5.5.0 with API refactoring and GridFS implementation updates (Java) (&lt;a href="https://github.com/apache/beam/pull/35946">#35946&lt;/a>).&lt;/li>
&lt;li>Introduced a dedicated module for JUnit-based testing support: &lt;code>sdks/java/testing/junit&lt;/code>, which provides &lt;code>TestPipelineExtension&lt;/code> for JUnit 5 while maintaining backward compatibility with existing JUnit 4 &lt;code>TestRule&lt;/code>-based tests (Java) (&lt;a href="https://github.com/apache/beam/issues/18733">#18733&lt;/a>, &lt;a href="https://github.com/apache/beam/pull/35688">#35688&lt;/a>).
&lt;ul>
&lt;li>To use JUnit 5 with Beam tests, add a test-scoped dependency on &lt;code>org.apache.beam:beam-sdks-java-testing-junit&lt;/code>.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Google CloudSQL enrichment handler added (Python) (&lt;a href="https://github.com/apache/beam/pull/34398">#34398&lt;/a>).
Beam now supports data enrichment capabilities using SQL databases, with built-in support for:
&lt;ul>
&lt;li>Managed PostgreSQL, MySQL, and Microsoft SQL Server instances on CloudSQL&lt;/li>
&lt;li>Unmanaged SQL database instances not hosted on CloudSQL (e.g., self-hosted or on-premises databases)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>[Python] Added the &lt;code>ReactiveThrottler&lt;/code> and &lt;code>ThrottlingSignaler&lt;/code> classes to streamline throttling behavior in DoFns, expose throttling mechanisms for users (&lt;a href="https://github.com/apache/beam/pull/35984">#35984&lt;/a>)&lt;/li>
&lt;li>Added a pipeline option to specify the processing timeout for a single element by any PTransform (Java/Python/Go) (&lt;a href="https://github.com/apache/beam/issues/35174">#35174&lt;/a>).
&lt;ul>
&lt;li>When specified, the SDK harness automatically restarts if an element takes too long to process. Beam runner may then retry processing of the same work item.&lt;/li>
&lt;li>Use the &lt;code>--element_processing_timeout_minutes&lt;/code> option to reduce the chance of having stalled pipelines due to unexpected cases of slow processing, where slowness might not happen again if processing of the same element is retried.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>(Python) Adding GCP Spanner Change Stream support for Python (apache_beam.io.gcp.spanner) (&lt;a href="https://github.com/apache/beam/issues/24103">#24103&lt;/a>).&lt;/li>
&lt;/ul>
&lt;h3 id="breaking-changes">Breaking Changes&lt;/h3>
&lt;ul>
&lt;li>Previously deprecated Beam ZetaSQL component has been removed (&lt;a href="https://github.com/apache/beam/issues/34423">#34423&lt;/a>).
ZetaSQL users could migrate to Calcite SQL with BigQuery dialect enabled.&lt;/li>
&lt;li>Upgraded Beam vendored Calcite to 1.40.0 for Beam SQL (&lt;a href="https://github.com/apache/beam/issues/35483">#35483&lt;/a>), which
improves support for BigQuery and other SQL dialects. Note: Minor behavior changes are observed such as output
significant digits related to casting.&lt;/li>
&lt;li>(Python) The deterministic fallback coder for complex types like NamedTuple, Enum, and dataclasses now uses cloudpickle instead of dill. If your pipeline is affected, you may see a warning like: &amp;ldquo;Using fallback deterministic coder for type X&amp;hellip;&amp;rdquo;. You can revert to the previous behavior by using the pipeline option &lt;code>--update_compatibility_version=2.67.0&lt;/code> (&lt;a href="https://github.com/apache/beam/pull/35725">35725&lt;/a>). Report any pickling related issues to &lt;a href="https://github.com/apache/beam/issues/34903">#34903&lt;/a>&lt;/li>
&lt;li>(Python) Prism runner now enabled by default for most Python pipelines using the direct runner (&lt;a href="https://github.com/apache/beam/pull/34612">#34612&lt;/a>). This may break some tests, see &lt;a href="https://github.com/apache/beam/pull/34612">https://github.com/apache/beam/pull/34612&lt;/a> for details on how to handle issues.&lt;/li>
&lt;li>Dropped Java 8 support for &lt;a href="https://central.sonatype.com/artifact/org.apache.beam/beam-sdks-java-io-expansion-service">IO expansion-service&lt;/a>. Cross-language pipelines using this expansion service will need a Java11+ runtime (&lt;a href="https://github.com/apache/beam/pull/35981">#35981&lt;/a>.&lt;/li>
&lt;/ul>
&lt;h3 id="deprecations">Deprecations&lt;/h3>
&lt;ul>
&lt;li>Python SDK native SpannerIO (apache_beam/io/gcp/experimental/spannerio) is deprecated. Use cross-language wrapper
(apache_beam/io/gcp/spanner) instead (Python) (&lt;a href="https://github.com/apache/beam/issues/35860">#35860&lt;/a>).&lt;/li>
&lt;li>Samza runner is deprecated and scheduled for removal in Beam 3.0 (&lt;a href="https://github.com/apache/beam/issues/35448">#35448&lt;/a>).&lt;/li>
&lt;li>Twister2 runner is deprecated and scheduled for removal in Beam 3.0 (&lt;a href="https://github.com/apache/beam/issues/35905">#35905&lt;/a>)).&lt;/li>
&lt;/ul>
&lt;h3 id="bugfixes">Bugfixes&lt;/h3>
&lt;ul>
&lt;li>(Python) Fixed Java YAML provider fails on Windows (&lt;a href="https://github.com/apache/beam/issues/35617">#35617&lt;/a>).&lt;/li>
&lt;li>Fixed BigQueryIO creating temporary datasets in wrong project when temp_dataset is specified with a different project than the pipeline project. For some jobs, temporary datasets will now be created in the correct project (Python) (&lt;a href="https://github.com/apache/beam/issues/35813">#35813&lt;/a>).&lt;/li>
&lt;li>(Go) Fix duplicates due to reads after blind writes to Bag State (&lt;a href="https://github.com/apache/beam/issues/35869">#35869&lt;/a>).
&lt;ul>
&lt;li>Earlier Go SDK versions can avoid the issue by not reading in the same call after a blind write.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="list-of-contributors">List of Contributors&lt;/h2>
&lt;p>According to git shortlog, the following people contributed to the 2.68.0 release. Thank you to all contributors!&lt;/p>
&lt;p>Ahmed Abualsaud, Andrew Crites, Ashok Devireddy, Chamikara Jayalath, Charles Nguyen, Danny McCormick, Davda James, Derrick Williams, Diego Hernandez, Dip Patel, Dustin Rhodes, Enrique Calderon, Hai Joey Tran, Jack McCluskey, Kenneth Knowles, Keshav, Khorbaladze A., LEEKYE, Lanny Boarts, Mattie Fu, Minbo Bae, Mohamed Awnallah, Naireen Hussain, Nathaniel Young, Radosław Stankiewicz, Razvan Culea, Robert Bradshaw, Robert Burke, Sam Whittle, Shehab, Shingo Furuyama, Shunping Huang, Steven van Rossum, Suvrat Acharya, Svetak Sundhar, Tarun Annapareddy, Tom Stepp, Valentyn Tymofieiev, Vitaly Terentyev, XQ Hu, Yi Hu, apanich, arnavarora2004, claudevdm, flpablo, kristynsmith, shreyakhajanchi&lt;/p></description><link>/blog/beam-2.68.0/</link><pubDate>Mon, 22 Sep 2025 15:00:00 -0500</pubDate><guid>/blog/beam-2.68.0/</guid><category>blog</category><category>release</category></item><item><title>Google Summer of Code 25 - Improving Apache Beam's Infrastructure</title><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;p>I loved contributing to Apache Beam during Google Summer of Code 2025. I worked on improving the infrastructure of Apache Beam, which included enhancing the CI/CD pipelines, automating various tasks, and improving the overall developer experience.&lt;/p>
&lt;h2 id="motivation">Motivation&lt;/h2>
&lt;p>Since I was in high school, I have been fascinated by computers, but when I discovered Open Source, I was amazed by the idea of people from all around the world collaborating to build software that anyone can use, just for the love of it. I started participating in open source communities, and I found it to be a great way to learn and grow as a developer.&lt;/p>
&lt;p>When I heard about Google Summer of Code, I saw it as an opportunity to take my open source contributions to the next level. The idea of working on a real-world project while being mentored by experienced developers sounded like an amazing opportunity. I heard about Apache Beam from another contributor and ex-GSoC participant, and I was immediately drawn to the project, specifically on the infrastructure side of things, as I have a strong interest in DevOps and automation.&lt;/p>
&lt;h2 id="the-challenge">The Challenge&lt;/h2>
&lt;p>When searching for a project, I was told that Apache Beam&amp;rsquo;s infrastructure had several areas that could be improved. I was excited because the ideas were focused on improving the developer experience, and creating tools that could benefit not only Beam&amp;rsquo;s developers but also the wider open source community.&lt;/p>
&lt;p>There were four main challenges:&lt;/p>
&lt;ol>
&lt;li>Automating the cleanup of unused cloud resources to reduce costs and improve resource management.&lt;/li>
&lt;li>Implementing a system for managing permissions through Git, allowing for better tracking and auditing of changes.&lt;/li>
&lt;li>Creating a tool for rotating service account keys to enhance security.&lt;/li>
&lt;li>Developing a security monitoring system to detect and respond to potential threats.&lt;/li>
&lt;/ol>
&lt;h2 id="the-solution">The Solution&lt;/h2>
&lt;p>I worked closely with my mentor to break down and define each challenge into manageable tasks, creating a plan for the summer. I started by taking a look at the current state of the infrastructure, after which I began working on each challenge one by one.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>Automating the cleanup of unused cloud resources:&lt;/strong> We noticed that some resources in the GCP project, especially Pub/Sub topics created for testing, were often forgotten, leading to unnecessary costs. Since the infrastructure is primarily for testing and development, there&amp;rsquo;s no need to keep unused resources. I developed a Python script that identifies and removes stale Pub/Sub topics that have existed for too long. This tool is now scheduled to run periodically via a GitHub Actions workflow to keep the project tidy and cost-effective.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Implementing a system for managing permissions through Git:&lt;/strong> This was more challenging, as it required a good understanding of both GCP IAM and the existing workflow. After some investigation, I learned that the current process was mostly manual and error-prone. The task involved creating a more automated and reliable system. This was achieved by using Terraform to define the desired state of IAM roles and permissions in code, which allows for better tracking and auditing of changes. This also included some custom roles, but that is still a work in progress.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Creating a tool for rotating service account keys:&lt;/strong> Key rotation is a security practice that we don&amp;rsquo;t always follow, but it is essential to ensure that service account keys are not compromised. I noticed that GCP had some APIs that could help with this, but the rotation process itself was not automated. So I wrote a Python script that automates the rotation of GCP service account keys, enhancing the security of service account credentials.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Developing a security monitoring system:&lt;/strong> To keep track of incorrect usage and potential threats, I built a log analysis tool that monitors GCP audit logs for suspicious activity, collecting and parsing logs to identify potential security threats, delivering email alerts when something unusual is detected.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>As an extra, and after noticing that some of these tools and policies could be ignored by developers, we also came up with the idea of an enforcement module to ensure the usage of these new tools and policies. This module would be integrated into the CI/CD pipeline, checking for compliance with the new infrastructure policies and notifying developers of any violations.&lt;/p>
&lt;h2 id="the-impact">The Impact&lt;/h2>
&lt;p>The tools developed during this project will have an impact on the Apache Beam community and the wider open source community. The automation of resource cleanup will help reduce costs and improve resource management, while the permission management system will provide better tracking and auditing of changes. The service account key rotation tool will enhance security, and the security monitoring system will help detect and respond to potential threats.&lt;/p>
&lt;h2 id="wrap-up">Wrap Up&lt;/h2>
&lt;p>This project has been an incredible learning experience for me. I have gained a better understanding of how GCP works, as well as how to use Terraform and GitHub Actions. I have also learned a lot about security best practices and how to implement them in a real-world project.&lt;/p>
&lt;p>I also learned a lot about working in an open source community, having direct communication with such experienced developers, and the importance of collaboration and communication in a distributed team. I am grateful for the opportunity to work on such an important project and to contribute to the Apache Beam community.&lt;/p>
&lt;p>Finally, a special thanks to my mentor, Pablo Estrada, for his guidance and support throughout the summer. I am grateful not only for his amazing technical skills but especially for his patience and encouragement on my journey contributing to open source.&lt;/p>
&lt;p>You can find my final report &lt;a href="https://gist.github.com/ksobrenat32/b028b8303393afbe73a8fc5e17daff90">here&lt;/a> if you want to take a look at the details of my work.&lt;/p>
&lt;h2 id="advice-for-future-participants">Advice for Future Participants&lt;/h2>
&lt;p>If you are considering participating in Google Summer of Code, my advice would be to choose an area you are passionate about; this will make any coding challenge easier to overcome. Also, don&amp;rsquo;t be afraid to ask questions and seek help from your mentors and the community. At the start, I made that mistake, and I learned that asking for help is a sign of strength, not weakness.&lt;/p>
&lt;p>Finally, make sure to manage your time effectively and stay organized (keeping a progress journal is a great idea). GSoC is a great opportunity to learn and grow as a developer, but it can also be time-consuming, so it&amp;rsquo;s important to stay focused and on track.&lt;/p></description><link>/blog/gsoc-25-infra/</link><pubDate>Mon, 15 Sep 2025 00:00:00 -0600</pubDate><guid>/blog/gsoc-25-infra/</guid><category>blog</category><category>gsoc</category></item><item><title>Apache Beam 2.67.0</title><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;p>We are happy to present the new 2.67.0 release of Beam.
This release includes both improvements and new functionality.
See the &lt;a href="/get-started/downloads/#2670-2025-08-12">download page&lt;/a> for this release.&lt;/p>
&lt;p>For more information on changes in 2.67.0, check out the &lt;a href="https://github.com/apache/beam/milestone/35?closed=1">detailed release notes&lt;/a>.&lt;/p>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;h3 id="ios">I/Os&lt;/h3>
&lt;ul>
&lt;li>Debezium IO upgraded to 3.1.1 requires Java 17 (Java) (&lt;a href="https://github.com/apache/beam/issues/34747">#34747&lt;/a>).&lt;/li>
&lt;li>Add support for streaming writes in IOBase (Python)&lt;/li>
&lt;li>Implement support for streaming writes in FileBasedSink (Python)&lt;/li>
&lt;li>Expose support for streaming writes in TextIO (Python)&lt;/li>
&lt;/ul>
&lt;h3 id="new-features--improvements">New Features / Improvements&lt;/h3>
&lt;ul>
&lt;li>Added support for Processing time Timer in the Spark Classic runner (&lt;a href="https://github.com/apache/beam/issues/33633">#33633&lt;/a>).&lt;/li>
&lt;li>Add pip-based install support for JupyterLab Sidepanel extension (&lt;a href="https://github.com/apache/beam/issues/35397">#35397&lt;/a>).&lt;/li>
&lt;li>[IcebergIO] Create tables with a specified table properties (&lt;a href="https://github.com/apache/beam/pull/35496">#35496&lt;/a>)&lt;/li>
&lt;li>Add support for comma-separated options in Python SDK (Python) (&lt;a href="https://github.com/apache/beam/pull/35580">#35580&lt;/a>).
Python SDK now supports comma-separated values for experiments and dataflow_service_options,
matching Java SDK behavior while maintaining backward compatibility.&lt;/li>
&lt;li>Milvus enrichment handler added (Python) (&lt;a href="https://github.com/apache/beam/pull/35216">#35216&lt;/a>).
Beam now supports Milvus enrichment handler capabilities for vector, keyword,
and hybrid search operations.&lt;/li>
&lt;li>[Beam SQL] Add support for DATABASEs, with an implementation for Iceberg (&lt;a href="https://github.com/apache/beam/issues/35637">#35637&lt;/a>)&lt;/li>
&lt;li>Respect BatchSize and MaxBufferingDuration when using &lt;code>JdbcIO.WriteWithResults&lt;/code>. Previously, these settings were ignored (&lt;a href="https://github.com/apache/beam/pull/35669">#35669&lt;/a>).&lt;/li>
&lt;/ul>
&lt;h3 id="breaking-changes">Breaking Changes&lt;/h3>
&lt;ul>
&lt;li>Go: The pubsubio.Read transform now accepts ReadOptions as a value type instead of a pointer, and requires exactly one of Topic or Subscription to be set (they are mutually exclusive). Additionally, the ReadOptions struct now includes a Topic field for specifying the topic directly, replacing the previous topic parameter in the Read function signature (&lt;a href="https://github.com/apache/beam/pull/35369">#35369&lt;/a>).&lt;/li>
&lt;li>SQL: The &lt;code>ParquetTable&lt;/code> external table provider has changed its handling of the &lt;code>LOCATION&lt;/code> property. To read from a directory, the path must now end with a trailing slash (e.g., &lt;code>LOCATION '/path/to/data/'&lt;/code>). Previously, a trailing slash was not required. This change was made to enable support for glob patterns and single-file paths (&lt;a href="https://github.com/apache/beam/pull/35582">#35582&lt;/a>).&lt;/li>
&lt;/ul>
&lt;h3 id="bugfixes">Bugfixes&lt;/h3>
&lt;ul>
&lt;li>[YAML] Fixed handling of missing optional fields in JSON parsing (&lt;a href="https://github.com/apache/beam/issues/35179">#35179&lt;/a>).&lt;/li>
&lt;li>[Python] Fix WriteToBigQuery transform using CopyJob does not work with WRITE_TRUNCATE write disposition (&lt;a href="https://github.com/apache/beam/issues/34247">#34247&lt;/a>)&lt;/li>
&lt;li>[Python] Fixed dicomio tags mismatch in integration tests (&lt;a href="https://github.com/apache/beam/issues/30760">#30760&lt;/a>).&lt;/li>
&lt;li>[Java] Fixed spammy logging issues that affected versions 2.64.0 to 2.66.0.&lt;/li>
&lt;/ul>
&lt;h3 id="known-issues">Known Issues&lt;/h3>
&lt;ul>
&lt;li>(&lt;a href="https://github.com/apache/beam/issues/35666">#35666&lt;/a>). YAML Flatten incorrectly drops fields when input PCollections&amp;rsquo; schema are different. This issue exists for all versions since 2.52.0.&lt;/li>
&lt;/ul>
&lt;h2 id="list-of-contributors">List of Contributors&lt;/h2>
&lt;p>According to git shortlog, the following people contributed to the 2.67.0 release. Thank you to all contributors!&lt;/p>
&lt;p>Aditya Shukla, Ahmed Abualsaud, Arun Pandian, Boris Li, Chamikara Jayalath, Charles Nguyen, Chenzo, Danny McCormick, David Adeniji, Derrick Williams, Dmytro Tsyliuryk, Dustin Rhodes, Enrique Calderon, Gottipati Gautam, Hai Joey Tran, Hunor Portik, Jack McCluskey, Kenneth Knowles, Khorbaladze A., Marcio Sugar, Minh Son Nguyen, Mohamed Awnallah, Nathaniel Young, Nhon Dinh, Quentin Sommer, Rafael Raposo, Rakesh Kumar, Razvan Culea, Reuven Lax, Robert Bradshaw, Sam Whittle, Shunping Huang, Steven van Rossum, Talat UYARER, Tanu Sharma, Tarun Annapareddy, Tobi Kaymak, Tobias Kaymak, Valentyn Tymofieiev, Veronica Wasson, Vitaly Terentyev, XQ Hu, Yi Hu, akashorabek, arnavarora2004, changliiu, claudevdm, fozzie15, mvhensbergen, twosom&lt;/p></description><link>/blog/beam-2.67.0/</link><pubDate>Tue, 12 Aug 2025 15:00:00 -0500</pubDate><guid>/blog/beam-2.67.0/</guid><category>blog</category><category>release</category></item><item><title>Our Experience at Beam College 2025: 1st Place Hackathon Winners</title><description>
&lt;!--
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements. See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to You under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h2 id="introduction-the-beam-of-an-idea">Introduction: The Beam of an Idea&lt;/h2>
&lt;p>In the world of machine learning for healthcare, preprocessing large pathology image datasets at scale remains a bottleneck. Whole Slide Images (WSIs) in medical imaging can reach massive sizes. Traditional Python tools (PIL, etc.) fail under memory pressure, especially when handling thousands of such high-resolution images. This becomes a bottleneck for ML modeling tasks using standard tools.&lt;/p>
&lt;p>Having previously worked on image processing for object detection in machine learning, we also understood how crucial it is to preprocess and structure image data correctly for downstream tasks. These challenges are non-trivial and even more critical in healthcare, making it a natural and high-impact use case for scalable data processing frameworks like Apache Beam.&lt;/p>
&lt;p>So, in the &lt;a href="https://beamcollege.dev/hackathon/">Beam Summit 2025 Hackathon&lt;/a>, we joined as team &amp;ldquo;PCollectors&amp;rdquo; with the goal to leverage Beam to process large image data and convert it to a format suitable for downstream ML tasks. We were amazed to know that we secured 1st place with the implemented solution!&lt;/p>
&lt;h2 id="the-project-scalable-wsi-preprocessing-beam-pipeline">The Project: Scalable WSI Preprocessing Beam Pipeline&lt;/h2>
&lt;p>&lt;a href="https://github.com/adityashukla8/medical_image_processing_beam">GitHub Repo&lt;/a>&lt;/p>
&lt;h3 id="the-goal">The Goal&lt;/h3>
&lt;p>The primary objective of the pipeline was to process patient data (CSV) &amp;amp; WSIs, extract embeddings, combine the metadata, and output the final dataset in TFRecord format, ready for large-scale ML training.&lt;/p>
&lt;h3 id="solution-overview">Solution Overview&lt;/h3>
&lt;p>Our pipeline processes:&lt;/p>
&lt;ul>
&lt;li>Patient metadata (CSV)&lt;/li>
&lt;li>WSI files (.tif)&lt;/li>
&lt;li>Split the images into “tiles”&lt;/li>
&lt;li>Extract filtered image tiles based on the background threshold&lt;/li>
&lt;li>Generate max &amp;amp; avg embeddings per patient using EfficientNet&lt;/li>
&lt;li>Merge metadata + embeddings into TFRecords&lt;/li>
&lt;/ul>
&lt;p>All in a scalable, memory-efficient, cloud-native pipeline using Apache Beam and Dataflow.&lt;/p>
&lt;h3 id="dataset">Dataset&lt;/h3>
&lt;p>Source: Mayo Clinic STRIP AI Dataset (Kaggle)
Metadata: Each row = { image_id, center_id, patient_id, image_num, label }
Multiple images per patient
Labels exist only at the patient level
Images:
High-res .tif pathology slides&lt;/p>
&lt;h3 id="tech-stack">Tech Stack&lt;/h3>
&lt;ul>
&lt;li>Apache Beam: Orchestration engine&lt;/li>
&lt;li>Google Cloud Dataflow: Scalable runner&lt;/li>
&lt;li>Google Cloud Storage: Input TIFFs + output TFRecords&lt;/li>
&lt;li>TensorFlow: For embedding generation (EfficientNet) and TFRecord serialization&lt;/li>
&lt;/ul>
&lt;h2 id="the-hackathon-journey">The Hackathon Journey&lt;/h2>
&lt;p>Participating in the hackathon introduced us to multiple new things and allowed us to learn and implement simultaneously. Through the hackathon weekend, we:&lt;/p>
&lt;ul>
&lt;li>Designed the end-to-end pipeline&lt;/li>
&lt;li>Integrated pyvips + openslide for efficient image loading&lt;/li>
&lt;li>Used Beam&amp;rsquo;s RunInference API with TensorFlow&lt;/li>
&lt;li>Tiled and filtered images&lt;/li>
&lt;li>Wrote patient-level embeddings to TFRecords&lt;/li>
&lt;/ul>
&lt;h2 id="what-we-learnt">What we Learnt&lt;/h2>
&lt;p>Apache Beam is really powerful for parallel and cloud-native ML preprocessing.
Dataflow is the go-to tool when processing large data, like medical images&lt;/p>
&lt;h2 id="whats-next-for-the-project">What’s Next for The Project&lt;/h2>
&lt;p>Looking ahead, the pipeline can be extended beyond fixed-size tiling by incorporating image segmentation techniques to generate more meaningful patches based on tissue regions. This approach can improve ML model performance by focusing only on relevant areas. Moreover, the same preprocessing framework can be adapted for video data, where frames can be treated as time-indexed image slices, effectively enabling temporal modeling for time-series tasks such as motion analysis or progression tracking. Finally, we plan to adapt this pipeline to multiple downstream use cases for AI in healthcare by combining histology images with genomic data, clinical notes, or radiology scans, paving the way for more comprehensive and context-aware models in biomedical machine learning.&lt;/p>
&lt;p>&lt;strong>Project Submission Demo&lt;/strong>: &lt;a href="https://drive.google.com/file/d/1Os5SvgqHiqfMkoCWOuaVvEPXsnhqXlLx/view?usp=sharing">Beam Demo - PCollectors.mp4&lt;/a>&lt;/p>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>We are ML Engineers, working at &lt;a href="www.intuitive.cloud">Intuitive.Cloud&lt;/a>, where we play around with large-scale data to build scalable, efficient, dynamic data processing pipelines that prepare it for downstream ML tasks, with Apache Beam and Google Cloud DataFlow being the central pieces.&lt;/p>
&lt;p>Participating in the hackathon was a great learning opportunity, huge thanks to the organizers, mentors, and the Apache Beam community!&lt;/p>
&lt;p>- &lt;a href="https://www.linkedin.com/in/adityashukla8/">Aditya Shukla&lt;/a> &amp;amp; &lt;a href="https://in.linkedin.com/in/darshan-kanade-0797851b3">Darshan Kanade&lt;/a>&lt;/p></description><link>/blog/beam-summit-2025-hackathon-pcollectors-blog/</link><pubDate>Tue, 08 Jul 2025 00:00:00 +0000</pubDate><guid>/blog/beam-summit-2025-hackathon-pcollectors-blog/</guid><category>blog</category></item><item><title>Apache Beam 2.66.0</title><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;p>We are happy to present the new 2.66.0 release of Beam.
This release includes both improvements and new functionality.
See the &lt;a href="/get-started/downloads/#2660-2025-07-01">download page&lt;/a> for this release.&lt;/p>
&lt;p>For more information on changes in 2.66.0, check out the &lt;a href="https://github.com/apache/beam/milestone/30?closed=1">detailed release notes&lt;/a>.&lt;/p>
&lt;h2 id="beam-300-development-highlights">Beam 3.0.0 Development Highlights&lt;/h2>
&lt;ul>
&lt;li>[Java] Java 8 support is now deprecated. It is still supported until Beam 3.
From now, pipeline submitted by Java 8 client uses Java 11 SDK container for
remote pipeline execution (&lt;a href="https://github.com/apache/beam/pull/35064">35064&lt;/a>).&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>[Python] Several quality-of-life improvements to the vLLM model handler. If you use Beam RunInference with vLLM model handlers, we strongly recommend updating past this release.&lt;/li>
&lt;/ul>
&lt;h3 id="ios">I/Os&lt;/h3>
&lt;ul>
&lt;li>[IcebergIO] Now available with Beam SQL! (&lt;a href="https://github.com/apache/beam/pull/34799">#34799&lt;/a>)&lt;/li>
&lt;li>[IcebergIO] Support reading with column pruning (&lt;a href="https://github.com/apache/beam/pull/34856">#34856&lt;/a>)&lt;/li>
&lt;li>[IcebergIO] Support reading with pushdown filtering (&lt;a href="https://github.com/apache/beam/pull/34827">#34827&lt;/a>)&lt;/li>
&lt;li>[IcebergIO] Create tables with a specified partition spec (&lt;a href="https://github.com/apache/beam/pull/34966">#34966&lt;/a>, &lt;a href="https://github.com/apache/beam/pull/35268">#35268&lt;/a>)&lt;/li>
&lt;li>[IcebergIO] Dynamically create namespaces if needed (&lt;a href="https://github.com/apache/beam/pull/35228">#35228&lt;/a>)&lt;/li>
&lt;/ul>
&lt;h3 id="new-features--improvements">New Features / Improvements&lt;/h3>
&lt;ul>
&lt;li>[Beam SQL] Introducing Beam Catalogs (&lt;a href="https://github.com/apache/beam/pull/35223">#35223&lt;/a>)&lt;/li>
&lt;li>Adding Google Storage Requests Pays feature (Golang)(&lt;a href="https://github.com/apache/beam/issues/30747">#30747&lt;/a>).&lt;/li>
&lt;li>[Python] Prism runner now auto-enabled for some Python pipelines using the direct runner (&lt;a href="https://github.com/apache/beam/pull/34921">#34921&lt;/a>).&lt;/li>
&lt;li>[YAML] WriteToTFRecord and ReadFromTFRecord Beam YAML support&lt;/li>
&lt;li>Python: Added JupyterLab 4.x extension compatibility for enhanced notebook integration (&lt;a href="https://github.com/apache/beam/pull/34495">#34495&lt;/a>).&lt;/li>
&lt;/ul>
&lt;h3 id="breaking-changes">Breaking Changes&lt;/h3>
&lt;ul>
&lt;li>Yapf version upgraded to 0.43.0 for formatting (Python) (&lt;a href="https://github.com/apache/beam/pull/34801/">#34801&lt;/a>).&lt;/li>
&lt;li>Python: Added JupyterLab 4.x extension compatibility for enhanced notebook integration (&lt;a href="https://github.com/apache/beam/pull/34495">#34495&lt;/a>).&lt;/li>
&lt;li>Python: Argument abbreviation is no longer enabled within Beam. If you previously abbreviated arguments (e.g. &lt;code>--r&lt;/code> for &lt;code>--runner&lt;/code>), you will now need to specify the whole argument (&lt;a href="https://github.com/apache/beam/pull/34934">#34934&lt;/a>).&lt;/li>
&lt;li>Java: Users of ReadFromKafkaViaSDF transform might encounter pipeline graph compatibility issues when updating the pipeline. To mitigate, set the &lt;code>updateCompatibilityVersion&lt;/code> option to the SDK version used for the original pipeline, example &lt;code>--updateCompatabilityVersion=2.64.0&lt;/code>&lt;/li>
&lt;li>Python: Updated &lt;code>AlloyDBVectorWriterConfig&lt;/code> API to align with new &lt;code>PostgresVectorWriter&lt;/code> transform. Heres a quick guide to update your code: (&lt;a href="https://github.com/apache/beam/issues/35225">#35225&lt;/a>)&lt;/li>
&lt;/ul>
&lt;h3 id="bugfixes">Bugfixes&lt;/h3>
&lt;ul>
&lt;li>(Java) Fixed CassandraIO ReadAll does not let a pipeline handle or retry exceptions (&lt;a href="https://github.com/apache/beam/pull/34191">#34191&lt;/a>).&lt;/li>
&lt;li>[Python] Fixed vLLM model handlers breaking Beam logging. (&lt;a href="https://github.com/apache/beam/pull/35053">#35053&lt;/a>).&lt;/li>
&lt;li>[Python] Fixed vLLM connection leaks that caused a throughput bottleneck and underutilization of GPU (&lt;a href="https://github.com/apache/beam/pull/35053">#35053&lt;/a>).&lt;/li>
&lt;li>[Python] Fixed vLLM server recovery mechanism in the event of a process termination (&lt;a href="https://github.com/apache/beam/pull/35234">#35234&lt;/a>).&lt;/li>
&lt;li>(Python) Fixed cloudpickle overwriting class states every time loading a same object of dynamic class (&lt;a href="https://github.com/apache/beam/issues/35062">#35062&lt;/a>).&lt;/li>
&lt;li>[Python] Fixed pip install apache-beam[interactive] causes crash on google colab (&lt;a href="https://github.com/apache/beam/pull/35148">#35148&lt;/a>).&lt;/li>
&lt;li>[IcebergIO] Fixed Beam &amp;lt;-&amp;gt; Iceberg conversion logic for arrays of structs and maps of structs (&lt;a href="https://github.com/apache/beam/pull/35230">#35230&lt;/a>).&lt;/li>
&lt;/ul>
&lt;h3 id="known-issues">Known Issues&lt;/h3>
&lt;p>N/A&lt;/p>
&lt;h2 id="list-of-contributors">List of Contributors&lt;/h2>
&lt;p>According to git shortlog, the following people contributed to the 2.66.0 release. Thank you to all contributors!&lt;/p>
&lt;p>Aditya Yadav, Adrian Stoll, Ahmed Abualsaud, Bhargavkonidena, Chamikara Jayalath, Charles Nguyen, Chenzo, Damon, Danny McCormick, Derrick Williams, Enrique Calderon, Hai Joey Tran, Jack McCluskey, Kenneth Knowles, Leonardo Cesar Borges, Michael Gruschke, Minbo Bae, Minh Son Nguyen, Niel Markwick, Radosław Stankiewicz, Rakesh Kumar, Robert Bradshaw, S. Veyrié, Sam Whittle, Shubham Jaiswal, Shunping Huang, Steven van Rossum, Tanu Sharma, Vardhan Thigle, Vitaly Terentyev, XQ Hu, Yi Hu, akashorabek, atask-g, atognolag, bullet03, changliiu, claudevdm, fozzie15, ikarapanca, kristynsmith, Pablo Rodriguez Defino, tvalentyn, twosom, wollowizard&lt;/p></description><link>/blog/beam-2.66.0/</link><pubDate>Tue, 01 Jul 2025 15:00:00 -0500</pubDate><guid>/blog/beam-2.66.0/</guid><category>blog</category><category>release</category></item><item><title>My Experience at Beam College 2025: 3rd Place Hackathon Winner</title><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h2 id="introduction-the-spark-of-an-idea">Introduction: The Spark of an Idea&lt;/h2>
&lt;p>In 2025, I had the opportunity to participate in the &lt;a href="https://beamcollege.dev/hackathon/">Beam College Hackathon&lt;/a>, a fantastic event that brings together students and professionals to explore the power of Apache Beam.&lt;/p>
&lt;p>For my project, I built &lt;strong>&lt;a href="https://github.com/msugar/anomaflow">Anomaflow&lt;/a>&lt;/strong>, an anomaly detection pipeline using &lt;strong>Apache Beam&lt;/strong> and &lt;strong>Google Cloud Dataflow&lt;/strong>. It was my first public hackathon, and the experience was both rewarding and creatively energizing. I’m proud to share that Anomaflow earned &lt;strong>3rd place&lt;/strong> in the competition.&lt;/p>
&lt;h2 id="the-project-building-anomaflow">The Project: Building Anomaflow&lt;/h2>
&lt;h3 id="goal">Goal&lt;/h3>
&lt;p>The primary objective of Anomaflow was to process &lt;strong>host telemetry data&lt;/strong> from systems monitored by OpenTelemetry agents. The long-term goal is to detect anomalies in near real time, which has important applications in cybersecurity.&lt;/p>
&lt;h3 id="tech-stack">Tech Stack&lt;/h3>
&lt;p>Here’s a breakdown of the technologies used:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Apache Beam (Python SDK)&lt;/strong> for pipeline development&lt;/li>
&lt;li>&lt;strong>Bindplane Collector &amp;amp; Server&lt;/strong> for OpenTelemetry data collection and configuration&lt;/li>
&lt;li>&lt;strong>Google Compute Engine (GCE)&lt;/strong> instancess for hosting the Bindplane Server and Collector&lt;/li>
&lt;li>&lt;strong>Google Cloud Dataflow&lt;/strong> for running the Beam pipeline at scale&lt;/li>
&lt;li>&lt;strong>Google Cloud Storage (GCS)&lt;/strong> as the pipeline’s source and sink during the hackathon&lt;/li>
&lt;li>&lt;strong>Terraform&lt;/strong> to provision GCP infrastructure&lt;/li>
&lt;li>&lt;strong>Docker&lt;/strong> for packaging and deployment&lt;/li>
&lt;/ul>
&lt;h2 id="the-hackathon-journey-from-streaming-vision-to-batch-reality">The Hackathon Journey: From Streaming Vision to Batch Reality&lt;/h2>
&lt;h3 id="the-initial-vision">The Initial Vision&lt;/h3>
&lt;p>The original plan was to create a fully streaming pipeline: the &lt;strong>Bindplane Collector&lt;/strong> running on &lt;strong>GCE&lt;/strong> would upload telemetry files to &lt;strong>GCS&lt;/strong>, which would trigger &lt;strong>notifications via Pub/Sub&lt;/strong>. These notifications would then initiate processing in a &lt;strong>Beam pipeline&lt;/strong>, with enriched results written to &lt;strong>BigQuery&lt;/strong> for analysis and visualization.&lt;/p>
&lt;h3 id="the-pivot">The Pivot&lt;/h3>
&lt;p>However, working solo during a time-limited hackathon meant I had to be pragmatic. I decided to implement a &lt;strong>batch pipeline&lt;/strong> instead, reading from and writing to &lt;strong>GCS buckets&lt;/strong>. This allowed me to deliver a functional MVP while preserving a foundation that can evolve toward the original streaming vision.&lt;/p>
&lt;h3 id="key-learnings">Key Learnings&lt;/h3>
&lt;p>Although I already had some real-world experience with Apache Beam, the hackathon gave me the freedom to explore new patterns and tools in a low-risk environment. It was refreshing to iterate rapidly, test ideas, and push beyond my daily work scope.&lt;/p>
&lt;h2 id="whats-next-for-anomaflow">What’s Next for Anomaflow?&lt;/h2>
&lt;p>Anomaflow is just getting started.&lt;/p>
&lt;p>I plan to evolve the pipeline into a true &lt;strong>streaming system&lt;/strong> using &lt;strong>Pub/Sub&lt;/strong> and &lt;strong>BigQuery&lt;/strong>. I also want to explore &lt;strong>sliding windows&lt;/strong>, &lt;strong>custom anomaly detection models&lt;/strong>, and &lt;strong>alerting mechanisms&lt;/strong>. With its modular design and strong foundation in Beam, Anomaflow will serve as a base for several future cybersecurity analytics tools I have in mind.&lt;/p>
&lt;p>&lt;strong>Watch the demo&lt;/strong>: &lt;a href="https://www.youtube.com/watch?v=dpbOm5ekOTc">https://www.youtube.com/watch?v=dpbOm5ekOTc&lt;/a>&lt;/p>
&lt;h2 id="tips-for-future-participants">Tips for Future Participants&lt;/h2>
&lt;p>If you’re considering joining Beam College next year:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Use the mentors!&lt;/strong> The Beam community professionals volunteering their time are a valuable resource. Ask questions, get feedback.&lt;/li>
&lt;li>&lt;strong>Check out the &lt;a href="https://beam.apache.org/get-started/resources/learning-resources/">Beam learning resources&lt;/a>&lt;/strong>. They’re super helpful, especially for getting started with the Beam model and runners.&lt;/li>
&lt;/ul>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>I’m currently a &lt;strong>Software Architect and Data Engineer at TELUS Security&lt;/strong>, where I work on the &lt;strong>Cybersecurity Analytics and Software Engineering&lt;/strong> team. We design data pipelines to detect and respond to threats at scale.&lt;/p>
&lt;p>Participating in Beam College was a great way to stretch my skills, meet passionate Beam users, and contribute to a vibrant open source community. I’m excited to see what others will build in future editions!&lt;/p>
&lt;p>– &lt;a href="https://www.linkedin.com/in/marcio-sugar/">Marcio Sugar&lt;/a>&lt;/p></description><link>/blog/beam-college-2025-anomaflow/</link><pubDate>Mon, 16 Jun 2025 00:00:00 +0000</pubDate><guid>/blog/beam-college-2025-anomaflow/</guid><category>blog</category></item><item><title>Apache Beam 2.65.0</title><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;p>We are happy to present the new 2.65.0 release of Beam.
This release includes both improvements and new functionality.
See the &lt;a href="/get-started/downloads/#2650-2025-05-12">download page&lt;/a> for this release.&lt;/p>
&lt;p>For more information on changes in 2.65.0, check out the &lt;a href="https://github.com/apache/beam/milestone/29?closed=1">detailed release notes&lt;/a>.&lt;/p>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;h3 id="ios">I/Os&lt;/h3>
&lt;ul>
&lt;li>Upgraded GoogleAdsAPI to v19 for GoogleAdsIO (Java) (&lt;a href="https://github.com/apache/beam/pull/34497">#34497&lt;/a>). Changed PTransform method from version-specified (&lt;code>v17()&lt;/code>) to &lt;code>current()&lt;/code> for better backward compatibility in the future.&lt;/li>
&lt;li>Added support for writing to Pubsub with ordering keys (Java) (&lt;a href="https://github.com/apache/beam/issues/21162">#21162&lt;/a>)&lt;/li>
&lt;/ul>
&lt;h3 id="new-features--improvements">New Features / Improvements&lt;/h3>
&lt;ul>
&lt;li>Added support for streaming side-inputs in the Spark Classic runner (&lt;a href="https://github.com/apache/beam/issues/18136">#18136&lt;/a>).&lt;/li>
&lt;/ul>
&lt;h3 id="breaking-changes">Breaking Changes&lt;/h3>
&lt;ul>
&lt;li>[Python] Cloudpickle is set as the default &lt;code>pickle_library&lt;/code>, where previously
dill was the default in &lt;a href="https://github.com/apache/beam/pull/34695">#34695&lt;/a>.
For known issues, reporting new issues, and understanding cloudpickle
behavior refer to &lt;a href="https://github.com/apache/beam/issues/34903">#34903&lt;/a>.&lt;/li>
&lt;li>[Python] Reshuffle now preserves PaneInfo, where previously PaneInfo was lost
after reshuffle. To opt out of this change, set the
update_compatibility_version to a previous Beam version e.g. &amp;ldquo;2.64.0&amp;rdquo;.
(&lt;a href="https://github.com/apache/beam/pull/34348">#34348&lt;/a>).&lt;/li>
&lt;li>[Python] PaneInfo is encoded by PaneInfoCoder, where previously PaneInfo was
encoded with FastPrimitivesCoder falling back to PickleCoder. This only
affects cases where PaneInfo is directly stored as an element.
(&lt;a href="https://github.com/apache/beam/pull/34824">#34824&lt;/a>).&lt;/li>
&lt;li>[Python] BigQueryFileLoads now adds a Reshuffle before triggering load jobs.
This fixes a bug where there can be data loss in a streaming pipeline if there
is a pending load job during autoscaling. To opt out of this change, set the
update_compatibility_version to a previous Beam version e.g. &amp;ldquo;2.64.0&amp;rdquo;.
(&lt;a href="https://github.com/apache/beam/pull/34657">#34657&lt;/a>)&lt;/li>
&lt;li>[YAML] Kafka source and sink will be automatically replaced with compatible managed transforms.
For older Beam versions, streaming update compatiblity can be maintained by specifying the pipeline
option &lt;code>update_compatibility_version&lt;/code> (&lt;a href="https://github.com/apache/beam/issues/34767">#34767&lt;/a>).&lt;/li>
&lt;/ul>
&lt;h3 id="deprecations">Deprecations&lt;/h3>
&lt;ul>
&lt;li>Beam ZetaSQL is deprecated and will be removed no earlier than Beam 2.68.0 (&lt;a href="https://github.com/apache/beam/issues/34423">#34423&lt;/a>).
Users are recommended to switch to &lt;a href="https://beam.apache.org/documentation/dsls/sql/calcite/overview/">Calcite SQL&lt;/a> dialect.&lt;/li>
&lt;/ul>
&lt;h3 id="bugfixes">Bugfixes&lt;/h3>
&lt;ul>
&lt;li>Fixed read Beam rows from cross-lang transform (for example, ReadFromJdbc) involving negative 32-bit integers incorrectly decoded to large integers (&lt;a href="https://github.com/apache/beam/issues/34089">#34089&lt;/a>)&lt;/li>
&lt;li>(Java) Fixed SDF-based KafkaIO (ReadFromKafkaViaSDF) to properly handle custom deserializers that extend Deserializer&lt;Row> interface(&lt;a href="https://github.com/apache/beam/pull/34505">#34505&lt;/a>)&lt;/li>
&lt;li>[Python] &lt;code>TypedDict&lt;/code> typehints are now compatible with &lt;code>Mapping&lt;/code> and &lt;code>Dict&lt;/code> type annotations.&lt;/li>
&lt;/ul>
&lt;h3 id="security-fixes">Security Fixes&lt;/h3>
&lt;ul>
&lt;li>Fixed &lt;a href="https://www.cve.org/CVERecord?id=CVE-2025-30065">CVE-2025-30065&lt;/a> (Java) (&lt;a href="https://github.com/apache/beam/pull/34573">#34573&lt;/a>)&lt;/li>
&lt;/ul>
&lt;h3 id="known-issues">Known Issues&lt;/h3>
&lt;p>N/A&lt;/p>
&lt;h2 id="list-of-contributors">List of Contributors&lt;/h2>
&lt;p>According to git shortlog, the following people contributed to the 2.65.0 release. Thank you to all contributors!&lt;/p>
&lt;p>Aaron Trelstad, Adrian Stoll, Ahmed Abualsaud, akashorabek, Arun Pandian, Bentsi Leviav, Bryan Dang, Celeste Zeng, Chamikara Jayalath, claudevdm, Danny McCormick, Derrick Williams, Ozzie Fernandez, Gabija Balvociute, Gayatri Kate, illoise, Jack McCluskey, Jan Lukavský, Jinho Lee, Justin Bandoro, Kenneth Knowles, XQ Hu, Luke Tsekouras, Martin Trieu, Matthew Suozzo, Naireen Hussain, Niel Markwick, Radosław Stankiewicz, Razvan Culea, Robert Bradshaw, Robert Burke, RuiLong J., Sam Whittle, Sarthak, Shubham Jaiswal, Shunping Huang, Steven van Rossum, Suvrat Acharya, &lt;a href="mailto:sveyrie@luminatedata.com">sveyrie@luminatedata.com&lt;/a>, Talat Uyarer, TanuSharma2511, Tobias Kaymak, Tom Stepp, Valentyn Tymofieiev, twosom, Vitaly Terentyev, wollowizard, Yi Hu, Yifan Ye, Zilin Du&lt;/p></description><link>/blog/beam-2.65.0/</link><pubDate>Mon, 12 May 2025 15:00:00 -0500</pubDate><guid>/blog/beam-2.65.0/</guid><category>blog</category><category>release</category></item><item><title>Apache Beam 2.64.0</title><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;p>We are happy to present the new 2.64.0 release of Beam.
This release includes both improvements and new functionality.
See the &lt;a href="/get-started/downloads/%7B$DOWNLOAD_ANCHOR%7D">download page&lt;/a> for this release.&lt;/p>
&lt;p>For more information on changes in 2.64.0, check out the &lt;a href="https://github.com/apache/beam/milestone/28">detailed release notes&lt;/a>.&lt;/p>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Managed API for &lt;a href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/managed/Managed.html">Java&lt;/a> and &lt;a href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.managed.html#module-apache_beam.transforms.managed">Python&lt;/a> supports &lt;a href="https://beam.apache.org/documentation/io/connectors/">key I/O connectors&lt;/a> Iceberg, Kafka, and BigQuery.&lt;/li>
&lt;/ul>
&lt;h2 id="ios">I/Os&lt;/h2>
&lt;ul>
&lt;li>[Java] Use API compatible with both com.google.cloud.bigdataoss:util 2.x and 3.x in BatchLoads (&lt;a href="https://github.com/apache/beam/pull/34105">#34105&lt;/a>)&lt;/li>
&lt;li>[IcebergIO] Added new CDC source for batch and streaming, available as &lt;code>Managed.ICEBERG_CDC&lt;/code> (&lt;a href="https://github.com/apache/beam/pull/33504">#33504&lt;/a>)&lt;/li>
&lt;li>[IcebergIO] Address edge case where bundle retry following a successful data commit results in data duplication (&lt;a href="https://github.com/apache/beam/pull/34264">#34264&lt;/a>)&lt;/li>
&lt;/ul>
&lt;h2 id="new-features--improvements">New Features / Improvements&lt;/h2>
&lt;ul>
&lt;li>[Python] Support custom coders in Reshuffle (&lt;a href="https://github.com/apache/beam/issues/29908">#29908&lt;/a>, &lt;a href="https://github.com/apache/beam/issues/33356">#33356&lt;/a>).&lt;/li>
&lt;li>[Java] Upgrade SLF4J to 2.0.16. Update default Spark version to 3.5.0. (&lt;a href="https://github.com/apache/beam/pull/33574">#33574&lt;/a>)&lt;/li>
&lt;li>[Java] Support for &lt;code>--add-modules&lt;/code> JVM option is added through a new pipeline option &lt;code>JdkAddRootModules&lt;/code>. This allows extending the module graph with optional modules such as SDK incubator modules. Sample usage: &lt;code>&amp;lt;pipeline invocation&amp;gt; --jdkAddRootModules=jdk.incubator.vector&lt;/code> (&lt;a href="https://github.com/apache/beam/issues/30281">#30281&lt;/a>).&lt;/li>
&lt;li>Managed API for &lt;a href="https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/managed/Managed.html">Java&lt;/a> and &lt;a href="https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.managed.html#module-apache_beam.transforms.managed">Python&lt;/a> supports &lt;a href="https://beam.apache.org/documentation/io/connectors/">key I/O connectors&lt;/a> Iceberg, Kafka, and BigQuery.&lt;/li>
&lt;li>Prism now supports event time triggers for most common cases. (&lt;a href="https://github.com/apache/beam/issues/31438">#31438&lt;/a>)
&lt;ul>
&lt;li>Prism does not yet support triggered side inputs, or triggers on merging windows (such as session windows).&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="breaking-changes">Breaking Changes&lt;/h2>
&lt;ul>
&lt;li>[Python] Reshuffle now correctly respects user-specified type hints, fixing a previous bug where it might use FastPrimitivesCoder wrongly. This change could break pipelines with incorrect type hints in Reshuffle. If you have issues after upgrading, temporarily set update_compatibility_version to a previous Beam version to use the old behavior. The recommended solution is to fix the type hints in your code. (&lt;a href="https://github.com/apache/beam/pull/33932">#33932&lt;/a>)&lt;/li>
&lt;li>[Java] SparkReceiver 2 has been moved to SparkReceiver 3 that supports Spark 3.x. (&lt;a href="https://github.com/apache/beam/pull/33574">#33574&lt;/a>)&lt;/li>
&lt;li>[Python] Correct parsing of &lt;code>collections.abc.Sequence&lt;/code> type hints was added, which can lead to pipelines failing type hint checks that were previously passing erroneously. These issues will be most commonly seen trying to consume a PCollection with a &lt;code>Sequence&lt;/code> type hint after a GroupByKey or a CoGroupByKey. (&lt;a href="https://github.com/apache/beam/pull/33999">#33999&lt;/a>).&lt;/li>
&lt;/ul>
&lt;h2 id="bugfixes">Bugfixes&lt;/h2>
&lt;ul>
&lt;li>(Python) Fixed occasional pipeline stuckness that was affecting Python 3.11 users (&lt;a href="https://github.com/apache/beam/issues/33966">#33966&lt;/a>).&lt;/li>
&lt;li>(Java) Fixed TIME field encodings for BigQuery Storage API writes on GenericRecords (&lt;a href="https://github.com/apache/beam/pull/34059">#34059&lt;/a>).&lt;/li>
&lt;li>(Java) Fixed a race condition in JdbcIO which could cause hangs trying to acquire a connection (&lt;a href="https://github.com/apache/beam/pull/34058">#34058&lt;/a>).&lt;/li>
&lt;li>(Java) Fix BigQuery Storage Write compatibility with Avro 1.8 (&lt;a href="https://github.com/apache/beam/pull/34281">#34281&lt;/a>).&lt;/li>
&lt;li>Fixed checkpoint recovery and streaming behavior in Spark Classic and Portable runner&amp;rsquo;s Flatten transform by replacing queueStream with SingleEmitInputDStream (&lt;a href="https://github.com/apache/beam/pull/34080">#34080&lt;/a>, &lt;a href="https://github.com/apache/beam/issues/18144">#18144&lt;/a>, &lt;a href="https://github.com/apache/beam/issues/20426">#20426&lt;/a>)&lt;/li>
&lt;li>(Java) Fixed Read caching of UnboundedReader objects to effectively cache across multiple DoFns and avoid checkpointing unstarted reader. &lt;a href="https://github.com/apache/beam/pull/34146">#34146&lt;/a> &lt;a href="https://github.com/apache/beam/pull/33901">#33901&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="known-issues">Known Issues&lt;/h2>
&lt;ul>
&lt;li>(Java) Current version of protobuf has a &lt;a href="https://github.com/protocolbuffers/protobuf/issues/20599">bug&lt;/a> leading to incompatibilities with clients using older versions of Protobuf (&lt;a href="https://github.com/GoogleCloudPlatform/DataflowTemplates/issues/2191">example issue&lt;/a>). This issue has been seen in SpannerIO in particular. Tracked in &lt;a href="https://github.com/GoogleCloudPlatform/DataflowTemplates/issues/34452">#34452&lt;/a>.&lt;/li>
&lt;li>(Java) When constructing &lt;code>SpannerConfig&lt;/code> for &lt;code>SpannerIO&lt;/code>, calling &lt;code>withHost&lt;/code> with a null or empty host will now result in a Null Pointer Exception (&lt;code>java.lang.NullPointerException: Cannot invoke &amp;quot;java.lang.CharSequence.length()&amp;quot; because &amp;quot;this.text&amp;quot; is null&lt;/code>). See &lt;a href="https://github.com/GoogleCloudPlatform/DataflowTemplates/issues/34489">https://github.com/GoogleCloudPlatform/DataflowTemplates/issues/34489&lt;/a> for context.&lt;/li>
&lt;/ul>
&lt;h2 id="list-of-contributors">List of Contributors&lt;/h2>
&lt;p>According to git shortlog, the following people contributed to the 2.64.0 release. Thank you to all contributors!&lt;/p>
&lt;p>Ahmed Abualsaud&lt;/p>
&lt;p>akashorabek&lt;/p>
&lt;p>Arun Pandian&lt;/p>
&lt;p>Bentsi Leviav&lt;/p>
&lt;p>Chamikara Jayalath&lt;/p>
&lt;p>Charles Nguyen&lt;/p>
&lt;p>Claire McGinty&lt;/p>
&lt;p>claudevdm&lt;/p>
&lt;p>Damon&lt;/p>
&lt;p>Danny McCormick&lt;/p>
&lt;p>darshan-sj&lt;/p>
&lt;p>Derrick Williams&lt;/p>
&lt;p>fozzie15&lt;/p>
&lt;p>Hai Joey Tran&lt;/p>
&lt;p>Jack McCluskey&lt;/p>
&lt;p>Jozef Vilcek&lt;/p>
&lt;p>jrmccluskey&lt;/p>
&lt;p>Kenneth Knowles&lt;/p>
&lt;p>Liam Miller-Cushon&lt;/p>
&lt;p>liferoad&lt;/p>
&lt;p>Luv Agarwal&lt;/p>
&lt;p>martin trieu&lt;/p>
&lt;p>Matar&lt;/p>
&lt;p>Matthew Suozzo&lt;/p>
&lt;p>Michel Davit&lt;/p>
&lt;p>Minbo Bae&lt;/p>
&lt;p>Mohamed Awnallah&lt;/p>
&lt;p>Naireen Hussain&lt;/p>
&lt;p>Pablo Rodriguez Defino&lt;/p>
&lt;p>Radosław Stankiewicz&lt;/p>
&lt;p>Rakesh Kumar&lt;/p>
&lt;p>Reuven Lax&lt;/p>
&lt;p>Robert Bradshaw&lt;/p>
&lt;p>Robert Burke&lt;/p>
&lt;p>Rohit&lt;/p>
&lt;p>Rohit Sinha&lt;/p>
&lt;p>Sam Whittle&lt;/p>
&lt;p>Saumil Patel&lt;/p>
&lt;p>Shunping Huang&lt;/p>
&lt;p>So-shi Nakachi&lt;/p>
&lt;p>Steven van Rossum&lt;/p>
&lt;p>Suvrat Acharya&lt;/p>
&lt;p>Svetak Sundhar&lt;/p>
&lt;p>synenka&lt;/p>
&lt;p>Talat UYARER&lt;/p>
&lt;p>tvalentyn&lt;/p>
&lt;p>twosom&lt;/p>
&lt;p>utkarshparekh&lt;/p>
&lt;p>Vitaly Terentyev&lt;/p>
&lt;p>XQ Hu&lt;/p>
&lt;p>Yi Hu&lt;/p>
&lt;p>Zilin Du&lt;/p></description><link>/blog/beam-2.64.0/</link><pubDate>Mon, 31 Mar 2025 10:30:00 -0500</pubDate><guid>/blog/beam-2.64.0/</guid><category>blog</category><category>release</category></item><item><title>Apache Beam 2.63.0</title><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;p>We are happy to present the new 2.63.0 release of Beam.
This release includes both improvements and new functionality.
See the &lt;a href="/get-started/downloads/%7B$DOWNLOAD_ANCHOR%7D">download page&lt;/a> for this release.&lt;/p>
&lt;p>For more information on changes in 2.63.0, check out the &lt;a href="https://github.com/apache/beam/milestone/27">detailed release notes&lt;/a>.&lt;/p>
&lt;h2 id="ios">I/Os&lt;/h2>
&lt;ul>
&lt;li>Support gcs-connector 3.x+ in GcsUtil (&lt;a href="https://github.com/apache/beam/pull/33368">#33368&lt;/a>)&lt;/li>
&lt;li>Support for X source added (Java/Python) (&lt;a href="https://github.com/apache/beam/issues/X">#X&lt;/a>).&lt;/li>
&lt;li>Introduced &lt;code>--groupFilesFileLoad&lt;/code> pipeline option to mitigate side-input related issues in BigQueryIO
batch FILE_LOAD on certain runners (including Dataflow Runner V2) (Java) (&lt;a href="https://github.com/apache/beam/pull/33587">#33587&lt;/a>).&lt;/li>
&lt;/ul>
&lt;h2 id="new-features--improvements">New Features / Improvements&lt;/h2>
&lt;ul>
&lt;li>Add BigQuery vector/embedding ingestion and enrichment components to apache_beam.ml.rag (Python) (&lt;a href="https://github.com/apache/beam/pull/33413">#33413&lt;/a>).&lt;/li>
&lt;li>Upgraded to protobuf 4 (Java) (&lt;a href="https://github.com/apache/beam/issues/33192">#33192&lt;/a>).&lt;/li>
&lt;li>[GCSIO] Added retry logic to each batch method of the GCS IO (Python) (&lt;a href="https://github.com/apache/beam/pull/33539">#33539&lt;/a>)&lt;/li>
&lt;li>[GCSIO] Enable recursive deletion for GCSFileSystem Paths (Python) (&lt;a href="https://github.com/apache/beam/pull/33611">#33611&lt;/a>).&lt;/li>
&lt;li>External, Process based Worker Pool support added to the Go SDK container. (&lt;a href="https://github.com/apache/beam/pull/33572">#33572&lt;/a>)
&lt;ul>
&lt;li>This is used to enable sidecar containers to run SDK workers for some runners.&lt;/li>
&lt;li>See &lt;a href="https://beam.apache.org/documentation/runtime/sdk-harness-config/">https://beam.apache.org/documentation/runtime/sdk-harness-config/&lt;/a> for details.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Support the Process Environment for execution in the Go SDK. (&lt;a href="https://github.com/apache/beam/pull/33651">#33651&lt;/a>)&lt;/li>
&lt;li>Prism
&lt;ul>
&lt;li>Prism now uses the same single port for both pipeline submission and execution on workers. Requests are differentiated by worker-id. (&lt;a href="https://github.com/apache/beam/pull/33438">#33438&lt;/a>)
&lt;ul>
&lt;li>This avoids port starvation and provides clarity on port use when running Prism in non-local environments.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Support for @RequiresTimeSortedInputs added. (&lt;a href="https://github.com/apache/beam/issues/33513">#33513&lt;/a>)&lt;/li>
&lt;li>Initial support for AllowedLateness added. (&lt;a href="https://github.com/apache/beam/pull/33542">#33542&lt;/a>)&lt;/li>
&lt;li>The Go SDK&amp;rsquo;s inprocess Prism runner (AKA the Go SDK default runner) now supports non-loopback mode environment types. (&lt;a href="https://github.com/apache/beam/pull/33572">#33572&lt;/a>)&lt;/li>
&lt;li>Support the Process Environment for execution in Prism (&lt;a href="https://github.com/apache/beam/pull/33651">#33651&lt;/a>)&lt;/li>
&lt;li>Support the AnyOf Environment for execution in Prism (&lt;a href="https://github.com/apache/beam/pull/33705">#33705&lt;/a>)
&lt;ul>
&lt;li>This improves support for developing Xlang pipelines, when using a compatible cross language service.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Partitions are now configurable for the DaskRunner in the Python SDK (&lt;a href="https://github.com/apache/beam/pull/33805">#33805&lt;/a>).&lt;/li>
&lt;li>[Dataflow Streaming] Enable Windmill GetWork Response Batching by default (&lt;a href="https://github.com/apache/beam/pull/33847">#33847&lt;/a>).
&lt;ul>
&lt;li>With this change user workers will request batched GetWork responses from backend and backend will send multiple WorkItems in the same response proto.&lt;/li>
&lt;li>The feature can be disabled by passing &lt;code>--windmillRequestBatchedGetWorkResponse=false&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="breaking-changes">Breaking Changes&lt;/h2>
&lt;ul>
&lt;li>AWS V1 I/Os have been removed (Java). As part of this, x-lang Python Kinesis I/O has been updated to consume the V2 IO and it also no longer supports setting producer_properties (&lt;a href="https://github.com/apache/beam/issues/33430">#33430&lt;/a>).&lt;/li>
&lt;li>Upgraded to protobuf 4 (Java) (&lt;a href="https://github.com/apache/beam/issues/33192">#33192&lt;/a>), but forced Debezium IO to use protobuf 3 (&lt;a href="https://github.com/apache/beam/issues/33541">#33541&lt;/a> because Debezium clients are not protobuf 4 compatible. This may cause conflicts when using clients which are only compatible with protobuf 4.&lt;/li>
&lt;li>Minimum Go version for Beam Go updated to 1.22.10 (&lt;a href="https://github.com/apache/beam/pull/33609">#33609&lt;/a>)&lt;/li>
&lt;/ul>
&lt;h2 id="bugfixes">Bugfixes&lt;/h2>
&lt;ul>
&lt;li>Fix data loss issues when reading gzipped files with TextIO (Python) (&lt;a href="https://github.com/apache/beam/issues/18390">#18390&lt;/a>, &lt;a href="https://github.com/apache/beam/issues/31040">#31040&lt;/a>).&lt;/li>
&lt;li>[BigQueryIO] Fixed an issue where Storage Write API sometimes doesn&amp;rsquo;t pick up auto-schema updates (&lt;a href="https://github.com/apache/beam/pull/33231">#33231&lt;/a>)&lt;/li>
&lt;li>Prism
&lt;ul>
&lt;li>Fixed an edge case where Bundle Finalization might not become enabled. (&lt;a href="https://github.com/apache/beam/issues/33493">#33493&lt;/a>).&lt;/li>
&lt;li>Fixed session window aggregation, which wasn&amp;rsquo;t being performed per-key. (&lt;a href="https://github.com/apache/beam/issues/33542">#33542&lt;/a>).)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>[Dataflow Streaming Appliance] Fixed commits failing with KeyCommitTooLargeException when a key outputs &amp;gt;180MB of results. &lt;a href="https://github.com/apache/beam/issues/33588">#33588&lt;/a>.&lt;/li>
&lt;li>Fixed a Dataflow template creation issue that ignores template file creation errors (Java) (&lt;a href="https://github.com/apache/beam/issues/33636">#33636&lt;/a>)&lt;/li>
&lt;li>Correctly documented Pane Encodings in the portability protocols (&lt;a href="https://github.com/apache/beam/issues/33840">#33840&lt;/a>).&lt;/li>
&lt;li>Fixed the user mailing list address (&lt;a href="https://github.com/apache/beam/issues/26013">#26013&lt;/a>).&lt;/li>
&lt;li>[Dataflow Streaming] Fixed an issue where Dataflow Streaming workers were reporting lineage metrics as cumulative rather than delta. (&lt;a href="https://github.com/apache/beam/pull/33691">#33691&lt;/a>)&lt;/li>
&lt;/ul>
&lt;h2 id="known-issues">Known Issues&lt;/h2>
&lt;ul>
&lt;li>(Java) Current version of protobuf has a &lt;a href="https://github.com/protocolbuffers/protobuf/issues/20599">bug&lt;/a> leading to incompatibilities with clients using older versions of Protobuf (&lt;a href="https://github.com/GoogleCloudPlatform/DataflowTemplates/issues/2191">example issue&lt;/a>). This issue has been seen in SpannerIO in particular. Tracked in &lt;a href="https://github.com/GoogleCloudPlatform/DataflowTemplates/issues/34452">#34452&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="list-of-contributors">List of Contributors&lt;/h2>
&lt;p>According to git shortlog, the following people contributed to the 2.63.0 release. Thank you to all contributors!&lt;/p>
&lt;p>Ahmed Abualsaud,
Alex Merose,
Andrej Galad,
Andrew Crites,
Arun Pandian,
Bartosz Zablocki,
Chamikara Jayalath,
Claire McGinty,
Clay Johnson,
Damon Douglas,
Danish Amjad,
Danny McCormick,
Deep1998,
Derrick Williams,
Dmitry Labutin,
Dmytro Sadovnychyi,
Eduardo Ramírez,
Filipe Regadas,
Hai Joey Tran,
Jack McCluskey,
Jan Lukavský,
Jeff Kinard,
Jozef Vilcek,
Julien Tournay,
Kenneth Knowles,
Michel Davit,
Miguel Trigueira,
Minbo Bae,
Mohamed Awnallah,
Mohit Paddhariya,
Nahian-Al Hasan,
Naireen Hussain,
Niall Pemberton,
Radosław Stankiewicz,
Razvan Culea,
Robert Bradshaw,
Robert Burke,
Rohit Sinha,
S. Veyrié,
Sam Whittle,
Sergei Lilichenko,
Shingo Furuyama,
Shunping Huang,
Thiago Nunes,
Tim Heckman,
Tobias Bredow,
Tom Stepp,
Tony Tang,
VISHESH TRIPATHI,
Vitaly Terentyev,
Yi Hu,
XQ Hu,
akashorabek,
claudevdm&lt;/p></description><link>/blog/beam-2.63.0/</link><pubDate>Tue, 18 Feb 2025 10:30:00 -0500</pubDate><guid>/blog/beam-2.63.0/</guid><category>blog</category><category>release</category></item></channel></rss>