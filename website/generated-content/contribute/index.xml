<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Apache Beam – Beam Contribution Guide</title><link>/contribute/</link><description>Recent content in Beam Contribution Guide on Apache Beam</description><generator>Hugo -- gohugo.io</generator><atom:link href="/contribute/index.xml" rel="self" type="application/rss+xml"/><item><title>Contribute: Beam Committer Guide</title><link>/contribute/committer-guide/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/contribute/committer-guide/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="committer-guide">Committer Guide&lt;/h1>
&lt;p>This guide is for
&lt;a href="https://www.apache.org/foundation/how-it-works.html#committers">committers&lt;/a>
and covers Beam&amp;rsquo;s guidelines for reviewing and merging code.&lt;/p>
&lt;h2 id="pull-request-review-objectives">Pull request review objectives&lt;/h2>
&lt;p>The review process aims for:&lt;/p>
&lt;ul>
&lt;li>Review iterations should be efficient, timely and of quality (avoid tiny or out-of-context changes or huge mega-changes)&lt;/li>
&lt;li>Support efficiency of authoring (don&amp;rsquo;t want to wait on a review for a tiny bit because GitHub makes it very hard to stack up reviews in sequence / don&amp;rsquo;t want to have major changes blocked because of difficulty of review)&lt;/li>
&lt;li>Ease of first-time contribution (encourage to follow &lt;a href="/contribute/#contributing-code">contribution guildelines&lt;/a>
but committer may absorb some extra effort for new contributors)&lt;/li>
&lt;li>Pull requests and commit messages establish a clear history with purpose and origin of changes&lt;/li>
&lt;li>Ability to perform a granular rollback, if necessary (also see &lt;a href="/contribute/postcommits-policies/">policies&lt;/a>)&lt;/li>
&lt;/ul>
&lt;p>Granularity of changes:&lt;/p>
&lt;ul>
&lt;li>We prefer small independent, incremental PRs with descriptive, isolated commits. Each commit is a single clear change&lt;/li>
&lt;li>It is OK to keep separate commits for different logical pieces of the code, if they make reviewing and revisiting code easier&lt;/li>
&lt;li>Making commits isolated is a good practice, authors should be able to relatively easily split the PR upon reviewer&amp;rsquo;s request&lt;/li>
&lt;li>Generally, every commit should compile and pass tests.&lt;/li>
&lt;li>Avoid keeping in history formatting messages such as checkstyle or spotless fixes. Squash such commits with previous one.&lt;/li>
&lt;/ul>
&lt;h2 id="always-get-to-lgtm-looks-good-to-me">Always get to LGTM (&amp;ldquo;Looks good to me!&amp;quot;)&lt;/h2>
&lt;p>After a pull request goes through rounds of reviews and revisions, it will
become ready for merge. A reviewer signals their approval either
by GitHub &amp;ldquo;approval&amp;rdquo; or by a comment such as &amp;ldquo;Looks good to me!&amp;rdquo; (LGTM).&lt;/p>
&lt;ul>
&lt;li>If the author of the pull request is not a committer, a committer must be
the one to approve the change.&lt;/li>
&lt;li>If the author of the pull request is a committer, approval from their chosen
reviewer is enough. A committer is trusted to choose an appropriate
reviewer, even if the reviewer is not a committer.&lt;/li>
&lt;/ul>
&lt;p>Once a pull request is approved, any committer can merge it.&lt;/p>
&lt;p>Exceptions to this rule are rare and made on a case-by-case basis. A committer
may use their discretion for situations such as build breaks. In this case, you
should still seek a review on the pull request! A common acronym you may see
is &amp;ldquo;TBR&amp;rdquo; &amp;ndash; &amp;ldquo;to be reviewed&amp;rdquo;.&lt;/p>
&lt;p>&lt;strong>Always go through a pull request, even if you won’t wait for the code
review.&lt;/strong> Committers should never commit anything without going through a pull
request, even when it is an urgent fix or rollback due to build breakage.
Skipping pull request bypasses test coverage and could potentially cause the
build to fail, or fail to fix breakage. In addition, pull requests ensure that
changes are communicated properly and potential flaws or improvements can be
spotted, even after the merge happens.&lt;/p>
&lt;h2 id="contributor-license-agreement">Contributor License Agreement&lt;/h2>
&lt;p>If you are merging a larger contribution, please make sure that the contributor
has an ICLA on file with the Apache Secretary. You can view the list of
committers &lt;a href="https://home.apache.org/phonebook.html?unix=committers">here&lt;/a>, as
well as &lt;a href="http://home.apache.org/unlistedclas.html">ICLA-signers who aren’t yet
committers&lt;/a>.&lt;/p>
&lt;p>For smaller contributions, however, this is not required. In this case, we rely
on &lt;a href="https://www.apache.org/licenses/LICENSE-2.0#contributions">clause five&lt;/a> of
the Apache License, Version 2.0, describing licensing of intentionally
submitted contributions.&lt;/p>
&lt;h2 id="tests">Tests&lt;/h2>
&lt;p>Before merging, please make sure that Jenkins tests pass, as visible in the
GitHub pull request. Do not merge the pull request if there are test failures.&lt;/p>
&lt;p>If the pull request contains changes that call for extra test coverage, you can
ask Jenkins to run an extended test suite. For example, if the pull request
modifies a runner, you can run the full &lt;code>ValidatesRunner&lt;/code> suite with a comment
such as &amp;ldquo;Run Spark ValidatesRunner&amp;rdquo;. You can run the examples and some IO
integration tests with &amp;ldquo;Run Java PostCommit&amp;rdquo;.&lt;/p>
&lt;h2 id="finishing-touches">Finishing touches&lt;/h2>
&lt;p>At some point in the review process, the change to the codebase will be
complete. However, the pull request may have a collection of review-related
commits that are not meaningful to preserve in the history. The reviewer should
give the LGTM and then request that the author of the pull request rebase,
squash, split, etc, the commits, so that the history is most useful:&lt;/p>
&lt;ul>
&lt;li>Favor commits that do just one thing. The commit is the smallest unit of easy
rollback; it is easy to roll back many commits, or a whole pull request, but
harder to roll back part of a commit.&lt;/li>
&lt;li>Commit messages should tag JIRAs and be otherwise descriptive.
It should later not be necessary to find a merge or first PR commit to find out what caused a change.&lt;/li>
&lt;li>&lt;code>CHANGES.md&lt;/code> file should be updated with noteworthy changes (e.g. new features, backward
incompatible changes, dependency changes, etc.).&lt;/li>
&lt;li>Squash the &amp;ldquo;Fixup!&amp;quot;, &amp;ldquo;Address comments&amp;rdquo; type of commits that resulted from review iterations.&lt;/li>
&lt;/ul>
&lt;h2 id="merging-it">Merging it!&lt;/h2>
&lt;p>While it is preferred that authors squash commits after review is complete,
there may be situations where it is more practical for the committer to handle this
(such as when the action to be taken is obvious or the author isn&amp;rsquo;t available).
The committer may use the &amp;ldquo;Squash and merge&amp;rdquo; option in Github (or modify the PR commits in other ways).
The committer is ultimately responsible and we &amp;ldquo;trust the committer&amp;rsquo;s judgment&amp;rdquo;!&lt;/p>
&lt;p>After all the tests pass, there should be a green merge button at the bottom of
the pull request. There are multiple choices. Unless you want to squash commits
as part of the merge (see above) you should choose &amp;ldquo;Merge pull
request&amp;rdquo; and ensure &amp;ldquo;Create a merge commit&amp;rdquo; is selected from the drop down.
This preserves the commit history and adds a merge
commit, so be sure the commit history has been curated appropriately.&lt;/p>
&lt;p>Do &lt;em>not&lt;/em> use the default GitHub commit message, which looks like this:&lt;/p>
&lt;pre>&lt;code>Merge pull request #1234 from some_user/transient_branch_name
[BEAM-7873] Fix the foo bizzle bazzle
&lt;/code>&lt;/pre>
&lt;p>Instead, pull it all into the subject line:&lt;/p>
&lt;pre>&lt;code>Merge pull request #1234: [BEAM-7873] Fix the foo bizzle bazzle
&lt;/code>&lt;/pre>
&lt;p>If you have comments to add, put them in the body of the commit message.&lt;/p></description></item><item><title>Contribute: Beam Design Documents</title><link>/contribute/design-documents/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/contribute/design-documents/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;!--
This page will be redirected to https://cwiki.apache.org/confluence/display/BEAM/Design+Documents
--></description></item><item><title>Contribute: Beam Feature Branches</title><link>/contribute/feature-branches/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/contribute/feature-branches/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="feature-branches">Feature Branches&lt;/h1>
&lt;p>Some larger features are developed on a feature branch before being merged into
&lt;code>master&lt;/code>. In particular, this is often used for initial development of new
components like SDKs or runners.&lt;/p>
&lt;p>We expect the work on a feature branch to be &lt;em>incomplete&lt;/em>, but it must not
be lower quality. Code reviews for feature branches must have the same
standards as code reviews for &lt;code>master&lt;/code>. Once a feature branch is ready for
merge to &lt;code>master&lt;/code>, the set of changes will be too large to review in its
entirety. Because of this, the code reviews during development must be
thorough and trustworthy.&lt;/p>
&lt;h2 id="establishing-a-feature-branch">Establishing a feature branch&lt;/h2>
&lt;p>If your project is large enough to need a feature branch, there should
be a discussion on the mailing list. The first step is to &lt;a href="/contribute/#connect-with-the-beam-community">engage&lt;/a> there to raise awareness
that you want to start a large project. Almost any project should be accepted
&amp;ndash; there is no real cost to letting a feature branch exist &amp;ndash; but you may find
other interested contributors or gain other advice from the community.&lt;/p>
&lt;p>After the community discussion, a committer must create your feature branch.
Any committer can do create the branch through the GitHub UIs or by pushing
directly to GitHub or ASF&amp;rsquo;s gitbox.&lt;/p>
&lt;h2 id="developing-on-a-feature-branch">Developing on a feature branch&lt;/h2>
&lt;p>To contribute code on a feature branch, use the same process as in the
&lt;a href="/contribute/contribution-guide/">Contribution Guide&lt;/a>, but
replace &lt;code>master&lt;/code> with the name of the feature branch.&lt;/p>
&lt;p>Since feature branches are often used for new components, you may find that
there is no committer familiar with all the details of the new language or
runner. In that case, consider asking someone else familiar with the technology
to do an initial review before looping in a committer for a final review and
merge.&lt;/p>
&lt;p>If you are working on a feature branch, you&amp;rsquo;ll also want to frequently merge in
changes from &lt;code>master&lt;/code>. This prevents the feature branch from
deviating too far from the current state of &lt;code>master&lt;/code>. Like all changes, this
should be done via pull request. A committer may self-merge such a pull request
if there are no conflicts or test failures. If there are any conflicts or tests
that need fixing, then those should get a full review from another committer.&lt;/p>
&lt;h2 id="merging-into-master">Merging into &lt;code>master&lt;/code>&lt;/h2>
&lt;p>To merge a feature branch into &lt;code>master&lt;/code>, new components and major features
should meet the following guidelines.&lt;/p>
&lt;ol>
&lt;li>Have at least 2 contributors interested in maintaining it, and 1 committer
interested in supporting it&lt;/li>
&lt;li>Provide both end-user and developer-facing documentation&lt;/li>
&lt;li>Have at least a basic level of unit test coverage&lt;/li>
&lt;li>Run all existing applicable integration tests with other Beam components and
create additional tests as appropriate&lt;/li>
&lt;/ol>
&lt;h3 id="merging-a-new-runner-into-master">Merging a new runner into &lt;code>master&lt;/code>&lt;/h3>
&lt;p>A new runner should:&lt;/p>
&lt;ol>
&lt;li>Be able to handle a subset of the model that addresses a significant set of
use cases, such as ‘traditional batch’ or ‘processing time streaming’.&lt;/li>
&lt;li>Update the capability matrix with the current status&lt;/li>
&lt;li>Add a webpage under &lt;code>documentation/runners&lt;/code>&lt;/li>
&lt;/ol>
&lt;h3 id="merging-a-new-sdk-into-master">Merging a new SDK into &lt;code>master&lt;/code>&lt;/h3>
&lt;p>A new SDK should:&lt;/p>
&lt;ol>
&lt;li>Provide the ability to construct graphs with all the basic building blocks
of the model (ParDo, GroupByKey, Window, Trigger, etc)&lt;/li>
&lt;li>Begin fleshing out the common composite transforms (Count, Join, etc) and I/O
connectors (Text, Kafka, etc)&lt;/li>
&lt;li>Have at least one runner that can execute the complete model (may be a
direct runner)&lt;/li>
&lt;li>Provide integration tests for executing against current and future runners&lt;/li>
&lt;li>Add a webpage under &lt;code>documentation/sdks&lt;/code>&lt;/li>
&lt;/ol></description></item><item><title>Contribute: Beam Release Guide</title><link>/contribute/release-guide/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/contribute/release-guide/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="apache-beam-release-guide">Apache Beam Release Guide&lt;/h1>
&lt;nav id="TableOfContents">
&lt;ul>
&lt;li>&lt;a href="#introduction">Introduction&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#overview">Overview&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#1-decide-to-release">1. Decide to release&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#checklist-to-proceed-to-the-next-step">Checklist to proceed to the next step&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#2-prepare-for-the-release">2. Prepare for the release&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#accounts">Accounts&lt;/a>&lt;/li>
&lt;li>&lt;a href="#one-time-setup-instructions">One-time setup instructions&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#gpg-key">GPG Key&lt;/a>&lt;/li>
&lt;li>&lt;a href="#access-to-apache-nexus-repository">Access to Apache Nexus repository&lt;/a>&lt;/li>
&lt;li>&lt;a href="#submit-your-gpg-public-key-into-mit-pgp-public-key-server">Submit your GPG public key into MIT PGP Public Key Server&lt;/a>&lt;/li>
&lt;li>&lt;a href="#website-development-setup">Website development setup&lt;/a>&lt;/li>
&lt;li>&lt;a href="#register-to-pypi">Register to PyPI&lt;/a>&lt;/li>
&lt;li>&lt;a href="#login-to-dockerhub">Login to DockerHub&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#create-a-new-version-in-jira">Create a new version in JIRA&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#3-investigate-performance-regressions">3. Investigate performance regressions&lt;/a>&lt;/li>
&lt;li>&lt;a href="#4-create-a-release-branch-in-apachebeam-repository">4. Create a release branch in apache/beam repository&lt;/a>
&lt;ul>
&lt;li>
&lt;ul>
&lt;li>&lt;a href="#use-cut_release_branchsh-to-cut-a-release-branch">Use cut_release_branch.sh to cut a release branch&lt;/a>&lt;/li>
&lt;li>&lt;a href="#alternative-run-all-steps-manually">(Alternative) Run all steps manually&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#start-a-snapshot-build">Start a snapshot build&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#run-start_snapshot_buildsh-to-trigger-build">Run start_snapshot_build.sh to trigger build&lt;/a>&lt;/li>
&lt;li>&lt;a href="#alternative-do-all-operations-manually">(Alternative) Do all operations manually&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#5-verify-release-branch">5. Verify release branch&lt;/a>
&lt;ul>
&lt;li>
&lt;ul>
&lt;li>&lt;a href="#run-automation-script-verify_release_buildsh">Run automation script (verify_release_build.sh)&lt;/a>&lt;/li>
&lt;li>&lt;a href="#verify-the-build-succeeds">Verify the build succeeds&lt;/a>&lt;/li>
&lt;li>&lt;a href="#alternative-run-release-build-manually-locally">(Alternative) Run release build manually (locally)&lt;/a>&lt;/li>
&lt;li>&lt;a href="#create-release-blocking-issues-in-jira">Create release-blocking issues in JIRA&lt;/a>&lt;/li>
&lt;li>&lt;a href="#inform-the-mailing-list">Inform the mailing list&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#6-triage-release-blocking-issues-in-jira">6. Triage release-blocking issues in JIRA&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#review-cherry-picks">Review cherry-picks&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#7-build-a-release-candidate">7. Build a release candidate&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#checklist-before-proceeding">Checklist before proceeding&lt;/a>&lt;/li>
&lt;li>&lt;a href="#run-build_release_candidatesh-to-create-a-release-candidate">Run build_release_candidate.sh to create a release candidate&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#tasks-you-need-to-do-manually">Tasks you need to do manually&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#8-prepare-documents">8. Prepare documents&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#update-and-verify-javadoc">Update and Verify Javadoc&lt;/a>&lt;/li>
&lt;li>&lt;a href="#build-the-pydoc-api-reference">Build the Pydoc API reference&lt;/a>&lt;/li>
&lt;li>&lt;a href="#propose-pull-requests-for-website-updates">Propose pull requests for website updates&lt;/a>&lt;/li>
&lt;li>&lt;a href="#blog-post">Blog post&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#checklist-to-proceed-to-the-next-step-1">Checklist to proceed to the next step&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#9-vote-and-validate-release-candidate">9. Vote and validate release candidate&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#run-validation-tests">Run validation tests&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#run-validations-using-run_rc_validationsh">Run validations using run_rc_validation.sh&lt;/a>&lt;/li>
&lt;li>&lt;a href="#run-validations-manually">Run validations manually&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#fix-any-issues">Fix any issues&lt;/a>&lt;/li>
&lt;li>&lt;a href="#checklist-to-proceed-to-the-next-step-2">Checklist to proceed to the next step&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#10-finalize-the-release">10. Finalize the release&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#deploy-artifacts-to-maven-central-repository">Deploy artifacts to Maven Central Repository&lt;/a>&lt;/li>
&lt;li>&lt;a href="#deploy-python-artifacts-to-pypi">Deploy Python artifacts to PyPI&lt;/a>&lt;/li>
&lt;li>&lt;a href="#deploy-sdk-docker-images-to-dockerhub">Deploy SDK docker images to DockerHub&lt;/a>&lt;/li>
&lt;li>&lt;a href="#merge-website-pull-requests">Merge Website pull requests&lt;/a>&lt;/li>
&lt;li>&lt;a href="#git-tag">Git tag&lt;/a>&lt;/li>
&lt;li>&lt;a href="#pmc-only-finalization">PMC-Only Finalization&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#deploy-source-release-to-distapacheorg">Deploy source release to dist.apache.org&lt;/a>&lt;/li>
&lt;li>&lt;a href="#mark-the-version-as-released-in-jira">Mark the version as released in JIRA&lt;/a>&lt;/li>
&lt;li>&lt;a href="#recordkeeping-with-asf">Recordkeeping with ASF&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#checklist-to-proceed-to-the-next-step-3">Checklist to proceed to the next step&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#11-promote-the-release">11. Promote the release&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#apache-mailing-lists">Apache mailing lists&lt;/a>&lt;/li>
&lt;li>&lt;a href="#social-media">Social media&lt;/a>&lt;/li>
&lt;li>&lt;a href="#checklist-to-declare-the-process-completed">Checklist to declare the process completed&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#improve-the-process">Improve the process&lt;/a>&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>The Apache Beam project periodically declares and publishes releases. A release is one or more packages of the project artifact(s) that are approved for general public distribution and use. They may come with various degrees of caveat regarding their perceived quality and potential for change, such as “alpha”, “beta”, “incubating”, “stable”, etc.&lt;/p>
&lt;p>The Beam community treats releases with great importance. They are a public face of the project and most users interact with the project only through the releases. Releases are signed off by the entire Beam community in a public vote.&lt;/p>
&lt;p>Each release is executed by a &lt;em>Release Manager&lt;/em>, who is selected among the Beam committers. This document describes the process that the Release Manager follows to perform a release. Any changes to this process should be discussed and adopted on the &lt;a href="/get-started/support/">dev@ mailing list&lt;/a>.&lt;/p>
&lt;p>Please remember that publishing software has legal consequences. This guide complements the foundation-wide &lt;a href="http://www.apache.org/dev/release.html">Product Release Policy&lt;/a> and &lt;a href="http://www.apache.org/dev/release-distribution">Release Distribution Policy&lt;/a>.&lt;/p>
&lt;h3 id="overview">Overview&lt;/h3>
&lt;img src="/images/release-guide-1.png" alt="Alt text" width="100%">
&lt;p>The release process consists of several steps:&lt;/p>
&lt;ol>
&lt;li>Decide to release&lt;/li>
&lt;li>Prepare for the release&lt;/li>
&lt;li>Investigate performance regressions&lt;/li>
&lt;li>Create a release branch&lt;/li>
&lt;li>Verify release branch&lt;/li>
&lt;li>Build a release candidate&lt;/li>
&lt;li>Vote on the release candidate&lt;/li>
&lt;li>During vote process, run validation tests&lt;/li>
&lt;li>If necessary, fix any issues and go back to step 3.&lt;/li>
&lt;li>Finalize the release&lt;/li>
&lt;li>Promote the release&lt;/li>
&lt;/ol>
&lt;h2 id="1-decide-to-release">1. Decide to release&lt;/h2>
&lt;p>Deciding to release and selecting a Release Manager is the first step of the release process. This is a consensus-based decision of the entire community.&lt;/p>
&lt;p>Anybody can propose a release on the dev@ mailing list, giving a solid argument and nominating a committer as the Release Manager (including themselves). There’s no formal process, no vote requirements, and no timing requirements. Any objections should be resolved by consensus before starting the release.&lt;/p>
&lt;p>In general, the community prefers to have a rotating set of 3-5 Release Managers. Keeping a small core set of managers allows enough people to build expertise in this area and improve processes over time, without Release Managers needing to re-learn the processes for each release. That said, if you are a committer interested in serving the community in this way, please reach out to the community on the dev@ mailing list.&lt;/p>
&lt;h3 id="checklist-to-proceed-to-the-next-step">Checklist to proceed to the next step&lt;/h3>
&lt;ol>
&lt;li>Community agrees to release&lt;/li>
&lt;li>Community selects a Release Manager&lt;/li>
&lt;/ol>
&lt;hr>
&lt;h2 id="2-prepare-for-the-release">2. Prepare for the release&lt;/h2>
&lt;p>Before your first release, you should perform one-time configuration steps. This will set up your security keys for signing the release and access to various release repositories.&lt;/p>
&lt;p>To prepare for each release, you should audit the project status in the JIRA issue tracker, and do necessary bookkeeping. Finally, you should create a release branch from which individual release candidates will be built.&lt;/p>
&lt;p>&lt;strong>NOTE&lt;/strong>: If you are using &lt;a href="https://help.github.com/articles/securing-your-account-with-two-factor-authentication-2fa/">GitHub two-factor authentication&lt;/a> and haven&amp;rsquo;t configure HTTPS access,
please follow &lt;a href="https://help.github.com/articles/creating-a-personal-access-token-for-the-command-line/">the guide&lt;/a> to configure command line access.&lt;/p>
&lt;h3 id="accounts">Accounts&lt;/h3>
&lt;p>Please have these credentials ready at hand, you will likely need to enter them multiple times:&lt;/p>
&lt;ul>
&lt;li>GPG pass phrase (see the next section);&lt;/li>
&lt;li>Apache ID and Password;&lt;/li>
&lt;li>GitHub ID and Password.&lt;/li>
&lt;li>DockerHub ID and Password. (You should be a member of maintainer team; email at dev@ if you are not.)&lt;/li>
&lt;/ul>
&lt;h3 id="one-time-setup-instructions">One-time setup instructions&lt;/h3>
&lt;h4 id="gpg-key">GPG Key&lt;/h4>
&lt;p>You need to have a GPG key to sign the release artifacts. Please be aware of the ASF-wide &lt;a href="https://www.apache.org/dev/release-signing.html">release signing guidelines&lt;/a>. If you don’t have a GPG key associated with your Apache account, please create one according to the guidelines.&lt;/p>
&lt;p>There are 2 ways to configure your GPG key for release, either using release automation script(which is recommended),
or running all commands manually.&lt;/p>
&lt;h5 id="use-preparation_before_releasesh-to-setup-gpg">Use preparation_before_release.sh to setup GPG&lt;/h5>
&lt;ul>
&lt;li>
&lt;p>Script: &lt;a href="https://github.com/apache/beam/blob/master/release/src/main/scripts/preparation_before_release.sh">preparation_before_release.sh&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Usage&lt;/p>
&lt;pre>&lt;code>./beam/release/src/main/scripts/preparation_before_release.sh
&lt;/code>&lt;/pre>&lt;/li>
&lt;li>
&lt;p>Tasks included&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Help you create a new GPG key if you want.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Configure &lt;code>git user.signingkey&lt;/code> with chosen pubkey.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Add chosen pubkey into &lt;a href="https://dist.apache.org/repos/dist/dev/beam/KEYS">dev KEYS&lt;/a> and &lt;a href="https://dist.apache.org/repos/dist/release/beam/KEYS">release KEYS&lt;/a>&lt;/p>
&lt;p>&lt;strong>NOTES&lt;/strong>: Only PMC can write into &lt;a href="https://dist.apache.org/repos/dist/release/beam/">release repo&lt;/a>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Start GPG agents.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>NOTE&lt;/strong>: When generating the key, please make sure you choose the key type as &lt;strong>RSA and RSA (default)&lt;/strong> and key size as &lt;strong>4096 bit&lt;/strong>.&lt;/p>
&lt;h5 id="run-all-commands-manually">Run all commands manually&lt;/h5>
&lt;ul>
&lt;li>
&lt;p>Get more entropy for creating a GPG key&lt;/p>
&lt;pre>&lt;code>sudo apt-get install rng-tools
sudo rngd -r /dev/urandom
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>Create a GPG key&lt;/p>
&lt;pre>&lt;code>gpg --full-generate-key
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>Determine your Apache GPG Key and Key ID, as follows:&lt;/p>
&lt;pre>&lt;code>gpg --list-sigs --keyid-format LONG
&lt;/code>&lt;/pre>
&lt;p>This will list your GPG keys. One of these should reflect your Apache account, for example:&lt;/p>
&lt;pre>&lt;code>--------------------------------------------------
pub 2048R/845E6689 2016-02-23
uid Nomen Nescio &amp;lt;anonymous@apache.org&amp;gt;
sub 2048R/BA4D50BE 2016-02-23
&lt;/code>&lt;/pre>
&lt;p>Here, the key ID is the 8-digit hex string in the &lt;code>pub&lt;/code> line: &lt;code>845E6689&lt;/code>.&lt;/p>
&lt;p>Now, add your Apache GPG key to the Beam’s &lt;code>KEYS&lt;/code> file both in &lt;a href="https://dist.apache.org/repos/dist/dev/beam/KEYS">&lt;code>dev&lt;/code>&lt;/a> and &lt;a href="https://dist.apache.org/repos/dist/release/beam/KEYS">&lt;code>release&lt;/code>&lt;/a> repositories at &lt;code>dist.apache.org&lt;/code>. Follow the instructions listed at the top of these files. (Note: Only PMC members have write access to the release repository. If you end up getting 403 errors ask on the mailing list for assistance.)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Configure &lt;code>git&lt;/code> to use this key when signing code by giving it your key ID, as follows:&lt;/p>
&lt;pre>&lt;code>git config --global user.signingkey 845E6689
&lt;/code>&lt;/pre>
&lt;p>You may drop the &lt;code>--global&lt;/code> option if you’d prefer to use this key for the current repository only.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Start GPG agent in order to unlock your GPG key&lt;/p>
&lt;pre>&lt;code>eval $(gpg-agent --daemon --no-grab --write-env-file $HOME/.gpg-agent-info)
export GPG_TTY=$(tty)
export GPG_AGENT_INFO
&lt;/code>&lt;/pre>
&lt;/li>
&lt;/ul>
&lt;h4 id="access-to-apache-nexus-repository">Access to Apache Nexus repository&lt;/h4>
&lt;p>Configure access to the &lt;a href="https://repository.apache.org/">Apache Nexus repository&lt;/a>, which enables final deployment of releases to the Maven Central Repository.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>You log in with your Apache account.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Confirm you have appropriate access by finding &lt;code>org.apache.beam&lt;/code> under &lt;code>Staging Profiles&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Navigate to your &lt;code>Profile&lt;/code> (top right dropdown menu of the page).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Choose &lt;code>User Token&lt;/code> from the dropdown, then click &lt;code>Access User Token&lt;/code>. Copy a snippet of the Maven XML configuration block.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Insert this snippet twice into your global Maven &lt;code>settings.xml&lt;/code> file, typically &lt;code>${HOME}/.m2/settings.xml&lt;/code>. The end result should look like this, where &lt;code>TOKEN_NAME&lt;/code> and &lt;code>TOKEN_PASSWORD&lt;/code> are your secret tokens:&lt;/p>
&lt;pre>&lt;code> &amp;lt;!-- make sure you have the root `settings node: --&amp;gt;
&amp;lt;settings&amp;gt;
&amp;lt;servers&amp;gt;
&amp;lt;server&amp;gt;
&amp;lt;id&amp;gt;apache.releases.https&amp;lt;/id&amp;gt;
&amp;lt;username&amp;gt;TOKEN_NAME&amp;lt;/username&amp;gt;
&amp;lt;password&amp;gt;TOKEN_PASSWORD&amp;lt;/password&amp;gt;
&amp;lt;/server&amp;gt;
&amp;lt;server&amp;gt;
&amp;lt;id&amp;gt;apache.snapshots.https&amp;lt;/id&amp;gt;
&amp;lt;username&amp;gt;TOKEN_NAME&amp;lt;/username&amp;gt;
&amp;lt;password&amp;gt;TOKEN_PASSWORD&amp;lt;/password&amp;gt;
&amp;lt;/server&amp;gt;
&amp;lt;/servers&amp;gt;
&amp;lt;/settings&amp;gt;
&lt;/code>&lt;/pre>
&lt;/li>
&lt;/ol>
&lt;h4 id="submit-your-gpg-public-key-into-mit-pgp-public-key-server">Submit your GPG public key into MIT PGP Public Key Server&lt;/h4>
&lt;p>In order to make yourself have right permission to stage java artifacts in Apache Nexus staging repository,
please submit your GPG public key into &lt;a href="http://pgp.mit.edu:11371/">MIT PGP Public Key Server&lt;/a>.&lt;/p>
&lt;p>If MIT doesn&amp;rsquo;t work for you (it probably won&amp;rsquo;t, it&amp;rsquo;s slow, returns 502 a lot, Nexus might error out not being able to find the keys),
use a keyserver at &lt;code>ubuntu.com&lt;/code> instead: &lt;a href="https://keyserver.ubuntu.com/">https://keyserver.ubuntu.com/&lt;/a>.&lt;/p>
&lt;h4 id="website-development-setup">Website development setup&lt;/h4>
&lt;p>Updating the Beam website requires submitting PRs to both the main &lt;code>apache/beam&lt;/code>
repo and the &lt;code>apache/beam-site&lt;/code> repo. The first contains reference manuals
generated from SDK code, while the second updates the current release version
number.&lt;/p>
&lt;p>You should already have setup a local clone of &lt;code>apache/beam&lt;/code>. Setting up a clone
of &lt;code>apache/beam-site&lt;/code> is similar:&lt;/p>
&lt;pre>&lt;code>$ git clone -b release-docs https://github.com/apache/beam-site.git
$ cd beam-site
$ git remote add &amp;lt;GitHub_user&amp;gt; git@github.com:&amp;lt;GitHub_user&amp;gt;/beam-site.git
$ git fetch --all
$ git checkout -b &amp;lt;my-branch&amp;gt; origin/release-docs
&lt;/code>&lt;/pre>
&lt;p>Further instructions on website development on &lt;code>apache/beam&lt;/code> is
&lt;a href="https://github.com/apache/beam/blob/master/website">here&lt;/a>. Background
information about how the website is updated can be found in &lt;a href="https://s.apache.org/beam-site-automation">Beam-Site
Automation Reliability&lt;/a>.&lt;/p>
&lt;h4 id="register-to-pypi">Register to PyPI&lt;/h4>
&lt;p>Release manager needs to have an account with PyPI. If you need one, &lt;a href="https://pypi.python.org/account/register/">register at PyPI&lt;/a>. You also need to be a maintainer (or an owner) of the &lt;a href="https://pypi.python.org/pypi/apache-beam">apache-beam&lt;/a> package in order to push a new release. Ask on the mailing list for assistance.&lt;/p>
&lt;h4 id="login-to-dockerhub">Login to DockerHub&lt;/h4>
&lt;p>Run following command manually. It will ask you to input your DockerHub ID and password if
authorization info cannot be found from ~/.docker/config.json file.&lt;/p>
&lt;pre>&lt;code>docker login docker.io
&lt;/code>&lt;/pre>&lt;p>After successful login, authorization info will be stored at ~/.docker/config.json file. For example,&lt;/p>
&lt;pre>&lt;code>&amp;quot;https://index.docker.io/v1/&amp;quot;: {
&amp;quot;auth&amp;quot;: &amp;quot;xxxxxx&amp;quot;
}
&lt;/code>&lt;/pre>&lt;p>Release managers should have push permission; please ask for help at dev@.&lt;/p>
&lt;pre>&lt;code>From: Release Manager
To: dev@beam.apache.org
Subject: DockerHub Push Permission
Hi DockerHub Admins
I need push permission to proceed with release, can you please add me to maintainer team?
My docker hub ID is: xxx
Thanks,
Release Manager
&lt;/code>&lt;/pre>&lt;h3 id="create-a-new-version-in-jira">Create a new version in JIRA&lt;/h3>
&lt;p>When contributors resolve an issue in JIRA, they are tagging it with a release that will contain their changes. With the release currently underway, new issues should be resolved against a subsequent future release. Therefore, you should create a release item for this subsequent release, as follows:&lt;/p>
&lt;p>&lt;strong>Attention&lt;/strong>: Only PMC has permission to perform this. If you are not a PMC, please ask for help in dev@ mailing list.&lt;/p>
&lt;ol>
&lt;li>In JIRA, navigate to &lt;a href="https://issues.apache.org/jira/plugins/servlet/project-config/BEAM/versions">&lt;code>Beam &amp;gt; Administration &amp;gt; Versions&lt;/code>&lt;/a>.&lt;/li>
&lt;li>Add a new release. Choose the next minor version number after the version currently underway, select the release cut date (today’s date) as the &lt;code>Start Date&lt;/code>, and choose &lt;code>Add&lt;/code>.&lt;/li>
&lt;li>At the end of the release, go to the same page and mark the recently released version as released. Use the &lt;code>...&lt;/code> menu and choose &lt;code>Release&lt;/code>.&lt;/li>
&lt;/ol>
&lt;hr>
&lt;h2 id="3-investigate-performance-regressions">3. Investigate performance regressions&lt;/h2>
&lt;p>Check the Beam load tests for possible performance regressions. Measurements are available on &lt;a href="http://metrics.beam.apache.org">metrics.beam.apache.org&lt;/a>.&lt;/p>
&lt;p>All Runners which publish data should be checked for the following, in both &lt;em>batch&lt;/em> and &lt;em>streaming&lt;/em> mode:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="http://metrics.beam.apache.org/d/MOi-kf3Zk/pardo-load-tests">ParDo&lt;/a> and &lt;a href="http://metrics.beam.apache.org/d/UYZ-oJ3Zk/gbk-load-test">GBK&lt;/a>: Runtime, latency, checkpoint duration&lt;/li>
&lt;li>&lt;a href="http://metrics.beam.apache.org/d/ahuaA_zGz/nexmark">Nexmark&lt;/a>: Query runtime for all queries&lt;/li>
&lt;li>&lt;a href="http://metrics.beam.apache.org/d/bnlHKP3Wz/java-io-it-tests-dataflow">IO&lt;/a>: Runtime&lt;/li>
&lt;/ul>
&lt;p>If regressions are found, the release branch can still be created, but the regressions should be investigated and fixed as part of the release process.
The role of the release manager is to file JIRA issues for each regression with the &amp;lsquo;Fix Version&amp;rsquo; set to the to-be-released version. The release manager
oversees these just like any other JIRA issue marked with the &amp;lsquo;Fix Version&amp;rsquo; of the release.&lt;/p>
&lt;p>The mailing list should be informed to allow fixing the regressions in the course of the release.&lt;/p>
&lt;h2 id="4-create-a-release-branch-in-apachebeam-repository">4. Create a release branch in apache/beam repository&lt;/h2>
&lt;p>Attention: Only committer has permission to create release branch in apache/beam.&lt;/p>
&lt;p>Release candidates are built from a release branch. As a final step in preparation for the release, you should create the release branch, push it to the Apache code repository, and update version information on the original branch.&lt;/p>
&lt;p>There are 2 ways to cut a release branch: either running automation script(recommended), or running all commands manually.&lt;/p>
&lt;h4 id="use-cut_release_branchsh-to-cut-a-release-branch">Use cut_release_branch.sh to cut a release branch&lt;/h4>
&lt;ul>
&lt;li>
&lt;p>Script: &lt;a href="https://github.com/apache/beam/blob/master/release/src/main/scripts/cut_release_branch.sh">cut_release_branch.sh&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Usage&lt;/p>
&lt;pre>&lt;code># Cut a release branch
./beam/release/src/main/scripts/cut_release_branch.sh \
--release=${RELEASE_VERSION} \
--next_release=${NEXT_VERSION}
# Show help page
./beam/release/src/main/scripts/cut_release_branch.sh -h
&lt;/code>&lt;/pre>&lt;/li>
&lt;li>
&lt;p>The script will:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Create release-${RELEASE_VERSION} branch locally.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Change and commit dev versoin number in master branch:&lt;/p>
&lt;p>&lt;a href="https://github.com/apache/beam/blob/e8abafe360e126818fe80ae0f6075e71f0fc227d/buildSrc/src/main/groovy/org/apache/beam/gradle/BeamModulePlugin.groovy#L209">BeamModulePlugin.groovy&lt;/a>,
&lt;a href="https://github.com/apache/beam/blob/e8abafe360e126818fe80ae0f6075e71f0fc227d/gradle.properties#L25">gradle.properties&lt;/a>,
&lt;a href="https://github.com/apache/beam/blob/e8abafe360e126818fe80ae0f6075e71f0fc227d/sdks/python/apache_beam/version.py#L21">version.py&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Change and commit version number in release branch:&lt;/p>
&lt;p>&lt;a href="https://github.com/apache/beam/blob/release-2.6.0/sdks/python/apache_beam/version.py#L21">version.py&lt;/a>,
&lt;a href="https://github.com/apache/beam/blob/release-2.6.0/runners/google-cloud-dataflow-java/build.gradle#L39">build.gradle&lt;/a>,
&lt;a href="https://github.com/apache/beam/blob/release-2.16.0/gradle.properties#L27">gradle.properties&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;h4 id="alternative-run-all-steps-manually">(Alternative) Run all steps manually&lt;/h4>
&lt;ul>
&lt;li>
&lt;p>Checkout working branch&lt;/p>
&lt;p>Check out the version of the codebase from which you start the release. For a new minor or major release, this may be &lt;code>HEAD&lt;/code> of the &lt;code>master&lt;/code> branch. To build a hotfix/incremental release, instead of the &lt;code>master&lt;/code> branch, use the release tag of the release being patched. (Please make sure your cloned repository is up-to-date before starting.)&lt;/p>
&lt;pre>&lt;code>git checkout &amp;lt;master branch OR release tag&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>NOTE&lt;/strong>: If you are doing an incremental/hotfix release (e.g. 2.5.1), please check out the previous release tag, rather than the master branch.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Set up environment variables&lt;/p>
&lt;p>Set up a few environment variables to simplify Maven commands that follow. (We use &lt;code>bash&lt;/code> Unix syntax in this guide.)&lt;/p>
&lt;pre>&lt;code>RELEASE=2.5.0
NEXT_VERSION_IN_BASE_BRANCH=2.6.0
BRANCH=release-${RELEASE}
&lt;/code>&lt;/pre>
&lt;p>Version represents the release currently underway, while next version specifies the anticipated next version to be released from that branch. Normally, 1.2.0 is followed by 1.3.0, while 1.2.3 is followed by 1.2.4.&lt;/p>
&lt;p>&lt;strong>NOTE&lt;/strong>: Only if you are doing an incremental/hotfix release (e.g. 2.5.1), please check out the previous release tag, before running the following instructions:&lt;/p>
&lt;pre>&lt;code>BASE_RELEASE=2.5.0
RELEASE=2.5.1
NEXT_VERSION_IN_BASE_BRANCH=2.6.0
git checkout tags/${BASE_RELEASE}
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>Create release branch locally&lt;/p>
&lt;pre>&lt;code>git branch ${BRANCH}
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>Update version files in the master branch.&lt;/p>
&lt;pre>&lt;code># Now change the version in existing gradle files, and Python files
sed -i -e &amp;quot;s/'${RELEASE}'/'${NEXT_VERSION_IN_BASE_BRANCH}'/g&amp;quot; build_rules.gradle
sed -i -e &amp;quot;s/${RELEASE}/${NEXT_VERSION_IN_BASE_BRANCH}/g&amp;quot; gradle.properties
sed -i -e &amp;quot;s/${RELEASE}/${NEXT_VERSION_IN_BASE_BRANCH}/g&amp;quot; sdks/python/apache_beam/version.py
# Save changes in master branch
git add gradle.properties build_rules.gradle sdks/python/apache_beam/version.py
git commit -m &amp;quot;Moving to ${NEXT_VERSION_IN_BASE_BRANCH}-SNAPSHOT on master branch.&amp;quot;
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>Check out the release branch.&lt;/p>
&lt;pre>&lt;code>git checkout ${BRANCH}
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>Update version files in release branch&lt;/p>
&lt;pre>&lt;code>DEV=${RELEASE}.dev
sed -i -e &amp;quot;s/${DEV}/${RELEASE}/g&amp;quot; sdks/python/apache_beam/version.py
sed -i -e &amp;quot;s/${DEV}/${RELEASE}/g&amp;quot; gradle.properties
sed -i -e &amp;quot;s/'beam-master-.*'/'beam-${RELEASE}'/g&amp;quot; runners/google-cloud-dataflow-java/build.gradle
&lt;/code>&lt;/pre>
&lt;/li>
&lt;/ul>
&lt;h3 id="start-a-snapshot-build">Start a snapshot build&lt;/h3>
&lt;p>Start a build of &lt;a href="https://ci-beam.apache.org/job/beam_Release_NightlySnapshot/">the nightly snapshot&lt;/a> against master branch.
Some processes, including our archetype tests, rely on having a live SNAPSHOT of the current version
from the &lt;code>master&lt;/code> branch. Once the release branch is cut, these SNAPSHOT versions are no longer found,
so builds will be broken until a new snapshot is available.&lt;/p>
&lt;p>There are 2 ways to trigger a nightly build, either using automation script(recommended), or perform all operations manually.&lt;/p>
&lt;h4 id="run-start_snapshot_buildsh-to-trigger-build">Run start_snapshot_build.sh to trigger build&lt;/h4>
&lt;ul>
&lt;li>
&lt;p>Script: &lt;a href="https://github.com/apache/beam/blob/master/release/src/main/scripts/start_snapshot_build.sh">start_snapshot_build.sh&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Usage&lt;/p>
&lt;pre>&lt;code>./beam/release/src/main/scripts/start_snapshot_build.sh
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>The script will:&lt;/p>
&lt;ol>
&lt;li>Install &lt;a href="https://github.com/github/hub">hub&lt;/a> with your agreement.&lt;/li>
&lt;li>Touch an empty txt file and commit changes into &lt;code>${your remote beam repo}/snapshot_build&lt;/code>&lt;/li>
&lt;li>Use hub to create a PR against apache:master, which triggers a Jenkins job to build snapshot.&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>Tasks you need to do manually to &lt;strong>verify the SNAPSHOT build&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>Check whether the Jenkins job gets triggered. If not, please comment &lt;code>Run Gradle Publish&lt;/code> into the generated PR.&lt;/li>
&lt;li>After verifying build succeeded, you need to close PR manually.&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;h4 id="alternative-do-all-operations-manually">(Alternative) Do all operations manually&lt;/h4>
&lt;ul>
&lt;li>Find one PR against apache:master in beam.&lt;/li>
&lt;li>Comment &lt;code>Run Gradle Publish&lt;/code> in this pull request to trigger build.&lt;/li>
&lt;li>Verify that build succeeds.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="5-verify-release-branch">5. Verify release branch&lt;/h2>
&lt;p>After the release branch is cut you need to make sure it builds and has no significant issues that would block the creation of the release candidate.
There are 2 ways to perform this verification, either running automation script(recommended), or running all commands manually.&lt;/p>
&lt;p>! Dataflow tests will fail if Dataflow worker container is not created and published by this time. (Should be done by Google)&lt;/p>
&lt;h4 id="run-automation-script-verify_release_buildsh">Run automation script (verify_release_build.sh)&lt;/h4>
&lt;ul>
&lt;li>
&lt;p>Script: &lt;a href="https://github.com/apache/beam/blob/master/release/src/main/scripts/verify_release_build.sh">verify_release_build.sh&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Usage&lt;/p>
&lt;ol>
&lt;li>Create a personal access token from your Github account. See instruction &lt;a href="https://help.github.com/en/articles/creating-a-personal-access-token-for-the-command-line">here&lt;/a>.
It&amp;rsquo;ll be used by the script for accessing Github API.
You don&amp;rsquo;t have to add any permissions to this token.&lt;/li>
&lt;li>Update required configurations listed in &lt;code>RELEASE_BUILD_CONFIGS&lt;/code> in &lt;a href="https://github.com/apache/beam/blob/master/release/src/main/scripts/script.config">script.config&lt;/a>&lt;/li>
&lt;li>Then run
&lt;pre>&lt;code>cd beam/release/src/main/scripts &amp;amp;&amp;amp; ./verify_release_build.sh
&lt;/code>&lt;/pre>&lt;/li>
&lt;li>Trigger &lt;code>beam_Release_Gradle_Build&lt;/code> and all PostCommit Jenkins jobs from PR (which is created by previous step).
To do so, only add one trigger phrase per comment. See &lt;code>JOB_TRIGGER_PHRASES&lt;/code> in &lt;a href="https://github.com/apache/beam/blob/master/release/src/main/scripts/verify_release_build.sh#L43">verify_release_build.sh&lt;/a>
for full list of phrases.&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>Tasks included in the script&lt;/p>
&lt;ol>
&lt;li>Installs &lt;code>hub&lt;/code> with your agreement and setup local git repo;&lt;/li>
&lt;li>Create a test PR against release branch;&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;p>Jenkins job &lt;code>beam_Release_Gradle_Build&lt;/code> basically run &lt;code>./gradlew build -PisRelease&lt;/code>.
This only verifies that everything builds with unit tests passing.&lt;/p>
&lt;p>You can use &lt;a href="https://github.com/apache/beam/blob/master/release/src/main/scripts/mass_comment.py">mass_comment.py&lt;/a> to mass-comment on PR.&lt;/p>
&lt;h4 id="verify-the-build-succeeds">Verify the build succeeds&lt;/h4>
&lt;ul>
&lt;li>Tasks you need to do manually to &lt;strong>verify the build succeed&lt;/strong>:
&lt;ol>
&lt;li>Check the build result.&lt;/li>
&lt;li>If build failed, scan log will contain all failures.&lt;/li>
&lt;li>You should stabilize the release branch until release build succeeded.&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;p>There are some projects that don&amp;rsquo;t produce the artifacts, e.g. &lt;code>beam-test-tools&lt;/code>, you may be able to
ignore failures there.&lt;/p>
&lt;p>To triage the failures and narrow things down you may want to look at &lt;code>settings.gradle&lt;/code> and run the build only for the
projects you&amp;rsquo;re interested at the moment, e.g. &lt;code>./gradlew :runners:java-fn-execution&lt;/code>.&lt;/p>
&lt;h4 id="alternative-run-release-build-manually-locally">(Alternative) Run release build manually (locally)&lt;/h4>
&lt;ul>
&lt;li>
&lt;p>Pre-installation for python build&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Install pip&lt;/p>
&lt;pre>&lt;code>curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py
python get-pip.py
&lt;/code>&lt;/pre>&lt;/li>
&lt;li>
&lt;p>Install virtualenv&lt;/p>
&lt;pre>&lt;code>pip install --upgrade virtualenv
&lt;/code>&lt;/pre>&lt;/li>
&lt;li>
&lt;p>Cython&lt;/p>
&lt;pre>&lt;code>sudo pip install cython
sudo apt-get install gcc
sudo apt-get install python-dev
sudo apt-get install python3-dev
sudo apt-get install python3.5-dev
sudo apt-get install python3.6-dev
sudo apt-get install python3.7-dev
&lt;/code>&lt;/pre>&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>Run gradle release build&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Clean current workspace&lt;/p>
&lt;pre>&lt;code>git clean -fdx
./gradlew clean
&lt;/code>&lt;/pre>&lt;/li>
&lt;li>
&lt;p>Unlock the secret key&lt;/p>
&lt;pre>&lt;code>gpg --output ~/doc.sig --sign ~/.bashrc
&lt;/code>&lt;/pre>&lt;/li>
&lt;li>
&lt;p>Run build command&lt;/p>
&lt;pre>&lt;code>./gradlew build -PisRelease --no-parallel --scan --stacktrace --continue
&lt;/code>&lt;/pre>&lt;p>To speed things up locally you might want to omit &lt;code>--no-parallel&lt;/code>. You can also omit &lt;code>--continue&lt;/code>
if you want build fails after the first error instead of continuing, it may be easier and faster
to find environment issues this way without having to wait until the full build completes.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;h4 id="create-release-blocking-issues-in-jira">Create release-blocking issues in JIRA&lt;/h4>
&lt;p>The verify_release_build.sh script may include failing or flaky tests. For each of the failing tests create a JIRA with the following properties:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Issue Type: Bug&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Summary: Name of failing gradle task and name of failing test (where applicable) in form of :MyGradleProject:SomeGradleTask NameOfFailedTest: Short description of failure&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Priority: Major&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Component: &amp;ldquo;test-failures&amp;rdquo;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Fix Version: Release number of verified release branch&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Description: Description of failure&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h4 id="inform-the-mailing-list">Inform the mailing list&lt;/h4>
&lt;p>The &lt;a href="mailto:dev@beam.apache.org">dev@beam.apache.org&lt;/a> mailing list should be informed about the release branch being cut. Alongside with this note,
a list of pending issues and to-be-trigated issues should be included. Afterwards, this list can be refined and updated
by the release manager and the Beam community.&lt;/p>
&lt;hr>
&lt;h2 id="6-triage-release-blocking-issues-in-jira">6. Triage release-blocking issues in JIRA&lt;/h2>
&lt;p>There could be outstanding release-blocking issues, which should be triaged before proceeding to build a release candidate. We track them by assigning a specific &lt;code>Fix version&lt;/code> field even before the issue resolved.&lt;/p>
&lt;p>The list of release-blocking issues is available at the &lt;a href="https://issues.apache.org/jira/browse/BEAM/?selectedTab=com.atlassian.jira.jira-projects-plugin:versions-panel">version status page&lt;/a>. Triage each unresolved issue with one of the following resolutions:&lt;/p>
&lt;p>The release manager should triage what does and does not block a release. An issue should not block the release if the problem exists in the current released version or is a bug in new functionality that does not exist in the current released version. It should be a blocker if the bug is a regression between the currently released version and the release in progress and has no easy workaround.&lt;/p>
&lt;p>For all JIRA issues:&lt;/p>
&lt;ul>
&lt;li>If the issue has been resolved and JIRA was not updated, resolve it accordingly.&lt;/li>
&lt;/ul>
&lt;p>For JIRA issues with type &amp;ldquo;Bug&amp;rdquo; or labeled &amp;ldquo;flaky&amp;rdquo;:&lt;/p>
&lt;ul>
&lt;li>If the issue is a known continuously failing test, it is not acceptable to defer this until the next release. Please work with the Beam community to resolve the issue.&lt;/li>
&lt;li>If the issue is a known flaky test, make an attempt to delegate a fix. However, if the issue may take too long to fix (to the discretion of the release manager):
&lt;ul>
&lt;li>Delegate manual testing of the flaky issue to ensure no release blocking issues.&lt;/li>
&lt;li>Update the &lt;code>Fix Version&lt;/code> field to the version of the next release. Please consider discussing this with stakeholders and the dev@ mailing list, as appropriate.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>For all other JIRA issues:&lt;/p>
&lt;ul>
&lt;li>If the issue has not been resolved and it is acceptable to defer this until the next release, update the &lt;code>Fix Version&lt;/code> field to the new version you just created. Please consider discussing this with stakeholders and the dev@ mailing list, as appropriate.&lt;/li>
&lt;li>If the issue has not been resolved and it is not acceptable to release until it is fixed, the release cannot proceed. Instead, work with the Beam community to resolve the issue.&lt;/li>
&lt;/ul>
&lt;p>If there is a bug found in the RC creation process/tools, those issues should be considered high priority and fixed in 7 days.&lt;/p>
&lt;h3 id="review-cherry-picks">Review cherry-picks&lt;/h3>
&lt;p>Check if there are outstanding cherry-picks into the release branch, &lt;a href="https://github.com/apache/beam/pulls?utf8=%E2%9C%93&amp;amp;q=is%3Apr+base%3Arelease-2.14.0">e.g. for &lt;code>2.14.0&lt;/code>&lt;/a>.
Make sure they have blocker JIRAs attached and are OK to get into the release by checking with community if needed.&lt;/p>
&lt;p>As the Release Manager you are empowered to accept or reject cherry-picks to the release branch. You are encouraged to ask the following questions to be answered on each cherry-pick PR and you can choose to reject cherry-pick requests if these questions are not satisfactorily answered:&lt;/p>
&lt;ul>
&lt;li>Is this a regression from a previous release? (If no, fix could go to a newer version.)&lt;/li>
&lt;li>Is this a new feature or related to a new feature? (If yes, fix could go to a new version.)&lt;/li>
&lt;li>Would this impact production workloads for users? (E.g. if this is a direct runner only fix it may not need to be a cherry pick.)&lt;/li>
&lt;li>What percentage of users would be impacted by this issue if it is not fixed? (E.g. If this is predicted to be a small number it may not need to be a cherry pick.)&lt;/li>
&lt;li>Would it be possible for the impacted users to skip this version? (If users could skip this version, fix could go to a newer version.)&lt;/li>
&lt;/ul>
&lt;p>It is important to accept major/blocking fixes to isolated issues to make a higher quality release. However, beyond that each cherry pick will increase the time required for the release and add more last minute code to the release branch. Neither late releases nor not fully tested code will provide positive user value.&lt;/p>
&lt;p>&lt;em>Tip&lt;/em>: Another tool in your toolbox is the known issues section of the release blog. Consider adding known issues there for minor issues instead of accepting cherry picks to the release branch.&lt;/p>
&lt;hr>
&lt;h2 id="7-build-a-release-candidate">7. Build a release candidate&lt;/h2>
&lt;h3 id="checklist-before-proceeding">Checklist before proceeding&lt;/h3>
&lt;ul>
&lt;li>Release Manager’s GPG key is published to &lt;code>dist.apache.org&lt;/code>;&lt;/li>
&lt;li>Release Manager’s GPG key is configured in &lt;code>git&lt;/code> configuration;&lt;/li>
&lt;li>Release Manager has &lt;code>org.apache.beam&lt;/code> listed under &lt;code>Staging Profiles&lt;/code> in Nexus;&lt;/li>
&lt;li>Release Manager’s Nexus User Token is configured in &lt;code>settings.xml&lt;/code>;&lt;/li>
&lt;li>JIRA release item for the subsequent release has been created;&lt;/li>
&lt;li>All test failures from branch verification have associated JIRA issues;&lt;/li>
&lt;li>There are no release blocking JIRA issues;&lt;/li>
&lt;li>Combined javadoc has the appropriate contents;&lt;/li>
&lt;li>Release branch has been created;&lt;/li>
&lt;li>There are no open pull requests to release branch;&lt;/li>
&lt;li>Originating branch has the version information updated to the new version;&lt;/li>
&lt;li>Nightly snapshot is in progress (do revisit it continually);&lt;/li>
&lt;/ul>
&lt;p>The core of the release process is the build-vote-fix cycle. Each cycle produces one release candidate. The Release Manager repeats this cycle until the community approves one release candidate, which is then finalized.&lt;/p>
&lt;p>For this step, we recommend you using automation script to create a RC, but you still can perform all steps manually if you want.&lt;/p>
&lt;h3 id="run-build_release_candidatesh-to-create-a-release-candidate">Run build_release_candidate.sh to create a release candidate&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>Script: &lt;a href="https://github.com/apache/beam/blob/master/release/src/main/scripts/build_release_candidate.sh">build_release_candidate.sh&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Usage&lt;/p>
&lt;pre>&lt;code>./beam/release/src/main/scripts/build_release_candidate.sh
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>The script will:&lt;/p>
&lt;ol>
&lt;li>Run gradle release to create rc tag and push source release into github repo.&lt;/li>
&lt;li>Run gradle publish to push java artifacts into Maven staging repo.&lt;/li>
&lt;li>Stage source release into dist.apache.org dev &lt;a href="https://dist.apache.org/repos/dist/dev/beam/">repo&lt;/a>.&lt;/li>
&lt;li>Stage, sign and hash python source distribution and wheels into dist.apache.org dev repo python dir&lt;/li>
&lt;li>Stage SDK docker images to &lt;a href="https://hub.docker.com/search?q=apache%2Fbeam&amp;amp;type=image">docker hub Apache organization&lt;/a>.&lt;/li>
&lt;li>Create a PR to update beam-site, changes includes:
&lt;ul>
&lt;li>Copy python doc into beam-site&lt;/li>
&lt;li>Copy java doc into beam-site&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;h4 id="tasks-you-need-to-do-manually">Tasks you need to do manually&lt;/h4>
&lt;ol>
&lt;li>Verify the script worked.
&lt;ol>
&lt;li>Verify that the source and Python binaries are present in &lt;a href="https://dist.apache.org/repos/dist/dev/beam">dist.apache.org&lt;/a>.&lt;/li>
&lt;li>Verify Docker images are published. How to find images:
&lt;ol>
&lt;li>Visit &lt;a href="https://hub.docker.com/search?q=apache%2Fbeam&amp;amp;type=image">https://hub.docker.com/u/apache&lt;/a>&lt;/li>
&lt;li>Visit each repository and navigate to &lt;em>tags&lt;/em> tab.&lt;/li>
&lt;li>Verify images are pushed with tags: ${RELEASE}_rc{RC_NUM}&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>Verify that third party licenses are included in Docker containers by logging in to the images.
&lt;ul>
&lt;li>For Python SDK images, there should be around 80 ~ 100 dependencies.
Please note that dependencies for the SDKs with different Python versions vary.
Need to verify all Python images by replacing &lt;code>${ver}&lt;/code> with each supported Python version &lt;code>X.Y&lt;/code>.&lt;/li>
&lt;/ul>
&lt;pre>&lt;code>docker run -it --entrypoint=/bin/bash apache/beam_python${ver}_sdk:${RELEASE}_rc{RC_NUM}
ls -al /opt/apache/beam/third_party_licenses/ | wc -l
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>For Java SDK images, there should be around 1400 dependencies.&lt;/li>
&lt;/ul>
&lt;pre>&lt;code>docker run -it --entrypoint=/bin/bash apache/beam_java_sdk:${RELEASE}_rc{RC_NUM}
ls -al /opt/apache/beam/third_party_licenses/ | wc -l
&lt;/code>&lt;/pre>&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>Publish staging artifacts
&lt;ol>
&lt;li>Log in to the &lt;a href="https://repository.apache.org/#stagingRepositories">Apache Nexus&lt;/a> website.&lt;/li>
&lt;li>Navigate to Build Promotion -&amp;gt; Staging Repositories (in the left sidebar).&lt;/li>
&lt;li>Select repository &lt;code>orgapachebeam-NNNN&lt;/code>.&lt;/li>
&lt;li>Click the Close button.&lt;/li>
&lt;li>When prompted for a description, enter “Apache Beam, version X, release candidate Y”.&lt;/li>
&lt;li>Review all staged artifacts on &lt;a href="https://repository.apache.org/content/repositories/orgapachebeam-NNNN/">https://repository.apache.org/content/repositories/orgapachebeam-NNNN/&lt;/a>. They should contain all relevant parts for each module, including &lt;code>pom.xml&lt;/code>, jar, test jar, javadoc, etc. Artifact names should follow &lt;a href="https://search.maven.org/#search%7Cga%7C1%7Cg%3A%22org.apache.beam%22">the existing format&lt;/a> in which artifact name mirrors directory structure, e.g., &lt;code>beam-sdks-java-io-kafka&lt;/code>. Carefully review any new artifacts.&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;hr>
&lt;h2 id="8-prepare-documents">8. Prepare documents&lt;/h2>
&lt;h3 id="update-and-verify-javadoc">Update and Verify Javadoc&lt;/h3>
&lt;p>The build with &lt;code>-PisRelease&lt;/code> creates the combined Javadoc for the release in &lt;code>sdks/java/javadoc&lt;/code>.&lt;/p>
&lt;p>The file &lt;code>sdks/java/javadoc/build.gradle&lt;/code> contains a list of modules to include
in and exclude, plus a list of offline URLs that populate links from Beam&amp;rsquo;s
Javadoc to the Javadoc for other modules that Beam depends on.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Confirm that new modules added since the last release have been added to the
inclusion list as appropriate.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Confirm that the excluded package list is up to date.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Verify the version numbers for offline links match the versions used by Beam. If
the version number has changed, download a new version of the corresponding
&lt;code>&amp;lt;module&amp;gt;-docs/package-list&lt;/code> file.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="build-the-pydoc-api-reference">Build the Pydoc API reference&lt;/h3>
&lt;p>Make sure you have &lt;code>tox&lt;/code> installed:&lt;/p>
&lt;pre>&lt;code>pip install tox
&lt;/code>&lt;/pre>&lt;p>Create the Python SDK documentation using sphinx by running a helper script.&lt;/p>
&lt;pre>&lt;code>cd sdks/python &amp;amp;&amp;amp; pip install -r build-requirements.txt &amp;amp;&amp;amp; tox -e py37-docs
&lt;/code>&lt;/pre>&lt;p>By default the Pydoc is generated in &lt;code>sdks/python/target/docs/_build&lt;/code>. Let &lt;code>${PYDOC_ROOT}&lt;/code> be the absolute path to &lt;code>_build&lt;/code>.&lt;/p>
&lt;h3 id="propose-pull-requests-for-website-updates">Propose pull requests for website updates&lt;/h3>
&lt;p>Beam publishes API reference manuals for each release on the website. For Java
and Python SDKs, that’s Javadoc and PyDoc, respectively. The final step of
building the candidate is to propose website pull requests that update these
manuals.&lt;/p>
&lt;p>Merge the pull requests only after finalizing the release. To avoid invalid
redirects for the &amp;lsquo;current&amp;rsquo; version, merge these PRs in the order listed. Once
the PR is merged, the new contents will get picked up automatically and served
to the Beam website, usually within an hour.&lt;/p>
&lt;p>&lt;strong>PR 1: apache/beam-site&lt;/strong>&lt;/p>
&lt;p>This pull request is against the &lt;code>apache/beam-site&lt;/code> repo, on the &lt;code>release-docs&lt;/code>
branch (&lt;a href="https://github.com/apache/beam-site/pull/603">example&lt;/a>).
It is created by &lt;code>build_release_candidate.sh&lt;/code> (see above).&lt;/p>
&lt;p>&lt;strong>PR 2: apache/beam&lt;/strong>&lt;/p>
&lt;p>This pull request is against the &lt;code>apache/beam&lt;/code> repo, on the &lt;code>master&lt;/code> branch (&lt;a href="https://github.com/apache/beam/pull/11727">example&lt;/a>).&lt;/p>
&lt;ul>
&lt;li>Update release version in &lt;code>website/www/site/config.toml&lt;/code>.&lt;/li>
&lt;li>Add new release in &lt;code>website/www/site/content/en/get-started/downloads.md&lt;/code>.
&lt;ul>
&lt;li>Download links will not work until the release is finalized.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Update &lt;code>website/www/site/static/.htaccess&lt;/code> to redirect to the new version.&lt;/li>
&lt;/ul>
&lt;h3 id="blog-post">Blog post&lt;/h3>
&lt;p>Write a blog post similar to &lt;a href="https://github.com/apache/beam/blob/master/website/www/site/content/en/blog/beam-2.20.0.md">beam-2.20.0.md&lt;/a>.&lt;/p>
&lt;ul>
&lt;li>Update &lt;code>CHANGES.md&lt;/code> by adding a new section for the next release.&lt;/li>
&lt;li>Copy the changes for the current release from &lt;code>CHANGES.md&lt;/code> to the blog post and edit as necessary.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Tip&lt;/strong>: Use git log to find contributors to the releases. (e.g: &lt;code>git log --pretty='%aN' ^v2.10.0 v2.11.0 | sort | uniq&lt;/code>).
Make sure to clean it up, as there may be duplicate or incorrect user names.&lt;/p>
&lt;p>&lt;strong>NOTE&lt;/strong>: Make sure to include any breaking changes, even to &lt;code>@Experimental&lt;/code> features,
all major features and bug fixes, and all known issues.&lt;/p>
&lt;p>Template:&lt;/p>
&lt;pre>&lt;code>We are happy to present the new {$RELEASE_VERSION} release of Beam. This release includes both improvements and new functionality.
See the [download page](/get-started/downloads/{$DOWNLOAD_ANCHOR}) for this release.
For more information on changes in {$RELEASE_VERSION}, check out the
[detailed release notes]({$JIRA_RELEASE_NOTES}).
## Highlights
* New highly anticipated feature X added to Python SDK ([BEAM-X](https://issues.apache.org/jira/browse/BEAM-X)).
* New highly anticipated feature Y added to JavaSDK ([BEAM-Y](https://issues.apache.org/jira/browse/BEAM-Y)).
{$TOPICS e.g.:}
### I/Os
* Support for X source added (Java) ([BEAM-X](https://issues.apache.org/jira/browse/BEAM-X)).
{$TOPICS}
### New Features / Improvements
* X feature added (Python) ([BEAM-X](https://issues.apache.org/jira/browse/BEAM-X)).
* Y feature added (Java) [BEAM-Y](https://issues.apache.org/jira/browse/BEAM-Y).
### Breaking Changes
* X behavior was changed ([BEAM-X](https://issues.apache.org/jira/browse/BEAM-X)).
* Y behavior was changed ([BEAM-Y](https://issues.apache.org/jira/browse/BEAM-Y)).
### Deprecations
* X behavior is deprecated and will be removed in X versions ([BEAM-X](https://issues.apache.org/jira/browse/BEAM-X)).
### Bugfixes
* Fixed X (Python) ([BEAM-Y](https://issues.apache.org/jira/browse/BEAM-X)).
* Fixed Y (Java) ([BEAM-Y](https://issues.apache.org/jira/browse/BEAM-Y)).
### Known Issues
* {$KNOWN_ISSUE_1}
* {$KNOWN_ISSUE_2}
* See a full list of open [issues that affect](https://issues.apache.org/jira/issues/?jql=project%20%3D%20BEAM%20AND%20affectedVersion%20%3D%20{$RELEASE}%20ORDER%20BY%20priority%20DESC%2C%20updated%20DESC) this version.
## List of Contributors
According to git shortlog, the following people contributed to the 2.XX.0 release. Thank you to all contributors!
${CONTRIBUTORS}
&lt;/code>&lt;/pre>&lt;h4 id="checklist-to-proceed-to-the-next-step-1">Checklist to proceed to the next step&lt;/h4>
&lt;ol>
&lt;li>Maven artifacts deployed to the staging repository of &lt;a href="https://repository.apache.org/content/repositories/">repository.apache.org&lt;/a>&lt;/li>
&lt;li>Source distribution deployed to the dev repository of &lt;a href="https://dist.apache.org/repos/dist/dev/beam/">dist.apache.org&lt;/a>&lt;/li>
&lt;li>Website pull request proposed to list the &lt;a href="/get-started/downloads/">release&lt;/a>, publish the &lt;a href="https://beam.apache.org/releases/javadoc/">Java API reference manual&lt;/a>, and publish the &lt;a href="https://beam.apache.org/releases/pydoc/">Python API reference manual&lt;/a>.&lt;/li>
&lt;li>Docker images are published to &lt;a href="https://hub.docker.com/search?q=apache%2Fbeam&amp;amp;type=image">DockerHub&lt;/a> with tags: {RELEASE}_rc{RC_NUM}.&lt;/li>
&lt;/ol>
&lt;p>You can (optionally) also do additional verification by:&lt;/p>
&lt;ol>
&lt;li>Check that Python zip file contains the &lt;code>README.md&lt;/code>, &lt;code>NOTICE&lt;/code>, and &lt;code>LICENSE&lt;/code> files.&lt;/li>
&lt;li>Check hashes (e.g. &lt;code>md5sum -c *.md5&lt;/code> and &lt;code>sha1sum -c *.sha1&lt;/code>)&lt;/li>
&lt;li>Check signatures (e.g. &lt;code>gpg --verify apache-beam-1.2.3-python.zip.asc apache-beam-1.2.3-python.zip&lt;/code>)&lt;/li>
&lt;li>&lt;code>grep&lt;/code> for legal headers in each file.&lt;/li>
&lt;li>Run all jenkins suites and include links to passing tests in the voting email.&lt;/li>
&lt;li>Pull docker images to make sure they are pullable.&lt;/li>
&lt;/ol>
&lt;pre>&lt;code>docker pull {image_name}
docker pull apache/beam_python3.5_sdk:2.16.0_rc1
&lt;/code>&lt;/pre>&lt;hr>
&lt;h2 id="9-vote-and-validate-release-candidate">9. Vote and validate release candidate&lt;/h2>
&lt;p>Once you have built and individually reviewed the release candidate, please share it for the community-wide review. Please review foundation-wide &lt;a href="http://www.apache.org/foundation/voting.html">voting guidelines&lt;/a> for more information.&lt;/p>
&lt;p>Start the review-and-vote thread on the dev@ mailing list. Here’s an email template; please adjust as you see fit.&lt;/p>
&lt;pre>&lt;code>From: Release Manager
To: dev@beam.apache.org
Subject: [VOTE] Release 1.2.3, release candidate #3
Hi everyone,
Please review and vote on the release candidate #3 for the version 1.2.3, as follows:
[ ] +1, Approve the release
[ ] -1, Do not approve the release (please provide specific comments)
The complete staging area is available for your review, which includes:
* JIRA release notes [1],
* the official Apache source release to be deployed to dist.apache.org [2], which is signed with the key with fingerprint FFFFFFFF [3],
* all artifacts to be deployed to the Maven Central Repository [4],
* source code tag &amp;quot;v1.2.3-RC3&amp;quot; [5],
* website pull request listing the release [6], publishing the API reference manual [7], and the blog post [8].
* Java artifacts were built with Maven MAVEN_VERSION and OpenJDK/Oracle JDK JDK_VERSION.
* Python artifacts are deployed along with the source release to the dist.apache.org [2].
* Validation sheet with a tab for 1.2.3 release to help with validation [9].
* Docker images published to Docker Hub [10].
The vote will be open for at least 72 hours. It is adopted by majority approval, with at least 3 PMC affirmative votes.
Thanks,
Release Manager
[1] https://jira.apache.org/jira/secure/ReleaseNote.jspa?projectId=...
[2] https://dist.apache.org/repos/dist/dev/beam/1.2.3/
[3] https://dist.apache.org/repos/dist/release/beam/KEYS
[4] https://repository.apache.org/content/repositories/orgapachebeam-NNNN/
[5] https://github.com/apache/beam/tree/v1.2.3-RC3
[6] https://github.com/apache/beam/pull/...
[7] https://github.com/apache/beam-site/pull/...
[8] https://github.com/apache/beam/pull/...
[9] https://docs.google.com/spreadsheets/d/1qk-N5vjXvbcEk68GjbkSZTR8AGqyNUM-oLFo_ZXBpJw/edit#gid=...
[10] https://hub.docker.com/search?q=apache%2Fbeam&amp;amp;type=image
&lt;/code>&lt;/pre>
&lt;p>If there are any issues found in the release candidate, reply on the vote thread to cancel the vote. There’s no need to wait 72 hours. Proceed to the &lt;code>Fix Issues&lt;/code> step below and address the problem. However, some issues don’t require cancellation. For example, if an issue is found in the website pull request, just correct it on the spot and the vote can continue as-is.&lt;/p>
&lt;p>If there are no issues, reply on the vote thread to close the voting. Then, tally the votes in a separate email thread. Here’s an email template; please adjust as you see fit.&lt;/p>
&lt;pre>&lt;code>From: Release Manager
To: dev@beam.apache.org
Subject: [RESULT] [VOTE] Release 1.2.3, release candidate #3
I'm happy to announce that we have unanimously approved this release.
There are XXX approving votes, XXX of which are binding:
* approver 1
* approver 2
* approver 3
* approver 4
There are no disapproving votes.
Thanks everyone!
&lt;/code>&lt;/pre>
&lt;h3 id="run-validation-tests">Run validation tests&lt;/h3>
&lt;p>All tests listed in this &lt;a href="https://s.apache.org/beam-release-validation">spreadsheet&lt;/a>&lt;/p>
&lt;p>Since there are a bunch of tests, we recommend you running validations using automation script. In case of script failure, you can still run all of them manually.&lt;/p>
&lt;h4 id="run-validations-using-run_rc_validationsh">Run validations using run_rc_validation.sh&lt;/h4>
&lt;ul>
&lt;li>
&lt;p>Script: &lt;a href="https://github.com/apache/beam/blob/master/release/src/main/scripts/run_rc_validation.sh">run_rc_validation.sh&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Usage&lt;/p>
&lt;ol>
&lt;li>First update required configurations listed in &lt;code>RC_VALIDATE_CONFIGS&lt;/code> in
&lt;a href="https://github.com/apache/beam/blob/master/release/src/main/scripts/script.config">script.config&lt;/a>&lt;/li>
&lt;li>Then run
&lt;pre>&lt;code>./beam/release/src/main/scripts/run_rc_validation.sh
&lt;/code>&lt;/pre>&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>Tasks included&lt;/p>
&lt;ol>
&lt;li>Run Java quickstart with Direct Runner, Flink local runner, Spark local runner and Dataflow runner.&lt;/li>
&lt;li>Run Java Mobile Games(UserScore, HourlyTeamScore, Leaderboard) with Dataflow runner.&lt;/li>
&lt;li>Create a PR to trigger python validation job, including
&lt;ul>
&lt;li>Python quickstart in batch and streaming mode with direct runner and Dataflow runner.&lt;/li>
&lt;li>Python Mobile Games(UserScore, HourlyTeamScore) with direct runner and Dataflow runner.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Run Python Streaming MobileGames, includes
&lt;ul>
&lt;li>Start a new terminal to run Java Pubsub injector.&lt;/li>
&lt;li>Start a new terminal to run python LeaderBoard with Direct Runner.&lt;/li>
&lt;li>Start a new terminal to run python LeaderBoard with Dataflow Runner.&lt;/li>
&lt;li>Start a new terminal to run python GameStats with Direct Runner.&lt;/li>
&lt;li>Start a new terminal to run python GameStats with Dataflow Runner.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>Tasks you need to do manually&lt;/p>
&lt;ol>
&lt;li>Check whether validations succeed by following console output instructions.&lt;/li>
&lt;li>Terminate streaming jobs and java injector.&lt;/li>
&lt;li>Sign up &lt;a href="https://s.apache.org/beam-release-validation">spreadsheet&lt;/a>.&lt;/li>
&lt;li>Vote in the release thread.&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;h4 id="run-validations-manually">Run validations manually&lt;/h4>
&lt;p>&lt;em>Note&lt;/em>: -Prepourl and -Pver can be found in the RC vote email sent by Release Manager.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Java Quickstart Validation&lt;/p>
&lt;p>Direct Runner:&lt;/p>
&lt;pre>&lt;code>./gradlew :runners:direct-java:runQuickstartJavaDirect \
-Prepourl=https://repository.apache.org/content/repositories/orgapachebeam-${KEY} \
-Pver=${RELEASE_VERSION}
&lt;/code>&lt;/pre>&lt;p>Flink Local Runner&lt;/p>
&lt;pre>&lt;code>./gradlew :runners:flink:1.10:runQuickstartJavaFlinkLocal \
-Prepourl=https://repository.apache.org/content/repositories/orgapachebeam-${KEY} \
-Pver=${RELEASE_VERSION}
&lt;/code>&lt;/pre>&lt;p>Spark Local Runner&lt;/p>
&lt;pre>&lt;code>./gradlew :runners:spark:runQuickstartJavaSpark \
-Prepourl=https://repository.apache.org/content/repositories/orgapachebeam-${KEY} \
-Pver=${RELEASE_VERSION}
&lt;/code>&lt;/pre>&lt;p>Dataflow Runner&lt;/p>
&lt;pre>&lt;code>./gradlew :runners:google-cloud-dataflow-java:runQuickstartJavaDataflow \
-Prepourl=https://repository.apache.org/content/repositories/orgapachebeam-${KEY} \
-Pver=${RELEASE_VERSION} \
-PgcpProject=${YOUR_GCP_PROJECT} \
-PgcsBucket=${YOUR_GCP_BUCKET}
&lt;/code>&lt;/pre>&lt;/li>
&lt;li>
&lt;p>Java Mobile Game(UserScore, HourlyTeamScore, Leaderboard)&lt;/p>
&lt;p>Pre-request&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Create your own BigQuery dataset&lt;/p>
&lt;pre>&lt;code>bq mk --project_id=${YOUR_GCP_PROJECT} ${YOUR_DATASET}
&lt;/code>&lt;/pre>&lt;/li>
&lt;li>
&lt;p>Create yout PubSub topic&lt;/p>
&lt;pre>&lt;code>gcloud alpha pubsub topics create --project=${YOUR_GCP_PROJECT} ${YOUR_PROJECT_PUBSUB_TOPIC}
&lt;/code>&lt;/pre>&lt;/li>
&lt;li>
&lt;p>Setup your service account&lt;/p>
&lt;p>Goto IAM console in your project to create a service account as &lt;code>project owner&lt;/code>&lt;/p>
&lt;p>Run&lt;/p>
&lt;pre>&lt;code>gcloud iam service-accounts keys create ${YOUR_KEY_JSON} --iam-account ${YOUR_SERVICE_ACCOUNT_NAME}@${YOUR_PROJECT_NAME}
export GOOGLE_APPLICATION_CREDENTIALS=${PATH_TO_YOUR_KEY_JSON}
&lt;/code>&lt;/pre>&lt;/li>
&lt;/ul>
&lt;p>Run&lt;/p>
&lt;pre>&lt;code>./gradlew :runners:google-cloud-dataflow-java:runMobileGamingJavaDataflow \
-Prepourl=https://repository.apache.org/content/repositories/orgapachebeam-${KEY} \
-Pver=${RELEASE_VERSION} \
-PgcpProject=${YOUR_GCP_PROJECT} \
-PgcsBucket=${YOUR_GCP_BUCKET} \
-PbqDataset=${YOUR_DATASET} -PpubsubTopic=${YOUR_PROJECT_PUBSUB_TOPIC}
&lt;/code>&lt;/pre>&lt;/li>
&lt;li>
&lt;p>Python Quickstart(batch &amp;amp; streaming), MobileGame(UserScore, HourlyTeamScore)&lt;/p>
&lt;p>Create a new PR in apache/beam&lt;/p>
&lt;p>In comment area, type in &lt;code>Run Python ReleaseCandidate&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Python Leaderboard &amp;amp; GameStats&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Get staging RC &lt;code>wget https://dist.apache.org/repos/dist/dev/beam/2.5.0/* &lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Verify the hashes&lt;/p>
&lt;pre>&lt;code>sha512sum -c apache-beam-2.5.0-python.zip.sha512
sha512sum -c apache-beam-2.5.0-source-release.zip.sha512
&lt;/code>&lt;/pre>&lt;/li>
&lt;li>
&lt;p>Build SDK&lt;/p>
&lt;pre>&lt;code>sudo apt-get install unzip
unzip apache-beam-2.5.0-source-release.zip
python setup.py sdist
&lt;/code>&lt;/pre>&lt;/li>
&lt;li>
&lt;p>Setup virtualenv&lt;/p>
&lt;pre>&lt;code>pip install --upgrade pip
pip install --upgrade setuptools
pip install --upgrade virtualenv
virtualenv beam_env
. beam_env/bin/activate
&lt;/code>&lt;/pre>&lt;/li>
&lt;li>
&lt;p>Install SDK&lt;/p>
&lt;pre>&lt;code>pip install dist/apache-beam-2.5.0.tar.gz
pip install dist/apache-beam-2.5.0.tar.gz[gcp]
&lt;/code>&lt;/pre>&lt;/li>
&lt;li>
&lt;p>Setup GCP&lt;/p>
&lt;p>Please repeat following steps for every following test.&lt;/p>
&lt;pre>&lt;code>bq rm -rf --project=${YOUR_PROJECT} ${USER}_test
bq mk --project_id=${YOUR_PROJECT} ${USER}_test
gsutil rm -rf ${YOUR_GS_STORAGE]
gsutil mb -p ${YOUR_PROJECT} ${YOUR_GS_STORAGE}
gcloud alpha pubsub topics create --project=${YOUR_PROJECT} ${YOUR_PUBSUB_TOPIC}
&lt;/code>&lt;/pre>&lt;p>Setup your service account as described in &lt;code>Java Mobile Game&lt;/code> section above.&lt;/p>
&lt;p>Produce data by using java injector:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Configure your ~/.m2/settings.xml as following:&lt;/p>
&lt;pre>&lt;code>&amp;lt;settings&amp;gt;
&amp;lt;profiles&amp;gt;
&amp;lt;profile&amp;gt;
&amp;lt;id&amp;gt;release-repo&amp;lt;/id&amp;gt;
&amp;lt;activation&amp;gt;
&amp;lt;activeByDefault&amp;gt;true&amp;lt;/activeByDefault&amp;gt;
&amp;lt;/activation&amp;gt;
&amp;lt;repositories&amp;gt;
&amp;lt;repository&amp;gt;
&amp;lt;id&amp;gt;Release 2.4.0 RC3&amp;lt;/id&amp;gt;
&amp;lt;name&amp;gt;Release 2.4.0 RC3&amp;lt;/name&amp;gt;
&amp;lt;url&amp;gt;https://repository.apache.org/content/repositories/orgapachebeam-1031/&amp;lt;/url&amp;gt;
&amp;lt;/repository&amp;gt;
&amp;lt;/repositories&amp;gt;
&amp;lt;/profile&amp;gt;
&amp;lt;/profiles&amp;gt;
&amp;lt;/settings&amp;gt;
&lt;/code>&lt;/pre>&lt;p>&lt;em>Note&lt;/em>: You can found the latest &lt;code>id&lt;/code>, &lt;code>name&lt;/code> and &lt;code>url&lt;/code> for one RC in the vote email thread sent out by Release Manager.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Run&lt;/p>
&lt;pre>&lt;code>mvn archetype:generate \
-DarchetypeGroupId=org.apache.beam \
-DarchetypeArtifactId=beam-sdks-java-maven-archetypes-examples \
-DarchetypeVersion=${RELEASE_VERSION} \
-DgroupId=org.example \
-DartifactId=word-count-beam \
-Dversion=&amp;quot;0.1&amp;quot; \
-Dpackage=org.apache.beam.examples \
-DinteractiveMode=false
-DarchetypeCatalog=internal
mvn compile exec:java -Dexec.mainClass=org.apache.beam.examples.complete.game.injector.Injector \
-Dexec.args=&amp;quot;${YOUR_PROJECT} ${YOUR_PUBSUB_TOPIC} none&amp;quot;
&lt;/code>&lt;/pre>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Run Leaderboard with Direct Runner&lt;/p>
&lt;pre>&lt;code>python -m apache_beam.examples.complete.game.leader_board \
--project=${YOUR_PROJECT} \
--topic projects/${YOUR_PROJECT}/topics/${YOUR_PUBSUB_TOPIC} \
--dataset ${USER}_test
&lt;/code>&lt;/pre>&lt;p>Inspect results:&lt;/p>
&lt;ul>
&lt;li>Check whether there is any error messages in console.&lt;/li>
&lt;li>Goto your BigQuery console and check whether your ${USER}_test has leader_board_users and leader_board_teams table.&lt;/li>
&lt;li>bq head -n 10 ${USER}_test.leader_board_users&lt;/li>
&lt;li>bq head -n 10 ${USER}_test.leader_board_teams&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Run Leaderboard with Dataflow Runner&lt;/p>
&lt;pre>&lt;code>python -m apache_beam.examples.complete.game.leader_board \
--project=${YOUR_PROJECT} \
--region=${GCE_REGION} \
--topic projects/${YOUR_PROJECT}/topics/${YOUR_PUBSUB_TOPIC} \
--dataset ${USER}_test \
--runner DataflowRunner \
--temp_location=${YOUR_GS_BUCKET}/temp/ \
--sdk_location dist/*
&lt;/code>&lt;/pre>&lt;p>Inspect results:&lt;/p>
&lt;ul>
&lt;li>Goto your Dataflow job console and check whether there is any error.&lt;/li>
&lt;li>Goto your BigQuery console and check whether your ${USER}_test has leader_board_users and leader_board_teams table.&lt;/li>
&lt;li>bq head -n 10 ${USER}_test.leader_board_users&lt;/li>
&lt;li>bq head -n 10 ${USER}_test.leader_board_teams&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Run GameStats with Direct Runner&lt;/p>
&lt;pre>&lt;code>python -m apache_beam.examples.complete.game.game_stats \
--project=${YOUR_PROJECT} \
--topic projects/${YOUR_PROJECT}/topics/${YOUR_PUBSUB_TOPIC} \
--dataset ${USER}_test \
--fixed_window_duration ${SOME_SMALL_DURATION}
&lt;/code>&lt;/pre>&lt;p>Inspect results:&lt;/p>
&lt;ul>
&lt;li>Check whether there is any error messages in console.&lt;/li>
&lt;li>Goto your BigQuery console and check whether your ${USER}_test has game_stats_teams and game_stats_sessions table.&lt;/li>
&lt;li>bq head -n 10 ${USER}_test.game_stats_teams&lt;/li>
&lt;li>bq head -n 10 ${USER}_test.game_stats_sessions&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Run GameStats with Dataflow Runner&lt;/p>
&lt;pre>&lt;code>python -m apache_beam.examples.complete.game.game_stats \
--project=${YOUR_PROJECT} \
--region=${GCE_REGION} \
--topic projects/${YOUR_PROJECT}/topics/${YOUR_PUBSUB_TOPIC} \
--dataset ${USER}_test \
--runner DataflowRunner \
--temp_location=${YOUR_GS_BUCKET}/temp/ \
--sdk_location dist/* \
--fixed_window_duration ${SOME_SMALL_DURATION}
&lt;/code>&lt;/pre>&lt;p>Inspect results:&lt;/p>
&lt;ul>
&lt;li>Goto your Dataflow job console and check whether there is any error.&lt;/li>
&lt;li>Goto your BigQuery console and check whether your ${USER}_test has game_stats_teams and game_stats_sessions table.&lt;/li>
&lt;li>bq head -n 10 ${USER}_test.game_stats_teams&lt;/li>
&lt;li>bq head -n 10 ${USER}_test.game_stats_sessions&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="fix-any-issues">Fix any issues&lt;/h3>
&lt;p>Any issues identified during the community review and vote should be fixed in this step. Additionally, any JIRA issues created from the initial branch verification should be fixed.&lt;/p>
&lt;p>Code changes should be proposed as standard pull requests to the &lt;code>master&lt;/code> branch and reviewed using the normal contributing process. Then, relevant changes should be cherry-picked into the release branch. The cherry-pick commits should then be proposed as the pull requests against the release branch, again reviewed and merged using the normal contributing process.&lt;/p>
&lt;p>Once all issues have been resolved, you should go back and build a new release candidate with these changes.&lt;/p>
&lt;h3 id="checklist-to-proceed-to-the-next-step-2">Checklist to proceed to the next step&lt;/h3>
&lt;ol>
&lt;li>Issues identified during vote have been resolved, with fixes committed to the release branch.&lt;/li>
&lt;li>All issues tagged with &lt;code>Fix-Version&lt;/code> for the current release should be closed.&lt;/li>
&lt;li>Community votes to release the proposed candidate, with at least three approving PMC votes&lt;/li>
&lt;/ol>
&lt;hr>
&lt;h2 id="10-finalize-the-release">10. Finalize the release&lt;/h2>
&lt;p>Once the release candidate has been reviewed and approved by the community, the release should be finalized. This involves the final deployment of the release candidate to the release repositories, merging of the website changes, etc.&lt;/p>
&lt;h3 id="deploy-artifacts-to-maven-central-repository">Deploy artifacts to Maven Central Repository&lt;/h3>
&lt;p>Use the &lt;a href="https://repository.apache.org/#stagingRepositories">Apache Nexus repository manager&lt;/a> to release the staged binary artifacts to the Maven Central repository. In the &lt;code>Staging Repositories&lt;/code> section, find the relevant release candidate &lt;code>orgapachebeam-XXX&lt;/code> entry and click &lt;code>Release&lt;/code>. Drop all other release candidates that are not being released.
&lt;strong>NOTE&lt;/strong>: If you are using &lt;a href="https://help.github.com/articles/securing-your-account-with-two-factor-authentication-2fa/">GitHub two-factor authentication&lt;/a> and haven&amp;rsquo;t configure HTTPS access,
please follow &lt;a href="https://help.github.com/articles/creating-a-personal-access-token-for-the-command-line/">the guide&lt;/a> to configure command line access.&lt;/p>
&lt;h3 id="deploy-python-artifacts-to-pypi">Deploy Python artifacts to PyPI&lt;/h3>
&lt;ul>
&lt;li>Script: &lt;a href="https://github.com/apache/beam/blob/master/release/src/main/scripts/deploy_pypi.sh">deploy_pypi.sh&lt;/a>&lt;/li>
&lt;li>Usage&lt;/li>
&lt;/ul>
&lt;pre>&lt;code>./beam/release/src/main/scripts/deploy_pypi.sh
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>Verify that the files at &lt;a href="https://pypi.org/project/apache-beam/#files">https://pypi.org/project/apache-beam/#files&lt;/a> are correct.
All wheels should be published, in addition to the zip of the release source.
(Signatures and hashes do &lt;em>not&lt;/em> need to be uploaded.)&lt;/li>
&lt;/ul>
&lt;h3 id="deploy-sdk-docker-images-to-dockerhub">Deploy SDK docker images to DockerHub&lt;/h3>
&lt;ul>
&lt;li>Script: &lt;a href="https://github.com/apache/beam/blob/master/release/src/main/scripts/publish_docker_images.sh">publish_docker_images.sh&lt;/a>&lt;/li>
&lt;li>Usage&lt;/li>
&lt;/ul>
&lt;pre>&lt;code>./beam/release/src/main/scripts/publish_docker_images.sh
&lt;/code>&lt;/pre>&lt;p>Verify that:&lt;/p>
&lt;ul>
&lt;li>Images are published at &lt;a href="https://hub.docker.com/search?q=apache%2Fbeam&amp;amp;type=image">DockerHub&lt;/a> with tags {RELEASE} and &lt;em>latest&lt;/em>.&lt;/li>
&lt;li>Images with &lt;em>latest&lt;/em> tag are pointing to current release by confirming
&lt;ol>
&lt;li>Digest of the image with &lt;em>latest&lt;/em> tag is the same as the one with {RELEASE} tag.&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;h3 id="merge-website-pull-requests">Merge Website pull requests&lt;/h3>
&lt;p>Merge all of the website pull requests&lt;/p>
&lt;ul>
&lt;li>&lt;a href="/get-started/downloads/">listing the release&lt;/a>&lt;/li>
&lt;li>publishing the &lt;a href="https://beam.apache.org/releases/pydoc/">Python API reference manual&lt;/a> and the &lt;a href="https://beam.apache.org/releases/javadoc/">Java API reference manual&lt;/a>, and&lt;/li>
&lt;li>adding the release blog post.&lt;/li>
&lt;/ul>
&lt;h3 id="git-tag">Git tag&lt;/h3>
&lt;p>Create and push a new signed tag for the released version by copying the tag for the final release candidate, as follows:&lt;/p>
&lt;pre>&lt;code>VERSION_TAG=&amp;quot;v${RELEASE}&amp;quot;
git tag -s &amp;quot;$VERSION_TAG&amp;quot; &amp;quot;$RC_TAG&amp;quot;
git push https://github.com/apache/beam &amp;quot;$VERSION_TAG&amp;quot;
&lt;/code>&lt;/pre>&lt;p>After the tag is uploaded, publish the release notes to Github, as follows:&lt;/p>
&lt;pre>&lt;code>cd beam/release/src/main/scripts &amp;amp;&amp;amp; ./publish_github_release_notes.sh
&lt;/code>&lt;/pre>&lt;p>Note this script reads the release notes from the blog post, so you should make sure to run this from master &lt;em>after&lt;/em> merging the blog post PR.&lt;/p>
&lt;h3 id="pmc-only-finalization">PMC-Only Finalization&lt;/h3>
&lt;p>There are a few release finalization tasks that only PMC members have permissions to do. Ping &lt;a href="mailto:dev@beam.apache.org">dev@&lt;/a> for assistance if you need it.&lt;/p>
&lt;h4 id="deploy-source-release-to-distapacheorg">Deploy source release to dist.apache.org&lt;/h4>
&lt;p>Copy the source release from the &lt;code>dev&lt;/code> repository to the &lt;code>release&lt;/code> repository at &lt;code>dist.apache.org&lt;/code> using Subversion.&lt;/p>
&lt;p>Make sure the last release&amp;rsquo;s artifacts have been copied from &lt;code>dist.apache.org&lt;/code> to &lt;code>archive.apache.org&lt;/code>. This should happen automatically: &lt;a href="https://lists.apache.org/thread.html/39c26c57c5125a7ca06c3c9315b4917b86cd0e4567b7174f4bc4d63b%40%3Cdev.beam.apache.org%3E">dev@ thread&lt;/a> with context. The release manager should also make sure to change these links on the website (&lt;a href="https://github.com/apache/beam/pull/11727">example&lt;/a>).&lt;/p>
&lt;h4 id="mark-the-version-as-released-in-jira">Mark the version as released in JIRA&lt;/h4>
&lt;p>In JIRA, inside &lt;a href="https://issues.apache.org/jira/plugins/servlet/project-config/BEAM/versions">version management&lt;/a>, hover over the current release and a settings menu will appear. Click &lt;code>Release&lt;/code>, and select today’s date.&lt;/p>
&lt;h4 id="recordkeeping-with-asf">Recordkeeping with ASF&lt;/h4>
&lt;p>Use reporter.apache.org to seed the information about the release into future project reports.&lt;/p>
&lt;h3 id="checklist-to-proceed-to-the-next-step-3">Checklist to proceed to the next step&lt;/h3>
&lt;ul>
&lt;li>Maven artifacts released and indexed in the &lt;a href="https://search.maven.org/#search%7Cga%7C1%7Cg%3A%22org.apache.beam%22">Maven Central Repository&lt;/a>&lt;/li>
&lt;li>Source distribution available in the release repository of &lt;a href="https://dist.apache.org/repos/dist/release/beam/">dist.apache.org&lt;/a>&lt;/li>
&lt;li>Source distribution removed from the dev repository of &lt;a href="https://dist.apache.org/repos/dist/dev/beam/">dist.apache.org&lt;/a>&lt;/li>
&lt;li>Website pull request to &lt;a href="/get-started/downloads/">list the release&lt;/a> and publish the &lt;a href="https://beam.apache.org/releases/javadoc/">API reference manual&lt;/a> merged&lt;/li>
&lt;li>Release tagged in the source code repository&lt;/li>
&lt;li>Release version finalized in JIRA. (Note: Not all committers have administrator access to JIRA. If you end up getting permissions errors ask on the mailing list for assistance.)&lt;/li>
&lt;li>Release version is listed at reporter.apache.org&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="11-promote-the-release">11. Promote the release&lt;/h2>
&lt;p>Once the release has been finalized, the last step of the process is to promote the release within the project and beyond.&lt;/p>
&lt;h3 id="apache-mailing-lists">Apache mailing lists&lt;/h3>
&lt;p>Announce on the dev@ mailing list that the release has been finished.&lt;/p>
&lt;p>Announce on the release on the user@ mailing list, listing major improvements and contributions.&lt;/p>
&lt;p>Announce the release on the &lt;a href="mailto:announce@apache.org">announce@apache.org&lt;/a> mailing list.
&lt;strong>NOTE&lt;/strong>: This can only be done from &lt;code>@apache.org&lt;/code> email address.&lt;/p>
&lt;h3 id="social-media">Social media&lt;/h3>
&lt;p>Tweet, post on Facebook, LinkedIn, and other platforms. Ask other contributors to do the same.&lt;/p>
&lt;p>Also, update &lt;a href="https://en.wikipedia.org/wiki/Apache_Beam">the Wikipedia article on Apache Beam&lt;/a>.&lt;/p>
&lt;h3 id="checklist-to-declare-the-process-completed">Checklist to declare the process completed&lt;/h3>
&lt;ol>
&lt;li>Release announced on the user@ mailing list.&lt;/li>
&lt;li>Blog post published, if applicable.&lt;/li>
&lt;li>Release recorded in reporter.apache.org.&lt;/li>
&lt;li>Release announced on social media.&lt;/li>
&lt;li>Completion declared on the dev@ mailing list.&lt;/li>
&lt;li>Update Wikipedia Apache Beam article.&lt;/li>
&lt;/ol>
&lt;hr>
&lt;h2 id="improve-the-process">Improve the process&lt;/h2>
&lt;p>It is important that we improve the release processes over time. Once you’ve finished the release, please take a step back and look what areas of this process and be improved. Perhaps some part of the process can be simplified. Perhaps parts of this guide can be clarified.&lt;/p>
&lt;p>If we have specific ideas, please start a discussion on the dev@ mailing list and/or propose a pull request to update this guide. Thanks!&lt;/p></description></item><item><title>Contribute: Beam Team</title><link>/contribute/team/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/contribute/team/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;!--
This page is redirected to https://home.apache.org/phonebook.html?pmc=beam
--></description></item><item><title>Contribute: Beam Testing</title><link>/contribute/testing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/contribute/testing/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;!--
This page is redirected to https://cwiki.apache.org/confluence/display/BEAM/Contribution+Testing+Guide
--></description></item><item><title>Contribute: Become A Committer</title><link>/contribute/become-a-committer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/contribute/become-a-committer/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="become-a-committer">Become a Committer&lt;/h1>
&lt;p>An Apache Beam
&lt;a href="https://www.apache.org/foundation/how-it-works.html#committers">committer&lt;/a> has
write access to the repository for merging pull requests, but you don&amp;rsquo;t have
to be a code contributor to become a committer. Becoming a committer means that
you have the project&amp;rsquo;s trust. Read the &lt;a href="https://www.apache.org/dev/committers.html#committer-responsibilities">ASF
documentation&lt;/a>
for more about being a committer in the Apache Software Foundation.&lt;/p>
&lt;p>The &lt;a href="https://www.apache.org/foundation/how-it-works.html#pmc-members">PMC&lt;/a>
makes someone a committer via nomination, discussion, and then majority vote.
We use data from as many sources as possible to inform our reasoning. Here are
some examples:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://lists.apache.org/list.html?dev@beam.apache.org">dev@ archives&lt;/a> and &lt;a href="https://lists.apache.org/trends.html?dev@beam.apache.org">statistics&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://lists.apache.org/list.html?user@beam.apache.org">user@ archives&lt;/a> and &lt;a href="https://lists.apache.org/trends.html?user@beam.apache.org">statistics&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://stackoverflow.com/questions/tagged/apache-beam">&lt;code>apache-beam&lt;/code> StackOverflow tag&lt;/a>&lt;/li>
&lt;li>Git metrics for &lt;a href="https://github.com/apache/beam/graphs/contributors">Beam&lt;/a>&lt;/li>
&lt;li>Code reviews given and received on
&lt;a href="https://github.com/apache/beam/pulls">Beam&lt;/a>&lt;/li>
&lt;li>Clear areas of ownership (a runner, a DSL, IO connector, documentation,
etc.)&lt;/li>
&lt;li>Public events&lt;/li>
&lt;li>Firsthand PMC testimonials&lt;/li>
&lt;/ul>
&lt;p>The PMC has assembled the following set of guidelines for becoming a committer.&lt;/p>
&lt;h2 id="an-apache-beam-committer">An Apache Beam committer&amp;hellip;&lt;/h2>
&lt;h3 id="takes-many-forms">Takes many forms&lt;/h3>
&lt;p>There are many actions other than coding that build the trust we place in a
committer - code review, design discussion, user support, community outreach, improving
infrastructure, documentation, project management, etc.&lt;/p>
&lt;h3 id="knows-upholds-and-reinforces-the-apache-software-foundation-code-of-conduct">Knows, upholds, and reinforces the Apache Software Foundation code of conduct&lt;/h3>
&lt;p>See the &lt;a href="https://www.apache.org/foundation/policies/conduct.html">ASF
documentation&lt;/a>. In
particular, they manifestly strive to:&lt;/p>
&lt;ul>
&lt;li>Be open&lt;/li>
&lt;li>Be empathetic&lt;/li>
&lt;li>Be welcoming&lt;/li>
&lt;li>Be friendly&lt;/li>
&lt;li>Be patient&lt;/li>
&lt;li>Be collaborative&lt;/li>
&lt;li>Be inquisitive&lt;/li>
&lt;li>Be careful in the words that they choose&lt;/li>
&lt;/ul>
&lt;h3 id="knows-upholds-and-reinforces-the-responsibilities-of-an-apache-software-foundation-committer">Knows, upholds, and reinforces the responsibilities of an Apache Software Foundation committer&lt;/h3>
&lt;p>See the &lt;a href="https://www.apache.org/dev/committers.html#committer-responsibilities">ASF documentation&lt;/a>.&lt;/p>
&lt;ul>
&lt;li>They help create a product that will outlive the interest of any particular
volunteer (including themselves)&lt;/li>
&lt;li>They grow and maintain the health of the Apache community&lt;/li>
&lt;li>They help out with surrounding work, such as the website &amp;amp; documentation&lt;/li>
&lt;li>They help users&lt;/li>
&lt;li>They can be trusted to decide when code is ready for release, or when to ask
someone else to make the judgment&lt;/li>
&lt;li>They can be trusted to decide when to merge code (if a code contributor) or
when to ask someone else to make the judgment&lt;/li>
&lt;/ul>
&lt;h3 id="knows-upholds-and-reinforces-the-beam-communitys-practices">Knows, upholds, and reinforces the Beam community’s practices&lt;/h3>
&lt;ul>
&lt;li>They have a proven commitment to the project&lt;/li>
&lt;li>They share their intentions with the community&lt;/li>
&lt;li>They accept and integrate community feedback in their plans, designs,
code, etc.&lt;/li>
&lt;li>They earnestly try to make Beam better with their contributions&lt;/li>
&lt;li>In particular, if a code contributor:
&lt;ul>
&lt;li>They earnestly try to make Beam better with their own code&lt;/li>
&lt;li>They earnestly try to make Beam better with code review&lt;/li>
&lt;li>They accept and integrate feedback on their code&lt;/li>
&lt;li>They know, follow, and enforce Beam’s practices while
reviewing/merging code - style, documentation, testing, backward
compatibility, etc.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title>Contribute: Dependencies Guide</title><link>/contribute/dependencies/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/contribute/dependencies/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="dependencies-guide">Dependencies Guide&lt;/h1>
&lt;p>This document describes policies for keeping Beam dependencies up to date.&lt;/p>
&lt;p>Old dependencies cause user pain and can result in a system being unusable for some users. Many users do not use Beam in isolation and bundle other dependencies in the same deployment. These additional dependencies might pull in incompatible dependencies to user’s environment which can again result in broken Beam pipelines, sometimes with undefined behavior. To prevent this, users will have to update their deployment environment or worse yet may end up not being able to use Beam along with some of the other dependencies at all.&lt;/p>
&lt;p>Beam Java SDK’s Gradle build defines a set of top level &lt;a href="https://github.com/apache/beam/blob/master/buildSrc/src/main/groovy/org/apache/beam/gradle/BeamModulePlugin.groovy">dependencies&lt;/a> and various components (runners, IO connectors, etc) can choose to include these dependencies. Components usually use the versions defined at the top level but may choose to override these versions.&lt;/p>
&lt;p>If a component &lt;em>X&lt;/em> chooses to override the version of a dependency &lt;em>D&lt;/em> from &lt;em>a&lt;/em> to &lt;em>b&lt;/em> and another component &lt;em>Y&lt;/em> is incompatible with version &lt;em>b&lt;/em> of &lt;em>D&lt;/em>, deployment of a user that uses both components &lt;em>X&lt;/em> and &lt;em>Y&lt;/em> will end up in a broken state.&lt;/p>
&lt;p>A similar issue could arise if two dependencies of Beam depend on a common library but use incompatible versions of that library.&lt;/p>
&lt;p>Also, users might not use Beam in isolation, a user that depends on Beam as well as other libraries in the same environment might run into similar issues if Beam and the other library share a dependency while using incompatible versions.&lt;/p>
&lt;p>Beam Python SDK handles dependencies slightly differently, all dependencies are defined in a single &lt;a href="https://github.com/apache/beam/blob/master/sdks/python/setup.py">setup.py&lt;/a> file and are grouped. One of the groups describes required dependencies while other groups are for defining dependencies for various optional features. All Python modules have to use the versions of dependencies defined in &lt;a href="https://github.com/apache/beam/blob/master/sdks/python/setup.py">setup.py&lt;/a> file. Additionally, for most of the dependencies, Python SDK allows automatic upgrades upto next major version. Because of this setup, Python SDK currently does not run into component conflicts but other two forms of dependency conflicts described above can still occur.&lt;/p>
&lt;p>This picture can become even more complicated during runtime. Runner specific code might be incompatible with dependencies included by certain modules and if these dependencies leak into runtime, a pipeline might end up in a broken state.&lt;/p>
&lt;p>The overall issue is not unique to Beam and is well known in the industry as the &lt;a href="https://en.wikipedia.org/wiki/Dependency_hell">Diamond Dependency problem (or Dependency Hell)&lt;/a>.&lt;/p>
&lt;p>One common solution for the diamond dependency problem is &lt;a href="https://semver.org/">semantic versioning&lt;/a>. The basic idea is that dependencies are versioned in the form &lt;em>x.y.z&lt;/em> where &lt;em>x&lt;/em> is the &lt;em>major version&lt;/em>, &lt;em>y&lt;/em> is the &lt;em>minor version&lt;/em>, and &lt;em>z&lt;/em> is the &lt;em>patch version&lt;/em>. A major version change may be backwards incompatible and is expected to be rare. Minor and patch versions may be released more regularly but are expected to be backwards compatible. But in practice, important fixes (such as security patches) might get released in the form of minor or patch version updates and it will be healthy for the Beam project to depend on recently released minor versions of dependencies.&lt;/p>
&lt;h2 id="identifying-outdated-dependencies">Identifying outdated dependencies&lt;/h2>
&lt;p>A big part of keeping dependencies up to date involves identifying outdated dependencies of Beam that the community should try to upgrade.&lt;/p>
&lt;p>Beam currently executes a weekly Jenkins job that tries to identify outdated dependencies for various SDKs. This Jenkins job generates a weekly report that is shared in Beam dev list.&lt;/p>
&lt;p>In addition to this, Beam community members might identify other critical dependency updates that have to be manually performed. For example,&lt;/p>
&lt;ul>
&lt;li>A minor release of a dependency due to a critical security vulnerability.&lt;/li>
&lt;li>A dependency conflict that was was triggered by a minor version release of a Beam dependency (this does not apply to Java SDK that depends on exact minor versions of dependencies).&lt;/li>
&lt;/ul>
&lt;p>These kind of urgently required upgrades might not get automatically picked up by the Jenkins job for few months. So Beam community has to act to identify such issues and perform upgrades early.&lt;/p>
&lt;h2 id="jira-issue-automation">JIRA Issue Automation&lt;/h2>
&lt;p>In order to track the dependency upgrade process, JIRA tickets will be created per significant outdated dependency based on the report. A bot named &lt;em>Beam Jira Bot&lt;/em> was created for managing JIRA issues. Beam community agrees on the following policies that creates and updates issues.&lt;/p>
&lt;ul>
&lt;li>Title (summary) of the issues will be in the format &amp;ldquo;Beam Dependency Update Request: &amp;lt;dep_name&amp;gt;&amp;rdquo; where &amp;lt;dep_name&amp;gt; is the dependency artifact name.&lt;/li>
&lt;li>Issues will be created under the component &lt;em>&amp;ldquo;dependencies&amp;rdquo;&lt;/em>.&lt;/li>
&lt;li>Owners of dependencies will be notified by tagging the corresponding JIRA IDs mentioned in the ownership files in the issue description. See &lt;a href="https://github.com/apache/beam/blob/master/ownership/JAVA_DEPENDENCY_OWNERS.yaml">Java Dependency Owners&lt;/a> and &lt;a href="https://github.com/apache/beam/blob/master/ownership/PYTHON_DEPENDENCY_OWNERS.yaml">Python Dependency Owners&lt;/a> for current owners for Java SDK and Python SDK dependencies respectively.&lt;/li>
&lt;li>Automated tool will not create duplicate issues for the same dependency. Instead the tool will look for an existing JIRA when one has to be created for a given dependency and description of the JIRA will be updated with latest information, for example, current version of the dependency.&lt;/li>
&lt;li>If a Beam community member determines that a given dependency should not be upgraded the corresponding JIRA issue can be closed with a fix version specified.&lt;/li>
&lt;li>Automated tool will reopen a JIRA for a given dependency when one of following conditions is met:
&lt;ul>
&lt;li>Next SDK release is for a fix version mentioned in the JIRA.&lt;/li>
&lt;li>Six months &lt;strong>and&lt;/strong> three or more minor releases have passed since the JIRA was closed.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="upgrading-identified-outdated-dependencies">Upgrading identified outdated dependencies&lt;/h2>
&lt;p>After outdated dependencies are identified, Beam community has to act to upgrade the dependencies regularly. Beam community has agreed on following policies regarding upgrading dependencies.&lt;/p>
&lt;p>&lt;strong>Human readable reports on status of Beam dependencies are generated weekly by an automated Jenkins job and shared with the Beam community through the dev list.&lt;/strong>&lt;/p>
&lt;p>These reports should be concise and should highlight the cases where the community has to act on.&lt;/p>
&lt;p>&lt;strong>Beam components should define dependencies and their versions at the top level. There can be rare exceptions, but they should come with explanations.&lt;/strong>&lt;/p>
&lt;p>Components include various Beam runners, IO connectors, etc. Component-level dependency version declarations should only be performed in rare cases and should come with a comment explaining the reasoning for overriding the dependency. For example, dependencies specific to a runner that are unlikely to be utilized by other components might be defined at the runner.&lt;/p>
&lt;p>&lt;strong>A significantly outdated dependency (identified manually or through the automated Jenkins job) should result in a JIRA that is a blocker for the next release. Release manager may choose to push the blocker to the subsequent release or downgrade from a blocker.&lt;/strong>&lt;/p>
&lt;p>This will be a blocker for next major and minor version releases of Beam. JIRA may be created automatically or manually.&lt;/p>
&lt;p>For manually identified critical dependency updates, Beam community members should create blocking JIRAs for next release. In addition to this Beam community members may trigger patch releases for any critical dependency fixes that should be made available to users urgently.&lt;/p>
&lt;p>&lt;strong>Dependency declarations may identify owners that are responsible for upgrading respective dependencies.&lt;/strong>&lt;/p>
&lt;p>Owners can be mentioned in the yaml files. Blocking JIRAs will be initially assigned to these owners (if available). Release manager may choose to re-assign these JIRAs. A dependency may have more than one declared owner and in this case the JIRA will be assigned to one of the owners mentioned.&lt;/p>
&lt;p>&lt;strong>Dependencies of Java SDK components that may cause issues to other components if leaked should be vendored.&lt;/strong>&lt;/p>
&lt;p>&lt;a href="https://www.ardanlabs.com/blog/2013/10/manage-dependencies-with-godep.html">Vendoring&lt;/a> is the process of creating copies of third party dependencies. Combined with repackaging, vendoring allows Beam components to depend on third party libraries without causing conflicts to other components. Vendoring should be done in a case-by-case basis since this can increase the total number of dependencies deployed in user&amp;rsquo;s enviroment.&lt;/p>
&lt;h2 id="dependency-updates-and-backwards-compatibility">Dependency updates and backwards compatibility&lt;/h2>
&lt;p>Beam releases &lt;a href="/get-started/downloads/">adhere to&lt;/a> semantic versioning. Hence, community members should take care when updating dependencies. Minor version updates to dependencies should be backwards compatible in most cases. Some updates to dependencies though may result in backwards incompatible API or functionality changes to Beam. PR reviewers and committers should take care to detect any dependency updates that could potentially introduce backwards incompatible changes to Beam before merging and PRs that update dependencies should include a statement regarding this verification in the form of a PR comment. Dependency updates that result in backwards incompatible changes to non-experimental features of Beam should be held till the next major version release of Beam. Any exceptions to this policy should only occur in extreme cases (for example, due to a security vulnerability of an existing dependency that is only fixed in a subsequent major version) and should be discussed on the Beam dev list. Note that backwards incompatible changes to experimental features may be introduced in a minor version release.&lt;/p></description></item><item><title>Contribute: Get Help Contributing</title><link>/contribute/get-help/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/contribute/get-help/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="get-help-contributing">Get Help Contributing&lt;/h1>
&lt;p>If you have any trouble contributing, don&amp;rsquo;t give up!&lt;/p>
&lt;ul>
&lt;li>Check the &lt;a href="https://cwiki.apache.org/confluence/display/BEAM/Contributor+FAQ" target="_blank">FAQ on our developers&amp;rsquo; wiki &lt;img src="/images/external-link-icon.png" alt="External link to Beam developers' Wiki" width="14px" height="14px">&lt;/a>.&lt;/li>
&lt;li>Send email to the Beam developer community on &lt;a href="/community/contact-us">dev@beam.apache.org&lt;/a>&lt;/li>
&lt;li>Find someone to chat with in realtime at &lt;a href="/community/contact-us">#beam on Slack&lt;/a>.&lt;/li>
&lt;/ul></description></item><item><title>Contribute: Jira Priorities</title><link>/contribute/jira-priorities/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/contribute/jira-priorities/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="jira-priorities">Jira Priorities&lt;/h1>
&lt;h2 id="p0-outage">P0: Outage&lt;/h2>
&lt;p>&lt;em>Expectation&lt;/em>: Drop everything else and work continuously to resolve. An outage
means that some piece of infrastructure that the community relies on is down. A
P0 issue is &lt;em>more&lt;/em> urgent than simply blocking the next release.&lt;/p>
&lt;p>&lt;em>Example P0 issues&lt;/em>:&lt;/p>
&lt;ul>
&lt;li>the build is broken, halting all development&lt;/li>
&lt;li>the website is down&lt;/li>
&lt;li>a vulnerability requires a point release ASAP&lt;/li>
&lt;/ul>
&lt;h2 id="p1-critical">P1: Critical&lt;/h2>
&lt;p>&lt;em>Expectation&lt;/em>: Continuous status updates. P1 bugs should not be
unassigned. Most P1 bugs should block release.&lt;/p>
&lt;p>&lt;em>Example P1 issues&lt;/em>:&lt;/p>
&lt;ul>
&lt;li>data loss error&lt;/li>
&lt;li>important component is nonfunctional for important use cases&lt;/li>
&lt;li>major performance regression&lt;/li>
&lt;li>failing postcommit test&lt;/li>
&lt;li>flaky test&lt;/li>
&lt;/ul>
&lt;h2 id="p2-default">P2: Default&lt;/h2>
&lt;p>&lt;em>Expectation&lt;/em>: Most tickets fall into this priority. These can be planned and
executed by anyone who is interested. No special urgency is associated, but if
no action is taken on a P2 ticket for a long time, it indicates it is actually
just P3/nice-to-have.&lt;/p>
&lt;p>&lt;em>Example P2 issues&lt;/em>&lt;/p>
&lt;ul>
&lt;li>typical feature request&lt;/li>
&lt;li>bug that affects some use cases but don&amp;rsquo;t make a component nonfunctional&lt;/li>
&lt;li>ignored (&amp;ldquo;sickbayed&amp;rdquo;) test&lt;/li>
&lt;/ul>
&lt;h2 id="p3-nice-to-have">P3: Nice-to-have&lt;/h2>
&lt;p>&lt;em>Expectation&lt;/em>: Nice-to-have improvements.&lt;/p>
&lt;p>&lt;em>Example P3 issues&lt;/em>&lt;/p>
&lt;ul>
&lt;li>feature request that is nice-to-have&lt;/li>
&lt;li>ticket filed as P2 that no one finds time to work on&lt;/li>
&lt;/ul>
&lt;h2 id="p4">P4&lt;/h2>
&lt;p>&lt;em>Expectation&lt;/em>: Nice-to-have improvements that are also very small and easy.
Usually it is quicker to just fix them than to file a bug, but the Jira
can be referenced by a pull request and shows up in release notes.&lt;/p>
&lt;p>&lt;em>Example P4 issues&lt;/em>&lt;/p>
&lt;ul>
&lt;li>spelling errors in comments or code&lt;/li>
&lt;/ul></description></item><item><title>Contribute: Post-commit policies details</title><link>/contribute/postcommits-policies-details/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/contribute/postcommits-policies-details/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="post-commit-policies-details">Post-commit policies details&lt;/h1>
&lt;p>A post-commit test failure means that there is a bug in the code. The longer the
bug exists, the harder it is to fix it due to ongoing code contributions. As a
result, we want to fix bugs quickly. The Beam community&amp;rsquo;s post-commit test
policies help keep our code and test results in a good state.&lt;/p>
&lt;h2 id="rollback_first">Rollback first&lt;/h2>
&lt;p>Beam uses a &amp;ldquo;rollback first&amp;rdquo; approach: the first action to resolve a test
failure is to rollback the culprit code change. The two main benefits of this
approach are short implementation time and high reliability. When we rollback
first, we quickly return to a previously verified good state.&lt;/p>
&lt;p>At a high level, this approach consists of the following steps:&lt;/p>
&lt;ol>
&lt;li>Revert the culprit commit.&lt;/li>
&lt;li>Re-run the post-commit tests to verify the tests pass.&lt;/li>
&lt;li>Push the revert commit.&lt;/li>
&lt;/ol>
&lt;p>For background on this policy, see the
&lt;a href="https://lists.apache.org/thread.html/3bb4aa777751da2e2d7e22666aa6a2e18ae31891cb09d91718b75e74@%3Cdev.beam.apache.org%3E">mailing list thread&lt;/a>
and &lt;a href="https://docs.google.com/document/d/1sczGwnCvdHiboVajGVdnZL0rfnr7ViXXAebBAf_uQME/edit">design doc&lt;/a>.&lt;/p>
&lt;h2 id="failing_test_is_critical_bug">A failing test is a critical/P1 issue&lt;/h2>
&lt;p>It is difficult to properly verify new changes made on top of buggy code. In
some cases, adding additional code can make the problem worse. To avoid this
situation, fixing failing tests is our highest priority.&lt;/p>
&lt;h2 id="flake_is_failing">A flaky test is a critical/P1 issue&lt;/h2>
&lt;p>Flaky tests are considered failing tests, and fixing a flaky test is a
critical/P1 issue.&lt;/p>
&lt;p>Flaky tests are tests that randomly succeed or fail while using the same code
version. Flaky test failures are one of the most dangerous types of failures
because they are easy to ignore &amp;ndash; another run of the flaky test might pass
successfully. However, these failures can hide real bugs and flaky tests often
slowly accumulate. Someone must repeatedly triage the failures, and flaky tests
are often the hardest ones to fix.&lt;/p>
&lt;p>Flaky tests do not provide a reliable quality signal, so it is important to
quickly fix the flakiness. If a fix will take awhile to implement, it is safer
to disable the test until the fix is ready.&lt;/p>
&lt;p>Martin Fowler has a good &lt;a href="https://martinfowler.com/articles/nonDeterminism.html">article&lt;/a>
about non-determinism in tests.&lt;/p>
&lt;h2 id="remove_flake">Flaky tests must be fixed or removed&lt;/h2>
&lt;p>Flaky tests do not provide a reliable quality signal, which has a harmful effect
on all tests and can lead to a loss of trust in our test suite. As a result,
contributors might start to ignore test failures.&lt;/p>
&lt;p>We want everyone to trust our tests, so it is important to diligently fix all
flaky tests. If it is not possible to fix a flaky test, we must remove the test.&lt;/p>
&lt;h2 id="precommit_for_postcommit">Add new pre-commit tests as part of a post-commit fix&lt;/h2>
&lt;p>Post-commit tests are an important fail-safe, but we want to fail fast. Failing
fast means that we want to detect bugs in pre-commit tests, and &lt;em>not&lt;/em> in
post-commit tests.&lt;/p>
&lt;p>When you implement a fix for a post-commit test failure, add a new pre-commit
test that will detect similar failures in the future. For example, you can
implement a new unit test that covers a problematic code branch.&lt;/p>
&lt;h2 id="inform_community">Inform the community if Beam breaks downstream projects&lt;/h2>
&lt;p>There are multiple external projects depending on Beam which contain tests that are
outside of Beam repository. For example, Dataflow, Samza runner, and IBM Streams.&lt;/p>
&lt;p>When an external project encounters an issue caused by (a PR) in Beam
and, in consequence, requests for a change in the Beam repository,
the first thing is to create a JIRA entry that addresses
the following three questions:&lt;/p>
&lt;ol>
&lt;li>Descriptions on what the issue is.&lt;/li>
&lt;li>Does a revert fix it? (Or it is supposed to be fixed differently)&lt;/li>
&lt;li>Is a revert the best way to fix it?&lt;/li>
&lt;/ol>
&lt;p>It is encouraged to bring the discussion to the dev mailing list as well.
Ideally, after the incident, we prefer to have discussions regarding
whether we should extend tests in Beam repository, with the goal of
catching similar issues early in the future.&lt;/p></description></item><item><title>Contribute: Post-commit tests policies</title><link>/contribute/postcommits-policies/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/contribute/postcommits-policies/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="post-commit-tests-policies">Post-commit tests policies&lt;/h1>
&lt;p>Post-commit tests validate that Beam works correctly in a live environment. The
tests also catch errors that are hard to predict in the design and
implementation stages.&lt;/p>
&lt;p>Even though post-commit tests run after the code is merged into the repository,
it is important that the tests pass reliably. Jenkins executes post-commit tests
against the HEAD of the &lt;code>master&lt;/code> branch. If post-commit tests fail, there is a
problem with the HEAD build. In addition, post-commit tests are time consuming
to run, and it is often hard to triage test failures.&lt;/p>
&lt;h2 id="policies">Policies&lt;/h2>
&lt;p>To ensure that Beam&amp;rsquo;s post-commit tests are reliable and healthy, the Beam
community follows these post-commit test policies:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="/contribute/postcommits-policies-details/index.html#rollback_first">Rollback first&lt;/a>&lt;/li>
&lt;li>&lt;a href="/contribute/postcommits-policies-details/index.html#failing_test_is_critical_bug">A failing test is a critical bug&lt;/a>&lt;/li>
&lt;li>&lt;a href="/contribute/postcommits-policies-details/index.html#flake_is_failing">A flaky test is a critical bug&lt;/a>&lt;/li>
&lt;li>&lt;a href="/contribute/postcommits-policies-details/index.html#remove_flake">Flaky tests must either be fixed or removed&lt;/a>&lt;/li>
&lt;li>&lt;a href="/contribute/postcommits-policies-details/index.html#precommit_for_postcommit">Fixes for post-commit failures should include a corresponding new pre-commit test&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="post-commit-test-failure-scenarios">Post-commit test failure scenarios&lt;/h2>
&lt;p>When a post-commit test fails, follow the provided steps for your situation.&lt;/p>
&lt;h3 id="found-failing-test">I found a test failure&lt;/h3>
&lt;ol>
&lt;li>Create a &lt;a href="https://s.apache.org/beam-test-failure">JIRA issue&lt;/a> and assign it to yourself.&lt;/li>
&lt;li>Do high level triage of the failure.&lt;/li>
&lt;li>&lt;a href="/contribute/postcommits-guides/index.html#find_specialist">Assign the JIRA issue to a relevant person&lt;/a>.&lt;/li>
&lt;/ol>
&lt;h3 id="assigned-failing-test">I was assigned a JIRA issue for a test failure&lt;/h3>
&lt;ol>
&lt;li>&lt;a href="/contribute/postcommits-guides/index.html#rollback">Rollback the culprit change&lt;/a>.&lt;/li>
&lt;li>If you determine that rollback will take longer than 8 hours, &lt;a href="/contribute/postcommits-guides/index.html#disabling">disable the
test temporarily&lt;/a> while you rollback or create a
fix.&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>Note: Rollback is always the first course of action. If a fix is trivial,
open a pull request with the proposed fix while doing rollback.&lt;/p>
&lt;/blockquote>
&lt;h3 id="pr-rolled-back">My change was rolled back due to a test failure&lt;/h3>
&lt;p>After rollback there is time for deeper investigation. Start by looking at the
JIRA issue to see the background information for the rollback. These scenarios
are all common:&lt;/p>
&lt;ul>
&lt;li>Your change contained a bug.&lt;/li>
&lt;li>Your change exposed an existing bug.&lt;/li>
&lt;li>Your change exposed a bad test (flaky, overspecified, etc).&lt;/li>
&lt;/ul>
&lt;p>&lt;em>These are all valid reasons for rollback. Maintaining clear signal is the
highest priority.&lt;/em>&lt;/p>
&lt;p>The high level steps are the same:&lt;/p>
&lt;ol>
&lt;li>Create a fix and re-run the post-commit tests.&lt;/li>
&lt;li>Implement new pre-commit tests that will catch similar failures
before future code is merged into the repository.&lt;/li>
&lt;li>Open a new PR that contains your fix and the new pre-commit tests.&lt;/li>
&lt;/ol>
&lt;p>If the bug is not in your code, here is how to &amp;ldquo;create a fix&amp;rdquo;:&lt;/p>
&lt;ol>
&lt;li>File a ticket for the existing bug, if it does not already exist.
Remember that
&lt;a href="/contribute/postcommits-policies-details/index.html#flake_is_failing">a flaky test is a critical bug&lt;/a>. Other
bad tests are similar: they may fail for arbitrary reasons having nothing
to do with what is being tested, making our signal unreliable.&lt;/li>
&lt;li>Mark the problematic test to be skipped, with a link to the JIRA ticket.&lt;/li>
&lt;/ol>
&lt;h2 id="useful-links">Useful links&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://cwiki.apache.org/confluence/display/BEAM/Contribution+Testing+Guide#ContributionTestingGuide-Bestpracticesforwritingtests">Best practices for writing tests&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="references">References&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://lists.apache.org/thread.html/3bb4aa777751da2e2d7e22666aa6a2e18ae31891cb09d91718b75e74@%3Cdev.beam.apache.org%3E">Keeping post-commit tests green&lt;/a>
mailing list proposal thread.&lt;/li>
&lt;/ol></description></item><item><title>Contribute: Post-commit tests processes guides</title><link>/contribute/postcommits-guides/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/contribute/postcommits-guides/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="post-commit-test-task-guides">Post-commit test task guides&lt;/h1>
&lt;p>These guides provide steps for common post-commit test failure tasks.&lt;/p>
&lt;h2 id="find_specialist">Finding someone to triage a post-commit test failure&lt;/h2>
&lt;p>To find the proper person to triage a test failure, you can use these
suggestions:&lt;/p>
&lt;ol>
&lt;li>If you can triage it yourself, go for it.&lt;/li>
&lt;li>Look at the GitHub blame for the files with problematic code.&lt;/li>
&lt;li>Ask in the &lt;a href="https://the-asf.slack.com/messages/C9H0YNP3P/apps/A0F7VRFKN/">Beam Slack chat&lt;/a>.&lt;/li>
&lt;li>Write to the dev list: &lt;a href="mailto:dev@beam.apache.org">dev@beam.apache.org&lt;/a>&lt;/li>
&lt;/ol>
&lt;h2 id="rollback">Rolling back a commit&lt;/h2>
&lt;p>Rolling back is usually the fastest way to fix a failing test. However it is
is often inconvenient for the original author. To help the author fix the
issue, follow these steps when you rollback someone&amp;rsquo;s change.&lt;/p>
&lt;ol>
&lt;li>Rollback the PR (or individual commit of the PR). The rollback PR should be green except in rare cases.&lt;/li>
&lt;li>Create a JIRA issue that contains the following information:
&lt;ul>
&lt;li>the reason for the rollback&lt;/li>
&lt;li>a link to the test failure&amp;rsquo;s JIRA issue&lt;/li>
&lt;li>triage information&lt;/li>
&lt;li>any other relevant details&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Assign the new JIRA issue to the original PR author.&lt;/li>
&lt;li>Consider re-opening the JIRA issue associated with the original PR (if
there is one).&lt;/li>
&lt;li>Send a notification email with information about the rollback, links to the
original PR and the rollback PR, and the reasons for the rollback to:
&lt;ul>
&lt;li>&lt;a href="mailto:dev@beam.apache.org">dev@beam.apache.org&lt;/a>&lt;/li>
&lt;li>the original PR author and the committer of the PR&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Close the test failure JIRA issue. Your work is done here!&lt;/li>
&lt;/ol>
&lt;h2 id="disabling">Disabling a failing test&lt;/h2>
&lt;p>If a test fails, our first priority is to rollback the problematic code and fix
the issue. However, if both: rollback and fix will take awhile to implement, it
is safer to temporarily disable the test until the fix is ready.&lt;/p>
&lt;p>Use caution when deciding to disable a test. When tests are disabled,
contributors are no longer developing on top of fully tested code. If you decide
to disable a test, use the following guidelines:&lt;/p>
&lt;ul>
&lt;li>Notify the &lt;a href="mailto:dev@beam.apache.org">dev@beam.apache.org&lt;/a> mailing list. Describe the problem and let
everyone know which test you are disabling.&lt;/li>
&lt;li>Implement the fix and get the test back online as soon as possible.&lt;/li>
&lt;/ul>
&lt;p>While the test is disabled, contributors should not push code to the failing
test&amp;rsquo;s coverage area. The code area is not properly tested until you fix the
test.&lt;/p></description></item><item><title>Contribute: Pre-commit Slowness Triage Guide</title><link>/contribute/precommit-triage-guide/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/contribute/precommit-triage-guide/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="pre-commit-slowness-triage-guide">Pre-commit Slowness Triage Guide&lt;/h1>
&lt;p>Beam pre-commit jobs are suites of tests run automatically on Jenkins build
machines for each pull request (PR) submitted to
&lt;a href="https://github.com/apache/beam">apache/beam&lt;/a>. For more information and the
difference between pre-commits and post-commits, see
&lt;a href="https://cwiki.apache.org/confluence/display/BEAM/Contribution+Testing+Guide">testing&lt;/a>.&lt;/p>
&lt;h2 id="what-are-fast-pre-commits">What are fast pre-commits?&lt;/h2>
&lt;p>Pre-commit tests are required to pass before a pull request (PR) is merged.
When these tests are slow they slow down Beam&amp;rsquo;s development process.
The aim is to have 95% of pre-commit jobs complete within 30 minutes
(failing or passing).&lt;/p>
&lt;p>Technically, the 95th percentile of running time should be below 30 minutes over
the past 4 weeks, where running time is the duration of time the job spends in
the Jenkins queue + the actual time it spends running.&lt;/p>
&lt;h2 id="determining-slowness">Determining Slowness&lt;/h2>
&lt;p>There are two main signs of slowness:&lt;/p>
&lt;ol>
&lt;li>Pre-commit jobs are timing out after 30 minutes. This can be determined from
the console log of a job.&lt;/li>
&lt;li>Pre-commits aren&amp;rsquo;t timing out, but the total wait time for pre-commit results
is &amp;gt;30m.&lt;/li>
&lt;/ol>
&lt;h3 id="pre-commit-dashboard">Pre-commit Dashboard&lt;/h3>
&lt;p>The Beam Community Metrics site contains a &lt;a href="http://metrics.beam.apache.org/d/_TNndF2iz/pre-commit-tests">Pre-Commit
Tests&lt;/a> dashboard showing
job timing trends. You can modify the time window (defaults to 7 days) or filter
down to a specific test suite by clicking on it.&lt;/p>
&lt;p>&lt;img src="/images/precommit_dashboard.png" alt="example pre-commit duration dashboard">&lt;/p>
&lt;h2 id="triage-process">Triage Process&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://issues.apache.org/jira/issues/?jql=project%20%3D%20BEAM%20AND%20status%20in%20(Open%2C%20%22In%20Progress%22%2C%20Reopened)%20AND%20labels%20%3D%20precommit%20ORDER%20BY%20priority%20DESC%2C%20updated%20DESC">Search for existing
issues&lt;/a>&lt;/li>
&lt;li>Create a new issue if needed: &lt;a href="https://issues.apache.org/jira/issues">Apache
JIRA&lt;/a>&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>Project: Beam&lt;/li>
&lt;li>Components: testing, anything else relevant&lt;/li>
&lt;li>Label: precommit&lt;/li>
&lt;li>Reference this page in the description.&lt;/li>
&lt;/ul>
&lt;ol>
&lt;li>Determine where the slowness is coming from and identify issues. Open
additional issues if needed (such as for multiple issues).&lt;/li>
&lt;li>Assign the issue as appropriate, e.g., to the test&amp;rsquo;s or PR&amp;rsquo;s author.&lt;/li>
&lt;/ol>
&lt;h2 id="resolution">Resolution&lt;/h2>
&lt;p>It is important that we quickly fix slow pre-commit tests. See &lt;a href="/contribute/precommit-policies/">pre-commit test
policies&lt;/a> for details.&lt;/p>
&lt;h2 id="possible-causes-and-solutions">Possible Causes and Solutions&lt;/h2>
&lt;p>This section lists some starting points for fixing pre-commit slowness.&lt;/p>
&lt;h3 id="resource-exhaustion">Resource Exhaustion&lt;/h3>
&lt;p>Have a look at the graphs in the Jupyter notebook. Does the rise in total
duration match the rise in queuing time? If so, the slowness might be unrelated
to this specific pre-commit job.&lt;/p>
&lt;p>Example of when total and queuing durations rise and fall together (mostly):
&lt;img src="/images/precommit_graph_queuing_time.png" alt="graph of pre-commit times">&lt;/p>
&lt;p>Since Jenkins machines are a limited resource, other jobs can
affect pre-commit queueing times. Try to figure out if other jobs have been
recently slower, increased in frequency, or new jobs have been introduced.&lt;/p>
&lt;p>Another option is to look at adding more Jenkins machines.&lt;/p>
&lt;h3 id="slow-individual-tests">Slow individual tests&lt;/h3>
&lt;p>Sometimes a pre-commit job is slowed down due to one or more tests. One way of
determining if this is the case is by looking at individual test timings.&lt;/p>
&lt;p>Where to find individual test timings:&lt;/p>
&lt;ul>
&lt;li>Look at the &lt;code>Gradle Build Scan&lt;/code> link on the pre-commit job&amp;rsquo;s Jenkins page.
This page will contain individual test timings for Java tests only (2018-08).&lt;/li>
&lt;li>Look at the &lt;code>Test Result&lt;/code> link on the pre-commit job&amp;rsquo;s Jenkins page. This
should be available for Java and Python tests (2018-08).&lt;/li>
&lt;/ul>
&lt;p>Sometimes tests can be made faster by refactoring. A test that spends a lot of
time waiting (such as an integration test) could be made to run concurrently with
the other tests.&lt;/p>
&lt;p>If a test is determined to be too slow to be part of pre-commit tests, it should
be removed from pre-commit and placed in post-commit instead. In addition,
ensure that the code covered by the removed test is &lt;a href="/contribute/postcommits-policies-details/#precommit_for_postcommit">covered by a unit test in
pre-commit&lt;/a>.&lt;/p>
&lt;h3 id="slow-integration-tests">Slow integration tests&lt;/h3>
&lt;p>Integration test slowdowns may be caused by dependent services.&lt;/p>
&lt;h2 id="references">References&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://docs.google.com/document/d/1udtvggmS2LTMmdwjEtZCcUQy6aQAiYTI3OrTP8CLfJM/edit?usp=sharing">Beam Fast Precommits design doc&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Contribute: Pre-commit Test Policies</title><link>/contribute/precommit-policies/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/contribute/precommit-policies/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="pre-commit-test-policies">Pre-commit test policies&lt;/h1>
&lt;h2 id="definitions">Definitions&lt;/h2>
&lt;ul>
&lt;li>Pre-commit test - Any single test in a pre-commit test suite.&lt;/li>
&lt;li>Pre-commit test suite - A collection of pre-commit tests that have a common
denominator. A test suite runs in a single Jenkins job. Currently, suites are
grouped by SDK languages, e.g., Python, Java, and Go.&lt;/li>
&lt;/ul>
&lt;h2 id="policies">Policies&lt;/h2>
&lt;h3 id="pull-requests">Pull Requests&lt;/h3>
&lt;ul>
&lt;li>A PR must pass pre-commit tests before being committed to the main Beam repo.
&lt;ul>
&lt;li>The relevant pre-commit test suites are automatically launched according to
PR contents.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="problems">Problems&lt;/h3>
&lt;h4 id="breakage">Breakage&lt;/h4>
&lt;p>Breakage is when one or more tests in a pre-commit test suite fails or
is flaky (occasionally fails).&lt;/p>
&lt;ul>
&lt;li>Breakages should be fixed within 8 hours.&lt;/li>
&lt;/ul>
&lt;h4 id="slowness">Slowness&lt;/h4>
&lt;p>Slowness is when the total time to run a pre-commit suite exceeds 30 minutes*,
including the time the job spends in the Jenkins queue.&lt;/p>
&lt;ul>
&lt;li>Slowness should be fixed within 24 hours.&lt;/li>
&lt;/ul>
&lt;p>* See the &lt;a href="/contribute/precommit-triage-guide/">Pre-commit Slowness Triage
Guide&lt;/a> for a precise definition of slowness
and for information on dealing with slowness.&lt;/p>
&lt;h3 id="problem-resolution">Problem Resolution&lt;/h3>
&lt;p>For any problem, the options are, one of:&lt;/p>
&lt;ul>
&lt;li>Roll back the culprit PR.&lt;/li>
&lt;li>Roll out a fix within 24 hours.&lt;/li>
&lt;li>Disable the slow test or feature temporarily (make sure there&amp;rsquo;s a tracking
issue to re-enable it).&lt;/li>
&lt;/ul></description></item><item><title>Contribute: PTransform Style Guide</title><link>/contribute/ptransform-style-guide/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/contribute/ptransform-style-guide/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="ptransform-style-guide">PTransform Style Guide&lt;/h1>
&lt;p>&lt;em>A style guide for writers of new reusable PTransforms.&lt;/em>&lt;/p>
&lt;nav id="TableOfContents">
&lt;ul>
&lt;li>&lt;a href="#language-neutral-considerations">Language-neutral considerations&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#consistency">Consistency&lt;/a>&lt;/li>
&lt;li>&lt;a href="#exposing-a-ptransform-vs-something-else">Exposing a PTransform vs. something else&lt;/a>&lt;/li>
&lt;li>&lt;a href="#naming">Naming&lt;/a>&lt;/li>
&lt;li>&lt;a href="#configuration">Configuration&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#what-goes-into-configuration-vs-input-collection">What goes into configuration vs. input collection&lt;/a>&lt;/li>
&lt;li>&lt;a href="#what-parameters-to-expose">What parameters to expose&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#error-handling">Error handling&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#transform-configuration-errors">Transform configuration errors&lt;/a>&lt;/li>
&lt;li>&lt;a href="#runtime-errors-and-data-consistency">Runtime errors and data consistency&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#performance">Performance&lt;/a>&lt;/li>
&lt;li>&lt;a href="#documentation">Documentation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#logging">Logging&lt;/a>&lt;/li>
&lt;li>&lt;a href="#testing">Testing&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#testing-the-transforms-run-time-behavior">Testing the transform&amp;rsquo;s run-time behavior&lt;/a>&lt;/li>
&lt;li>&lt;a href="#testing-transform-construction-and-validation">Testing transform construction and validation&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#compatibility">Compatibility&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#java-specific-considerations">Java specific considerations&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#api">API&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#choosing-types-of-input-and-output-pcollections">Choosing types of input and output PCollection&amp;rsquo;s&lt;/a>&lt;/li>
&lt;li>&lt;a href="#transforms-with-multiple-output-collections">Transforms with multiple output collections&lt;/a>&lt;/li>
&lt;li>&lt;a href="#fluent-builders-for-configuration">Fluent builders for configuration&lt;/a>&lt;/li>
&lt;li>&lt;a href="#transforms-with-type-parameters">Transforms with type parameters&lt;/a>&lt;/li>
&lt;li>&lt;a href="#injecting-user-specified-behavior">Injecting user-specified behavior&lt;/a>&lt;/li>
&lt;li>&lt;a href="#packaging-a-family-of-transforms">Packaging a family of transforms&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#behavior">Behavior&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#immutability">Immutability&lt;/a>&lt;/li>
&lt;li>&lt;a href="#serialization">Serialization&lt;/a>&lt;/li>
&lt;li>&lt;a href="#validation">Validation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#coders">Coders&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;h2 id="language-neutral-considerations">Language-neutral considerations&lt;/h2>
&lt;h3 id="consistency">Consistency&lt;/h3>
&lt;p>Be consistent with prior art:&lt;/p>
&lt;ul>
&lt;li>Please read the &lt;a href="/contribute/">contribution guide&lt;/a>.&lt;/li>
&lt;li>If there is already a similar transform in some SDK, make the API of your transform similar, so that users&amp;rsquo; experience with one of them will transfer to the other. This applies to transforms in the same-language SDK and different-language SDKs.
&lt;em>Exception:&lt;/em> pre-existing transforms that clearly violate the current style guide for the sole reason that they were developed before this guide was ratified. In this case, the style guide takes priority over consistency with the existing transform.&lt;/li>
&lt;li>When there is no existing similar transform, stay within what is idiomatic within your language of choice (e.g. Java or Python).&lt;/li>
&lt;/ul>
&lt;h3 id="exposing-a-ptransform-vs-something-else">Exposing a PTransform vs. something else&lt;/h3>
&lt;p>So you want to develop a library that people will use in their Beam pipelines - a connector to a third-party system, a machine learning algorithm, etc. How should you expose it?&lt;/p>
&lt;p>Do:&lt;/p>
&lt;ul>
&lt;li>Expose every major data-parallel task accomplished by your library as a composite &lt;code>PTransform&lt;/code>. This allows the structure of the transform to evolve transparently to the code that uses it: e.g. something that started as a &lt;code>ParDo&lt;/code> can become a more complex transform over time.&lt;/li>
&lt;li>Expose large, non-trivial, reusable sequential bits of the transform&amp;rsquo;s code, which others might want to reuse in ways you haven&amp;rsquo;t anticipated, as a regular function or class library. The transform should simply wire this logic together. As a side benefit, you can unit-test those functions and classes independently.
&lt;em>Example:&lt;/em> when developing a transform that parses files in a custom data format, expose the format parser as a library; likewise for a transform that implements a complex machine learning algorithm, etc.&lt;/li>
&lt;li>In some cases, this may include Beam-specific classes, such as &lt;code>CombineFn&lt;/code>, or nontrivial &lt;code>DoFn&lt;/code>s (those that are more than just a single &lt;code>@ProcessElement&lt;/code> method).
As a rule of thumb: expose these if you anticipate that the full packaged &lt;code>PTransform&lt;/code> may be insufficient for a user&amp;rsquo;s needs and the user may want to reuse the lower-level primitive.&lt;/li>
&lt;/ul>
&lt;p>Do not:&lt;/p>
&lt;ul>
&lt;li>Do not expose the exact way the transform is internally structured. E.g.: the public API surface of your library &lt;em>usually&lt;/em> (with exception of the last bullet above) should not expose &lt;code>DoFn&lt;/code>, concrete &lt;code>Source&lt;/code> or &lt;code>Sink&lt;/code> classes, etc., in order to avoid presenting users with a confusing choice between applying the &lt;code>PTransform&lt;/code> or using the &lt;code>DoFn&lt;/code>/&lt;code>Source&lt;/code>/&lt;code>Sink&lt;/code>.&lt;/li>
&lt;/ul>
&lt;h3 id="naming">Naming&lt;/h3>
&lt;p>Do:&lt;/p>
&lt;ul>
&lt;li>Respect language-specific naming conventions, e.g. name classes in &lt;code>PascalCase&lt;/code> in Java and Python, functions in &lt;code>camelCase&lt;/code> in Java but &lt;code>snake_case&lt;/code> in Python, etc.&lt;/li>
&lt;li>Name factory functions so that either the function name is a verb, or referring to the transform reads like a verb: e.g. &lt;code>MongoDbIO.read()&lt;/code>, &lt;code>Flatten.iterables()&lt;/code>.&lt;/li>
&lt;li>In typed languages, name &lt;code>PTransform&lt;/code> classes also like verbs (e.g.: &lt;code>MongoDbIO.Read&lt;/code>, &lt;code>Flatten.Iterables&lt;/code>).&lt;/li>
&lt;li>Name families of transforms for interacting with a storage system using the word &amp;ldquo;IO&amp;rdquo;: &lt;code>MongoDbIO&lt;/code>, &lt;code>JdbcIO&lt;/code>.&lt;/li>
&lt;/ul>
&lt;p>Do not:&lt;/p>
&lt;ul>
&lt;li>Do not use words &lt;code>transform&lt;/code>, &lt;code>source&lt;/code>, &lt;code>sink&lt;/code>, &lt;code>reader&lt;/code>, &lt;code>writer&lt;/code>, &lt;code>bound&lt;/code>, &lt;code>unbound&lt;/code> in &lt;code>PTransform&lt;/code> class names (note: &lt;code>bounded&lt;/code> and &lt;code>unbounded&lt;/code> are fine when referring to whether a &lt;code>PCollection&lt;/code> is bounded or unbounded): these words are redundant, confusing, obsolete, or name an existing different concept in the SDK.&lt;/li>
&lt;/ul>
&lt;h3 id="configuration">Configuration&lt;/h3>
&lt;h4 id="what-goes-into-configuration-vs-input-collection">What goes into configuration vs. input collection&lt;/h4>
&lt;ul>
&lt;li>&lt;strong>Into input &lt;code>PCollection&lt;/code>:&lt;/strong> anything of which there may be a very large number of instances (if there can be &amp;gt;1000 of it, it should be in a &lt;code>PCollection&lt;/code>), or which is potentially not known at pipeline construction time.
E.g.: records to be processed or written to a third-party system; filenames to be read.
Exception: sometimes Beam APIs require things to be known at pipeline construction time - e.g. the &lt;code>Bounded&lt;/code>/&lt;code>UnboundedSource&lt;/code> API. If you absolutely have to use such an API, its input can of course go only into transform configuration.&lt;/li>
&lt;li>&lt;strong>Into transform configuration:&lt;/strong> what is constant throughout the transform (including &lt;code>ValueProvider&lt;/code>s) and does not depend on the contents of the transform&amp;rsquo;s input &lt;code>PCollection&lt;/code>s.
E.g.: a database query or connection string; credentials; a user-specified callback; a tuning parameter.
One advantage of putting a parameter into transform configuration is, it can be validated at pipeline construction time.&lt;/li>
&lt;/ul>
&lt;h4 id="what-parameters-to-expose">What parameters to expose&lt;/h4>
&lt;p>Do:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Expose&lt;/strong> parameters that are necessary to compute the output.&lt;/li>
&lt;/ul>
&lt;p>Do not:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Do not expose&lt;/strong> tuning knobs, such as batch sizes, connection pool sizes, unless it&amp;rsquo;s impossible to automatically supply or compute a good-enough value (i.e., unless you can imagine a reasonable person reporting a bug about the absence of this knob).&lt;/li>
&lt;li>When developing a connector to a library that has many parameters, &lt;strong>do not mirror each parameter&lt;/strong> of the underlying library - if necessary, reuse the underlying library&amp;rsquo;s configuration class and let user supply a whole instance. Example: &lt;code>JdbcIO&lt;/code>.
&lt;em>Exception 1:&lt;/em> if some parameters of the underlying library interact with Beam semantics non-trivially, then expose them. E.g. when developing a connector to a pub/sub system that has a &amp;ldquo;delivery guarantee&amp;rdquo; parameter for publishers, expose the parameter but prohibit values incompatible with the Beam model (at-most-once and exactly-once).
&lt;em>Exception 2:&lt;/em> if the underlying library&amp;rsquo;s configuration class is cumbersome to use - e.g. does not declare a stable API, exposes problematic transitive dependencies, or does not obey &lt;a href="https://semver.org/">semantic versioning&lt;/a> - in this case, it is better to wrap it and expose a cleaner and more stable API to users of the transform.&lt;/li>
&lt;/ul>
&lt;h3 id="error-handling">Error handling&lt;/h3>
&lt;h4 id="transform-configuration-errors">Transform configuration errors&lt;/h4>
&lt;p>Detect errors early. Errors can be detected at the following stages:&lt;/p>
&lt;ul>
&lt;li>(in a compiled language) compilation of the source code of a user&amp;rsquo;s pipeline&lt;/li>
&lt;li>constructing or setting up the transform&lt;/li>
&lt;li>applying the transform in a pipeline&lt;/li>
&lt;li>running the pipeline&lt;/li>
&lt;/ul>
&lt;p>For example:&lt;/p>
&lt;ul>
&lt;li>In a typed language, take advantage of compile-time error checking by making the API of the transform strongly-typed:
&lt;ul>
&lt;li>&lt;strong>Strongly-typed configuration:&lt;/strong> e.g. in Java, a parameter that is a URL should use the &lt;code>URL&lt;/code> class, rather than the &lt;code>String&lt;/code> class.&lt;/li>
&lt;li>&lt;strong>Strongly-typed input and output:&lt;/strong> e.g. a transform that writes to Mongo DB should take a &lt;code>PCollection&amp;lt;Document&amp;gt;&lt;/code> rather than &lt;code>PCollection&amp;lt;String&amp;gt;&lt;/code> (assuming it is possible to provide a &lt;code>Coder&lt;/code> for &lt;code>Document&lt;/code>).&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Detect invalid values of individual parameters in setter methods.&lt;/li>
&lt;li>Detect invalid combinations of parameters in the transform&amp;rsquo;s validate method.&lt;/li>
&lt;/ul>
&lt;h4 id="runtime-errors-and-data-consistency">Runtime errors and data consistency&lt;/h4>
&lt;p>Favor data consistency above everything else. Do not mask data loss or corruption. If data loss can&amp;rsquo;t be prevented, fail.&lt;/p>
&lt;p>Do:&lt;/p>
&lt;ul>
&lt;li>In a &lt;code>DoFn&lt;/code>, retry transient failures if the operation is likely to succeed on retry. Perform such retries at the narrowest scope possible in order to minimize the amount of retried work (i.e. ideally at the level of the RPC library itself, or at the level of directly sending the failing RPC to a third-party system). Otherwise, let the runner retry work at the appropriate level of granularity for you (different runners may have different retry behavior, but most of them do &lt;em>some&lt;/em> retrying).&lt;/li>
&lt;li>If the transform has side effects, strive to make them idempotent (i.e. safe to apply multiple times). Due to retries, the side effects may be executed multiple times, possibly in parallel.&lt;/li>
&lt;li>If the transform can have unprocessable (permanently failing) records and you want the pipeline to proceed despite that:
&lt;ul>
&lt;li>If bad records are safe to ignore, count the bad records in a metric. Make sure the transform&amp;rsquo;s documentation mentions this aggregator. Beware that there is no programmatic access to reading the aggregator value from inside the pipeline during execution.&lt;/li>
&lt;li>If bad records may need manual inspection by the user, emit them into an output that contains only those records.&lt;/li>
&lt;li>Alternatively take a (default zero) threshold above which element failures become bundle failures (structure the transform to count the total number of elements and of failed elements, compare them and fail if failures are above the threshold).&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>If the user requests a higher data consistency guarantee than you&amp;rsquo;re able to provide, fail. E.g.: if a user requests QoS 2 (exactly-once delivery) from an MQTT connector, the connector should fail since Beam runners may retry writing to the connector and hence exactly-once delivery can&amp;rsquo;t be done.&lt;/li>
&lt;/ul>
&lt;p>Do not:&lt;/p>
&lt;ul>
&lt;li>If you can&amp;rsquo;t handle a failure, don&amp;rsquo;t even catch it.
*Exception: *It may be valuable to catch the error, log a message, and rethrow it, if you&amp;rsquo;re able to provide valuable context that the original error doesn&amp;rsquo;t have.&lt;/li>
&lt;li>Never, ever, ever do this:
&lt;code>catch(...) { log an error; return null or false or otherwise ignore; }&lt;/code>
&lt;strong>Rule of thumb: if a bundle didn&amp;rsquo;t fail, its output must be correct and complete.&lt;/strong>
For a user, a transform that logged an error but succeeded is silent data loss.&lt;/li>
&lt;/ul>
&lt;h3 id="performance">Performance&lt;/h3>
&lt;p>Many runners optimize chains of &lt;code>ParDo&lt;/code>s in ways that improve performance if the &lt;code>ParDo&lt;/code>s emit a small to moderate number of elements per input element, or have relatively cheap per-element processing (e.g. Dataflow&amp;rsquo;s &amp;ldquo;fusion&amp;rdquo;), but limit parallelization if these assumptions are violated. In that case you may need a &amp;ldquo;fusion break&amp;rdquo; (&lt;code>Reshuffle.of()&lt;/code>) to improve the parallelizability of processing the output &lt;code>PCollection&lt;/code> of the &lt;code>ParDo&lt;/code>.&lt;/p>
&lt;ul>
&lt;li>If the transform includes a &lt;code>ParDo&lt;/code> that outputs a potentially large number of elements per input element, apply a fusion break after this &lt;code>ParDo&lt;/code> to make sure downstream transforms can process its output in parallel.&lt;/li>
&lt;li>If the transform includes a &lt;code>ParDo&lt;/code> that takes a very long time to process an element, insert a fusion break before this &lt;code>ParDo&lt;/code> to make sure all or most elements can be processed in parallel regardless of how its input &lt;code>PCollection&lt;/code> was produced.&lt;/li>
&lt;/ul>
&lt;h3 id="documentation">Documentation&lt;/h3>
&lt;p>Document how to configure the transform (give code examples), and what guarantees it expects about its input or provides about its output, accounting for the Beam model. E.g.:&lt;/p>
&lt;ul>
&lt;li>Are the input and output collections of this transform bounded or unbounded, or can it work with either?&lt;/li>
&lt;li>If the transform writes data to a third-party system, does it guarantee that data will be written at least once? at most once? exactly once? (how does it achieve exactly-once in case the runner executes a bundle multiple times due to retries or speculative execution a.k.a. backups?)&lt;/li>
&lt;li>If the transform reads data from a third-party system, what&amp;rsquo;s the maximum potential degree of parallelism of the read? E.g., if the transform reads data sequentially (e.g. executes a single SQL query), documentation should mention that.&lt;/li>
&lt;li>If the transform is querying an external system during processing (e.g. joining a &lt;code>PCollection&lt;/code> with information from an external key-value store), what are the guarantees on freshness of queried data: e.g. is it all loaded at the beginning of the transform, or queried per-element (in that case, what if data for a single element changes while the transform runs)?&lt;/li>
&lt;li>If there&amp;rsquo;s a non-trivial relationship between arrival of items in the input &lt;code>PCollection&lt;/code> and emitting output into the output &lt;code>PCollection&lt;/code>, what is this relationship? (e.g. if the transform internally does windowing, triggering, grouping, or uses the state or timers API)&lt;/li>
&lt;/ul>
&lt;h3 id="logging">Logging&lt;/h3>
&lt;p>Anticipate abnormal situations that a user of the transform may run into. Log information that they would have found sufficient for debugging, but limit the volume of logging. Here is some advice that applies to all programs, but is especially important when data volume is massive and execution is distributed.&lt;/p>
&lt;p>Do:&lt;/p>
&lt;ul>
&lt;li>When handling an error from a third-party system, log the full error with any error details the third-party system provides about it, and include any additional context the transform knows. This enables the user to take action based on the information provided in the message. When handling an exception and rethrowing your own exception, wrap the original exception in it (some languages offer more advanced facilities, e.g. Java&amp;rsquo;s &amp;ldquo;suppressed exceptions&amp;rdquo;). Never silently drop available information about an error.&lt;/li>
&lt;li>When performing a rare (not per-element) and slow operation (e.g. expanding a large file-pattern, or initiating an import/export job), log when the operation begins and ends. If the operation has an identifier, log the identifier, so the user can look up the operation for later debugging.&lt;/li>
&lt;li>When computing something low-volume that is critically important for correctness or performance of further processing, log the input and output, so a user in the process of debugging can sanity-check them or reproduce an abnormal result manually.
E.g. when expanding a filepattern into files, log what the filepattern was and how many parts it was split into; when executing a query, log the query and log how many results it produced.&lt;/li>
&lt;/ul>
&lt;p>Do not:&lt;/p>
&lt;ul>
&lt;li>Do not log at &lt;code>INFO&lt;/code> per element or per bundle. &lt;code>DEBUG&lt;/code>/&lt;code>TRACE&lt;/code> may be okay because these levels are disabled by default.&lt;/li>
&lt;li>Avoid logging data payloads that may contain sensitive information, or sanitize them before logging (e.g. user data, credentials, etc).&lt;/li>
&lt;/ul>
&lt;h3 id="testing">Testing&lt;/h3>
&lt;p>Data processing is tricky, full of corner cases, and difficult to debug, because pipelines take a long time to run, it&amp;rsquo;s hard to check if the output is correct, you can&amp;rsquo;t attach a debugger, and you often can&amp;rsquo;t log as much as you wish to, due to high volume of data. Because of that, testing is particularly important.&lt;/p>
&lt;h4 id="testing-the-transforms-run-time-behavior">Testing the transform&amp;rsquo;s run-time behavior&lt;/h4>
&lt;ul>
&lt;li>Unit-test the overall semantics of the transform using &lt;code>TestPipeline&lt;/code> and &lt;code>PAssert&lt;/code>. Start with testing against the direct runner. Assertions on &lt;code>PCollection&lt;/code> contents should be strict: e.g. when a read from a database is expected to read the numbers 1 through 10, assert not just that there are 10 elements in the output &lt;code>PCollection&lt;/code>, or that each element is in the range [1, 10] - but assert that each number 1 through 10 appears exactly once.&lt;/li>
&lt;li>Identify non-trivial sequential logic in the transform that is prone to corner cases which are difficult to reliably simulate using a &lt;code>TestPipeline&lt;/code>, extract this logic into unit-testable functions, and unit-test them. Common corner cases are:
&lt;ul>
&lt;li>&lt;code>DoFn&lt;/code>s processing empty bundles&lt;/li>
&lt;li>&lt;code>DoFn&lt;/code>s processing extremely large bundles (contents doesn&amp;rsquo;t fit in memory, including &amp;ldquo;hot keys&amp;rdquo; with a very large number of values)&lt;/li>
&lt;li>Third-party APIs failing&lt;/li>
&lt;li>Third-party APIs providing wildly inaccurate information&lt;/li>
&lt;li>Leaks of &lt;code>Closeable&lt;/code>/&lt;code>AutoCloseable&lt;/code> resources in failure cases&lt;/li>
&lt;li>Common corner cases when developing sources: complicated arithmetic in &lt;code>BoundedSource.split&lt;/code> (e.g. splitting key or offset ranges), iteration over empty data sources or composite data sources that have some empty components.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Mock out the interactions with third-party systems, or better, use &lt;a href="https://martinfowler.com/articles/mocksArentStubs.html">&amp;ldquo;fake&amp;rdquo;&lt;/a> implementations when available. Make sure that the mocked-out interactions are representative of all interesting cases of the actual behavior of these systems.&lt;/li>
&lt;li>To unit test &lt;code>DoFn&lt;/code>s, &lt;code>CombineFn&lt;/code>s, and &lt;code>BoundedSource&lt;/code>s, consider using &lt;code>DoFnTester&lt;/code>, &lt;code>CombineFnTester&lt;/code>, and &lt;code>SourceTestUtils&lt;/code> respectively which can exercise the code in non-trivial ways to flesh out potential bugs.&lt;/li>
&lt;li>For transforms that work over unbounded collections, test their behavior in the presence of late or out-of-order data using &lt;code>TestStream&lt;/code>.&lt;/li>
&lt;li>Tests must pass 100% of the time, including in hostile, CPU- or network-constrained environments (continuous integration servers). Never put timing-dependent code (e.g. sleeps) into tests. Experience shows that no reasonable amount of sleeping is enough - code can be suspended for more than several seconds.&lt;/li>
&lt;li>For detailed instructions on test code organization, see the &lt;a href="https://cwiki.apache.org/confluence/display/BEAM/Contribution+Testing+Guide">Beam Testing Guide&lt;/a>.&lt;/li>
&lt;/ul>
&lt;h4 id="testing-transform-construction-and-validation">Testing transform construction and validation&lt;/h4>
&lt;p>The code for constructing and validating a transform is usually trivial and mostly boilerplate. However, minor mistakes or typos in it can have serious consequences (e.g. ignoring a property that the user has set), so it needs to be tested as well. Yet, an excessive amount of trivial tests can be hard to maintain and give a false impression that the transform is well-tested.&lt;/p>
&lt;p>Do:&lt;/p>
&lt;ul>
&lt;li>Test non-trivial validation code, where missing/incorrect/uninformative validation may lead to serious problems: data loss, counter-intuitive behavior, value of a property being silently ignored, or other hard-to-debug errors. Create 1 test per non-trivial class of validation error. Some examples of validation that should be tested:
&lt;ul>
&lt;li>If properties &lt;code>withFoo()&lt;/code> and &lt;code>withBar()&lt;/code> cannot both be specified at the same time, test that a transform specifying both of them is rejected, rather than one of the properties being silently ignored at runtime.&lt;/li>
&lt;li>If the transform is known to behave incorrectly or counter-intuitively for a particular configuration, test that this configuration is rejected, rather than producing wrong results at runtime. For example, a transform might work properly only for bounded collections, or only for globally-windowed collections. Or, suppose a streaming system supports several levels of &amp;ldquo;quality of service&amp;rdquo;, one of which is &amp;ldquo;exactly once delivery&amp;rdquo;. However, a transform that writes to this system might be unable to provide exactly-once due to retries in case of failures. In that case, test that the transform disallows specifying exactly-once QoS, rather than failing to provide the expected end-to-end semantics at runtime.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Test that each &lt;code>withFoo()&lt;/code> method (including each overload) has effect (is not ignored), using &lt;code>TestPipeline&lt;/code> and &lt;code>PAssert&lt;/code> to create tests where the expected test results depend on the value of &lt;code>withFoo()&lt;/code>.&lt;/li>
&lt;/ul>
&lt;p>Do not:&lt;/p>
&lt;ul>
&lt;li>Do not test successful validation (e.g. &amp;ldquo;validation does not fail when the transform is configured correctly&amp;rdquo;)&lt;/li>
&lt;li>Do not test trivial validation errors (e.g. &amp;ldquo;validation fails when a property is unset/null/empty/negative/&amp;hellip;&amp;quot;)&lt;/li>
&lt;/ul>
&lt;h3 id="compatibility">Compatibility&lt;/h3>
&lt;p>Do:&lt;/p>
&lt;ul>
&lt;li>Generally, follow the rules of &lt;a href="https://semver.org/">semantic versioning&lt;/a>.&lt;/li>
&lt;li>If the API of the transform is not yet stable, annotate it as &lt;code>@Experimental&lt;/code> (Java) or &lt;code>@experimental&lt;/code> (&lt;a href="https://beam.apache.org/releases/pydoc/2.23.0/apache_beam.utils.annotations.html">Python&lt;/a>).&lt;/li>
&lt;li>If the API deprecated, annotate it as &lt;code>@Deprecated&lt;/code> (Java) or &lt;code>@deprecated&lt;/code> (&lt;a href="https://beam.apache.org/releases/pydoc/2.23.0/apache_beam.utils.annotations.html">Python&lt;/a>).&lt;/li>
&lt;li>Pay attention to the stability and versioning of third-party classes exposed by the transform&amp;rsquo;s API: if they are unstable or improperly versioned (do not obey &lt;a href="https://semver.org/">semantic versioning&lt;/a>), it is better to wrap them in your own classes.&lt;/li>
&lt;/ul>
&lt;p>Do not:&lt;/p>
&lt;ul>
&lt;li>Do not silently change the behavior of the transform, in a way where code will keep compiling but will do something different than the previously documented behavior (e.g. produce different output or expect different input, of course unless the previous output was incorrect).
Strive to make such incompatible behavior changes cause a compile error (e.g. it&amp;rsquo;s better to introduce a new transform for a new behavior and deprecate and then delete the old one (in a new major version), than to silently change the behavior of an existing transform), or at least a runtime error.&lt;/li>
&lt;li>If the behavior of the transform stays the same and you&amp;rsquo;re merely changing implementation or API - do not change API of the transform in a way that will make a user&amp;rsquo;s code stop compiling.&lt;/li>
&lt;/ul>
&lt;h2 id="java-specific-considerations">Java specific considerations&lt;/h2>
&lt;p>Good examples for most of the practices below are &lt;code>JdbcIO&lt;/code> and &lt;code>MongoDbIO&lt;/code>.&lt;/p>
&lt;h3 id="api">API&lt;/h3>
&lt;h4 id="choosing-types-of-input-and-output-pcollections">Choosing types of input and output PCollection&amp;rsquo;s&lt;/h4>
&lt;p>Whenever possible, use types specific to the nature of the transform. People can wrap it with conversion &lt;code>DoFn&lt;/code>s from their own types if necessary. E.g. a Datastore connector should use the Datastore &lt;code>Entity&lt;/code> type, a MongoDb connector should use Mongo &lt;code>Document&lt;/code> type, not a String representation of the JSON.&lt;/p>
&lt;p>Sometimes that&amp;rsquo;s not possible (e.g. JDBC does not provide a Beam-compatible (encodable with a Coder) &amp;ldquo;JDBC record&amp;rdquo; datatype) - then let the user provide a function for converting between the transform-specific type and a Beam-compatible type (e.g. see &lt;code>JdbcIO&lt;/code> and &lt;code>MongoDbGridFSIO&lt;/code>).&lt;/p>
&lt;p>When the transform should logically return a composite type for which no Java class exists yet, create a new POJO class with well-named fields. Do not use generic tuple classes or &lt;code>KV&lt;/code> (unless the fields are legitimately a key and a value).&lt;/p>
&lt;h4 id="transforms-with-multiple-output-collections">Transforms with multiple output collections&lt;/h4>
&lt;p>If the transform needs to return multiple collections, it should be a &lt;code>PTransform&amp;lt;..., PCollectionTuple&amp;gt;&lt;/code> and expose methods &lt;code>getBlahTag()&lt;/code> for each collection.&lt;/p>
&lt;p>E.g. if you want to return a &lt;code>PCollection&amp;lt;Foo&amp;gt;&lt;/code> and a &lt;code>PCollection&amp;lt;Bar&amp;gt;&lt;/code>, expose &lt;code>TupleTag&amp;lt;Foo&amp;gt; getFooTag()&lt;/code> and &lt;code>TupleTag&amp;lt;Bar&amp;gt; getBarTag()&lt;/code>.&lt;/p>
&lt;p>For example:&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">MyTransform&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">PTransform&lt;/span>&lt;span class="o">&amp;lt;...,&lt;/span> &lt;span class="n">PCollectionTuple&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Moo&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">mooTag&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Moo&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{};&lt;/span>
&lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Blah&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">blahTag&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Blah&lt;/span>&lt;span class="o">&amp;gt;()&lt;/span> &lt;span class="o">{};&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="n">PCollectionTuple&lt;/span> &lt;span class="nf">expand&lt;/span>&lt;span class="o">(...&lt;/span> &lt;span class="n">input&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Moo&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">moo&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Blah&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">blah&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">PCollectionTuple&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">of&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">mooTag&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">moo&lt;/span>&lt;span class="o">)&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">and&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">blahTag&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">blah&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Moo&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="nf">getMooTag&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">mooTag&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">TupleTag&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Blah&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="nf">getBlahTag&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">blahTag&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="fluent-builders-for-configuration">Fluent builders for configuration&lt;/h4>
&lt;p>Make the transform class immutable, with methods to produce modified immutable objects. Use &lt;a href="https://github.com/google/auto/tree/master/value">AutoValue&lt;/a>. Autovalue can provide a Builder helper class. Use &lt;code>@Nullable&lt;/code> to mark parameters of class type that don&amp;rsquo;t have a default value or whose default value is null, except for primitive types (e.g. int).&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="nd">@AutoValue&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">abstract&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">MyTransform&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">PTransform&lt;/span>&lt;span class="o">&amp;lt;...&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kt">int&lt;/span> &lt;span class="nf">getMoo&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="nd">@Nullable&lt;/span> &lt;span class="kd">abstract&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="nf">getBlah&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="kd">abstract&lt;/span> &lt;span class="n">Builder&lt;/span> &lt;span class="nf">toBuilder&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="nd">@AutoValue.Builder&lt;/span>
&lt;span class="kd">abstract&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">Builder&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">abstract&lt;/span> &lt;span class="n">Builder&lt;/span> &lt;span class="nf">setMoo&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="n">moo&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="kd">abstract&lt;/span> &lt;span class="n">Builder&lt;/span> &lt;span class="nf">setBlah&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span> &lt;span class="n">blah&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="kd">abstract&lt;/span> &lt;span class="n">MyTransform&lt;/span> &lt;span class="nf">build&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h5 id="factory-methods">Factory methods&lt;/h5>
&lt;p>Provide a single argumentless static factory method, either in the enclosing class (see &amp;ldquo;Packaging a family of transforms&amp;rdquo;) or in the transform class itself.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">Thumbs&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">Twiddle&lt;/span> &lt;span class="nf">twiddle&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">AutoValue_Thumbs_Twiddle&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Builder&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">build&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">abstract&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">Twiddle&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">PTransform&lt;/span>&lt;span class="o">&amp;lt;...&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="o">...&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="c1">// or:
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">public&lt;/span> &lt;span class="kd">abstract&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">TwiddleThumbs&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">PTransform&lt;/span>&lt;span class="o">&amp;lt;...&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">TwiddleThumbs&lt;/span> &lt;span class="nf">create&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">AutoValue_Thumbs_Twiddle&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Builder&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">build&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Exception: when transform has a single overwhelmingly most important parameter, then call the factory method &lt;code>of&lt;/code> and put the parameter into an argument of the factory method: &lt;code>ParDo.of(DoFn).withAllowedLateness()&lt;/code>.&lt;/p>
&lt;h5 id="fluent-builder-methods-for-setting-parameters">Fluent builder methods for setting parameters&lt;/h5>
&lt;p>Call them &lt;code>withBlah()&lt;/code>. All builder methods must return exactly the same type; if it&amp;rsquo;s a parameterized (generic) type, with the same values of type parameters.&lt;/p>
&lt;p>Treat &lt;code>withBlah()&lt;/code> methods as an unordered set of keyword arguments - result must not depend on the order in which you call &lt;code>withFoo()&lt;/code> and &lt;code>withBar()&lt;/code> (e.g., &lt;code>withBar()&lt;/code> must not read the current value of foo).&lt;/p>
&lt;p>Document implications of each &lt;code>withBlah&lt;/code> method: when to use this method at all, what values are allowed, what is the default, what are the implications of changing the value.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="cm">/**
&lt;/span>&lt;span class="cm"> * Returns a new {@link TwiddleThumbs} transform with moo set
&lt;/span>&lt;span class="cm"> * to the given value.
&lt;/span>&lt;span class="cm"> *
&lt;/span>&lt;span class="cm"> * &amp;lt;p&amp;gt;Valid values are 0 (inclusive) to 100 (exclusive). The default is 42.
&lt;/span>&lt;span class="cm"> *
&lt;/span>&lt;span class="cm"> * &amp;lt;p&amp;gt;Higher values generally improve throughput, but increase chance
&lt;/span>&lt;span class="cm"> * of spontaneous combustion.
&lt;/span>&lt;span class="cm"> */&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">Twiddle&lt;/span> &lt;span class="nf">withMoo&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="n">moo&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">checkArgument&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">moo&lt;/span> &lt;span class="o">&amp;gt;=&lt;/span> &lt;span class="n">0&lt;/span> &lt;span class="o">&amp;amp;&amp;amp;&lt;/span> &lt;span class="n">moo&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="n">100&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="s">&amp;#34;Thumbs.Twiddle.withMoo() called with an invalid moo of %s. &amp;#34;&lt;/span>
&lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34;Valid values are 0 (inclusive) to 100 (exclusive)&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">moo&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">toBuilder&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">setMoo&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">moo&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">build&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h5 id="default-values-for-parameters">Default values for parameters&lt;/h5>
&lt;p>Specify them in the factory method (factory method returns an object with default values).&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">Thumbs&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">Twiddle&lt;/span> &lt;span class="nf">twiddle&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">AutoValue_Thumbs_Twiddle&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Builder&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">setMoo&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">42&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">build&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h5 id="packaging-multiple-parameters-into-a-reusable-object">Packaging multiple parameters into a reusable object&lt;/h5>
&lt;p>If several parameters of the transform are very tightly logically coupled, sometimes it makes sense to encapsulate them into a container object. Use the same guidelines for this container object (make it immutable, use AutoValue with builders, document &lt;code>withBlah()&lt;/code> methods, etc.). For an example, see &lt;a href="https://github.com/apache/beam/blob/master/sdks/java/io/jdbc/src/main/java/org/apache/beam/sdk/io/jdbc/JdbcIO.java">JdbcIO.DataSourceConfiguration&lt;/a>.&lt;/p>
&lt;h4 id="transforms-with-type-parameters">Transforms with type parameters&lt;/h4>
&lt;p>All type parameters should be specified explicitly on factory method. Builder methods (&lt;code>withBlah()&lt;/code>) should not change the types.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">Thumbs&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">Twiddle&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">T&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="nf">twiddle&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">AutoValue_Thumbs_Twiddle&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Builder&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">T&lt;/span>&lt;span class="o">&amp;gt;().&lt;/span>&lt;span class="na">build&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="nd">@AutoValue&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">abstract&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">Twiddle&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">T&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="kd">extends&lt;/span> &lt;span class="n">PTransform&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Foo&lt;/span>&lt;span class="o">&amp;gt;,&lt;/span> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Bar&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">T&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="err">…&lt;/span>
&lt;span class="nd">@Nullable&lt;/span> &lt;span class="kd">abstract&lt;/span> &lt;span class="n">Bar&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">T&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="nf">getBar&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="kd">abstract&lt;/span> &lt;span class="n">Builder&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">T&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="nf">toBuilder&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="nd">@AutoValue.Builder&lt;/span>
&lt;span class="kd">abstract&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">Builder&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">T&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="err">…&lt;/span>
&lt;span class="kd">abstract&lt;/span> &lt;span class="n">Builder&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">T&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="nf">setBar&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Bar&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">T&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">bar&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="kd">abstract&lt;/span> &lt;span class="n">Twiddle&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">T&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="nf">build&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="err">…&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="c1">// User code:
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">Thumbs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Twiddle&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">twiddle&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Thumbs&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">twiddle&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="c1">// Or:
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Bar&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">bars&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">foos&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Thumbs&lt;/span>&lt;span class="o">.&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">twiddle&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="err">…&lt;/span> &lt;span class="o">);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>Exception: when the transform has a single most important parameter and this parameter depends on type T, then prefer to put it right into the factory method: e.g. &lt;code>Combine.globally(SerializableFunction&amp;lt;Iterable&amp;lt;V&amp;gt;,V&amp;gt;&lt;/code>). This improves Java&amp;rsquo;s type inference and allows the user not to specify type parameters explicitly.&lt;/p>
&lt;p>When the transform has more than one type parameter, or if the meaning of the parameter is non-obvious, name the type parameters like &lt;code>SomethingT&lt;/code>, e.g.: a PTransform implementing a classifier algorithm and assigning each input element with a label might be typed as &lt;code>Classify&amp;lt;InputT, LabelT&amp;gt;&lt;/code>.&lt;/p>
&lt;h4 id="injecting-user-specified-behavior">Injecting user-specified behavior&lt;/h4>
&lt;p>If the transform has an aspect of behavior to be customized by a user&amp;rsquo;s code, make a decision as follows:&lt;/p>
&lt;p>Do:&lt;/p>
&lt;ul>
&lt;li>If possible, just use PTransform composition as an extensibility device - i.e. if the same effect can be achieved by the user applying the transform in their pipeline and composing it with another &lt;code>PTransform&lt;/code>, then the transform itself should not be extensible. E.g., a transform that writes JSON objects to a third-party system should take a &lt;code>PCollection&amp;lt;JsonObject&amp;gt;&lt;/code> (assuming it is possible to provide a &lt;code>Coder&lt;/code> for &lt;code>JsonObject&lt;/code>), rather than taking a generic &lt;code>PCollection&amp;lt;T&amp;gt;&lt;/code> and a &lt;code>ProcessFunction&amp;lt;T, JsonObject&amp;gt;&lt;/code> (anti-example that should be fixed: &lt;code>TextIO&lt;/code>).&lt;/li>
&lt;li>If extensibility by user code is necessary inside the transform, pass the user code as a &lt;code>ProcessFunction&lt;/code> or define your own serializable function-like type (ideally single-method, for interoperability with Java 8 lambdas). Because Java erases the types of lambdas, you should be sure to have adequate type information even if a raw-type &lt;code>ProcessFunction&lt;/code> is provided by the user. See &lt;code>MapElements&lt;/code> and &lt;code>FlatMapElements&lt;/code> for examples of how to use &lt;code>ProcessFunction&lt;/code> and &lt;code>InferableFunction&lt;/code> in tandem to provide good support for both lambdas and concrete subclasses with type information.&lt;/li>
&lt;/ul>
&lt;p>Do not:&lt;/p>
&lt;ul>
&lt;li>Do not use inheritance for extensibility: users should not subclass the &lt;code>PTransform&lt;/code> class.&lt;/li>
&lt;/ul>
&lt;h4 id="packaging-a-family-of-transforms">Packaging a family of transforms&lt;/h4>
&lt;p>When developing a family of highly related transforms (e.g. interacting with the same system in different ways, or providing different implementations of the same high-level task), use a top-level class as a namespace, with multiple factory methods returning transforms corresponding to each individual use case.&lt;/p>
&lt;p>The container class must have a private constructor, so it can&amp;rsquo;t be instantiated directly.&lt;/p>
&lt;p>Document common stuff at &lt;code>FooIO&lt;/code> level, and each factory method individually.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="cm">/** Transforms for clustering data. */&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">Cluster&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Force use of static factory methods.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="nf">Cluster&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{}&lt;/span>
&lt;span class="cm">/** Returns a new {@link UsingKMeans} transform. */&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">UsingKMeans&lt;/span> &lt;span class="nf">usingKMeans&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="o">...&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">Hierarchically&lt;/span> &lt;span class="nf">hierarchically&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="o">...&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="cm">/** Clusters data using the K-Means algorithm. */&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">UsingKMeans&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">PTransform&lt;/span>&lt;span class="o">&amp;lt;...&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="o">...&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">Hierarchically&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">PTransform&lt;/span>&lt;span class="o">&amp;lt;...&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="o">...&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">FooIO&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Force use of static factory methods.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="nf">FooIO&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">Read&lt;/span> &lt;span class="nf">read&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="o">...&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">Read&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">PTransform&lt;/span>&lt;span class="o">&amp;lt;...&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="o">...&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">Write&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">PTransform&lt;/span>&lt;span class="o">&amp;lt;...&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="o">...&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">Delete&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">PTransform&lt;/span>&lt;span class="o">&amp;lt;...&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="o">...&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">Mutate&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">PTransform&lt;/span>&lt;span class="o">&amp;lt;...&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="o">...&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>When supporting multiple versions with incompatible APIs, use the version as a namespace-like class too, and put implementations of different API versions in different files.&lt;/p>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// FooIO.java
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">FooIO&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Force use of static factory methods.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="nf">FooIO&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">FooV1&lt;/span> &lt;span class="nf">v1&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="k">return&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">FooV1&lt;/span>&lt;span class="o">();&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">FooV2&lt;/span> &lt;span class="nf">v2&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="k">return&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">FooV2&lt;/span>&lt;span class="o">();&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="c1">// FooV1.java
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">FooV1&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Force use of static factory methods outside the package.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">FooV1&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">Read&lt;/span> &lt;span class="nf">read&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="o">...&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">Read&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">PTransform&lt;/span>&lt;span class="o">&amp;lt;...&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="o">...&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="c1">// FooV2.java
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">FooV2&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Force use of static factory methods outside the package.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">FooV2&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">Read&lt;/span> &lt;span class="nf">read&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="o">...&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">Read&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">PTransform&lt;/span>&lt;span class="o">&amp;lt;...&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="o">...&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h3 id="behavior">Behavior&lt;/h3>
&lt;h4 id="immutability">Immutability&lt;/h4>
&lt;ul>
&lt;li>Transform classes must be immutable: all variables must be private final and themselves immutable (e.g. if it&amp;rsquo;s a list, it must be an &lt;code>ImmutableList&lt;/code>).&lt;/li>
&lt;li>Elements of all &lt;code>PCollection&lt;/code>s must be immutable.&lt;/li>
&lt;/ul>
&lt;h4 id="serialization">Serialization&lt;/h4>
&lt;p>&lt;code>DoFn&lt;/code>, &lt;code>PTransform&lt;/code>, &lt;code>CombineFn&lt;/code> and other instances will be serialized. Keep the amount of serialized data to a minimum: Mark fields that you don&amp;rsquo;t want serialized as &lt;code>transient&lt;/code>. Make classes &lt;code>static&lt;/code> whenever possible (so that the instance doesn&amp;rsquo;t capture and serialize the enclosing class instance). Note: In some cases this means that you cannot use anonymous classes.&lt;/p>
&lt;h4 id="validation">Validation&lt;/h4>
&lt;ul>
&lt;li>Validate individual parameters in &lt;code>.withBlah()&lt;/code> methods using &lt;code>checkArgument()&lt;/code>. Error messages should mention the name of the parameter, the actual value, and the range of valid values.&lt;/li>
&lt;li>Validate parameter combinations and missing required parameters in the &lt;code>PTransform&lt;/code>'s &lt;code>.expand()&lt;/code> method.&lt;/li>
&lt;li>Validate parameters that the &lt;code>PTransform&lt;/code> takes from &lt;code>PipelineOptions&lt;/code> in the &lt;code>PTransform&lt;/code>'s &lt;code>.validate(PipelineOptions)&lt;/code> method.
These validations will be executed when the pipeline is already fully constructed/expanded and is about to be run with a particular &lt;code>PipelineOptions&lt;/code>.
Most &lt;code>PTransform&lt;/code>s do not use &lt;code>PipelineOptions&lt;/code> and thus don&amp;rsquo;t need a &lt;code>validate()&lt;/code> method - instead, they should perform their validation via the two other methods above.&lt;/li>
&lt;/ul>
&lt;div class=language-java>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="nd">@AutoValue&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">abstract&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">TwiddleThumbs&lt;/span>
&lt;span class="kd">extends&lt;/span> &lt;span class="n">PTransform&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Foo&lt;/span>&lt;span class="o">&amp;gt;,&lt;/span> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Bar&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">abstract&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="nf">getMoo&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="kd">abstract&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="nf">getBoo&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="c1">// Validating individual parameters
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="n">TwiddleThumbs&lt;/span> &lt;span class="nf">withMoo&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="n">moo&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">checkArgument&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">moo&lt;/span> &lt;span class="o">&amp;gt;=&lt;/span> &lt;span class="n">0&lt;/span> &lt;span class="o">&amp;amp;&amp;amp;&lt;/span> &lt;span class="n">moo&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="n">100&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="s">&amp;#34;Moo must be between 0 (inclusive) and 100 (exclusive), but was: %s&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">moo&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">toBuilder&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">setMoo&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">moo&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">build&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">TwiddleThumbs&lt;/span> &lt;span class="nf">withBoo&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span> &lt;span class="n">boo&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">checkArgument&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">boo&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="kc">null&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;Boo can not be null&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">checkArgument&lt;/span>&lt;span class="o">(!&lt;/span>&lt;span class="n">boo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">isEmpty&lt;/span>&lt;span class="o">(),&lt;/span> &lt;span class="s">&amp;#34;Boo can not be empty&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">toBuilder&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">setBoo&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">boo&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">build&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="nd">@Override&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">validate&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">PipelineOptions&lt;/span> &lt;span class="n">options&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kt">int&lt;/span> &lt;span class="n">woo&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">options&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">as&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TwiddleThumbsOptions&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">getWoo&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">checkArgument&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">woo&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">getMoo&lt;/span>&lt;span class="o">(),&lt;/span>
&lt;span class="s">&amp;#34;Woo (%s) must be smaller than moo (%s)&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">woo&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">getMoo&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="nd">@Override&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Bar&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="nf">expand&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">PCollection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Foo&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">input&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Validating that a required parameter is present
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">checkArgument&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">getBoo&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="kc">null&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;Must specify boo&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="c1">// Validating a combination of parameters
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">checkArgument&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">getMoo&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">0&lt;/span> &lt;span class="o">||&lt;/span> &lt;span class="n">getBoo&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="kc">null&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="s">&amp;#34;Must specify at most one of moo or boo, but was: moo = %s, boo = %s&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">getMoo&lt;/span>&lt;span class="o">(),&lt;/span> &lt;span class="n">getBoo&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;h4 id="coders">Coders&lt;/h4>
&lt;p>&lt;code>Coder&lt;/code>s are a way for a Beam runner to materialize intermediate data or transmit it between workers when necessary. &lt;code>Coder&lt;/code> should not be used as a general-purpose API for parsing or writing binary formats because the particular binary encoding of a &lt;code>Coder&lt;/code> is intended to be its private implementation detail.&lt;/p>
&lt;h5 id="providing-default-coders-for-types">Providing default coders for types&lt;/h5>
&lt;p>Provide default &lt;code>Coder&lt;/code>s for all new data types. Use &lt;code>@DefaultCoder&lt;/code> annotations or &lt;code>CoderProviderRegistrar&lt;/code> classes annotated with &lt;code>@AutoService&lt;/code>: see usages of these classes in the SDK for examples. If performance is not important, you can use &lt;code>SerializableCoder&lt;/code> or &lt;code>AvroCoder&lt;/code>. Otherwise, develop an efficient custom coder (subclass &lt;code>AtomicCoder&lt;/code> for concrete types, &lt;code>StructuredCoder&lt;/code> for generic types).&lt;/p>
&lt;h5 id="setting-coders-on-output-collections">Setting coders on output collections&lt;/h5>
&lt;p>All &lt;code>PCollection&lt;/code>s created by your &lt;code>PTransform&lt;/code> (both output and intermediate collections) must have a &lt;code>Coder&lt;/code> set on them: a user should never need to call &lt;code>.setCoder()&lt;/code> to &amp;ldquo;fix up&amp;rdquo; a coder on a &lt;code>PCollection&lt;/code> produced by your &lt;code>PTransform&lt;/code> (in fact, Beam intends to eventually deprecate &lt;code>setCoder&lt;/code>). In some cases, coder inference will be sufficient to achieve this; in other cases, your transform will need to explicitly call &lt;code>setCoder&lt;/code> on its collections.&lt;/p>
&lt;p>If the collection is of a concrete type, that type usually has a corresponding coder. Use a specific most efficient coder (e.g. &lt;code>StringUtf8Coder.of()&lt;/code> for strings, &lt;code>ByteArrayCoder.of()&lt;/code> for byte arrays, etc.), rather than a general-purpose coder like &lt;code>SerializableCoder&lt;/code>.&lt;/p>
&lt;p>If the type of the collection involves generic type variables, the situation is more complex:&lt;/p>
&lt;ul>
&lt;li>If it coincides with the transform&amp;rsquo;s input type or is a simple wrapper over it, you can reuse the coder of the input &lt;code>PCollection&lt;/code>, available via &lt;code>input.getCoder()&lt;/code>.&lt;/li>
&lt;li>Attempt to infer the coder via &lt;code>input.getPipeline().getCoderRegistry().getCoder(TypeDescriptor)&lt;/code>. Use utilities in &lt;code>TypeDescriptors&lt;/code> to obtain the &lt;code>TypeDescriptor&lt;/code> for the generic type. For an example of this approach, see the implementation of &lt;code>AvroIO.parseGenericRecords()&lt;/code>. However, coder inference for generic types is best-effort and in some cases it may fail due to Java type erasure.&lt;/li>
&lt;li>Always make it possible for the user to explicitly specify a &lt;code>Coder&lt;/code> for the relevant type variable(s) as a configuration parameter of your &lt;code>PTransform&lt;/code>. (e.g. &lt;code>AvroIO.&amp;lt;T&amp;gt;parseGenericRecords().withCoder(Coder&amp;lt;T&amp;gt;)&lt;/code>). Fall back to inference if the coder was not explicitly specified.&lt;/li>
&lt;/ul></description></item><item><title>Contribute: Release blockers</title><link>/contribute/release-blocking/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/contribute/release-blocking/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="release-blockers">Release blockers&lt;/h1>
&lt;p>A release blocking Jira is any open Jira that has its &lt;code>Fix Version&lt;/code> field set
to an upcoming version of Beam.&lt;/p>
&lt;h2 id="release-blocking-bugs">Release-blocking bugs&lt;/h2>
&lt;p>A bug should block a release if it is a significant regression or loss of
functionality. It should usually have priority Critical/P1. Lower priorities do
not have urgency, while Blocker/P0 is reserved for issues so urgent they do not
wait for a release.&lt;/p>
&lt;h2 id="release-blocking-features">Release-blocking features&lt;/h2>
&lt;p>By default, features do not block releases. Beam has a steady 6 week cadence of
cutting release branches and releasing. Features &amp;ldquo;catch the train&amp;rdquo; or else wait
for the next release.&lt;/p>
&lt;p>A feature can block a release if there is community consensus to delay a
release in order to include the feature.&lt;/p></description></item><item><title>Contribute: Runner Authoring Guide</title><link>/contribute/runner-guide/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/contribute/runner-guide/</guid><description>
&lt;!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
&lt;h1 id="runner-authoring-guide">Runner Authoring Guide&lt;/h1>
&lt;p>This guide walks through how to implement a new runner. It is aimed at someone
who has a data processing system and wants to use it to execute a Beam
pipeline. The guide starts from the basics, to help you evaluate the work
ahead. Then the sections become more and more detailed, to be a resource
throughout the development of your runner.&lt;/p>
&lt;p>Topics covered:&lt;/p>
&lt;nav id="TableOfContents">
&lt;ul>
&lt;li>&lt;a href="#basics-of-the-beam-model">Basics of the Beam model&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#pipeline">Pipeline&lt;/a>&lt;/li>
&lt;li>&lt;a href="#ptransforms">PTransforms&lt;/a>&lt;/li>
&lt;li>&lt;a href="#pcollections">PCollections&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#bounded-vs-unbounded">Bounded vs Unbounded&lt;/a>&lt;/li>
&lt;li>&lt;a href="#timestamps">Timestamps&lt;/a>&lt;/li>
&lt;li>&lt;a href="#watermarks">Watermarks&lt;/a>&lt;/li>
&lt;li>&lt;a href="#windowed-elements">Windowed elements&lt;/a>&lt;/li>
&lt;li>&lt;a href="#coder">Coder&lt;/a>&lt;/li>
&lt;li>&lt;a href="#windowing-strategy">Windowing Strategy&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#user-defined-functions-udfs">User-Defined Functions (UDFs)&lt;/a>&lt;/li>
&lt;li>&lt;a href="#runner">Runner&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#implementing-the-beam-primitives">Implementing the Beam Primitives&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#what-if-you-havent-implemented-some-of-these-features">What if you haven&amp;rsquo;t implemented some of these features?&lt;/a>&lt;/li>
&lt;li>&lt;a href="#implementing-the-pardo-primitive">Implementing the ParDo primitive&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#bundles">Bundles&lt;/a>&lt;/li>
&lt;li>&lt;a href="#the-dofn-lifecycle">The DoFn Lifecycle&lt;/a>&lt;/li>
&lt;li>&lt;a href="#dofnrunners">DoFnRunner(s)&lt;/a>&lt;/li>
&lt;li>&lt;a href="#side-inputs">Side Inputs&lt;/a>&lt;/li>
&lt;li>&lt;a href="#state-and-timers">State and Timers&lt;/a>&lt;/li>
&lt;li>&lt;a href="#splittable-dofn">Splittable DoFn&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#implementing-the-groupbykey-and-window-primitive">Implementing the GroupByKey (and window) primitive&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#group-by-encoded-bytes">Group By Encoded Bytes&lt;/a>&lt;/li>
&lt;li>&lt;a href="#window-merging">Window Merging&lt;/a>&lt;/li>
&lt;li>&lt;a href="#implementing-via-groupbykeyonly--groupalsobywindow">Implementing via GroupByKeyOnly + GroupAlsoByWindow&lt;/a>&lt;/li>
&lt;li>&lt;a href="#dropping-late-data">Dropping late data&lt;/a>&lt;/li>
&lt;li>&lt;a href="#triggering">Triggering&lt;/a>&lt;/li>
&lt;li>&lt;a href="#timestampcombiner">TimestampCombiner&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#implementing-the-window-primitive">Implementing the Window primitive&lt;/a>&lt;/li>
&lt;li>&lt;a href="#implementing-the-read-primitive">Implementing the Read primitive&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#reading-from-an-unboundedsource">Reading from an UnboundedSource&lt;/a>&lt;/li>
&lt;li>&lt;a href="#reading-from-a-boundedsource">Reading from a BoundedSource&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#implementing-the-flatten-primitive">Implementing the Flatten primitive&lt;/a>&lt;/li>
&lt;li>&lt;a href="#special-mention-the-combine-composite">Special mention: the Combine composite&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#working-with-pipelines">Working with pipelines&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#traversing-a-pipeline">Traversing a pipeline&lt;/a>&lt;/li>
&lt;li>&lt;a href="#altering-a-pipeline">Altering a pipeline&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#testing-your-runner">Testing your runner&lt;/a>&lt;/li>
&lt;li>&lt;a href="#integrating-your-runner-nicely-with-sdks">Integrating your runner nicely with SDKs&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#integrating-with-the-java-sdk">Integrating with the Java SDK&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#allowing-users-to-pass-options-to-your-runner">Allowing users to pass options to your runner&lt;/a>&lt;/li>
&lt;li>&lt;a href="#registering-your-runner-with-sdks-for-command-line-use">Registering your runner with SDKs for command line use&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#integrating-with-the-python-sdk">Integrating with the Python SDK&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#writing-an-sdk-independent-runner">Writing an SDK-independent runner&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#the-fn-api">The Fn API&lt;/a>&lt;/li>
&lt;li>&lt;a href="#the-runner-api">The Runner API&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#the-runner-api-protos">The Runner API protos&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#functionspec-proto">&lt;code>FunctionSpec&lt;/code> proto&lt;/a>&lt;/li>
&lt;li>&lt;a href="#sdkfunctionspec-proto">&lt;code>SdkFunctionSpec&lt;/code> proto&lt;/a>&lt;/li>
&lt;li>&lt;a href="#primitive-transform-payload-protos">Primitive transform payload protos&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#pardopayload-proto">&lt;code>ParDoPayload&lt;/code> proto&lt;/a>&lt;/li>
&lt;li>&lt;a href="#readpayload-proto">&lt;code>ReadPayload&lt;/code> proto&lt;/a>&lt;/li>
&lt;li>&lt;a href="#windowintopayload-proto">&lt;code>WindowIntoPayload&lt;/code> proto&lt;/a>&lt;/li>
&lt;li>&lt;a href="#combinepayload-proto">&lt;code>CombinePayload&lt;/code> proto&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#ptransform-proto">&lt;code>PTransform&lt;/code> proto&lt;/a>&lt;/li>
&lt;li>&lt;a href="#pcollection-proto">&lt;code>PCollection&lt;/code> proto&lt;/a>&lt;/li>
&lt;li>&lt;a href="#coder-proto">&lt;code>Coder&lt;/code> proto&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#the-runner-api-rpcs">The Runner API RPCs&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#pipelinerunnerrunpipeline-rpc">&lt;code>PipelineRunner.run(Pipeline)&lt;/code> RPC&lt;/a>&lt;/li>
&lt;li>&lt;a href="#pipelineresult-aka-job-api">&lt;code>PipelineResult&lt;/code> aka &amp;ldquo;Job API&amp;rdquo;&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;h2 id="basics-of-the-beam-model">Basics of the Beam model&lt;/h2>
&lt;p>Suppose you have a data processing engine that can pretty easily process graphs
of operations. You want to integrate it with the Beam ecosystem to get access
to other languages, great event time processing, and a library of connectors.
You need to know the core vocabulary:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="#pipeline">&lt;em>Pipeline&lt;/em>&lt;/a> - A pipeline is a graph of transformations that a user constructs
that defines the data processing they want to do.&lt;/li>
&lt;li>&lt;a href="#pcollections">&lt;em>PCollection&lt;/em>&lt;/a> - Data being processed in a pipeline is part of a PCollection.&lt;/li>
&lt;li>&lt;a href="#ptransforms">&lt;em>PTransforms&lt;/em>&lt;/a> - The operations executed within a pipeline. These are best
thought of as operations on PCollections.&lt;/li>
&lt;li>&lt;em>SDK&lt;/em> - A language-specific library for pipeline authors (we often call them
&amp;ldquo;users&amp;rdquo; even though we have many kinds of users) to build transforms,
construct their pipelines and submit them to a runner&lt;/li>
&lt;li>&lt;em>Runner&lt;/em> - You are going to write a piece of software called a runner that
takes a Beam pipeline and executes it using the capabilities of your data
processing engine.&lt;/li>
&lt;/ul>
&lt;p>These concepts may be very similar to your processing engine&amp;rsquo;s concepts. Since
Beam&amp;rsquo;s design is for cross-language operation and reusable libraries of
transforms, there are some special features worth highlighting.&lt;/p>
&lt;h3 id="pipeline">Pipeline&lt;/h3>
&lt;p>A pipeline in Beam is a graph of PTransforms operating on PCollections. A
pipeline is constructed by a user in their SDK of choice, and makes its way to
your runner either via the SDK directly or via the Runner API&amp;rsquo;s (forthcoming)
RPC interfaces.&lt;/p>
&lt;h3 id="ptransforms">PTransforms&lt;/h3>
&lt;p>In Beam, a PTransform can be one of the five primitives or it can be a
composite transform encapsulating a subgraph. The primitives are:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="#implementing-the-read-primitive">&lt;em>Read&lt;/em>&lt;/a> - parallel connectors to external
systems&lt;/li>
&lt;li>&lt;a href="#implementing-the-pardo-primitive">&lt;em>ParDo&lt;/em>&lt;/a> - per element processing&lt;/li>
&lt;li>&lt;a href="#implementing-the-groupbykey-and-window-primitive">&lt;em>GroupByKey&lt;/em>&lt;/a> -
aggregating elements per key and window&lt;/li>
&lt;li>&lt;a href="#implementing-the-flatten-primitive">&lt;em>Flatten&lt;/em>&lt;/a> - union of PCollections&lt;/li>
&lt;li>&lt;a href="#implementing-the-window-primitive">&lt;em>Window&lt;/em>&lt;/a> - set the windowing strategy
for a PCollection&lt;/li>
&lt;/ul>
&lt;p>When implementing a runner, these are the operations you need to implement.
Composite transforms may or may not be important to your runner. If you expose
a UI, maintaining some of the composite structure will make the pipeline easier
for a user to understand. But the result of processing is not changed.&lt;/p>
&lt;h3 id="pcollections">PCollections&lt;/h3>
&lt;p>A PCollection is an unordered bag of elements. Your runner will be responsible
for storing these elements. There are some major aspects of a PCollection to
note:&lt;/p>
&lt;h4 id="bounded-vs-unbounded">Bounded vs Unbounded&lt;/h4>
&lt;p>A PCollection may be bounded or unbounded.&lt;/p>
&lt;ul>
&lt;li>&lt;em>Bounded&lt;/em> - it is finite and you know it, as in batch use cases&lt;/li>
&lt;li>&lt;em>Unbounded&lt;/em> - it may be never end, you don&amp;rsquo;t know, as in streaming use cases&lt;/li>
&lt;/ul>
&lt;p>These derive from the intuitions of batch and stream processing, but the two
are unified in Beam and bounded and unbounded PCollections can coexist in the
same pipeline. If your runner can only support bounded PCollections, you&amp;rsquo;ll
need to reject pipelines that contain unbounded PCollections. If your
runner is only really targeting streams, there are adapters in our support code
to convert everything to APIs targeting unbounded data.&lt;/p>
&lt;h4 id="timestamps">Timestamps&lt;/h4>
&lt;p>Every element in a PCollection has a timestamp associated with it.&lt;/p>
&lt;p>When you execute a primitive connector to some storage system, that connector
is responsible for providing initial timestamps. Your runner will need to
propagate and aggregate timestamps. If the timestamp is not important, as with
certain batch processing jobs where elements do not denote events, they will be
the minimum representable timestamp, often referred to colloquially as
&amp;ldquo;negative infinity&amp;rdquo;.&lt;/p>
&lt;h4 id="watermarks">Watermarks&lt;/h4>
&lt;p>Every PCollection has to have a watermark that estimates how complete the
PCollection is.&lt;/p>
&lt;p>The watermark is a guess that &amp;ldquo;we&amp;rsquo;ll never see an element with an earlier
timestamp&amp;rdquo;. Sources of data are responsible for producing a watermark. Your
runner needs to implement watermark propagation as PCollections are processed,
merged, and partitioned.&lt;/p>
&lt;p>The contents of a PCollection are complete when a watermark advances to
&amp;ldquo;infinity&amp;rdquo;. In this manner, you may discover that an unbounded PCollection is
finite.&lt;/p>
&lt;h4 id="windowed-elements">Windowed elements&lt;/h4>
&lt;p>Every element in a PCollection resides in a window. No element resides in
multiple windows (two elements can be equal except for their window, but they
are not the same).&lt;/p>
&lt;p>When elements are read from the outside world they arrive in the global window.
When they are written to the outside world, they are effectively placed back
into the global window (any writing transform that doesn&amp;rsquo;t take this
perspective probably risks data loss).&lt;/p>
&lt;p>A window has a maximum timestamp, and when the watermark exceeds this plus
user-specified allowed lateness the window is expired. All data related
to an expired window may be discarded at any time.&lt;/p>
&lt;h4 id="coder">Coder&lt;/h4>
&lt;p>Every PCollection has a coder, a specification of the binary format of the elements.&lt;/p>
&lt;p>In Beam, the user&amp;rsquo;s pipeline may be written in a language other than the
language of the runner. There is no expectation that the runner can actually
deserialize user data. So the Beam model operates principally on encoded data -
&amp;ldquo;just bytes&amp;rdquo;. Each PCollection has a declared encoding for its elements, called
a coder. A coder has a URN that identifies the encoding, and may have
additional sub-coders (for example, a coder for lists may contain a coder for
the elements of the list). Language-specific serialization techniques can, and
frequently are used, but there are a few key formats - such as key-value pairs
and timestamps - that are common so your runner can understand them.&lt;/p>
&lt;h4 id="windowing-strategy">Windowing Strategy&lt;/h4>
&lt;p>Every PCollection has a windowing strategy, a specification of essential
information for grouping and triggering operations.&lt;/p>
&lt;p>The details will be discussed below when we discuss the
&lt;a href="#implementing-the-window-primitive">Window&lt;/a> primitive, which sets up the
windowing strategy, and
&lt;a href="#implementing-the-groupbykey-and-window-primitive">GroupByKey&lt;/a> primitive,
which has behavior governed by the windowing strategy.&lt;/p>
&lt;h3 id="user-defined-functions-udfs">User-Defined Functions (UDFs)&lt;/h3>
&lt;p>Beam has seven varieties of user-defined function (UDF). A Beam pipeline
may contain UDFs written in a language other than your runner, or even multiple
languages in the same pipeline (see the &lt;a href="#the-runner-api">Runner API&lt;/a>) so the
definitions are language-independent (see the &lt;a href="#the-fn-api">Fn API&lt;/a>).&lt;/p>
&lt;p>The UDFs of Beam are:&lt;/p>
&lt;ul>
&lt;li>&lt;em>DoFn&lt;/em> - per-element processing function (used in ParDo)&lt;/li>
&lt;li>&lt;em>WindowFn&lt;/em> - places elements in windows and merges windows (used in Window
and GroupByKey)&lt;/li>
&lt;li>&lt;em>Source&lt;/em> - emits data read from external sources, including initial and
dynamic splitting for parallelism (used in Read)&lt;/li>
&lt;li>&lt;em>ViewFn&lt;/em> - adapts a materialized PCollection to a particular interface (used
in side inputs)&lt;/li>
&lt;li>&lt;em>WindowMappingFn&lt;/em> - maps one element&amp;rsquo;s window to another, and specifies
bounds on how far in the past the result window will be (used in side
inputs)&lt;/li>
&lt;li>&lt;em>CombineFn&lt;/em> - associative and commutative aggregation (used in Combine and
state)&lt;/li>
&lt;li>&lt;em>Coder&lt;/em> - encodes user data; some coders have standard formats and are not really UDFs&lt;/li>
&lt;/ul>
&lt;p>The various types of user-defined functions will be described further alongside
the primitives that use them.&lt;/p>
&lt;h3 id="runner">Runner&lt;/h3>
&lt;p>The term &amp;ldquo;runner&amp;rdquo; is used for a couple of things. It generally refers to the
software that takes a Beam pipeline and executes it somehow. Often, this is the
translation code that you write. It usually also includes some customized
operators for your data processing engine, and is sometimes used to refer to
the full stack.&lt;/p>
&lt;p>A runner has just a single method &lt;code>run(Pipeline)&lt;/code>. From here on, I will often
use code font for proper nouns in our APIs, whether or not the identifiers
match across all SDKs.&lt;/p>
&lt;p>The &lt;code>run(Pipeline)&lt;/code> method should be asynchronous and results in a
PipelineResult which generally will be a job descriptor for your data
processing engine, providing methods for checking its status, canceling it, and
waiting for it to terminate.&lt;/p>
&lt;h2 id="implementing-the-beam-primitives">Implementing the Beam Primitives&lt;/h2>
&lt;p>Aside from encoding and persisting data - which presumably your engine already
does in some way or another - most of what you need to do is implement the Beam
primitives. This section provides a detailed look at each primitive, covering
what you need to know that might not be obvious and what support code is
provided.&lt;/p>
&lt;p>The primitives are designed for the benefit of pipeline authors, not runner
authors. Each represents a different conceptual mode of operation (external IO,
element-wise, grouping, windowing, union) rather than a specific implementation
decision. The same primitive may require a very different implementation based
on how the user instantiates it. For example, a &lt;code>ParDo&lt;/code> that uses state or
timers may require key partitioning, a &lt;code>GroupByKey&lt;/code> with speculative triggering
may require a more costly or complex implementation, and &lt;code>Read&lt;/code> is completely
different for bounded and unbounded data.&lt;/p>
&lt;h3 id="what-if-you-havent-implemented-some-of-these-features">What if you haven&amp;rsquo;t implemented some of these features?&lt;/h3>
&lt;p>That&amp;rsquo;s OK! You don&amp;rsquo;t have to do it all at once, and there may even be features
that don&amp;rsquo;t make sense for your runner to ever support. We maintain a
&lt;a href="/documentation/runners/capability-matrix/">capability matrix&lt;/a> on the Beam site so you can tell
users what you support. When you receive a &lt;code>Pipeline&lt;/code>, you should traverse it
and determine whether or not you can execute each &lt;code>DoFn&lt;/code> that you find. If
you cannot execute some &lt;code>DoFn&lt;/code> in the pipeline (or if there is any other
requirement that your runner lacks) you should reject the pipeline. In your
native environment, this may look like throwing an
&lt;code>UnsupportedOperationException&lt;/code>. The Runner API RPCs will make this explicit,
for cross-language portability.&lt;/p>
&lt;h3 id="implementing-the-pardo-primitive">Implementing the ParDo primitive&lt;/h3>
&lt;p>The &lt;code>ParDo&lt;/code> primitive describes element-wise transformation for a
&lt;code>PCollection&lt;/code>. &lt;code>ParDo&lt;/code> is the most complex primitive, because it is where any
per-element processing is described. In addition to very simple operations like
standard &lt;code>map&lt;/code> or &lt;code>flatMap&lt;/code> from functional programming, &lt;code>ParDo&lt;/code> also supports
multiple outputs, side inputs, initialization, flushing, teardown, and stateful
processing.&lt;/p>
&lt;p>The UDF that is applied to each element is called a &lt;code>DoFn&lt;/code>. The exact APIs for
a &lt;code>DoFn&lt;/code> can vary per language/SDK but generally follow the same pattern, so we
can discuss it with pseudocode. I will also often refer to the Java support
code, since I know it and most of our current and future runners are
Java-based.&lt;/p>
&lt;h4 id="bundles">Bundles&lt;/h4>
&lt;p>For correctness, a &lt;code>DoFn&lt;/code> &lt;em>should&lt;/em> represent an element-wise function, but in
fact is a long-lived object that processes elements in small groups called
bundles.&lt;/p>
&lt;p>Your runner decides how many elements, and which elements, to include in a
bundle, and can even decide dynamically in the middle of processing that the
current bundle has &amp;ldquo;ended&amp;rdquo;. How a bundle is processed ties in with the rest of
a DoFn&amp;rsquo;s lifecycle.&lt;/p>
&lt;p>It will generally improve throughput to make the largest bundles possible, so
that initialization and finalization costs are amortized over many elements.
But if your data is arriving as a stream, then you will want to terminate a
bundle in order to achieve appropriate latency, so bundles may be just a few
elements.&lt;/p>
&lt;h4 id="the-dofn-lifecycle">The DoFn Lifecycle&lt;/h4>
&lt;p>While each language&amp;rsquo;s SDK is free to make different decisions, the Python and
Java SDKs share an API with the following stages of a DoFn&amp;rsquo;s lifecycle.&lt;/p>
&lt;p>However, if you choose to execute a DoFn directly to improve performance or
single-language simplicity, then your runner is responsible for implementing
the following sequence:&lt;/p>
&lt;ul>
&lt;li>&lt;em>Setup&lt;/em> - called once per DoFn instance before anything else; this has not been
implemented in the Python SDK so the user can work around just with lazy
initialization&lt;/li>
&lt;li>&lt;em>StartBundle&lt;/em> - called once per bundle as initialization (actually, lazy
initialization is almost always equivalent and more efficient, but this hook
remains for simplicity for users)&lt;/li>
&lt;li>&lt;em>ProcessElement&lt;/em> / &lt;em>OnTimer&lt;/em> - called for each element and timer activation&lt;/li>
&lt;li>&lt;em>FinishBundle&lt;/em> - essentially &amp;ldquo;flush&amp;rdquo;; required to be called before
considering elements as actually processed&lt;/li>
&lt;li>&lt;em>Teardown&lt;/em> - release resources that were used across bundles; calling this
can be best effort due to failures&lt;/li>
&lt;/ul>
&lt;h4 id="dofnrunners">DoFnRunner(s)&lt;/h4>
&lt;p>This is a support class that has manifestations in both the Java codebase and
the Python codebase.&lt;/p>
&lt;p>&lt;strong>Java&lt;/strong>&lt;/p>
&lt;p>In Java, the &lt;code>beam-runners-core-java&lt;/code> library provides an interface
&lt;code>DoFnRunner&lt;/code> for bundle processing, with implementations for many situations.&lt;/p>
&lt;div class=language-java&amp;#32;no-toggle>
&lt;pre>&lt;code>interface DoFnRunner&amp;lt;InputT, OutputT&amp;gt; {
void startBundle();
void processElement(WindowedValue&amp;lt;InputT&amp;gt; elem);
void onTimer(String timerId, BoundedWindow window, Instant timestamp, TimeDomain timeDomain);
void finishBundle();
}&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>There are some implementations and variations of this for different scenarios:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/apache/beam/blob/master/runners/core-java/src/main/java/org/apache/beam/runners/core/SimpleDoFnRunner.java">&lt;code>SimpleDoFnRunner&lt;/code>&lt;/a> -
not actually simple at all; implements lots of the core functionality of
&lt;code>ParDo&lt;/code>. This is how most runners execute most &lt;code>DoFns&lt;/code>.&lt;/li>
&lt;li>&lt;a href="https://github.com/apache/beam/blob/master/runners/core-java/src/main/java/org/apache/beam/runners/core/LateDataDroppingDoFnRunner.java">&lt;code>LateDataDroppingDoFnRunner&lt;/code>&lt;/a> -
wraps a &lt;code>DoFnRunner&lt;/code> and drops data from expired windows so the wrapped
&lt;code>DoFnRunner&lt;/code> doesn&amp;rsquo;t get any unpleasant surprises&lt;/li>
&lt;li>&lt;a href="https://github.com/apache/beam/blob/master/runners/core-java/src/main/java/org/apache/beam/runners/core/StatefulDoFnRunner.java">&lt;code>StatefulDoFnRunner&lt;/code>&lt;/a> -
handles collecting expired state&lt;/li>
&lt;li>&lt;a href="https://github.com/apache/beam/blob/master/runners/core-java/src/main/java/org/apache/beam/runners/core/PushbackSideInputDoFnRunner.java">&lt;code>PushBackSideInputDoFnRunner&lt;/code>&lt;/a> -
buffers input while waiting for side inputs to be ready&lt;/li>
&lt;/ul>
&lt;p>These are all used heavily in implementations of Java runners. Invocations
via the &lt;a href="#the-fn-api">Fn API&lt;/a> may manifest as another implementation of
&lt;code>DoFnRunner&lt;/code> even though it will be doing far more than running a &lt;code>DoFn&lt;/code>.&lt;/p>
&lt;p>&lt;strong>Python&lt;/strong>&lt;/p>
&lt;p>See the &lt;a href="https://beam.apache.org/releases/pydoc/2.0.0/apache_beam.runners.html#apache_beam.runners.common.DoFnRunner">DoFnRunner pydoc&lt;/a>.&lt;/p>
&lt;h4 id="side-inputs">Side Inputs&lt;/h4>
&lt;p>&lt;em>Main design document:
&lt;a href="https://s.apache.org/beam-side-inputs-1-pager">https://s.apache.org/beam-side-inputs-1-pager&lt;/a>&lt;/em>&lt;/p>
&lt;p>A side input is a global view of a window of a &lt;code>PCollection&lt;/code>. This distinguishes
it from the main input, which is processed one element at a time. The SDK/user
prepares a &lt;code>PCollection&lt;/code> adequately, the runner materializes it, and then the
runner feeds it to the &lt;code>DoFn&lt;/code>.&lt;/p>
&lt;p>What you will need to implement is to inspect the materialization requested for
the side input, and prepare it appropriately, and corresponding interactions
when a &lt;code>DoFn&lt;/code> reads the side inputs.&lt;/p>
&lt;p>The details and available support code vary by language.&lt;/p>
&lt;p>&lt;strong>Java&lt;/strong>&lt;/p>
&lt;p>If you are using one of the above &lt;code>DoFnRunner&lt;/code> classes, then the interface for
letting them request side inputs is
&lt;a href="https://github.com/apache/beam/blob/master/runners/core-java/src/main/java/org/apache/beam/runners/core/SideInputReader.java">&lt;code>SideInputReader&lt;/code>&lt;/a>.
It is a simple mapping from side input and window to a value. The &lt;code>DoFnRunner&lt;/code>
will perform a mapping with the
&lt;a href="https://github.com/apache/beam/blob/master/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/windowing/WindowMappingFn.java">&lt;code>WindowMappingFn&lt;/code>&lt;/a>
to request the appropriate window so you do not worry about invoking this UDF.
When using the Fn API, it will be the SDK harness that maps windows as well.&lt;/p>
&lt;p>A simple, but not necessarily optimal approach to building a
&lt;a href="https://github.com/apache/beam/blob/master/runners/core-java/src/main/java/org/apache/beam/runners/core/SideInputReader.java">&lt;code>SideInputReader&lt;/code>&lt;/a>
is to use a state backend. In our Java support code, this is called
&lt;a href="https://github.com/apache/beam/blob/master/runners/core-java/src/main/java/org/apache/beam/runners/core/StateInternals.java">&lt;code>StateInternals&lt;/code>&lt;/a>
and you can build a
&lt;a href="https://github.com/apache/beam/blob/master/runners/core-java/src/main/java/org/apache/beam/runners/core/SideInputHandler.java">&lt;code>SideInputHandler&lt;/code>&lt;/a>
that will use your &lt;code>StateInternals&lt;/code> to materialize a &lt;code>PCollection&lt;/code> into the
appropriate side input view and then yield the value when requested for a
particular side input and window.&lt;/p>
&lt;p>When a side input is needed but the side input has no data associated with it
for a given window, elements in that window must be deferred until the side
input has some data. The aforementioned
&lt;a href="https://github.com/apache/beam/blob/master/runners/core-java/src/main/java/org/apache/beam/runners/core/PushbackSideInputDoFnRunner.java">&lt;code>PushBackSideInputDoFnRunner&lt;/code>&lt;/a>
is used to implement this.&lt;/p>
&lt;p>&lt;strong>Python&lt;/strong>&lt;/p>
&lt;p>In Python, &lt;a href="https://beam.apache.org/releases/pydoc/2.0.0/apache_beam.transforms.html#apache_beam.transforms.sideinputs.SideInputMap">&lt;code>SideInputMap&lt;/code>&lt;/a> maps
windows to side input values. The &lt;code>WindowMappingFn&lt;/code> manifests as a simple
function. See
&lt;a href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/transforms/sideinputs.py">sideinputs.py&lt;/a>.&lt;/p>
&lt;h4 id="state-and-timers">State and Timers&lt;/h4>
&lt;p>&lt;em>Main design document: &lt;a href="https://s.apache.org/beam-state">https://s.apache.org/beam-state&lt;/a>&lt;/em>&lt;/p>
&lt;p>When a &lt;code>ParDo&lt;/code> includes state and timers, its execution on your runner is usually
very different. See the full details beyond those covered here.&lt;/p>
&lt;p>State and timers are partitioned per key and window. You may need or want to
explicitly shuffle data to support this.&lt;/p>
&lt;p>&lt;strong>Java&lt;/strong>&lt;/p>
&lt;p>We provide
&lt;a href="https://github.com/apache/beam/blob/master/runners/core-java/src/main/java/org/apache/beam/runners/core/StatefulDoFnRunner.java">&lt;code>StatefulDoFnRunner&lt;/code>&lt;/a>
to help with state cleanup. The non-user-facing interface
&lt;a href="https://github.com/apache/beam/blob/master/runners/core-java/src/main/java/org/apache/beam/runners/core/StateInternals.java">&lt;code>StateInternals&lt;/code>&lt;/a>
is what a runner generally implements, and then the Beam support code can use
this to implement user-facing state.&lt;/p>
&lt;h4 id="splittable-dofn">Splittable DoFn&lt;/h4>
&lt;p>&lt;em>Main design document: &lt;a href="https://s.apache.org/splittable-do-fn">https://s.apache.org/splittable-do-fn&lt;/a>&lt;/em>&lt;/p>
&lt;p>Splittable &lt;code>DoFn&lt;/code> is a generalization and combination of &lt;code>ParDo&lt;/code> and &lt;code>Read&lt;/code>. It
is per-element processing where each element has the capability of being &amp;ldquo;split&amp;rdquo;
in the same ways as a &lt;code>BoundedSource&lt;/code> or &lt;code>UnboundedSource&lt;/code>. This enables better
performance for use cases such as a &lt;code>PCollection&lt;/code> of names of large files where
you want to read each of them. Previously they would have to be static data in
the pipeline or be read in a non-splittable manner.&lt;/p>
&lt;p>This feature is still under development, but likely to become the new primitive
for reading. It is best to be aware of it and follow developments.&lt;/p>
&lt;h3 id="implementing-the-groupbykey-and-window-primitive">Implementing the GroupByKey (and window) primitive&lt;/h3>
&lt;p>The &lt;code>GroupByKey&lt;/code> operation (sometimes called GBK for short) groups a
&lt;code>PCollection&lt;/code> of key-value pairs by key and window, emitting results according
to the &lt;code>PCollection&lt;/code>'s triggering configuration.&lt;/p>
&lt;p>It is quite a bit more elaborate than simply colocating elements with the same
key, and uses many fields from the &lt;code>PCollection&lt;/code>'s windowing strategy.&lt;/p>
&lt;h4 id="group-by-encoded-bytes">Group By Encoded Bytes&lt;/h4>
&lt;p>For both the key and window, your runner sees them as &amp;ldquo;just bytes&amp;rdquo;. So you need
to group in a way that is consistent with grouping by those bytes, even if you
have some special knowledge of the types involved.&lt;/p>
&lt;p>The elements you are processing will be key-value pairs, and you&amp;rsquo;ll need to extract
the keys. For this reason, the format of key-value pairs is standardized and
shared across all SDKS. See either
&lt;a href="https://beam.apache.org/releases/javadoc/2.0.0/org/apache/beam/sdk/coders/KvCoder.html">&lt;code>KvCoder&lt;/code>&lt;/a>
in Java or
&lt;a href="https://beam.apache.org/releases/pydoc/2.0.0/apache_beam.coders.html#apache_beam.coders.coders.TupleCoder.key_coder">&lt;code>TupleCoder&lt;/code>&lt;/a>
in Python for documentation on the binary format.&lt;/p>
&lt;h4 id="window-merging">Window Merging&lt;/h4>
&lt;p>As well as grouping by key, your runner must group elements by their window. A
&lt;code>WindowFn&lt;/code> has the option of declaring that it merges windows on a per-key
basis. For example, session windows for the same key will be merged if they
overlap. So your runner must invoke the merge method of the &lt;code>WindowFn&lt;/code> during
grouping.&lt;/p>
&lt;h4 id="implementing-via-groupbykeyonly--groupalsobywindow">Implementing via GroupByKeyOnly + GroupAlsoByWindow&lt;/h4>
&lt;p>The Java codebase includes support code for a particularly common way of
implementing the full &lt;code>GroupByKey&lt;/code> operation: first group the keys, and then group
by window. For merging windows, this is essentially required, since merging is
per key.&lt;/p>
&lt;h4 id="dropping-late-data">Dropping late data&lt;/h4>
&lt;p>&lt;em>Main design document:
&lt;a href="https://s.apache.org/beam-lateness">https://s.apache.org/beam-lateness&lt;/a>&lt;/em>&lt;/p>
&lt;p>A window is expired in a &lt;code>PCollection&lt;/code> if the watermark of the input PCollection
has exceeded the end of the window by at least the input &lt;code>PCollection&lt;/code>'s
allowed lateness.&lt;/p>
&lt;p>Data for an expired window can be dropped any time and should be dropped at a
&lt;code>GroupByKey&lt;/code>. If you are using &lt;code>GroupAlsoByWindow&lt;/code>, then just before executing
this transform. You may shuffle less data if you drop data prior to
&lt;code>GroupByKeyOnly&lt;/code>, but should only safely be done for non-merging windows, as a
window that appears expired may merge to become not expired.&lt;/p>
&lt;h4 id="triggering">Triggering&lt;/h4>
&lt;p>&lt;em>Main design document:
&lt;a href="https://s.apache.org/beam-triggers">https://s.apache.org/beam-triggers&lt;/a>&lt;/em>&lt;/p>
&lt;p>The input &lt;code>PCollection&lt;/code>'s trigger and accumulation mode specify when and how
outputs should be emitted from the &lt;code>GroupByKey&lt;/code> operation.&lt;/p>
&lt;p>In Java, there is a lot of support code for executing triggers in the
&lt;code>GroupAlsoByWindow&lt;/code> implementations, &lt;code>ReduceFnRunner&lt;/code> (legacy name), and
&lt;code>TriggerStateMachine&lt;/code>, which is an obvious way of implementing all triggers as
an event-driven machine over elements and timers.&lt;/p>
&lt;h4 id="timestampcombiner">TimestampCombiner&lt;/h4>
&lt;p>When an aggregated output is produced from multiple inputs, the &lt;code>GroupByKey&lt;/code>
operation has to choose a timestamp for the combination. To do so, first the
WindowFn has a chance to shift timestamps - this is needed to ensure watermarks
do not prevent progress of windows like sliding windows (the details are beyond
this doc). Then, the shifted timestamps need to be combined - this is specified
by a &lt;code>TimestampCombiner&lt;/code>, which can either select the minimum or maximum of its
inputs, or just ignore inputs and choose the end of the window.&lt;/p>
&lt;h3 id="implementing-the-window-primitive">Implementing the Window primitive&lt;/h3>
&lt;p>The window primitive applies a &lt;code>WindowFn&lt;/code> UDF to place each input element into
one or more windows of its output PCollection. Note that the primitive also
generally configures other aspects of the windowing strategy for a &lt;code>PCollection&lt;/code>,
but the fully constructed graph that your runner receives will already have a
complete windowing strategy for each &lt;code>PCollection&lt;/code>.&lt;/p>
&lt;p>To implement this primitive, you need to invoke the provided WindowFn on each
element, which will return some set of windows for that element to be a part of
in the output &lt;code>PCollection&lt;/code>.&lt;/p>
&lt;p>&lt;strong>Implementation considerations&lt;/strong>&lt;/p>
&lt;p>A &amp;ldquo;window&amp;rdquo; is just a second grouping key that has a &amp;ldquo;maximum timestamp&amp;rdquo;. It can
be any arbitrary user-defined type. The &lt;code>WindowFn&lt;/code> provides the coder for the
window type.&lt;/p>
&lt;p>Beam&amp;rsquo;s support code provides &lt;code>WindowedValue&lt;/code> which is a compressed
representation of an element in multiple windows. You may want to do use this,
or your own compressed representation. Remember that it simply represents
multiple elements at the same time; there is no such thing as an element &amp;ldquo;in
multiple windows&amp;rdquo;.&lt;/p>
&lt;p>For values in the global window, you may want to use an even further compressed
representation that doesn&amp;rsquo;t bother including the window at all.&lt;/p>
&lt;p>In the future, this primitive may be retired as it can be implemented as a
ParDo if the capabilities of ParDo are enhanced to allow output to new windows.&lt;/p>
&lt;h3 id="implementing-the-read-primitive">Implementing the Read primitive&lt;/h3>
&lt;p>You implement this primitive to read data from an external system. The APIs are
carefully crafted to enable efficient parallel execution. Reading from an
&lt;code>UnboundedSource&lt;/code> is a bit different than reading from a &lt;code>BoundedSource&lt;/code>.&lt;/p>
&lt;h4 id="reading-from-an-unboundedsource">Reading from an UnboundedSource&lt;/h4>
&lt;p>An &lt;code>UnboundedSource&lt;/code> is a source of potentially infinite data; you can think of
it like a stream. The capabilities are:&lt;/p>
&lt;ul>
&lt;li>&lt;code>split(int)&lt;/code> - your runner should call this to get the desired parallelism&lt;/li>
&lt;li>&lt;code>createReader(...)&lt;/code> - call this to start reading elements; it is an enhanced iterator that also provides:&lt;/li>
&lt;li>watermark (for this source) which you should propagate downstream&lt;/li>
&lt;li>timestamps, which you should associate with elements read&lt;/li>
&lt;li>record identifiers, so you can dedup downstream if needed&lt;/li>
&lt;li>progress indication of its backlog&lt;/li>
&lt;li>checkpointing&lt;/li>
&lt;li>&lt;code>requiresDeduping&lt;/code> - this indicates that there is some chance that the source
may emit duplicates; your runner should do its best to dedupe based on the
identifier attached to emitted records&lt;/li>
&lt;/ul>
&lt;p>An unbounded source has a custom type of checkpoints and an associated coder for serializing them.&lt;/p>
&lt;h4 id="reading-from-a-boundedsource">Reading from a BoundedSource&lt;/h4>
&lt;p>A &lt;code>BoundedSource&lt;/code> is a source of data that you know is finite, such as a static
collection of log files, or a database table. The capabilities are:&lt;/p>
&lt;ul>
&lt;li>&lt;code>split(int)&lt;/code> - your runner should call this to get desired initial parallelism (but you can often steal work later)&lt;/li>
&lt;li>&lt;code>getEstimatedSizeBytes(...)&lt;/code> - self explanatory&lt;/li>
&lt;li>&lt;code>createReader(...)&lt;/code> - call this to start reading elements; it is an enhanced iterator that also provides:&lt;/li>
&lt;li>timestamps to associate with each element read&lt;/li>
&lt;li>&lt;code>splitAtFraction&lt;/code> for dynamic splitting to enable work stealing, and other
methods to support it - see the &lt;a href="/blog/2016/05/18/splitAtFraction-method.html">Beam blog post on dynamic work
rebalancing&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>The &lt;code>BoundedSource&lt;/code> does not report a watermark currently. Most of the time, reading
from a bounded source can be parallelized in ways that result in utterly out-of-order
data, so a watermark is not terribly useful.
Thus the watermark for the output &lt;code>PCollection&lt;/code> from a bounded read should
remain at the minimum timestamp throughout reading (otherwise data might get
dropped) and advance to the maximum timestamp when all data is exhausted.&lt;/p>
&lt;h3 id="implementing-the-flatten-primitive">Implementing the Flatten primitive&lt;/h3>
&lt;p>This one is easy - take as input a finite set of &lt;code>PCollections&lt;/code> and outputs their
bag union, keeping windows intact.&lt;/p>
&lt;p>For this operation to make sense, it is the SDK&amp;rsquo;s responsibility to make sure
the windowing strategies are compatible.&lt;/p>
&lt;p>Also note that there is no requirement that the coders for all the &lt;code>PCollections&lt;/code>
be the same. If your runner wants to require that (to avoid tedious
re-encoding) you have to enforce it yourself. Or you could just implement the
fast path as an optimization.&lt;/p>
&lt;h3 id="special-mention-the-combine-composite">Special mention: the Combine composite&lt;/h3>
&lt;p>A composite transform that is almost always treated specially by a runner is
&lt;code>Combine&lt;/code> (per key), which applies an associative and commutative operator to
the elements of a &lt;code>PCollection&lt;/code>. This composite is not a primitive. It is
implemented in terms of &lt;code>ParDo&lt;/code> and &lt;code>GroupByKey&lt;/code>, so your runner will work
without treating it - but it does carry additional information that you
probably want to use for optimizations: the associative-commutative operator,
known as a &lt;code>CombineFn&lt;/code>.&lt;/p>
&lt;h2 id="working-with-pipelines">Working with pipelines&lt;/h2>
&lt;p>When you receive a pipeline from a user, you will need to translate it. This is
a tour of the APIs that you&amp;rsquo;ll use to do it.&lt;/p>
&lt;h3 id="traversing-a-pipeline">Traversing a pipeline&lt;/h3>
&lt;p>Something you will likely do is to traverse a pipeline, probably to translate
it into primitives for your engine. The general pattern is to write a visitor
that builds a job specification as it walks the graph of &lt;code>PTransforms&lt;/code>.&lt;/p>
&lt;p>The entry point for this in Java is
&lt;a href="https://beam.apache.org/releases/javadoc/2.0.0/org/apache/beam/sdk/Pipeline.html#traverseTopologically-org.apache.beam.sdk.Pipeline.PipelineVisitor-">&lt;code>Pipeline.traverseTopologically&lt;/code>&lt;/a>
and
&lt;a href="https://beam.apache.org/releases/pydoc/2.0.0/apache_beam.html#apache_beam.pipeline.Pipeline.visit">&lt;code>Pipeline.visit&lt;/code>&lt;/a>
in Python. See the generated documentation for details.&lt;/p>
&lt;h3 id="altering-a-pipeline">Altering a pipeline&lt;/h3>
&lt;p>Often, the best way to keep your
translator simple will be to alter the pipeline prior to translation. Some
alterations you might perform:&lt;/p>
&lt;ul>
&lt;li>Elaboration of a Beam primitive into a composite transform that uses
multiple runner-specific primitives&lt;/li>
&lt;li>Optimization of a Beam composite into a specialized primitive for your
runner&lt;/li>
&lt;li>Replacement of a Beam composite with a different expansion more suitable for
your runner&lt;/li>
&lt;/ul>
&lt;p>The Java SDK and the &amp;ldquo;runners core construction&amp;rdquo; library (the artifact is
&lt;code>beam-runners-core-construction-java&lt;/code> and the namespaces is
&lt;code>org.apache.beam.runners.core.construction&lt;/code>) contain helper code for this sort
of work. In Python, support code is still under development.&lt;/p>
&lt;p>All pipeline alteration is done via
&lt;a href="https://beam.apache.org/releases/javadoc/2.0.0/org/apache/beam/sdk/Pipeline.html#replaceAll-java.util.List-">&lt;code>Pipeline.replaceAll(PTransformOverride)&lt;/code>&lt;/a>
method. A
&lt;a href="https://github.com/apache/beam/blob/master/sdks/java/core/src/main/java/org/apache/beam/sdk/runners/PTransformOverride.java">&lt;code>PTransformOverride&lt;/code>&lt;/a>
is a pair of a
&lt;a href="https://github.com/apache/beam/blob/master/sdks/java/core/src/main/java/org/apache/beam/sdk/runners/PTransformMatcher.java">&lt;code>PTransformMatcher&lt;/code>&lt;/a>
to select transforms for replacement and a
&lt;a href="https://github.com/apache/beam/blob/master/sdks/java/core/src/main/java/org/apache/beam/sdk/runners/PTransformOverrideFactory.java">&lt;code>PTransformOverrideFactory&lt;/code>&lt;/a>
to produce the replacement. All &lt;code>PTransformMatchers&lt;/code> that have been needed by
runners to date are provided. Examples include: matching a specific class,
matching a &lt;code>ParDo&lt;/code> where the &lt;code>DoFn&lt;/code> uses state or timers, etc.&lt;/p>
&lt;h2 id="testing-your-runner">Testing your runner&lt;/h2>
&lt;p>The Beam Java SDK and Python SDK have suites of runner validation tests. The
configuration may evolve faster than this document, so check the configuration
of other Beam runners. But be aware that we have tests and you can use them
very easily! To enable these tests in a Java-based runner using Gradle, you
scan the dependencies of the SDK for tests with the JUnit category
&lt;code>ValidatesRunner&lt;/code>.&lt;/p>
&lt;div class=no-toggle>
&lt;pre>&lt;code>task validatesRunner(type: Test) {
group = &amp;#34;Verification&amp;#34;
description = &amp;#34;Validates the runner&amp;#34;
def pipelineOptions = JsonOutput.toJson([&amp;#34;--runner=MyRunner&amp;#34;, ... misc test options ...])
systemProperty &amp;#34;beamTestPipelineOptions&amp;#34;, pipelineOptions
classpath = configurations.validatesRunner
testClassesDirs = files(project(&amp;#34;:sdks:java:core&amp;#34;).sourceSets.test.output.classesDirs)
useJUnit {
includeCategories &amp;#39;org.apache.beam.sdk.testing.ValidatesRunner&amp;#39;
}
}&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>Enabling these tests in other languages is unexplored.&lt;/p>
&lt;h2 id="integrating-your-runner-nicely-with-sdks">Integrating your runner nicely with SDKs&lt;/h2>
&lt;p>Whether or not your runner is based in the same language as an SDK (such as
Java), you will want to provide a shim to invoke it from another SDK if you
want the users of that SDK (such as Python) to use it.&lt;/p>
&lt;h3 id="integrating-with-the-java-sdk">Integrating with the Java SDK&lt;/h3>
&lt;h4 id="allowing-users-to-pass-options-to-your-runner">Allowing users to pass options to your runner&lt;/h4>
&lt;p>The mechanism for configuration is
&lt;a href="https://beam.apache.org/releases/javadoc/2.0.0/org/apache/beam/sdk/options/PipelineOptions.html">&lt;code>PipelineOptions&lt;/code>&lt;/a>,
an interface that works completely differently than normal Java objects. Forget
what you know, and follow the rules, and &lt;code>PipelineOptions&lt;/code> will treat you well.&lt;/p>
&lt;p>You must implement a sub-interface for your runner with getters and setters
with matching names, like so:&lt;/p>
&lt;div class=language-java&amp;#32;no-toggle>
&lt;pre>&lt;code>public interface MyRunnerOptions extends PipelineOptions {
@Description(&amp;#34;The Foo to use with MyRunner&amp;#34;)
@Required
public Foo getMyRequiredFoo();
public void setMyRequiredFoo(Foo newValue);
@Description(&amp;#34;Enable Baz; on by default&amp;#34;)
@Default.Boolean(true)
public Boolean isBazEnabled();
public void setBazEnabled(Boolean newValue);
}&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>You can set up defaults, etc. See the javadoc for details. When your runner is
instantiated with a &lt;code>PipelineOptions&lt;/code> object, you access your interface by
&lt;code>options.as(MyRunnerOptions.class)&lt;/code>.&lt;/p>
&lt;p>To make these options available on the command line, you register your options
with a &lt;code>PipelineOptionsRegistrar&lt;/code>. It is easy if you use &lt;code>@AutoService&lt;/code>:&lt;/p>
&lt;div class=language-java&amp;#32;no-toggle>
&lt;pre>&lt;code>@AutoService(PipelineOptionsRegistrar.class)
public static class MyOptionsRegistrar implements PipelineOptionsRegistrar {
@Override
public Iterable&amp;lt;Class&amp;lt;? extends PipelineOptions&amp;gt;&amp;gt; getPipelineOptions() {
return ImmutableList.&amp;lt;Class&amp;lt;? extends PipelineOptions&amp;gt;&amp;gt;of(MyRunnerOptions.class);
}
}&lt;/code>&lt;/pre>
&lt;/div>
&lt;h4 id="registering-your-runner-with-sdks-for-command-line-use">Registering your runner with SDKs for command line use&lt;/h4>
&lt;p>To make your runner available on the command line, you register your options
with a &lt;code>PipelineRunnerRegistrar&lt;/code>. It is easy if you use &lt;code>@AutoService&lt;/code>:&lt;/p>
&lt;div class=language-java&amp;#32;no-toggle>
&lt;pre>&lt;code>@AutoService(PipelineRunnerRegistrar.class)
public static class MyRunnerRegistrar implements PipelineRunnerRegistrar {
@Override
public Iterable&amp;lt;Class&amp;lt;? extends PipelineRunner&amp;gt;&amp;gt; getPipelineRunners() {
return ImmutableList.&amp;lt;Class&amp;lt;? extends PipelineRunner&amp;gt;&amp;gt;of(MyRunner.class);
}
}&lt;/code>&lt;/pre>
&lt;/div>
&lt;h3 id="integrating-with-the-python-sdk">Integrating with the Python SDK&lt;/h3>
&lt;p>In the Python SDK the registration of the code is not automatic. So there are
few things to keep in mind when creating a new runner.&lt;/p>
&lt;p>Any dependencies on packages for the new runner should be options so create a
new target in &lt;code>extra_requires&lt;/code> in &lt;code>setup.py&lt;/code> that is needed for the new runner.&lt;/p>
&lt;p>All runner code should go in it&amp;rsquo;s own package in &lt;code>apache_beam/runners&lt;/code> directory.&lt;/p>
&lt;p>Register the new runner in the &lt;code>create_runner&lt;/code> function of &lt;code>runner.py&lt;/code> so that the
partial name is matched with the correct class to be used.&lt;/p>
&lt;h2 id="writing-an-sdk-independent-runner">Writing an SDK-independent runner&lt;/h2>
&lt;p>There are two aspects to making your runner SDK-independent, able to run
pipelines written in other languages: The Fn API and the Runner API.&lt;/p>
&lt;h3 id="the-fn-api">The Fn API&lt;/h3>
&lt;p>&lt;em>Design documents:&lt;/em>&lt;/p>
&lt;ul>
&lt;li>&lt;em>&lt;a href="https://s.apache.org/beam-fn-api">https://s.apache.org/beam-fn-api&lt;/a>&lt;/em>&lt;/li>
&lt;li>&lt;em>&lt;a href="https://s.apache.org/beam-fn-api-processing-a-bundle">https://s.apache.org/beam-fn-api-processing-a-bundle&lt;/a>&lt;/em>&lt;/li>
&lt;li>&lt;em>&lt;a href="https://s.apache.org/beam-fn-api-send-and-receive-data">https://s.apache.org/beam-fn-api-send-and-receive-data&lt;/a>&lt;/em>&lt;/li>
&lt;/ul>
&lt;p>To run a user&amp;rsquo;s pipeline, you need to be able to invoke their UDFs. The Fn API
is an RPC interface for the standard UDFs of Beam, implemented using protocol
buffers over gRPC.&lt;/p>
&lt;p>The Fn API includes:&lt;/p>
&lt;ul>
&lt;li>APIs for registering a subgraph of UDFs&lt;/li>
&lt;li>APIs for streaming elements of a bundle&lt;/li>
&lt;li>Shared data formats (key-value pairs, timestamps, iterables, etc)&lt;/li>
&lt;/ul>
&lt;p>You are fully welcome to &lt;em>also&lt;/em> use the SDK for your language for utility code,
or provide optimized implementations of bundle processing for same-language
UDFs.&lt;/p>
&lt;h3 id="the-runner-api">The Runner API&lt;/h3>
&lt;p>The Runner API is an SDK-independent schema for a pipeline along with RPC
interfaces for launching a pipeline and checking the status of a job. The RPC
interfaces are still in development so for now we focus on the SDK-agnostic
representation of a pipeline. By examining a pipeline only through Runner API
interfaces, you remove your runner&amp;rsquo;s dependence on the SDK for its language for
pipeline analysis and job translation.&lt;/p>
&lt;p>To execute such an SDK-independent pipeline, you will need to support the Fn
API. UDFs are embedded in the pipeline as a specification of the function
(often just opaque serialized bytes for a particular language) plus a
specification of an environment that can execute it (essentially a particular
SDK). So far, this specification is expected to be a URI for a Docker container
hosting the SDK&amp;rsquo;s Fn API harness.&lt;/p>
&lt;p>You are fully welcome to &lt;em>also&lt;/em> use the SDK for your language, which may offer
useful utility code.&lt;/p>
&lt;p>The language-independent definition of a pipeline is described via a protocol
buffers schema, covered below for reference. But your runner &lt;em>should not&lt;/em>
directly manipulate protobuf messages. Instead, the Beam codebase provides
utilities for working with pipelines so that you don&amp;rsquo;t need to be aware of
whether or not the pipeline has ever been serialized or transmitted, or what
language it may have been written in to begin with.&lt;/p>
&lt;p>&lt;strong>Java&lt;/strong>&lt;/p>
&lt;p>If your runner is Java-based, the tools to interact with pipelines in an
SDK-agnostic manner are in the &lt;code>beam-runners-core-construction-java&lt;/code>
artifact, in the &lt;code>org.apache.beam.runners.core.construction&lt;/code> namespace.
The utilities are named consistently, like so:&lt;/p>
&lt;ul>
&lt;li>&lt;code>PTransformTranslation&lt;/code> - registry of known transforms and standard URNs&lt;/li>
&lt;li>&lt;code>ParDoTranslation&lt;/code> - utilities for working with &lt;code>ParDo&lt;/code> in a
language-independent manner&lt;/li>
&lt;li>&lt;code>WindowIntoTranslation&lt;/code> - same for &lt;code>Window&lt;/code>&lt;/li>
&lt;li>&lt;code>FlattenTranslation&lt;/code> - same for &lt;code>Flatten&lt;/code>&lt;/li>
&lt;li>&lt;code>WindowingStrategyTranslation&lt;/code> - same for windowing strategies&lt;/li>
&lt;li>&lt;code>CoderTranslation&lt;/code> - same for coders&lt;/li>
&lt;li>&amp;hellip; etc, etc &amp;hellip;&lt;/li>
&lt;/ul>
&lt;p>By inspecting transforms only through these classes, your runner will not
depend on the particulars of the Java SDK.&lt;/p>
&lt;h2 id="the-runner-api-protos">The Runner API protos&lt;/h2>
&lt;p>The &lt;a href="https://github.com/apache/beam/blob/master/model/pipeline/src/main/proto/beam_runner_api.proto">Runner
API&lt;/a>
refers to a specific manifestation of the concepts in the Beam model, as a
protocol buffers schema. Even though you should not manipulate these messages
directly, it can be helpful to know the canonical data that makes up a
pipeline.&lt;/p>
&lt;p>Most of the API is exactly the same as the high-level description; you can get
started implementing a runner without understanding all the low-level details.&lt;/p>
&lt;p>The most important takeaway of the Runner API for you is that it is a
language-independent definition of a Beam pipeline. You will probably always
interact via a particular SDK&amp;rsquo;s support code wrapping these definitions with
sensible idiomatic APIs, but always be aware that this is the specification and
any other data is not necessarily inherent to the pipeline, but may be
SDK-specific enrichments (or bugs!).&lt;/p>
&lt;p>The UDFs in the pipeline may be written for any Beam SDK, or even multiple in
the same pipeline. So this is where we will start, taking a bottom-up approach
to understanding the protocol buffers definitions for UDFs before going back to
the higher-level, mostly obvious, record definitions.&lt;/p>
&lt;h3 id="functionspec-proto">&lt;code>FunctionSpec&lt;/code> proto&lt;/h3>
&lt;p>The heart of cross-language portability is the &lt;code>FunctionSpec&lt;/code>. This is a
language-independent specification of a function, in the usual programming
sense that includes side effects, etc.&lt;/p>
&lt;div class=no-toggle>
&lt;pre>&lt;code>message FunctionSpec {
string urn;
google.protobuf.Any parameter;
}&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>A &lt;code>FunctionSpec&lt;/code> includes a URN identifying the function as well as an arbitrary
fixed parameter. For example the (hypothetical) &amp;ldquo;max&amp;rdquo; CombineFn might have the
URN &lt;code>beam:combinefn:max:0.1&lt;/code> and a parameter that indicates by what
comparison to take the max.&lt;/p>
&lt;p>For most UDFs in a pipeline constructed using a particular language&amp;rsquo;s SDK, the
URN will indicate that the SDK must interpret it, for example
&lt;code>beam:dofn:javasdk:0.1&lt;/code> or &lt;code>beam:dofn:pythonsdk:0.1&lt;/code>. The parameter
will contain serialized code, such as a Java-serialized &lt;code>DoFn&lt;/code> or a Python
pickled &lt;code>DoFn&lt;/code>.&lt;/p>
&lt;p>A &lt;code>FunctionSpec&lt;/code> is not only for UDFs. It is just a generic way to name/specify
any function. It is also used as the specification for a &lt;code>PTransform&lt;/code>. But when
used in a &lt;code>PTransform&lt;/code> it describes a function from &lt;code>PCollection&lt;/code> to &lt;code>PCollection&lt;/code>
and cannot be specific to an SDK because the runner is in charge of evaluating
transforms and producing &lt;code>PCollections&lt;/code>.&lt;/p>
&lt;h3 id="sdkfunctionspec-proto">&lt;code>SdkFunctionSpec&lt;/code> proto&lt;/h3>
&lt;p>When a &lt;code>FunctionSpec&lt;/code> represents a UDF, in general only the SDK that serialized
it will be guaranteed to understand it. So in that case, it will always come
with an environment that can understand and execute the function. This is
represented by the &lt;code>SdkFunctionSpec&lt;/code>.&lt;/p>
&lt;div class=no-toggle>
&lt;pre>&lt;code>message SdkFunctionSpec {
FunctionSpec spec;
bytes environment_id;
}&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>In the Runner API, many objects are stored by reference. Here in the
&lt;code>environment_id&lt;/code> is a pointer, local to the pipeline and just made up by the
SDK that serialized it, that can be dereferenced to yield the actual
environment proto.&lt;/p>
&lt;p>Thus far, an environment is expected to be a Docker container specification for
an SDK harness that can execute the specified UDF.&lt;/p>
&lt;h3 id="primitive-transform-payload-protos">Primitive transform payload protos&lt;/h3>
&lt;p>The payload for the primitive transforms are just proto serializations of their
specifications. Rather than reproduce their full code here, I will just
highlight the important pieces to show how they fit together.&lt;/p>
&lt;p>It is worth emphasizing again that while you probably will not interact
directly with these payloads, they are the only data that is inherently part of
the transform.&lt;/p>
&lt;h4 id="pardopayload-proto">&lt;code>ParDoPayload&lt;/code> proto&lt;/h4>
&lt;p>A &lt;code>ParDo&lt;/code> transform carries its &lt;code>DoFn&lt;/code> in an &lt;code>SdkFunctionSpec&lt;/code> and then
provides language-independent specifications for its other features - side
inputs, state declarations, timer declarations, etc.&lt;/p>
&lt;div class=no-toggle>
&lt;pre>&lt;code>message ParDoPayload {
SdkFunctionSpec do_fn;
map&amp;lt;string, SideInput&amp;gt; side_inputs;
map&amp;lt;string, StateSpec&amp;gt; state_specs;
map&amp;lt;string, TimerSpec&amp;gt; timer_specs;
...
}&lt;/code>&lt;/pre>
&lt;/div>
&lt;h4 id="readpayload-proto">&lt;code>ReadPayload&lt;/code> proto&lt;/h4>
&lt;p>A &lt;code>Read&lt;/code> transform carries an &lt;code>SdkFunctionSpec&lt;/code> for its &lt;code>Source&lt;/code> UDF.&lt;/p>
&lt;div class=no-toggle>
&lt;pre>&lt;code>message ReadPayload {
SdkFunctionSpec source;
...
}&lt;/code>&lt;/pre>
&lt;/div>
&lt;h4 id="windowintopayload-proto">&lt;code>WindowIntoPayload&lt;/code> proto&lt;/h4>
&lt;p>A &lt;code>Window&lt;/code> transform carries an &lt;code>SdkFunctionSpec&lt;/code> for its &lt;code>WindowFn&lt;/code> UDF. It is
part of the Fn API that the runner passes this UDF along and tells the SDK
harness to use it to assign windows (as opposed to merging).&lt;/p>
&lt;div class=no-toggle>
&lt;pre>&lt;code>message WindowIntoPayload {
SdkFunctionSpec window_fn;
...
}&lt;/code>&lt;/pre>
&lt;/div>
&lt;h4 id="combinepayload-proto">&lt;code>CombinePayload&lt;/code> proto&lt;/h4>
&lt;p>&lt;code>Combine&lt;/code> is not a primitive. But non-primitives are perfectly able to carry
additional information for better optimization. The most important thing that a
&lt;code>Combine&lt;/code> transform carries is the &lt;code>CombineFn&lt;/code> in an &lt;code>SdkFunctionSpec&lt;/code> record.
In order to effectively carry out the optimizations desired, it is also
necessary to know the coder for intermediate accumulations, so it also carries
a reference to this coder.&lt;/p>
&lt;div class=no-toggle>
&lt;pre>&lt;code>message CombinePayload {
SdkFunctionSpec combine_fn;
string accumulator_coder_id;
...
}&lt;/code>&lt;/pre>
&lt;/div>
&lt;h3 id="ptransform-proto">&lt;code>PTransform&lt;/code> proto&lt;/h3>
&lt;p>A &lt;code>PTransform&lt;/code> is a function from &lt;code>PCollection&lt;/code> to &lt;code>PCollection&lt;/code>. This is
represented in the proto using a FunctionSpec. Note that this is not an
&lt;code>SdkFunctionSpec&lt;/code>, since it is the runner that observes these. They will never
be passed back to an SDK harness; they do not represent a UDF.&lt;/p>
&lt;div class=no-toggle>
&lt;pre>&lt;code>message PTransform {
FunctionSpec spec;
repeated string subtransforms;
// Maps from local string names to PCollection ids
map&amp;lt;string, bytes&amp;gt; inputs;
map&amp;lt;string, bytes&amp;gt; outputs;
...
}&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>A &lt;code>PTransform&lt;/code> may have subtransforms if it is a composite, in which case the
&lt;code>FunctionSpec&lt;/code> may be omitted since the subtransforms define its behavior.&lt;/p>
&lt;p>The input and output &lt;code>PCollections&lt;/code> are unordered and referred to by a local
name. The SDK decides what this name is, since it will likely be embedded in
serialized UDFs.&lt;/p>
&lt;h3 id="pcollection-proto">&lt;code>PCollection&lt;/code> proto&lt;/h3>
&lt;p>A &lt;code>PCollection&lt;/code> just stores a coder, windowing strategy, and whether or not it
is bounded.&lt;/p>
&lt;div class=no-toggle>
&lt;pre>&lt;code>message PCollection {
string coder_id;
IsBounded is_bounded;
string windowing_strategy_id;
...
}&lt;/code>&lt;/pre>
&lt;/div>
&lt;h3 id="coder-proto">&lt;code>Coder&lt;/code> proto&lt;/h3>
&lt;p>This is a very interesting proto. A coder is a parameterized function that may
only be understood by a particular SDK, hence an &lt;code>SdkFunctionSpec&lt;/code>, but also
may have component coders that fully define it. For example, a &lt;code>ListCoder&lt;/code> is
only a meta-format, while &lt;code>ListCoder(VarIntCoder)&lt;/code> is a fully specified format.&lt;/p>
&lt;div class=no-toggle>
&lt;pre>&lt;code>message Coder {
SdkFunctionSpec spec;
repeated string component_coder_ids;
}&lt;/code>&lt;/pre>
&lt;/div>
&lt;h2 id="the-runner-api-rpcs">The Runner API RPCs&lt;/h2>
&lt;p>While your language&amp;rsquo;s SDK will probably insulate you from touching the Runner
API protos directly, you may need to implement adapters for your runner, to
expose it to another language. So this section covers proto that you will
possibly interact with quite directly.&lt;/p>
&lt;p>The specific manner in which the existing runner method calls will be expressed
as RPCs is not implemented as proto yet. This RPC layer is to enable, for
example, building a pipeline using the Python SDK and launching it on a runner
that is written in Java. It is expected that a small Python shim will
communicate with a Java process or service hosting the Runner API.&lt;/p>
&lt;p>The RPCs themselves will necessarily follow the existing APIs of PipelineRunner
and PipelineResult, but altered to be the minimal backend channel, versus a
rich and convenient API.&lt;/p>
&lt;h3 id="pipelinerunnerrunpipeline-rpc">&lt;code>PipelineRunner.run(Pipeline)&lt;/code> RPC&lt;/h3>
&lt;p>This will take the same form, but &lt;code>PipelineOptions&lt;/code> will have to be serialized
to JSON (or a proto &lt;code>Struct&lt;/code>) and passed along.&lt;/p>
&lt;div class=no-toggle>
&lt;pre>&lt;code>message RunPipelineRequest {
Pipeline pipeline;
Struct pipeline_options;
}&lt;/code>&lt;/pre>
&lt;/div>
&lt;div class=no-toggle>
&lt;pre>&lt;code>message RunPipelineResponse {
bytes pipeline_id;
// TODO: protocol for rejecting pipelines that cannot be executed
// by this runner. May just be REJECTED job state with error message.
// totally opaque to the SDK; for the shim to interpret
Any contents;
}&lt;/code>&lt;/pre>
&lt;/div>
&lt;h3 id="pipelineresult-aka-job-api">&lt;code>PipelineResult&lt;/code> aka &amp;ldquo;Job API&amp;rdquo;&lt;/h3>
&lt;p>The two core pieces of functionality in this API today are getting the state of
a job and canceling the job. It is very much likely to evolve, for example to
be generalized to support draining a job (stop reading input and let watermarks
go to infinity). Today, verifying our test framework benefits (but does not
depend upon wholly) querying metrics over this channel.&lt;/p>
&lt;div class=no-toggle>
&lt;pre>&lt;code>message CancelPipelineRequest {
bytes pipeline_id;
...
}
message GetStateRequest {
bytes pipeline_id;
...
}
message GetStateResponse {
JobState state;
...
}
enum JobState {
...
}&lt;/code>&lt;/pre>
&lt;/div></description></item></channel></rss>