<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>Cloud Dataflow Runner</title><meta name=description content="Apache Beam is an open source, unified model and set of language-specific SDKs for defining and executing data processing workflows, and also data ingestion and integration flows, supporting Enterprise Integration Patterns (EIPs) and Domain Specific Languages (DSLs). Dataflow pipelines simplify the mechanics of large-scale batch and streaming data processing and can run on a number of runtimes like Apache Flink, Apache Spark, and Google Cloud Dataflow (a cloud service). Beam also brings DSL in different languages, allowing users to easily implement their data integration processes."><link href="https://fonts.googleapis.com/css?family=Roboto:100,300,400" rel=stylesheet><link rel=preload href=/scss/main.min.7bfa213b38fe814e9a5d5af502d4d2e0d4e9e7dfe8a528843e32a858c6c92bc2.css as=style><link href=/scss/main.min.7bfa213b38fe814e9a5d5af502d4d2e0d4e9e7dfe8a528843e32a858c6c92bc2.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-2.2.4.min.js></script><style>.body__contained img{max-width:100%}</style><script src=/js/bootstrap.min.js></script><script src=/js/language-switch.js></script><script src=/js/fix-menu.js></script><script src=/js/section-nav.js></script><script src=/js/page-nav.js></script><link rel=alternate type=application/rss+xml title="Apache Beam" href=/feed.xml><link rel=canonical href=/documentation/runners/dataflow/ data-proofer-ignore><link rel="shortcut icon" type=image/x-icon href=/images/favicon.ico><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.4.1/css/all.css integrity=sha384-5sAR7xN1Nv6T6+dT2mhtzEpVJvfS3NScPQTrOxhwjIuvcA67KV2R5Jz6kr4abQsz crossorigin=anonymous><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-73650088-1','auto');ga('send','pageview');</script></head><body class=body data-spy=scroll data-target=.page-nav data-offset=0><nav class="header navbar navbar-fixed-top"><div class=navbar-header><button type=button class=navbar-toggle aria-expanded=false aria-controls=navbar>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span><span class=icon-bar></span><span class=icon-bar></span></button>
<a href=/ class=navbar-brand><img alt=Brand style=height:25px src=/images/beam_logo_navbar.png></a></div><div class="navbar-mask closed"></div><div id=navbar class="navbar-container closed"><ul class="nav navbar-nav"><li><a href=/get-started/beam-overview/>Get Started</a></li><li><a href=/documentation/>Documentation</a></li><li><a href=/documentation/sdks/java/>Languages</a></li><li><a href=/documentation/runners/capability-matrix/>RUNNERS</a></li><li><a href=/roadmap/>Roadmap</a></li><li><a href=/contribute/>Contribute</a></li><li><a href=/community/contact-us/>Community</a></li><li><a href=/blog/>Blog</a></li></ul><ul class="nav navbar-nav navbar-right"><li><div style=width:300px><script>(function(){var cx='012923275103528129024:4emlchv9wzi';var gcse=document.createElement('script');gcse.type='text/javascript';gcse.async=true;gcse.src='https://cse.google.com/cse.js?cx='+cx;var s=document.getElementsByTagName('script')[0];s.parentNode.insertBefore(gcse,s);})();</script><gcse:search></gcse:search></div></li><li class=dropdown><a href=# class=dropdown-toggle data-toggle=dropdown role=button aria-haspopup=true aria-expanded=false><img src=https://www.apache.org/foundation/press/kit/feather_small.png alt="Apache Logo" style=height:20px><span class=caret></span></a><ul class="dropdown-menu dropdown-menu-right"><li><a href=http://www.apache.org/>ASF Homepage</a></li><li><a href=http://www.apache.org/licenses/>License</a></li><li><a href=http://www.apache.org/security/>Security</a></li><li><a href=http://www.apache.org/foundation/thanks.html>Thanks</a></li><li><a href=http://www.apache.org/foundation/sponsorship.html>Sponsorship</a></li><li><a href=https://www.apache.org/foundation/policies/conduct>Code of Conduct</a></li></ul></li><li><a href=https://github.com/apache/beam/edit/master/website/www/site/content/en/documentation/runners/dataflow.md data-proofer-ignore><i class="far fa-edit fa-lg" alt="Edit on GitHub" title="Edit on GitHub"></i></a></li></ul></div></nav><div class="clearfix container-main-content"><div class="section-nav closed" data-offset-top=90 data-offset-bottom=500><span class="section-nav-back glyphicon glyphicon-menu-left"></span><nav><ul class=section-nav-list data-section-nav><li><span class=section-nav-list-main-title>Runners</span></li><li><a href=/documentation/runners/capability-matrix/>Capability Matrix</a></li><li><a href=/documentation/runners/direct/>Direct Runner</a></li><li><a href=/documentation/runners/flink/>Apache Flink</a></li><li><a href=/documentation/runners/nemo/>Apache Nemo</a></li><li><a href=/documentation/runners/samza/>Apache Samza</a></li><li><a href=/documentation/runners/spark/>Apache Spark</a></li><li><a href=/documentation/runners/dataflow/>Google Cloud Dataflow</a></li><li><a href=/documentation/runners/jet/>Hazelcast Jet</a></li><li><a href=/documentation/runners/twister2/>Twister2</a></li></ul></nav></div><nav class="page-nav clearfix" data-offset-top=90 data-offset-bottom=500><nav id=TableOfContents><ul><li><a href=#setup>Cloud Dataflow Runner prerequisites and setup</a><ul><li><a href=#dependency>Specify your dependency</a></li><li><a href=#self-executing-jar>Self executing JAR</a></li></ul></li><li><a href=#pipeline-options>Pipeline options for the Cloud Dataflow Runner</a></li><li><a href=#additional-info>Additional information and caveats</a><ul><li><a href=#monitoring>Monitoring your job</a></li><li><a href=#blocking-execution>Blocking Execution</a></li><li><a href=#streaming-execution>Streaming Execution</a></li></ul></li></ul></nav></nav><div class="body__contained body__section-nav"><h1 id=using-the-google-cloud-dataflow-runner>Using the Google Cloud Dataflow Runner</h1><nav class=language-switcher><strong>Adapt for:</strong><ul><li data-type=language-java class=active>Java SDK</li><li data-type=language-py>Python SDK</li></ul></nav><p>The Google Cloud Dataflow Runner uses the <a href=https://cloud.google.com/dataflow/service/dataflow-service-desc>Cloud Dataflow managed service</a>. When you run your pipeline with the Cloud Dataflow service, the runner uploads your executable code and dependencies to a Google Cloud Storage bucket and creates a Cloud Dataflow job, which executes your pipeline on managed resources in Google Cloud Platform.</p><p>The Cloud Dataflow Runner and service are suitable for large scale, continuous jobs, and provide:</p><ul><li>a fully managed service</li><li><a href=https://cloud.google.com/dataflow/service/dataflow-service-desc#autoscaling>autoscaling</a> of the number of workers throughout the lifetime of the job</li><li><a href=https://cloud.google.com/blog/big-data/2016/05/no-shard-left-behind-dynamic-work-rebalancing-in-google-cloud-dataflow>dynamic work rebalancing</a></li></ul><p>The <a href=/documentation/runners/capability-matrix/>Beam Capability Matrix</a> documents the supported capabilities of the Cloud Dataflow Runner.</p><h2 id=setup>Cloud Dataflow Runner prerequisites and setup</h2><p>To use the Cloud Dataflow Runner, you must complete the setup in the <em>Before you
begin</em> section of the <a href=https://cloud.google.com/dataflow/docs/quickstarts>Cloud Dataflow quickstart</a>
for your chosen language.</p><ol><li>Select or create a Google Cloud Platform Console project.</li><li>Enable billing for your project.</li><li>Enable the required Google Cloud APIs: Cloud Dataflow, Compute Engine,
Stackdriver Logging, Cloud Storage, Cloud Storage JSON, and Cloud Resource
Manager. You may need to enable additional APIs (such as BigQuery, Cloud
Pub/Sub, or Cloud Datastore) if you use them in your pipeline code.</li><li>Authenticate with Google Cloud Platform.</li><li>Install the Google Cloud SDK.</li><li>Create a Cloud Storage bucket.</li></ol><h3 id=dependency>Specify your dependency</h3><p><span class=language-java>When using Java, you must specify your dependency on the Cloud Dataflow Runner in your <code>pom.xml</code>.</span><div class=language-java><div class=highlight><pre class=chroma><code class=language-java data-lang=java><span class=o>&lt;</span><span class=n>dependency</span><span class=o>&gt;</span>
  <span class=o>&lt;</span><span class=n>groupId</span><span class=o>&gt;</span><span class=n>org</span><span class=o>.</span><span class=na>apache</span><span class=o>.</span><span class=na>beam</span><span class=o>&lt;/</span><span class=n>groupId</span><span class=o>&gt;</span>
  <span class=o>&lt;</span><span class=n>artifactId</span><span class=o>&gt;</span><span class=n>beam</span><span class=o>-</span><span class=n>runners</span><span class=o>-</span><span class=n>google</span><span class=o>-</span><span class=n>cloud</span><span class=o>-</span><span class=n>dataflow</span><span class=o>-</span><span class=n>java</span><span class=o>&lt;/</span><span class=n>artifactId</span><span class=o>&gt;</span>
  <span class=o>&lt;</span><span class=n>version</span><span class=o>&gt;</span><span class=n>2</span><span class=o>.</span><span class=na>23</span><span class=o>.</span><span class=na>0</span><span class=o>&lt;/</span><span class=n>version</span><span class=o>&gt;</span>
  <span class=o>&lt;</span><span class=n>scope</span><span class=o>&gt;</span><span class=n>runtime</span><span class=o>&lt;/</span><span class=n>scope</span><span class=o>&gt;</span>
<span class=o>&lt;/</span><span class=n>dependency</span><span class=o>&gt;</span></code></pre></div></div></p><p><span class=language-py>This section is not applicable to the Beam SDK for Python.</span></p><h3 id=self-executing-jar>Self executing JAR</h3><p class=language-py>This section is not applicable to the Beam SDK for Python.</p><p class=language-java>In some cases, such as starting a pipeline using a scheduler such as <a href=https://airflow.apache.org>Apache AirFlow</a>, you must have a self-contained application. You can pack a self-executing JAR by explicitly adding the following dependency on the Project section of your pom.xml, in addition to the adding existing dependency shown in the previous section.</p><div class=language-java><div class=highlight><pre class=chroma><code class=language-java data-lang=java><span class=o>&lt;</span><span class=n>dependency</span><span class=o>&gt;</span>
    <span class=o>&lt;</span><span class=n>groupId</span><span class=o>&gt;</span><span class=n>org</span><span class=o>.</span><span class=na>apache</span><span class=o>.</span><span class=na>beam</span><span class=o>&lt;/</span><span class=n>groupId</span><span class=o>&gt;</span>
    <span class=o>&lt;</span><span class=n>artifactId</span><span class=o>&gt;</span><span class=n>beam</span><span class=o>-</span><span class=n>runners</span><span class=o>-</span><span class=n>google</span><span class=o>-</span><span class=n>cloud</span><span class=o>-</span><span class=n>dataflow</span><span class=o>-</span><span class=n>java</span><span class=o>&lt;/</span><span class=n>artifactId</span><span class=o>&gt;</span>
    <span class=o>&lt;</span><span class=n>version</span><span class=o>&gt;</span><span class=n>$</span><span class=o>{</span><span class=n>beam</span><span class=o>.</span><span class=na>version</span><span class=o>}&lt;/</span><span class=n>version</span><span class=o>&gt;</span>
    <span class=o>&lt;</span><span class=n>scope</span><span class=o>&gt;</span><span class=n>runtime</span><span class=o>&lt;/</span><span class=n>scope</span><span class=o>&gt;</span>
<span class=o>&lt;/</span><span class=n>dependency</span><span class=o>&gt;</span></code></pre></div></div><p class=language-java>Then, add the mainClass name in the Maven JAR plugin.</p><div class=language-java><div class=highlight><pre class=chroma><code class=language-java data-lang=java><span class=o>&lt;</span><span class=n>plugin</span><span class=o>&gt;</span>
  <span class=o>&lt;</span><span class=n>groupId</span><span class=o>&gt;</span><span class=n>org</span><span class=o>.</span><span class=na>apache</span><span class=o>.</span><span class=na>maven</span><span class=o>.</span><span class=na>plugins</span><span class=o>&lt;/</span><span class=n>groupId</span><span class=o>&gt;</span>
  <span class=o>&lt;</span><span class=n>artifactId</span><span class=o>&gt;</span><span class=n>maven</span><span class=o>-</span><span class=n>jar</span><span class=o>-</span><span class=n>plugin</span><span class=o>&lt;/</span><span class=n>artifactId</span><span class=o>&gt;</span>
  <span class=o>&lt;</span><span class=n>version</span><span class=o>&gt;</span><span class=n>$</span><span class=o>{</span><span class=n>maven</span><span class=o>-</span><span class=n>jar</span><span class=o>-</span><span class=n>plugin</span><span class=o>.</span><span class=na>version</span><span class=o>}&lt;/</span><span class=n>version</span><span class=o>&gt;</span>
  <span class=o>&lt;</span><span class=n>configuration</span><span class=o>&gt;</span>
    <span class=o>&lt;</span><span class=n>archive</span><span class=o>&gt;</span>
      <span class=o>&lt;</span><span class=n>manifest</span><span class=o>&gt;</span>
        <span class=o>&lt;</span><span class=n>addClasspath</span><span class=o>&gt;</span><span class=kc>true</span><span class=o>&lt;/</span><span class=n>addClasspath</span><span class=o>&gt;</span>
        <span class=o>&lt;</span><span class=n>classpathPrefix</span><span class=o>&gt;</span><span class=n>lib</span><span class=o>/&lt;/</span><span class=n>classpathPrefix</span><span class=o>&gt;</span>
        <span class=o>&lt;</span><span class=n>mainClass</span><span class=o>&gt;</span><span class=n>YOUR_MAIN_CLASS_NAME</span><span class=o>&lt;/</span><span class=n>mainClass</span><span class=o>&gt;</span>
      <span class=o>&lt;/</span><span class=n>manifest</span><span class=o>&gt;</span>
    <span class=o>&lt;/</span><span class=n>archive</span><span class=o>&gt;</span>
  <span class=o>&lt;/</span><span class=n>configuration</span><span class=o>&gt;</span>
<span class=o>&lt;/</span><span class=n>plugin</span><span class=o>&gt;</span></code></pre></div></div><p class=language-java>After running <code>mvn package</code>, run <code>ls target</code> and you should see (assuming your artifactId is <code>beam-examples</code> and the version is 1.0.0) the following output.</p><div class=language-java><div class=highlight><pre class=chroma><code class=language-java data-lang=java><span class=n>beam</span><span class=o>-</span><span class=n>examples</span><span class=o>-</span><span class=n>bundled</span><span class=o>-</span><span class=n>1</span><span class=o>.</span><span class=na>0</span><span class=o>.</span><span class=na>0</span><span class=o>.</span><span class=na>jar</span></code></pre></div></div><p class=language-java>To run the self-executing JAR on Cloud Dataflow, use the following command.</p><div class=language-java><div class=highlight><pre class=chroma><code class=language-java data-lang=java><span class=n>java</span> <span class=o>-</span><span class=n>jar</span> <span class=n>target</span><span class=o>/</span><span class=n>beam</span><span class=o>-</span><span class=n>examples</span><span class=o>-</span><span class=n>bundled</span><span class=o>-</span><span class=n>1</span><span class=o>.</span><span class=na>0</span><span class=o>.</span><span class=na>0</span><span class=o>.</span><span class=na>jar</span> <span class=err>\</span>
  <span class=o>--</span><span class=n>runner</span><span class=o>=</span><span class=n>DataflowRunner</span> <span class=err>\</span>
  <span class=o>--</span><span class=n>project</span><span class=o>=&lt;</span><span class=n>YOUR_GCP_PROJECT_ID</span><span class=o>&gt;</span> <span class=err>\</span>
  <span class=o>--</span><span class=n>region</span><span class=o>=&lt;</span><span class=n>GCP_REGION</span><span class=o>&gt;</span> <span class=err>\</span>
  <span class=o>--</span><span class=n>tempLocation</span><span class=o>=</span><span class=n>gs</span><span class=o>://&lt;</span><span class=n>YOUR_GCS_BUCKET</span><span class=o>&gt;/</span><span class=n>temp</span><span class=o>/</span></code></pre></div></div><h2 id=pipeline-options>Pipeline options for the Cloud Dataflow Runner</h2><p><span class=language-java>When executing your pipeline with the Cloud Dataflow Runner (Java), consider these common pipeline options.</span>
<span class=language-py>When executing your pipeline with the Cloud Dataflow Runner (Python), consider these common pipeline options.</span></p><table class="table table-bordered"><tr><th>Field</th><th>Description</th><th>Default Value</th></tr><tr><td><code>runner</code></td><td>The pipeline runner to use. This option allows you to determine the pipeline runner at runtime.</td><td>Set to <code>dataflow</code> or <code>DataflowRunner</code> to run on the Cloud Dataflow Service.</td></tr><tr><td><code>project</code></td><td>The project ID for your Google Cloud Project.</td><td>If not set, defaults to the default project in the current environment. The default project is set via <code>gcloud</code>.</td></tr><tr><td><code>region</code></td><td>The Google Compute Engine region to create the job.</td><td>If not set, defaults to the default region in the current environment. The default region is set via <code>gcloud</code>.</td></tr><tr><td><code>streaming</code></td><td>Whether streaming mode is enabled or disabled; <code>true</code> if enabled. Set to <code>true</code> if running pipelines with unbounded <code>PCollection</code>s.</td><td><code>false</code></td></tr><tr><td><span class=language-java><code>tempLocation</code></span>
<span class=language-py><code>temp_location</code></span></td><td><span class=language-java>Optional.</span>
<span class=language-py>Required.</span>
Path for temporary files. Must be a valid Google Cloud Storage URL that begins with <code>gs://</code>.
<span class=language-java>If set, <code>tempLocation</code> is used as the default value for <code>gcpTempLocation</code>.</span></td><td>No default value.</td></tr><tr class=language-java><td><code>gcpTempLocation</code></td><td>Cloud Storage bucket path for temporary files. Must be a valid Cloud Storage URL that begins with <code>gs://</code>.</td><td>If not set, defaults to the value of <code>tempLocation</code>, provided that <code>tempLocation</code> is a valid Cloud Storage URL. If <code>tempLocation</code> is not a valid Cloud Storage URL, you must set <code>gcpTempLocation</code>.</td></tr><tr><td><span class=language-java><code>stagingLocation</code></span>
<span class=language-py><code>staging_location</code></span></td><td>Optional. Cloud Storage bucket path for staging your binary and any temporary files. Must be a valid Cloud Storage URL that begins with <code>gs://</code>.</td><td><span class=language-java>If not set, defaults to a staging directory within <code>gcpTempLocation</code>.</span>
<span class=language-py>If not set, defaults to a staging directory within <code>temp_location</code>.</span></td></tr><tr class=language-py><td><code>save_main_session</code></td><td>Save the main session state so that pickled functions and classes defined in <code>__main__</code> (e.g. interactive session) can be unpickled. Some workflows do not need the session state if, for instance, all of their functions/classes are defined in proper modules (not <code>__main__</code>) and the modules are importable in the worker.</td><td><code>false</code></td></tr><tr class=language-py><td><code>sdk_location</code></td><td>Override the default location from where the Beam SDK is downloaded. This value can be a URL, a Cloud Storage path, or a local path to an SDK tarball. Workflow submissions will download or copy the SDK tarball from this location. If set to the string <code>default</code>, a standard SDK location is used. If empty, no SDK is copied.</td><td><code>default</code></td></tr></table><p>See the reference documentation for the
<span class=language-java><a href=https://beam.apache.org/releases/javadoc/2.23.0/index.html?org/apache/beam/runners/dataflow/options/DataflowPipelineOptions.html>DataflowPipelineOptions</a></span>
<span class=language-py><a href=https://beam.apache.org/releases/pydoc/2.23.0/apache_beam.options.pipeline_options.html#apache_beam.options.pipeline_options.PipelineOptions><code>PipelineOptions</code></a></span>
interface (and any subinterfaces) for additional pipeline configuration options.</p><h2 id=additional-info>Additional information and caveats</h2><h3 id=monitoring>Monitoring your job</h3><p>While your pipeline executes, you can monitor the job&rsquo;s progress, view details on execution, and receive updates on the pipeline&rsquo;s results by using the <a href=https://cloud.google.com/dataflow/pipelines/dataflow-monitoring-intf>Dataflow Monitoring Interface</a> or the <a href=https://cloud.google.com/dataflow/pipelines/dataflow-command-line-intf>Dataflow Command-line Interface</a>.</p><h3 id=blocking-execution>Blocking Execution</h3><p>To block until your job completes, call <span class=language-java><code>waitToFinish</code></span><span class=language-py><code>wait_until_finish</code></span> on the <code>PipelineResult</code> returned from <code>pipeline.run()</code>. The Cloud Dataflow Runner prints job status updates and console messages while it waits. While the result is connected to the active job, note that pressing <strong>Ctrl+C</strong> from the command line does not cancel your job. To cancel the job, you can use the <a href=https://cloud.google.com/dataflow/pipelines/dataflow-monitoring-intf>Dataflow Monitoring Interface</a> or the <a href=https://cloud.google.com/dataflow/pipelines/dataflow-command-line-intf>Dataflow Command-line Interface</a>.</p><h3 id=streaming-execution>Streaming Execution</h3><p>If your pipeline uses an unbounded data source or sink, you must set the <code>streaming</code> option to <code>true</code>.</p><p>When using streaming execution, keep the following considerations in mind.</p><ol><li><p>Streaming pipelines do not terminate unless explicitly cancelled by the user.
You can cancel your streaming job from the <a href=https://cloud.google.com/dataflow/pipelines/stopping-a-pipeline>Dataflow Monitoring Interface</a>
or with the <a href=https://cloud.google.com/dataflow/pipelines/dataflow-command-line-intf>Dataflow Command-line Interface</a>
(<a href=https://cloud.google.com/sdk/gcloud/reference/dataflow/jobs/cancel>gcloud dataflow jobs cancel</a>
command).</p></li><li><p>Streaming jobs use a Google Compute Engine <a href=https://cloud.google.com/compute/docs/machine-types>machine type</a>
of <code>n1-standard-2</code> or higher by default. You must not override this, as
<code>n1-standard-2</code> is the minimum required machine type for running streaming
jobs.</p></li><li><p>Streaming execution <a href=https://cloud.google.com/dataflow/pricing>pricing</a>
differs from batch execution.</p></li></ol></div></div><footer class=footer><div class=footer__contained><div class=footer__cols><div class=footer__cols__col><div class=footer__cols__col__logo><img src=/images/beam_logo_circle.svg class=footer__logo alt="Beam logo"></div><div class=footer__cols__col__logo><img src=/images/apache_logo_circle.svg class=footer__logo alt="Apache logo"></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Start</div><div class=footer__cols__col__link><a href=/get-started/beam-overview/>Overview</a></div><div class=footer__cols__col__link><a href=/get-started/quickstart-java/>Quickstart (Java)</a></div><div class=footer__cols__col__link><a href=/get-started/quickstart-py/>Quickstart (Python)</a></div><div class=footer__cols__col__link><a href=/get-started/quickstart-go/>Quickstart (Go)</a></div><div class=footer__cols__col__link><a href=/get-started/downloads/>Downloads</a></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Docs</div><div class=footer__cols__col__link><a href=/documentation/programming-guide/>Concepts</a></div><div class=footer__cols__col__link><a href=/documentation/pipelines/design-your-pipeline/>Pipelines</a></div><div class=footer__cols__col__link><a href=/documentation/runners/capability-matrix/>Runners</a></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Community</div><div class=footer__cols__col__link><a href=/contribute/>Contribute</a></div><div class=footer__cols__col__link><a href=https://projects.apache.org/committee.html?beam target=_blank>Team<img src=/images/external-link-icon.png width=14 height=14 alt="External link."></a></div><div class=footer__cols__col__link><a href=/community/presentation-materials/>Media</a></div><div class=footer__cols__col__link><a href=/community/in-person/>Events/Meetups</a></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Resources</div><div class=footer__cols__col__link><a href=/blog/>Blog</a></div><div class=footer__cols__col__link><a href=/community/contact-us/>Contact Us</a></div><div class=footer__cols__col__link><a href=https://github.com/apache/beam>GitHub</a></div></div></div></div><div class=footer__bottom>&copy;
<a href=http://www.apache.org>The Apache Software Foundation</a>
| <a href=/privacy_policy>Privacy Policy</a>
| <a href=/feed.xml>RSS Feed</a><br><br>Apache Beam, Apache, Beam, the Beam logo, and the Apache feather logo are either registered trademarks or trademarks of The Apache Software Foundation. All other products or name brands are trademarks of their respective holders, including The Apache Software Foundation.</div></footer></body></html>