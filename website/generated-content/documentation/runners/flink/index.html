<!DOCTYPE html>
<!--
 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at
   http://www.apache.org/licenses/LICENSE-2.0
 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License. See accompanying LICENSE file.
-->

<html lang="en">
  <!--
 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at
   http://www.apache.org/licenses/LICENSE-2.0
 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License. See accompanying LICENSE file.
-->

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Apache Flink Runner</title>
  <meta name="description" content="Apache Beam is an open source, unified model and set of language-specific SDKs for defining and executing data processing workflows, and also data ingestion and integration flows, supporting Enterprise Integration Patterns (EIPs) and Domain Specific Languages (DSLs). Dataflow pipelines simplify the mechanics of large-scale batch and streaming data processing and can run on a number of runtimes like Apache Flink, Apache Spark, and Google Cloud Dataflow (a cloud service). Beam also brings DSL in different languages, allowing users to easily implement their data integration processes.
">
  <link href="https://fonts.googleapis.com/css?family=Roboto:100,300,400" rel="stylesheet">
  <link rel="stylesheet" href="/css/site.css">
  <script src="https://code.jquery.com/jquery-2.2.4.min.js"></script>
  <script src="/js/bootstrap.min.js"></script>
  <script src="/js/language-switch.js"></script>
  <script src="/js/fix-menu.js"></script>
  <script src="/js/section-nav.js"></script>
  <script src="/js/page-nav.js"></script>
  <link rel="canonical" href="https://beam.apache.org/documentation/runners/flink/" data-proofer-ignore>
  <link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico">
  <link rel="alternate" type="application/rss+xml" title="Apache Beam" href="https://beam.apache.org/feed.xml">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css" integrity="sha384-5sAR7xN1Nv6T6+dT2mhtzEpVJvfS3NScPQTrOxhwjIuvcA67KV2R5Jz6kr4abQsz" crossorigin="anonymous">
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-73650088-1', 'auto');
    ga('send', 'pageview');
  </script>
</head>

  <body class="body" data-spy="scroll" data-target=".page-nav" data-offset="0">
    <!--
 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at
   http://www.apache.org/licenses/LICENSE-2.0
 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License. See accompanying LICENSE file.
-->

<nav class="header navbar navbar-fixed-top">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" aria-expanded="false" aria-controls="navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>

      <a href="/" class="navbar-brand" >
        <img alt="Brand" style="height: 25px" src="/images/beam_logo_navbar.png">
      </a>
    </div>

    <div class="navbar-mask closed"></div>

    <div id="navbar" class="navbar-container closed">
      <ul class="nav navbar-nav">
        <li>
          <a href="/get-started/beam-overview/">Get Started</a>
        </li>
        <li>
          <a href="/documentation/">Documentation</a>
        </li>
        <li>
          <a href="/documentation/sdks/java/">Languages</a>
        </li>
        <li>
          <a href="/documentation/runners/capability-matrix/">RUNNERS</a>
        </li>
        <li>
          <a href="/roadmap/">Roadmap</a>
        </li>
        <li>
          <a href="/contribute/">Contribute</a>
        </li>
        <li>
          <a href="/community/contact-us/">Community</a>
        </li>
        <li><a href="/blog">Blog</a></li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
          <div style="width: 300px;">
            <script>
              (function() {
                var cx = '012923275103528129024:4emlchv9wzi';
                var gcse = document.createElement('script');
                gcse.type = 'text/javascript';
                gcse.async = true;
                gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
                var s = document.getElementsByTagName('script')[0];
                s.parentNode.insertBefore(gcse, s);
              })();
            </script>
            <gcse:search></gcse:search>
          </div>
        </li>
        <li class="dropdown">
          <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false"><img src="https://www.apache.org/foundation/press/kit/feather_small.png" alt="Apache Logo" style="height:20px;"><span class="caret"></span></a>
          <ul class="dropdown-menu dropdown-menu-right">
            <li><a href="http://www.apache.org/">ASF Homepage</a></li>
            <li><a href="http://www.apache.org/licenses/">License</a></li>
            <li><a href="http://www.apache.org/security/">Security</a></li>
            <li><a href="http://www.apache.org/foundation/thanks.html">Thanks</a></li>
            <li><a href="http://www.apache.org/foundation/sponsorship.html">Sponsorship</a></li>
            <li><a href="https://www.apache.org/foundation/policies/conduct">Code of Conduct</a></li>
          </ul>
        </li>
        <li>
          <!--
            data-proofer-ignore disables link checking from website test automation.
            GitHub links will not resolve until the markdown source is available on the master branch.
            New pages would fail validation during development / PR test automation.
          -->
          <a href="https://github.com/apache/beam/edit/master/website/src/documentation/runners/flink.md" data-proofer-ignore>
            <i class="far fa-edit fa-lg" alt="Edit on GitHub" title="Edit on GitHub"></i>
          </a>
        </li>
      </ul>
    </div>
</nav>

    <div class="clearfix container-main-content">
      <div class="section-nav closed" data-offset-top="90" data-offset-bottom="500">
        <span class="section-nav-back glyphicon glyphicon-menu-left"></span>
        <nav>
          <ul class="section-nav-list" data-section-nav>
            <!--
 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at
   http://www.apache.org/licenses/LICENSE-2.0
 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License. See accompanying LICENSE file.
-->

<li><span class="section-nav-list-main-title">Runners</span></li>
<li><a href="/documentation/runners/capability-matrix/">Capability Matrix</a></li>
<li><a href="/documentation/runners/direct/">Direct Runner</a></li>
<li><a href="/documentation/runners/apex/">Apache Apex</a></li>
<li><a href="/documentation/runners/flink/">Apache Flink</a></li>
<li><a href="/documentation/runners/gearpump/">Apache Gearpump</a></li>
<li><a href="/documentation/runners/nemo/">Apache Nemo</a></li>
<li><a href="/documentation/runners/samza/">Apache Samza</a></li>
<li><a href="/documentation/runners/spark/">Apache Spark</a></li>
<li><a href="/documentation/runners/dataflow/">Google Cloud Dataflow</a></li>
<li><a href="/documentation/runners/jet/">Hazelcast Jet</a></li>

          </ul>
        </nav>
      </div>

      <nav class="page-nav clearfix" data-offset-top="90" data-offset-bottom="500">
        <!--
 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at
   http://www.apache.org/licenses/LICENSE-2.0
 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License. See accompanying LICENSE file.
-->



<ul class="nav">
  <li><a href="#prerequisites-and-setup">Prerequisites and Setup</a></li>
  <li><a href="#version-compatibility">Version Compatibility</a>
    <ul>
      <li><a href="#dependencies">Dependencies</a></li>
      <li><a href="#executing-a-beam-pipeline-on-a-flink-cluster">Executing a Beam pipeline on a Flink Cluster</a></li>
    </ul>
  </li>
  <li><a href="#additional-information-and-caveats">Additional information and caveats</a>
    <ul>
      <li><a href="#monitoring-your-job">Monitoring your job</a></li>
      <li><a href="#streaming-execution">Streaming Execution</a></li>
    </ul>
  </li>
  <li><a href="#pipeline-options-for-the-flink-runner">Pipeline options for the Flink Runner</a></li>
  <li><a href="#capability">Capability</a></li>
</ul>


      </nav>

      <div class="body__contained body__section-nav">
        <!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->

<h1 id="overview">Overview</h1>

<p>The Apache Flink Runner can be used to execute Beam pipelines using <a href="https://flink.apache.org">Apache
Flink</a>. For execution you can choose between a cluster
execution mode (e.g. Yarn/Kubernetes/Mesos) or a local embedded execution mode
which is useful for testing pipelines.</p>

<p>The Flink Runner and Flink are suitable for large scale, continuous jobs, and provide:</p>

<ul>
  <li>A streaming-first runtime that supports both batch processing and data streaming programs</li>
  <li>A runtime that supports very high throughput and low event latency at the same time</li>
  <li>Fault-tolerance with <em>exactly-once</em> processing guarantees</li>
  <li>Natural back-pressure in streaming programs</li>
  <li>Custom memory management for efficient and robust switching between in-memory and out-of-core data processing algorithms</li>
  <li>Integration with YARN and other components of the Apache Hadoop ecosystem</li>
</ul>

<h1 id="using-the-apache-flink-runner">Using the Apache Flink Runner</h1>

<p>It is important to understand that the Flink Runner comes in two flavors:</p>

<ol>
  <li>A <em>legacy Runner</em> which supports only Java (and other JVM-based languages)</li>
  <li>A <em>portable Runner</em> which supports Java/Python/Go</li>
</ol>

<p>You may ask why there are two Runners?</p>

<p>Beam and its Runners originally only supported JVM-based languages
(e.g. Java/Scala/Kotlin). Python and Go SDKs were added later on. The
architecture of the Runners had to be changed significantly to support executing
pipelines written in other languages.</p>

<p>If your applications only use Java, then you should currently go with the legacy
Runner. Eventually, the portable Runner will replace the legacy Runner because
it contains the generalized framework for executing Java, Python, Go, and more
languages in the future.</p>

<p>If you want to run Python pipelines with Beam on Flink you want to use the
portable Runner. For more information on
portability, please visit the <a href="/roadmap/portability/">Portability page</a>.</p>

<p>Consequently, this guide is split into two parts to document the legacy and
the portable functionality of the Flink Runner. Please use the switcher below to
select the appropriate Runner:</p>

<nav class="language-switcher">
  <strong>Adapt for:</strong>
  <ul>
    <li data-type="language-java">Legacy (Java)</li>
    <li data-type="language-py">Portable (Java/Python/Go)</li>
  </ul>
</nav>

<h2 id="prerequisites-and-setup">Prerequisites and Setup</h2>

<p>If you want to use the local execution mode with the Flink Runner you don’t have
to complete any cluster setup. You can simply run your Beam pipeline. Be sure to
set the Runner to <span class="language-java"><code class="highlighter-rouge">FlinkRunner</code></span><span class="language-py"><code class="highlighter-rouge">PortableRunner</code></span>.</p>

<p>To use the Flink Runner for executing on a cluster, you have to setup a Flink cluster by following the
Flink <a href="https://ci.apache.org/projects/flink/flink-docs-stable/quickstart/setup_quickstart.html#setup-download-and-start-flink">Setup Quickstart</a>.</p>

<h2 id="version-compatibility">Version Compatibility</h2>

<p>The Flink cluster version has to match the minor version used by the FlinkRunner.
The minor version is the first two numbers in the version string, e.g. in <code class="highlighter-rouge">1.7.0</code> the
minor version is <code class="highlighter-rouge">1.7</code>.</p>

<p>We try to track the latest version of Apache Flink at the time of the Beam release.
A Flink version is supported by Beam for the time it is supported by the Flink community.
The Flink community typially supports the last two minor versions. When support for a Flink
version is dropped, it may be deprecated and removed also from Beam, with the exception of
Beam LTS releases. LTS releases continue to receive bug fixes for long as the LTS support
period.</p>

<p>To find out which version of Flink is compatible with Beam please see the table below:</p>

<table class="table table-bordered">
<tr>
  <th>Beam Version</th>
  <th>Flink Version</th>
  <th>Artifact Id</th>
</tr>
<tr>
  <td>&gt;=2.13.0</td>
  <td>1.8.x</td>
  <td>beam-runners-flink-1.8</td>
</tr>
<tr>
  <td rowspan="3">&gt;=2.10.0</td>
  <td>1.7.x</td>
  <td>beam-runners-flink-1.7</td>
</tr>
<tr>
  <td>1.6.x</td>
  <td>beam-runners-flink-1.6</td>
</tr>
<tr>
  <td>1.5.x</td>
  <td>beam-runners-flink_2.11</td>
</tr>
<tr>
  <td>2.9.0</td>
  <td rowspan="4">1.5.x</td>
  <td rowspan="4">beam-runners-flink_2.11</td>
</tr>
<tr>
  <td>2.8.0</td>
</tr>
<tr>
  <td>2.7.0</td>
</tr>
<tr>
  <td>2.6.0</td>
</tr>
<tr>
  <td>2.5.0</td>
  <td rowspan="3">1.4.x with Scala 2.11</td>
  <td rowspan="3">beam-runners-flink_2.11</td>
</tr>
<tr>
  <td>2.4.0</td>
</tr>
<tr>
  <td>2.3.0</td>
</tr>
<tr>
  <td>2.2.0</td>
  <td rowspan="2">1.3.x with Scala 2.10</td>
  <td rowspan="2">beam-runners-flink_2.10</td>
</tr>
<tr>
  <td>2.1.x</td>
</tr>
<tr>
  <td>2.0.0</td>
  <td>1.2.x with Scala 2.10</td>
  <td>beam-runners-flink_2.10</td>
</tr>
</table>

<p>For retrieving the right Flink version, see the <a href="https://flink.apache.org/downloads.html">Flink downloads page</a>.</p>

<p>For more information, the <a href="https://ci.apache.org/projects/flink/flink-docs-stable/">Flink Documentation</a> can be helpful.</p>

<h3 id="dependencies">Dependencies</h3>

<p><span class="language-java">You must specify your dependency on the Flink Runner
in your <code class="highlighter-rouge">pom.xml</code> or <code class="highlighter-rouge">build.gradle</code>. Use the Beam version and the artifact id
from the above table. For example:
</span></p>

<div class="language-java highlighter-rouge"><pre class="highlight"><code><span class="o">&lt;</span><span class="n">dependency</span><span class="o">&gt;</span>
  <span class="o">&lt;</span><span class="n">groupId</span><span class="o">&gt;</span><span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">beam</span><span class="o">&lt;/</span><span class="n">groupId</span><span class="o">&gt;</span>
  <span class="o">&lt;</span><span class="n">artifactId</span><span class="o">&gt;</span><span class="n">beam</span><span class="o">-</span><span class="n">runners</span><span class="o">-</span><span class="n">flink</span><span class="o">-</span><span class="mf">1.6</span><span class="o">&lt;/</span><span class="n">artifactId</span><span class="o">&gt;</span>
  <span class="o">&lt;</span><span class="n">version</span><span class="o">&gt;</span><span class="mf">2.14</span><span class="o">.</span><span class="mi">0</span><span class="o">&lt;/</span><span class="n">version</span><span class="o">&gt;</span>
<span class="o">&lt;/</span><span class="n">dependency</span><span class="o">&gt;</span>
</code></pre>
</div>

<p><span class="language-py">
You will need Docker to be installed in your execution environment. To develop
Apache Beam with Python you have to install the Apache Beam Python SDK: <code class="highlighter-rouge">pip
install apache_beam</code>. Please refer to the <a href="/documentation/sdks/python/">Python documentation</a>
on how to create a Python pipeline.
</span></p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">pip</span> <span class="n">install</span> <span class="n">apache_beam</span>
</code></pre>
</div>

<h3 id="executing-a-beam-pipeline-on-a-flink-cluster">Executing a Beam pipeline on a Flink Cluster</h3>

<p><span class="language-java">
For executing a pipeline on a Flink cluster you need to package your program
along with all dependencies in a so-called fat jar. How you do this depends on
your build system but if you follow along the <a href="/get-started/quickstart/">Beam Quickstart</a> this is the command that you have to run:
</span></p>

<div class="language-java highlighter-rouge"><pre class="highlight"><code><span class="err">$</span> <span class="n">mvn</span> <span class="kn">package</span> <span class="o">-</span><span class="n">Pflink</span><span class="o">-</span><span class="n">runner</span>
</code></pre>
</div>
<p><span class="language-java">Look for the output JAR of this command in the
install apache_beam``target` folder.
<span></span></span></p>

<p><span class="language-java">
The Beam Quickstart Maven project is setup to use the Maven Shade plugin to
create a fat jar and the <code class="highlighter-rouge">-Pflink-runner</code> argument makes sure to include the
dependency on the Flink Runner.
</span></p>

<p><span class="language-java">
For running the pipeline the easiest option is to use the <code class="highlighter-rouge">flink</code> command which
is part of Flink:
</span></p>

<div class="language-java highlighter-rouge"><pre class="highlight"><code><span class="err">$</span> <span class="n">bin</span><span class="o">/</span><span class="n">flink</span> <span class="n">run</span> <span class="o">-</span><span class="n">c</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">beam</span><span class="o">.</span><span class="na">examples</span><span class="o">.</span><span class="na">WordCount</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">your</span><span class="o">.</span><span class="na">jar</span>
<span class="o">--</span><span class="n">runner</span><span class="o">=</span><span class="n">FlinkRunner</span> <span class="o">--</span><span class="n">other</span><span class="o">-</span><span class="n">parameters</span>
</code></pre>
</div>

<p><span class="language-java">
Alternatively you can also use Maven’s exec command. For example, to execute the
WordCount example:
</span></p>

<div class="language-java highlighter-rouge"><pre class="highlight"><code><span class="n">mvn</span> <span class="nl">exec:</span><span class="n">java</span> <span class="o">-</span><span class="n">Dexec</span><span class="o">.</span><span class="na">mainClass</span><span class="o">=</span><span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">beam</span><span class="o">.</span><span class="na">examples</span><span class="o">.</span><span class="na">WordCount</span> <span class="err">\</span>
    <span class="o">-</span><span class="n">Pflink</span><span class="o">-</span><span class="n">runner</span> <span class="err">\</span>
    <span class="o">-</span><span class="n">Dexec</span><span class="o">.</span><span class="na">args</span><span class="o">=</span><span class="s">"--runner=FlinkRunner \
      --inputFile=/path/to/pom.xml \
      --output=/path/to/counts \
      --flinkMaster=&lt;flink master url&gt; \
      --filesToStage=target/word-count-beam-bundled-0.1.jar"</span>
</code></pre>
</div>
<!-- Span implictly ended -->

<p><span class="language-java">
If you have a Flink <code class="highlighter-rouge">JobManager</code> running on your local machine you can provide <code class="highlighter-rouge">localhost:8081</code> for
<code class="highlighter-rouge">flinkMaster</code>. Otherwise an embedded Flink cluster will be started for the job.
</span></p>

<p><span class="language-py">
As of now you will need a copy of Apache Beam’s source code. You can
download it on the <a href="/get-started/downloads/">Downloads page</a>. In the future there will be pre-built Docker images
available.
</span></p>

<p><span class="language-py">1. <em>Only required once:</em> Build the SDK harness container: <code class="highlighter-rouge">./gradlew :sdks:python:container:docker</code>
</span></p>

<p><span class="language-py">2. Start the JobService endpoint: <code class="highlighter-rouge">./gradlew :runners:flink:1.5:job-server:runShadow</code>
</span></p>

<p><span class="language-py">
The JobService is the central instance where you submit your Beam pipeline to.
The JobService will create a Flink job for the pipeline and execute the job
job. To execute the job on a Flink cluster, the Beam JobService needs to be
provided with the Flink JobManager address.
</span></p>

<p><span class="language-py">3. Submit the Python pipeline to the above endpoint by using the <code class="highlighter-rouge">PortableRunner</code> and <code class="highlighter-rouge">job_endpoint</code> set to <code class="highlighter-rouge">localhost:8099</code> (this is the default address of the JobService). For example:
</span></p>

<div class="language-py highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">apache_beam</span> <span class="kn">as</span> <span class="nn">beam</span>
<span class="kn">from</span> <span class="nn">apache_beam.options.pipeline_options</span> <span class="kn">import</span> <span class="n">PipelineOptions</span>

<span class="n">options</span> <span class="o">=</span> <span class="n">PipelineOptions</span><span class="p">([</span><span class="s">"--runner=PortableRunner"</span><span class="p">,</span> <span class="s">"--job_endpoint=localhost:8099"</span><span class="p">])</span>
<span class="k">with</span> <span class="n">beam</span><span class="o">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">options</span><span class="p">)</span> <span class="k">as</span> <span class="n">p</span><span class="p">:</span>
    <span class="o">...</span>
</code></pre>
</div>

<p><span class="language-py">
To run on a separate <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.5/quickstart/setup_quickstart.html">Flink cluster</a>:
</span></p>

<p><span class="language-py">1. Start a Flink cluster which exposes the Rest interface on <code class="highlighter-rouge">localhost:8081</code> by default.
</span></p>

<p><span class="language-py">2. Start JobService with Flink Rest endpoint: <code class="highlighter-rouge">./gradlew :runners:flink:1.5:job-server:runShadow -PflinkMasterUrl=localhost:8081</code>.
</span></p>

<p><span class="language-py">3. Submit the pipeline as above.
</span></p>

<p><span class="language-py">As of Beam 2.15.0, steps 2 and 3 can be automated in Python by using the <code class="highlighter-rouge">FlinkRunner</code>,
plus the optional <code class="highlighter-rouge">flink_version</code> and <code class="highlighter-rouge">flink_master_url</code> options if required, i.e.
</span></p>

<div class="language-py highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">apache_beam</span> <span class="kn">as</span> <span class="nn">beam</span>
<span class="kn">from</span> <span class="nn">apache_beam.options.pipeline_options</span> <span class="kn">import</span> <span class="n">PipelineOptions</span>

<span class="n">options</span> <span class="o">=</span> <span class="n">PipelineOptions</span><span class="p">([</span><span class="s">"--runner=FlinkRunner"</span><span class="p">,</span> <span class="s">"--flink_version=1.8"</span><span class="p">,</span> <span class="s">"--flink_master_url=localhost:8081"</span><span class="p">])</span>
<span class="k">with</span> <span class="n">beam</span><span class="o">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">options</span><span class="p">)</span> <span class="k">as</span> <span class="n">p</span><span class="p">:</span>
    <span class="o">...</span>
</code></pre>
</div>

<h2 id="additional-information-and-caveats">Additional information and caveats</h2>

<h3 id="monitoring-your-job">Monitoring your job</h3>

<p>You can monitor a running Flink job using the Flink JobManager Dashboard or its Rest interfaces. By default, this is available at port <code class="highlighter-rouge">8081</code> of the JobManager node. If you have a Flink installation on your local machine that would be <code class="highlighter-rouge">http://localhost:8081</code>. Note: When you use the <code class="highlighter-rouge">[local]</code> mode an embedded Flink cluster will be started which does not make a dashboard available.</p>

<h3 id="streaming-execution">Streaming Execution</h3>

<p>If your pipeline uses an unbounded data source or sink, the Flink Runner will automatically switch to streaming mode. You can enforce streaming mode by using the <code class="highlighter-rouge">streaming</code> setting mentioned below.</p>

<p>Note: The Runner will print a warning message when unbounded sources are used and checkpointing is not enabled.
Many sources like <code class="highlighter-rouge">PubSubIO</code> rely on their checkpoints to be acknowledged which can only be done when checkpointing is enabled for the <code class="highlighter-rouge">FlinkRunner</code>. To enable checkpointing, please set <span class="language-java"><code class="highlighter-rouge">checkpointingInterval</code></span><span class="language-py"><code class="highlighter-rouge">checkpointing_interval</code></span> to the desired checkpointing interval in milliseconds.</p>

<h2 id="pipeline-options-for-the-flink-runner">Pipeline options for the Flink Runner</h2>

<p>When executing your pipeline with the Flink Runner, you can set these pipeline options.</p>

<p>See the reference documentation for the<span class="language-java">
<a href="https://beam.apache.org/releases/javadoc/2.14.0/index.html?org/apache/beam/runners/flink/FlinkPipelineOptions.html">FlinkPipelineOptions</a>
</span><span class="language-py">
<a href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/options/pipeline_options.py">PipelineOptions</a>
</span>interface (and its subinterfaces) for the complete list of pipeline configuration options.</p>

<!-- Java Options -->
<div class="language-java">
<table class="table table-bordered">
<tr>
  <th>Field</th>
  <th>Description</th>
  <th>Default Value</th>
</tr>
<tr>
  <td><code>runner</code></td>
  <td>The pipeline runner to use. This option allows you to determine the pipeline runner at runtime.</td>
  <td>Set to <code>FlinkRunner</code> to run using Flink.</td>
</tr>
<tr>
  <td><code>streaming</code></td>
  <td>Whether streaming mode is enabled or disabled; <code>true</code> if enabled. Set to <code>true</code> if running pipelines with unbounded <code>PCollection</code>s.</td>
  <td><code>false</code></td>
</tr>
<tr>
  <td><code>flinkMaster</code></td>
  <td>The url of the Flink JobManager on which to execute pipelines. This can either be the address of a cluster JobManager, in the form <code>"host:port"</code> or one of the special Strings <code>"[local]"</code> or <code>"[auto]"</code>. <code>"[local]"</code> will start a local Flink Cluster in the JVM while <code>"[auto]"</code> will let the system decide where to execute the pipeline based on the environment.</td>
  <td><code>[auto]</code></td>
</tr>
<tr>
  <td><code>filesToStage</code></td>
  <td>Jar Files to send to all workers and put on the classpath. Here you have to put the fat jar that contains your program along with all dependencies.</td>
  <td>empty</td>
</tr>
<tr>
  <td><code>parallelism</code></td>
  <td>The degree of parallelism to be used when distributing operations onto workers.</td>
  <td>For local execution: <code>Number of available CPU cores</code>
            For remote execution: <code>Default parallelism configuerd at remote cluster</code>
            Otherwise: <code>1</code>
            </td>
</tr>
<tr>
  <td><code>maxParallelism</code></td>
  <td>The pipeline wide maximum degree of parallelism to be used. The maximum parallelism specifies the upper limit for dynamic scaling and the number of key groups used for partitioned state.</td>
  <td><code>-1L</code>, meaning same as the parallelism</td>
</tr>
<tr>
  <td><code>checkpointingInterval</code></td>
  <td>The interval between consecutive checkpoints (i.e. snapshots of the current pipeline state used for fault tolerance).</td>
  <td><code>-1L</code>, i.e. disabled</td>
</tr>
<tr>
  <td><code>checkpointMode</code></td>
  <td>The checkpointing mode that defines consistency guarantee.</td>
  <td><code>EXACTLY_ONCE</code></td>
</tr>
<tr>
  <td><code>checkpointTimeoutMillis</code></td>
  <td>The maximum time in milliseconds that a checkpoint may take before being discarded</td>
  <td><code>-1</code>, the cluster default</td>
</tr>
<tr>
  <td><code>minPauseBetweenCheckpoints</code></td>
  <td>The minimal pause in milliseconds before the next checkpoint is triggered.</td>
  <td><code>-1</code>, the cluster default</td>
</tr>
<tr>
  <td><code>failOnCheckpointingErrors</code></td>
  <td>
  Sets the expected behaviour for tasks in case that they encounter an error in their
            checkpointing procedure. If this is set to true, the task will fail on checkpointing error.
            If this is set to false, the task will only decline a the checkpoint and continue running.
  </td>
  <td><code>-1</code>, the cluster default</td>
</tr>
<tr>
  <td><code>numberOfExecutionRetries</code></td>
  <td>Sets the number of times that failed tasks are re-executed. A value of <code>0</code> effectively disables fault tolerance. A value of <code>-1</code> indicates that the system default value (as defined in the configuration) should be used.</td>
  <td><code>-1</code></td>
</tr>
<tr>
  <td><code>executionRetryDelay</code></td>
  <td>Sets the delay between executions. A value of <code>-1</code> indicates that the default value should be used.</td>
  <td><code>-1</code></td>
</tr>
<tr>
  <td><code>objectReuse</code></td>
  <td>Sets the behavior of reusing objects.</td>
  <td><code>false</code>, no Object reuse</td>
</tr>
<tr>
  <td><code>stateBackend</code></td>
  <td>Sets the state backend to use in streaming mode. The default is to read this setting from the Flink config.</td>
  <td><code>empty</code>, i.e. read from Flink config</td>
</tr>
<tr>
  <td><code>enableMetrics</code></td>
  <td>Enable/disable Beam metrics in Flink Runner</td>
  <td>Default: <code>true</code></td>
</tr>
<tr>
  <td><code>externalizedCheckpointsEnabled</code></td>
  <td>Enables or disables externalized checkpoints. Works in conjunction with CheckpointingInterval</td>
  <td>Default: <code>false</code></td>
</tr>
<tr>
  <td><code>retainExternalizedCheckpointsOnCancellation</code></td>
  <td>Sets the behavior of externalized checkpoints on cancellation.</td>
  <td>Default: <code>false</code></td>
</tr>
<tr>
  <td><code>maxBundleSize</code></td>
  <td>The maximum number of elements in a bundle.</td>
  <td>Default: <code>1000</code></td>
</tr>
<tr>
  <td><code>maxBundleTimeMills</code></td>
  <td>The maximum time to wait before finalising a bundle (in milliseconds).</td>
  <td>Default: <code>1000</code></td>
</tr>
<tr>
  <td><code>shutdownSourcesOnFinalWatermark</code></td>
  <td>If set, shutdown sources when their watermark reaches +Inf.</td>
  <td>Default: <code>false</code></td>
</tr>
<tr>
  <td><code>latencyTrackingInterval</code></td>
  <td>Interval in milliseconds for sending latency tracking marks from the sources to the sinks. Interval value &lt;= 0 disables the feature.</td>
  <td>Default: <code>0</code></td>
</tr>
<tr>
  <td><code>autoWatermarkInterval</code></td>
  <td>The interval in milliseconds for automatic watermark emission.</td>
</tr>
<tr>
  <td><code>executionModeForBatch</code></td>
  <td>Flink mode for data exchange of batch pipelines. Reference {@link org.apache.flink.api.common.ExecutionMode}. Set this to BATCH_FORCED if pipelines get blocked, see https://issues.apache.org/jira/browse/FLINK-10672</td>
  <td>Default: <code>PIPELINED</code></td>
</tr>
<tr>
  <td><code>savepointPath</code></td>
  <td>Savepoint restore path. If specified, restores the streaming pipeline from the provided path.</td>
  <td>Default: None</td>
</tr>
<tr>
  <td><code>allowNonRestoredState</code></td>
  <td>Flag indicating whether non restored state is allowed if the savepoint contains state for an operator that is no longer part of the pipeline.</td>
  <td>Default: <code>false</code></td>
</tr>
</table>
</div>

<!-- Python Options -->
<div class="language-py">
<table class="table table-bordered">

<tr>
  <td><code>files_to_stage</code></td>
  <td>Jar-Files to send to all workers and put on the classpath. The default value is all files from the classpath.</td>
</tr>
<tr>
  <td><code>flink_master</code></td>
  <td>Address of the Flink Master where the Pipeline should be executed. Can either be of the form "host:port" or one of the special values [local], [collection] or [auto].</td>
  <td>Default: <code>[auto]</code></td>
</tr>
<tr>
  <td><code>parallelism</code></td>
  <td>The degree of parallelism to be used when distributing operations onto workers. If the parallelism is not set, the configured Flink default is used, or 1 if none can be found.</td>
  <td>Default: <code>-1</code></td>
</tr>
<tr>
  <td><code>max_parallelism</code></td>
  <td>The pipeline wide maximum degree of parallelism to be used. The maximum parallelism specifies the upper limit for dynamic scaling and the number of key groups used for partitioned state.</td>
  <td>Default: <code>-1</code></td>
</tr>
<tr>
  <td><code>checkpointing_interval</code></td>
  <td>The interval in milliseconds at which to trigger checkpoints of the running pipeline. Default: No checkpointing.</td>
  <td>Default: <code>-1</code></td>
</tr>
<tr>
  <td><code>checkpointing_mode</code></td>
  <td>The checkpointing mode that defines consistency guarantee.</td>
  <td>Default: <code>EXACTLY_ONCE</code></td>
</tr>
<tr>
  <td><code>checkpoint_timeout_millis</code></td>
  <td>The maximum time in milliseconds that a checkpoint may take before being discarded.</td>
  <td>Default: <code>-1</code></td>
</tr>
<tr>
  <td><code>min_pause_between_checkpoints</code></td>
  <td>The minimal pause in milliseconds before the next checkpoint is triggered.</td>
  <td>Default: <code>-1</code></td>
</tr>
<tr>
  <td><code>fail_on_checkpointing_errors</code></td>
  <td>Sets the expected behaviour for tasks in case that they encounter an error in their checkpointing procedure. If this is set to true, the task will fail on checkpointing error. If this is set to false, the task will only decline a the checkpoint and continue running. </td>
  <td>Default: <code>true</code></td>
</tr>
<tr>
  <td><code>number_of_execution_retries</code></td>
  <td>Sets the number of times that failed tasks are re-executed. A value of zero effectively disables fault tolerance. A value of -1 indicates that the system default value (as defined in the configuration) should be used.</td>
  <td>Default: <code>-1</code></td>
</tr>
<tr>
  <td><code>execution_retry_delay</code></td>
  <td>Sets the delay in milliseconds between executions. A value of {@code -1} indicates that the default value should be used.</td>
  <td>Default: <code>-1</code></td>
</tr>
<tr>
  <td><code>object_reuse</code></td>
  <td>Sets the behavior of reusing objects.</td>
  <td>Default: <code>false</code></td>
</tr>
<tr>
  <td><code>state_backend</code></td>
  <td>Sets the state backend to use in streaming mode. Otherwise the default is read from the Flink config.</td>
</tr>
<tr>
  <td><code>enable_metrics</code></td>
  <td>Enable/disable Beam metrics in Flink Runner</td>
  <td>Default: <code>true</code></td>
</tr>
<tr>
  <td><code>externalized_checkpoints_enabled</code></td>
  <td>Enables or disables externalized checkpoints. Works in conjunction with CheckpointingInterval</td>
  <td>Default: <code>false</code></td>
</tr>
<tr>
  <td><code>retain_externalized_checkpoints_on_cancellation</code></td>
  <td>Sets the behavior of externalized checkpoints on cancellation.</td>
  <td>Default: <code>false</code></td>
</tr>
<tr>
  <td><code>max_bundle_size</code></td>
  <td>The maximum number of elements in a bundle.</td>
  <td>Default: <code>1000</code></td>
</tr>
<tr>
  <td><code>max_bundle_time_mills</code></td>
  <td>The maximum time to wait before finalising a bundle (in milliseconds).</td>
  <td>Default: <code>1000</code></td>
</tr>
<tr>
  <td><code>shutdown_sources_on_final_watermark</code></td>
  <td>If set, shutdown sources when their watermark reaches +Inf.</td>
  <td>Default: <code>false</code></td>
</tr>
<tr>
  <td><code>latency_tracking_interval</code></td>
  <td>Interval in milliseconds for sending latency tracking marks from the sources to the sinks. Interval value &lt;= 0 disables the feature.</td>
  <td>Default: <code>0</code></td>
</tr>
<tr>
  <td><code>auto_watermark_interval</code></td>
  <td>The interval in milliseconds for automatic watermark emission.</td>
</tr>
<tr>
  <td><code>execution_mode_for_batch</code></td>
  <td>Flink mode for data exchange of batch pipelines. Reference {@link org.apache.flink.api.common.ExecutionMode}. Set this to BATCH_FORCED if pipelines get blocked, see https://issues.apache.org/jira/browse/FLINK-10672</td>
  <td>Default: <code>PIPELINED</code></td>
</tr>
<tr>
  <td><code>savepoint_path</code></td>
  <td>Savepoint restore path. If specified, restores the streaming pipeline from the provided path.</td>
</tr>
<tr>
  <td><code>allow_non_restored_state</code></td>
  <td>Flag indicating whether non restored state is allowed if the savepoint contains state for an operator that is no longer part of the pipeline.</td>
  <td>Default: <code>false</code></td>
</tr>

</table>
</div>

<h2 id="capability">Capability</h2>

<p>The <a href="/documentation/runners/capability-matrix/">Beam Capability Matrix</a> documents the
capabilities of the legacy Flink Runner.</p>

<p>The <a href="https://s.apache.org/apache-beam-portability-support-table">Portable Capability
Matrix</a> documents
the capabilities of the portable Flink Runner.</p>


      </div>
    </div>
    <!--
 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at
   http://www.apache.org/licenses/LICENSE-2.0
 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License. See accompanying LICENSE file.
-->

<footer class="footer">
  <div class="footer__contained">
    <div class="footer__cols">
      <div class="footer__cols__col">
        <div class="footer__cols__col__logo">
          <img src="/images/beam_logo_circle.svg" class="footer__logo" alt="Beam logo">
        </div>
        <div class="footer__cols__col__logo">
          <img src="/images/apache_logo_circle.svg" class="footer__logo" alt="Apache logo">
        </div>
      </div>
      <div class="footer__cols__col footer__cols__col--md">
        <div class="footer__cols__col__title">Start</div>
        <div class="footer__cols__col__link"><a href="/get-started/beam-overview/">Overview</a></div>
        <div class="footer__cols__col__link"><a href="/get-started/quickstart-java/">Quickstart (Java)</a></div>
        <div class="footer__cols__col__link"><a href="/get-started/quickstart-py/">Quickstart (Python)</a></div>
        <div class="footer__cols__col__link"><a href="/get-started/quickstart-go/">Quickstart (Go)</a></div>
        <div class="footer__cols__col__link"><a href="/get-started/downloads/">Downloads</a></div>
      </div>
      <div class="footer__cols__col footer__cols__col--md">
        <div class="footer__cols__col__title">Docs</div>
        <div class="footer__cols__col__link"><a href="/documentation/programming-guide/">Concepts</a></div>
        <div class="footer__cols__col__link"><a href="/documentation/pipelines/design-your-pipeline/">Pipelines</a></div>
        <div class="footer__cols__col__link"><a href="/documentation/runners/capability-matrix/">Runners</a></div>
      </div>
      <div class="footer__cols__col footer__cols__col--md">
        <div class="footer__cols__col__title">Community</div>
        <div class="footer__cols__col__link"><a href="/contribute/">Contribute</a></div>
        <div class="footer__cols__col__link"><a href="https://projects.apache.org/committee.html?beam" target="_blank">Team<img src="/images/external-link-icon.png"
                                                                                                                                width="14" height="14"
                                                                                                                                alt="External link."></a></div>
        <div class="footer__cols__col__link"><a href="/contribute/presentation-materials/">Media</a></div>
      </div>
      <div class="footer__cols__col footer__cols__col--md">
        <div class="footer__cols__col__title">Resources</div>
        <div class="footer__cols__col__link"><a href="/blog/">Blog</a></div>
        <div class="footer__cols__col__link"><a href="/get-started/support/">Support</a></div>
        <div class="footer__cols__col__link"><a href="https://github.com/apache/beam">GitHub</a></div>
      </div>
    </div>
  </div>
  <div class="footer__bottom">
    &copy;
    <a href="http://www.apache.org">The Apache Software Foundation</a>
    | <a href="/privacy_policy">Privacy Policy</a>
    | <a href="/feed.xml">RSS Feed</a>
    <br><br>
    Apache Beam, Apache, Beam, the Beam logo, and the Apache feather logo are
    either registered trademarks or trademarks of The Apache Software
    Foundation. All other products or name brands are trademarks of their
    respective holders, including The Apache Software Foundation.
  </div>
</footer>

  </body>
</html>
