<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>Google BigQuery I/O connector</title><meta name=description content="Apache Beam is an open source, unified model and set of language-specific SDKs for defining and executing data processing workflows, and also data ingestion and integration flows, supporting Enterprise Integration Patterns (EIPs) and Domain Specific Languages (DSLs). Dataflow pipelines simplify the mechanics of large-scale batch and streaming data processing and can run on a number of runtimes like Apache Flink, Apache Spark, and Google Cloud Dataflow (a cloud service). Beam also brings DSL in different languages, allowing users to easily implement their data integration processes."><link href="https://fonts.googleapis.com/css?family=Roboto:100,300,400" rel=stylesheet><link rel=preload href=/scss/main.min.7bfa213b38fe814e9a5d5af502d4d2e0d4e9e7dfe8a528843e32a858c6c92bc2.css as=style><link href=/scss/main.min.7bfa213b38fe814e9a5d5af502d4d2e0d4e9e7dfe8a528843e32a858c6c92bc2.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-2.2.4.min.js></script><style>.body__contained img{max-width:100%}</style><script src=/js/bootstrap.min.js></script><script src=/js/language-switch.js></script><script src=/js/fix-menu.js></script><script src=/js/section-nav.js></script><script src=/js/page-nav.js></script><link rel=alternate type=application/rss+xml title="Apache Beam" href=/feed.xml><link rel=canonical href=/documentation/io/built-in/google-bigquery/ data-proofer-ignore><link rel="shortcut icon" type=image/x-icon href=/images/favicon.ico><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.4.1/css/all.css integrity=sha384-5sAR7xN1Nv6T6+dT2mhtzEpVJvfS3NScPQTrOxhwjIuvcA67KV2R5Jz6kr4abQsz crossorigin=anonymous><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-73650088-1','auto');ga('send','pageview');</script></head><body class=body data-spy=scroll data-target=.page-nav data-offset=0><nav class="header navbar navbar-fixed-top"><div class=navbar-header><button type=button class=navbar-toggle aria-expanded=false aria-controls=navbar>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span><span class=icon-bar></span><span class=icon-bar></span></button>
<a href=/ class=navbar-brand><img alt=Brand style=height:25px src=/images/beam_logo_navbar.png></a></div><div class="navbar-mask closed"></div><div id=navbar class="navbar-container closed"><ul class="nav navbar-nav"><li><a href=/get-started/beam-overview/>Get Started</a></li><li><a href=/documentation/>Documentation</a></li><li><a href=/documentation/sdks/java/>Languages</a></li><li><a href=/documentation/runners/capability-matrix/>RUNNERS</a></li><li><a href=/roadmap/>Roadmap</a></li><li><a href=/contribute/>Contribute</a></li><li><a href=/community/contact-us/>Community</a></li><li><a href=/blog/>Blog</a></li></ul><ul class="nav navbar-nav navbar-right"><li><div style=width:300px><script>(function(){var cx='012923275103528129024:4emlchv9wzi';var gcse=document.createElement('script');gcse.type='text/javascript';gcse.async=true;gcse.src='https://cse.google.com/cse.js?cx='+cx;var s=document.getElementsByTagName('script')[0];s.parentNode.insertBefore(gcse,s);})();</script><gcse:search></gcse:search></div></li><li class=dropdown><a href=# class=dropdown-toggle data-toggle=dropdown role=button aria-haspopup=true aria-expanded=false><img src=https://www.apache.org/foundation/press/kit/feather_small.png alt="Apache Logo" style=height:20px><span class=caret></span></a><ul class="dropdown-menu dropdown-menu-right"><li><a href=http://www.apache.org/>ASF Homepage</a></li><li><a href=http://www.apache.org/licenses/>License</a></li><li><a href=http://www.apache.org/security/>Security</a></li><li><a href=http://www.apache.org/foundation/thanks.html>Thanks</a></li><li><a href=http://www.apache.org/foundation/sponsorship.html>Sponsorship</a></li><li><a href=https://www.apache.org/foundation/policies/conduct>Code of Conduct</a></li></ul></li><li><a href=https://github.com/apache/beam/edit/master/website/www/site/content/en/documentation/io/built-in/google-bigquery.md data-proofer-ignore><i class="far fa-edit fa-lg" alt="Edit on GitHub" title="Edit on GitHub"></i></a></li></ul></div></nav><div class="clearfix container-main-content"><div class="section-nav closed" data-offset-top=90 data-offset-bottom=500><span class="section-nav-back glyphicon glyphicon-menu-left"></span><nav><ul class=section-nav-list data-section-nav><li><span class=section-nav-list-main-title>Documentation</span></li><li><a href=/documentation>Using the Documentation</a></li><li><span class=section-nav-list-title>Pipeline development lifecycle</span><ul class=section-nav-list><li><a href=/documentation/pipelines/design-your-pipeline/>Design Your Pipeline</a></li><li><a href=/documentation/pipelines/create-your-pipeline/>Create Your Pipeline</a></li><li><a href=/documentation/pipelines/test-your-pipeline/>Test Your Pipeline</a></li></ul></li><li><span class=section-nav-list-title>Beam programming guide</span><ul class=section-nav-list><li><a href=/documentation/programming-guide/>Overview</a></li><li><a href=/documentation/programming-guide/#creating-a-pipeline>Pipelines</a></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>PCollections</span><ul class=section-nav-list><li><a href=/documentation/programming-guide/#pcollections>Creating a PCollection</a></li><li><a href=/documentation/programming-guide/#pcollection-characteristics>PCollection characteristics</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Transforms</span><ul class=section-nav-list><li><a href=/documentation/programming-guide/#applying-transforms>Applying transforms</a></li><li><span class=section-nav-list-title>Core Beam transforms</span><ul class=section-nav-list><li><a href=/documentation/programming-guide/#pardo>ParDo</a></li><li><a href=/documentation/programming-guide/#groupbykey>GroupByKey</a></li><li><a href=/documentation/programming-guide/#cogroupbykey>CoGroupByKey</a></li><li><a href=/documentation/programming-guide/#combine>Combine</a></li><li><a href=/documentation/programming-guide/#flatten>Flatten</a></li><li><a href=/documentation/programming-guide/#partition>Partition</a></li></ul></li><li><a href=/documentation/programming-guide/#requirements-for-writing-user-code-for-beam-transforms>Requirements for user code</a></li><li><a href=/documentation/programming-guide/#side-inputs>Side inputs</a></li><li><a href=/documentation/programming-guide/#additional-outputs>Additional outputs</a></li><li><a href=/documentation/programming-guide/#composite-transforms>Composite transforms</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Pipeline I/O</span><ul class=section-nav-list><li><a href=/documentation/programming-guide/#pipeline-io>Using I/O transforms</a></li><li><a href=/documentation/io/built-in/>Built-in I/O connectors</a></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Built-in I/O connector guides</span><ul class=section-nav-list><li><a href=/documentation/io/built-in/parquet/>Apache Parquet I/O connector</a></li><li><a href=/documentation/io/built-in/hadoop/>Hadoop Input/Output Format IO</a></li><li><a href=/documentation/io/built-in/hcatalog/>HCatalog IO</a></li><li><a href=/documentation/io/built-in/google-bigquery/>Google BigQuery I/O connector</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Developing new I/O connectors</span><ul class=section-nav-list><li><a href=/documentation/io/developing-io-overview/>Overview: Developing connectors</a></li><li><a href=/documentation/io/developing-io-java/>Developing connectors (Java)</a></li><li><a href=/documentation/io/developing-io-python/>Developing connectors (Python)</a></li></ul></li><li><a href=/documentation/io/testing/>Testing I/O transforms</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Schemas</span><ul class=section-nav-list><li><a href=/documentation/programming-guide/#what-is-a-schema>What is a schema</a></li><li><a href=/documentation/programming-guide/#schemas-for-pl-types>Schemas for programming language types</a></li><li><a href=/documentation/programming-guide/#schema-definition>Schema definition</a></li><li><a href=/documentation/programming-guide/#logical-types>Logical types</a></li><li><a href=/documentation/programming-guide/#creating-schemas>Creating schemas</a></li><li><a href=/documentation/programming-guide/#using-schemas>Using schemas</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Data encoding and type safety</span><ul class=section-nav-list><li><a href=/documentation/programming-guide/#data-encoding-and-type-safety>Data encoding basics</a></li><li><a href=/documentation/programming-guide/#specifying-coders>Specifying coders</a></li><li><a href=/documentation/programming-guide/#default-coders-and-the-coderregistry>Default coders and the CoderRegistry</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Windowing</span><ul class=section-nav-list><li><a href=/documentation/programming-guide/#windowing>Windowing basics</a></li><li><a href=/documentation/programming-guide/#provided-windowing-functions>Provided windowing functions</a></li><li><a href=/documentation/programming-guide/#setting-your-pcollections-windowing-function>Setting your PCollection’s windowing function</a></li><li><a href=/documentation/programming-guide/#watermarks-and-late-data>Watermarks and late data</a></li><li><a href=/documentation/programming-guide/#adding-timestamps-to-a-pcollections-elements>Adding timestamps to a PCollection’s elements</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Triggers</span><ul class=section-nav-list><li><a href=/documentation/programming-guide/#triggers>Trigger basics</a></li><li><a href=/documentation/programming-guide/#event-time-triggers>Event time triggers and the default trigger</a></li><li><a href=/documentation/programming-guide/#processing-time-triggers>Processing time triggers</a></li><li><a href=/documentation/programming-guide/#data-driven-triggers>Data-driven triggers</a></li><li><a href=/documentation/programming-guide/#setting-a-trigger>Setting a trigger</a></li><li><a href=/documentation/programming-guide/#composite-triggers>Composite triggers</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Metrics</span><ul class=section-nav-list><li><a href=/documentation/programming-guide/#metrics>Metrics basics</a></li><li><a href=/documentation/programming-guide/#types-of-metrics>Types of metrics</a></li><li><a href=/documentation/programming-guide/#querying-metrics>Querying metrics</a></li><li><a href=/documentation/programming-guide/#using-metrics>Using metrics in pipeline</a></li><li><a href=/documentation/programming-guide/#export-metrics>Export metrics</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>State and Timers</span><ul class=section-nav-list><li><a href=/documentation/programming-guide/#types-of-state>Types of state</a></li><li><a href=/documentation/programming-guide/#deferred-state-reads>Deferred state reads</a></li><li><a href=/documentation/programming-guide/#timers>Timers</a></li><li><a href=/documentation/programming-guide/#garbage-collecting-state>Garbage collecting state</a></li><li><a href=/documentation/programming-guide/#state-timers-examples>State and timers examples</a></li></ul></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Transform catalog</span><ul class=section-nav-list><li class=section-nav-item--collapsible><span class=section-nav-list-title>Python</span><ul class=section-nav-list><li><a href=/documentation/transforms/python/overview/>Overview</a></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Element-wise</span><ul class=section-nav-list><li><a href=/documentation/transforms/python/elementwise/filter/>Filter</a></li><li><a href=/documentation/transforms/python/elementwise/flatmap/>FlatMap</a></li><li><a href=/documentation/transforms/python/elementwise/keys/>Keys</a></li><li><a href=/documentation/transforms/python/elementwise/kvswap/>KvSwap</a></li><li><a href=/documentation/transforms/python/elementwise/map/>Map</a></li><li><a href=/documentation/transforms/python/elementwise/pardo/>ParDo</a></li><li><a href=/documentation/transforms/python/elementwise/partition/>Partition</a></li><li><a href=/documentation/transforms/python/elementwise/regex/>Regex</a></li><li><a href=/documentation/transforms/python/elementwise/reify/>Reify</a></li><li><a href=/documentation/transforms/python/elementwise/tostring/>ToString</a></li><li><a href=/documentation/transforms/python/elementwise/values/>Values</a></li><li><a href=/documentation/transforms/python/elementwise/withtimestamps/>WithTimestamps</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Aggregation</span><ul class=section-nav-list><li><a href=/documentation/transforms/python/aggregation/cogroupbykey/>CoGroupByKey</a></li><li><a href=/documentation/transforms/python/aggregation/combineglobally/>CombineGlobally</a></li><li><a href=/documentation/transforms/python/aggregation/combineperkey/>CombinePerKey</a></li><li><a href=/documentation/transforms/python/aggregation/combinevalues/>CombineValues</a></li><li><a href=/documentation/transforms/python/aggregation/count/>Count</a></li><li><a href=/documentation/transforms/python/aggregation/distinct/>Distinct</a></li><li><a href=/documentation/transforms/python/aggregation/groupbykey/>GroupByKey</a></li><li><a href=/documentation/transforms/python/aggregation/groupintobatches/>GroupIntoBatches</a></li><li><a href=/documentation/transforms/python/aggregation/latest/>Latest</a></li><li><a href=/documentation/transforms/python/aggregation/max/>Max</a></li><li><a href=/documentation/transforms/python/aggregation/mean/>Mean</a></li><li><a href=/documentation/transforms/python/aggregation/min/>Min</a></li><li><a href=/documentation/transforms/python/aggregation/sample/>Sample</a></li><li><a href=/documentation/transforms/python/aggregation/top/>Top</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Other</span><ul class=section-nav-list><li><a href=/documentation/transforms/python/other/create/>Create</a></li><li><a href=/documentation/transforms/python/other/flatten/>Flatten</a></li><li><a href=/documentation/transforms/python/other/reshuffle/>Reshuffle</a></li><li><a href=/documentation/transforms/python/other/windowinto/>WindowInto</a></li></ul></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Java</span><ul class=section-nav-list><li><a href=/documentation/transforms/java/overview/>Overview</a></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Element-wise</span><ul class=section-nav-list><li><a href=/documentation/transforms/java/elementwise/filter/>Filter</a></li><li><a href=/documentation/transforms/java/elementwise/flatmapelements/>FlatMapElements</a></li><li><a href=/documentation/transforms/java/elementwise/keys/>Keys</a></li><li><a href=/documentation/transforms/java/elementwise/kvswap/>KvSwap</a></li><li><a href=/documentation/transforms/java/elementwise/mapelements/>MapElements</a></li><li><a href=/documentation/transforms/java/elementwise/pardo/>ParDo</a></li><li><a href=/documentation/transforms/java/elementwise/partition/>Partition</a></li><li><a href=/documentation/transforms/java/elementwise/regex/>Regex</a></li><li><a href=/documentation/transforms/java/elementwise/reify/>Reify</a></li><li><a href=/documentation/transforms/java/elementwise/values/>Values</a></li><li><a href=/documentation/transforms/java/elementwise/tostring/>ToString</a></li><li><a href=/documentation/transforms/java/elementwise/withkeys/>WithKeys</a></li><li><a href=/documentation/transforms/java/elementwise/withtimestamps/>WithTimestamps</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Aggregation</span><ul class=section-nav-list><li><a href=/documentation/transforms/java/aggregation/approximatequantiles/>ApproximateQuantiles</a></li><li><a href=/documentation/transforms/java/aggregation/approximateunique/>ApproximateUnique</a></li><li><a href=/documentation/transforms/java/aggregation/cogroupbykey/>CoGroupByKey</a></li><li><a href=/documentation/transforms/java/aggregation/combine/>Combine</a></li><li><a href=/documentation/transforms/java/aggregation/combinewithcontext/>CombineWithContext</a></li><li><a href=/documentation/transforms/java/aggregation/count/>Count</a></li><li><a href=/documentation/transforms/java/aggregation/distinct/>Distinct</a></li><li><a href=/documentation/transforms/java/aggregation/groupbykey/>GroupByKey</a></li><li><a href=/documentation/transforms/java/aggregation/groupintobatches/>GroupIntoBatches</a></li><li><a href=/documentation/transforms/java/aggregation/hllcount/>HllCount</a></li><li><a href=/documentation/transforms/java/aggregation/latest/>Latest</a></li><li><a href=/documentation/transforms/java/aggregation/max/>Max</a></li><li><a href=/documentation/transforms/java/aggregation/mean/>Mean</a></li><li><a href=/documentation/transforms/java/aggregation/min/>Min</a></li><li><a href=/documentation/transforms/java/aggregation/sample/>Sample</a></li><li><a href=/documentation/transforms/java/aggregation/sum/>Sum</a></li><li><a href=/documentation/transforms/java/aggregation/top/>Top</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Other</span><ul class=section-nav-list><li><a href=/documentation/transforms/java/other/create/>Create</a></li><li><a href=/documentation/transforms/java/other/flatten/>Flatten</a></li><li><a href=/documentation/transforms/java/other/passert/>PAssert</a></li><li><a href=/documentation/transforms/java/other/view/>View</a></li><li><a href=/documentation/transforms/java/other/window/>Window</a></li></ul></li></ul></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Common pipeline patterns</span><ul class=section-nav-list><li><a href=/documentation/patterns/overview/>Overview</a></li><li><a href=/documentation/patterns/file-processing/>File processing</a></li><li><a href=/documentation/patterns/side-inputs/>Side inputs</a></li><li><a href=/documentation/patterns/pipeline-options/>Pipeline options</a></li><li><a href=/documentation/patterns/custom-io/>Custom I/O</a></li><li><a href=/documentation/patterns/custom-windows/>Custom windows</a></li><li><a href=/documentation/patterns/bigqueryio/>BigQueryIO</a></li><li><a href=/documentation/patterns/ai-platform/>AI Platform</a></li><li><a href=/documentation/patterns/schema/>Schema</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Runtime systems</span><ul class=section-nav-list><li><a href=/documentation/runtime/model/>Execution model</a></li><li><a href=/documentation/runtime/environments/>Container environments</a></li><li><a href=/documentation/runtime/sdk-harness-config/>SDK Harness Configuration</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Learning resources</span><ul class=section-nav-list><li><a href=/documentation/resources/learning-resources/#getting-started>Getting Started</a></li><li><a href=/documentation/resources/learning-resources/#articles>Articles</a></li><li><a href=/documentation/resources/learning-resources/#interactive-labs>Interactive Labs</a></li><li><a href=/documentation/resources/learning-resources/#beam-katas>Beam Katas</a></li><li><a href=/documentation/resources/learning-resources/#code-examples>Code Examples</a></li><li><a href=/documentation/resources/learning-resources/#api-reference>API Reference</a></li><li><a href=/documentation/resources/learning-resources/#feedback-and-suggestions>Feedback and Suggestions</a></li><li><a href=/documentation/resources/learning-resources/#how-to-contribute>How to Contribute</a></li><li><a href=/documentation/resources/videos-and-podcasts>Videos and Podcasts</a></li></ul></li><li><a href=https://cwiki.apache.org/confluence/display/BEAM/Apache+Beam>Beam Wiki</a></li></ul></nav></div><nav class="page-nav clearfix" data-offset-top=90 data-offset-bottom=500><nav id=TableOfContents><ul><li><a href=#before-you-start>Before you start</a></li><li><a href=#bigquery-basics>BigQuery basics</a><ul><li><a href=#table-names>Table names</a><ul><li><a href=#using-a-string>Using a string</a></li><li><a href=#using-a-tablereference>Using a TableReference</a></li></ul></li><li><a href=#table-rows>Table rows</a></li><li><a href=#schemas>Schemas</a></li><li><a href=#data-types>Data types</a></li></ul></li><li><a href=#reading-from-bigquery>Reading from BigQuery</a><ul><li><a href=#reading-from-a-table>Reading from a table</a></li><li><a href=#reading-with-a-query-string>Reading with a query string</a></li><li><a href=#storage-api>Using the BigQuery Storage API</a><ul><li><a href=#updating-your-code>Updating your code</a></li></ul></li></ul></li><li><a href=#writing-to-bigquery>Writing to BigQuery</a><ul><li><a href=#create-disposition>Create disposition</a></li><li><a href=#write-disposition>Write disposition</a></li><li><a href=#creating-a-table-schema>Creating a table schema</a><ul><li><a href=#using-a-tableschema>Using a TableSchema</a></li><li><a href=#using-a-string-1>Using a string</a></li></ul></li><li><a href=#setting-the-insertion-method>Setting the insertion method</a></li><li><a href=#writing-to-a-table>Writing to a table</a></li><li><a href=#using-dynamic-destinations>Using dynamic destinations</a></li><li><a href=#using-time-partitioning>Using time partitioning</a></li></ul></li><li><a href=#limitations>Limitations</a></li><li><a href=#additional-examples>Additional examples</a><ul><li><a href=#java-cookbook-examples>Java cookbook examples</a></li><li><a href=#java-complete-examples>Java complete examples</a></li><li><a href=#python-cookbook-examples>Python cookbook examples</a></li></ul></li></ul></nav></nav><div class="body__contained body__section-nav"><p><a href=/documentation/io/built-in/>Built-in I/O Transforms</a></p><h1 id=google-bigquery-io-connector>Google BigQuery I/O connector</h1><nav class=language-switcher><strong>Adapt for:</strong><ul><li data-type=language-java class=active>Java SDK</li><li data-type=language-py>Python SDK</li></ul></nav><p>The Beam SDKs include built-in transforms that can read data from and write data
to <a href=https://cloud.google.com/bigquery>Google BigQuery</a> tables.</p><h2 id=before-you-start>Before you start</h2><p class=language-java>To use BigQueryIO, add the Maven artifact dependency to your <code>pom.xml</code> file.</p><div class=language-java><div class=highlight><pre class=chroma><code class=language-java data-lang=java><span class=o>&lt;</span><span class=n>dependency</span><span class=o>&gt;</span>
    <span class=o>&lt;</span><span class=n>groupId</span><span class=o>&gt;</span><span class=n>org</span><span class=o>.</span><span class=na>apache</span><span class=o>.</span><span class=na>beam</span><span class=o>&lt;/</span><span class=n>groupId</span><span class=o>&gt;</span>
    <span class=o>&lt;</span><span class=n>artifactId</span><span class=o>&gt;</span><span class=n>beam</span><span class=o>-</span><span class=n>sdks</span><span class=o>-</span><span class=n>java</span><span class=o>-</span><span class=n>io</span><span class=o>-</span><span class=n>google</span><span class=o>-</span><span class=n>cloud</span><span class=o>-</span><span class=n>platform</span><span class=o>&lt;/</span><span class=n>artifactId</span><span class=o>&gt;</span>
    <span class=o>&lt;</span><span class=n>version</span><span class=o>&gt;</span><span class=n>2</span><span class=o>.</span><span class=na>23</span><span class=o>.</span><span class=na>0</span><span class=o>&lt;/</span><span class=n>version</span><span class=o>&gt;</span>
<span class=o>&lt;/</span><span class=n>dependency</span><span class=o>&gt;</span></code></pre></div></div><p class=language-java>Additional resources:</p><span class=language-java><ul><li><a href=https://github.com/apache/beam/tree/master/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery>BigQueryIO source code</a></li><li><a href=https://beam.apache.org/releases/javadoc/2.23.0/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIO.html>BigQueryIO Javadoc</a></li><li><a href=https://cloud.google.com/bigquery/docs>Google BigQuery documentation</a></li></ul></span><p class=language-py>To use BigQueryIO, you must install the Google Cloud Platform dependencies by
running <code>pip install apache-beam[gcp]</code>.</p><p class=language-py>Additional resources:</p><span class=language-py><ul><li><a href=https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/gcp/bigquery.py>BigQueryIO source code</a></li><li><a href=https://beam.apache.org/releases/pydoc/2.23.0/apache_beam.io.gcp.bigquery.html>BigQueryIO Pydoc</a></li><li><a href=https://cloud.google.com/bigquery/docs>Google BigQuery documentation</a></li></ul></span><h2 id=bigquery-basics>BigQuery basics</h2><h3 id=table-names>Table names</h3><p>To read or write from a BigQuery table, you must provide a fully-qualified
BigQuery table name (for example, <code>bigquery-public-data:github_repos.sample_contents</code>).
A fully-qualified BigQuery table name consists of three parts:</p><ul><li><strong>Project ID</strong>: The ID for your Google Cloud Project. The default value comes
from your pipeline options object.</li><li><strong>Dataset ID</strong>: The BigQuery dataset ID, which is unique within a given Cloud
Project.</li><li><strong>Table ID</strong>: A BigQuery table ID, which is unique within a given dataset.</li></ul><p>A table name can also include a <a href=https://cloud.google.com/bigquery/table-decorators>table decorator</a>
if you are using <a href=#using-time-partitioning>time-partitioned tables</a>.</p><p>To specify a BigQuery table, you can use either the table&rsquo;s fully-qualified name as
a string, or use a
<span class=language-java><a href=https://developers.google.com/resources/api-libraries/documentation/bigquery/v2/java/latest/index.html?com/google/api/services/bigquery/model/TableReference.html>TableReference</a></span>
<span class=language-py><a href=https://github.com/googleapis/google-cloud-python/blob/master/bigquery/google/cloud/bigquery/table.py#L153>TableReference</a></span>
object.</p><h4 id=using-a-string>Using a string</h4><p>To specify a table with a string, use the format
<code>[project_id]:[dataset_id].[table_id]</code> to specify the fully-qualified BigQuery
table name.</p><div class=language-java><div class=highlight><pre class=chroma><code class=language-java data-lang=java><span class=n>String</span> <span class=n>tableSpec</span> <span class=o>=</span> <span class=s>&#34;clouddataflow-readonly:samples.weather_stations&#34;</span><span class=o>;</span></code></pre></div></div><div class=language-py><div class=highlight><pre class=chroma><code class=language-py data-lang=py><span class=c1># project-id:dataset_id.table_id</span>
<span class=n>table_spec</span> <span class=o>=</span> <span class=s1>&#39;clouddataflow-readonly:samples.weather_stations&#39;</span></code></pre></div></div><p>You can also omit <code>project_id</code> and use the <code>[dataset_id].[table_id]</code> format. If
you omit the project ID, Beam uses the default project ID from your
<span class=language-java><a href=https://beam.apache.org/releases/javadoc/2.23.0/org/apache/beam/sdk/extensions/gcp/options/GcpOptions.html>pipeline options</a>.</span>
<span class=language-py><a href=https://beam.apache.org/releases/pydoc/2.23.0/apache_beam.options.pipeline_options.html#apache_beam.options.pipeline_options.GoogleCloudOptions>pipeline options</a>.</span></p><div class=language-java><div class=highlight><pre class=chroma><code class=language-java data-lang=java><span class=n>String</span> <span class=n>tableSpec</span> <span class=o>=</span> <span class=s>&#34;samples.weather_stations&#34;</span><span class=o>;</span></code></pre></div></div><div class=language-py><div class=highlight><pre class=chroma><code class=language-py data-lang=py><span class=c1># dataset_id.table_id</span>
<span class=n>table_spec</span> <span class=o>=</span> <span class=s1>&#39;samples.weather_stations&#39;</span></code></pre></div></div><h4 id=using-a-tablereference>Using a TableReference</h4><p>To specify a table with a <code>TableReference</code>, create a new <code>TableReference</code> using
the three parts of the BigQuery table name.</p><div class=language-java><div class=highlight><pre class=chroma><code class=language-java data-lang=java><span class=n>TableReference</span> <span class=n>tableSpec</span> <span class=o>=</span>
    <span class=k>new</span> <span class=n>TableReference</span><span class=o>()</span>
        <span class=o>.</span><span class=na>setProjectId</span><span class=o>(</span><span class=s>&#34;clouddataflow-readonly&#34;</span><span class=o>)</span>
        <span class=o>.</span><span class=na>setDatasetId</span><span class=o>(</span><span class=s>&#34;samples&#34;</span><span class=o>)</span>
        <span class=o>.</span><span class=na>setTableId</span><span class=o>(</span><span class=s>&#34;weather_stations&#34;</span><span class=o>);</span></code></pre></div></div><div class=language-py><div class=highlight><pre class=chroma><code class=language-py data-lang=py><span class=kn>from</span> <span class=nn>apache_beam.io.gcp.internal.clients</span> <span class=kn>import</span> <span class=n>bigquery</span>

<span class=n>table_spec</span> <span class=o>=</span> <span class=n>bigquery</span><span class=o>.</span><span class=n>TableReference</span><span class=p>(</span>
    <span class=n>projectId</span><span class=o>=</span><span class=s1>&#39;clouddataflow-readonly&#39;</span><span class=p>,</span>
    <span class=n>datasetId</span><span class=o>=</span><span class=s1>&#39;samples&#39;</span><span class=p>,</span>
    <span class=n>tableId</span><span class=o>=</span><span class=s1>&#39;weather_stations&#39;</span><span class=p>)</span></code></pre></div></div><p class=language-java>The Beam SDK for Java also provides the <a href=https://beam.apache.org/releases/javadoc/2.23.0/org/apache/beam/sdk/io/gcp/bigquery/BigQueryHelpers.html><code>parseTableSpec</code></a>
helper method, which constructs a <code>TableReference</code> object from a String that
contains the fully-qualified BigQuery table name. However, the static factory
methods for BigQueryIO transforms accept the table name as a String and
construct a <code>TableReference</code> object for you.</p><h3 id=table-rows>Table rows</h3><p>BigQueryIO read and write transforms produce and consume data as a <code>PCollection</code>
of dictionaries, where each element in the <code>PCollection</code> represents a single row
in the table.</p><h3 id=schemas>Schemas</h3><p>When writing to BigQuery, you must supply a table schema for the destination
table that you want to write to, unless you specify a <a href=#create-disposition>create
disposition</a> of <code>CREATE_NEVER</code>. <a href=#creating-a-table-schema>Creating a table
schema</a> covers schemas in more detail.</p><h3 id=data-types>Data types</h3><p>BigQuery supports the following data types: STRING, BYTES, INTEGER, FLOAT,
NUMERIC, BOOLEAN, TIMESTAMP, DATE, TIME, DATETIME and GEOGRAPHY.
All possible values are described at <a href=https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types>https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types</a>.
BigQueryIO allows you to use all of these data types. The following example
shows the correct format for data types used when reading from and writing to
BigQuery:</p><div class=language-java><div class=highlight><pre class=chroma><code class=language-java data-lang=java><span class=n>TableRow</span> <span class=n>row</span> <span class=o>=</span> <span class=k>new</span> <span class=n>TableRow</span><span class=o>();</span>
<span class=n>row</span><span class=o>.</span><span class=na>set</span><span class=o>(</span><span class=s>&#34;string&#34;</span><span class=o>,</span> <span class=s>&#34;abc&#34;</span><span class=o>);</span>
<span class=kt>byte</span><span class=o>[]</span> <span class=n>rawbytes</span> <span class=o>=</span> <span class=o>{(</span><span class=kt>byte</span><span class=o>)</span> <span class=n>0xab</span><span class=o>,</span> <span class=o>(</span><span class=kt>byte</span><span class=o>)</span> <span class=n>0xac</span><span class=o>};</span>
<span class=n>row</span><span class=o>.</span><span class=na>set</span><span class=o>(</span><span class=s>&#34;bytes&#34;</span><span class=o>,</span> <span class=n>Base64</span><span class=o>.</span><span class=na>getEncoder</span><span class=o>().</span><span class=na>encodeToString</span><span class=o>(</span><span class=n>rawbytes</span><span class=o>));</span>
<span class=n>row</span><span class=o>.</span><span class=na>set</span><span class=o>(</span><span class=s>&#34;integer&#34;</span><span class=o>,</span> <span class=n>5</span><span class=o>);</span>
<span class=n>row</span><span class=o>.</span><span class=na>set</span><span class=o>(</span><span class=s>&#34;float&#34;</span><span class=o>,</span> <span class=n>0</span><span class=o>.</span><span class=na>5</span><span class=o>);</span>
<span class=n>row</span><span class=o>.</span><span class=na>set</span><span class=o>(</span><span class=s>&#34;numeric&#34;</span><span class=o>,</span> <span class=n>5</span><span class=o>);</span>
<span class=n>row</span><span class=o>.</span><span class=na>set</span><span class=o>(</span><span class=s>&#34;boolean&#34;</span><span class=o>,</span> <span class=kc>true</span><span class=o>);</span>
<span class=n>row</span><span class=o>.</span><span class=na>set</span><span class=o>(</span><span class=s>&#34;timestamp&#34;</span><span class=o>,</span> <span class=s>&#34;2018-12-31 12:44:31.744957 UTC&#34;</span><span class=o>);</span>
<span class=n>row</span><span class=o>.</span><span class=na>set</span><span class=o>(</span><span class=s>&#34;date&#34;</span><span class=o>,</span> <span class=s>&#34;2018-12-31&#34;</span><span class=o>);</span>
<span class=n>row</span><span class=o>.</span><span class=na>set</span><span class=o>(</span><span class=s>&#34;time&#34;</span><span class=o>,</span> <span class=s>&#34;12:44:31&#34;</span><span class=o>);</span>
<span class=n>row</span><span class=o>.</span><span class=na>set</span><span class=o>(</span><span class=s>&#34;datetime&#34;</span><span class=o>,</span> <span class=s>&#34;2019-06-11T14:44:31&#34;</span><span class=o>);</span>
<span class=n>row</span><span class=o>.</span><span class=na>set</span><span class=o>(</span><span class=s>&#34;geography&#34;</span><span class=o>,</span> <span class=s>&#34;POINT(30 10)&#34;</span><span class=o>);</span></code></pre></div></div><div class=language-py><div class=highlight><pre class=chroma><code class=language-py data-lang=py><span class=n>bigquery_data</span> <span class=o>=</span> <span class=p>[{</span>
    <span class=s1>&#39;string&#39;</span><span class=p>:</span> <span class=s1>&#39;abc&#39;</span><span class=p>,</span>
    <span class=s1>&#39;bytes&#39;</span><span class=p>:</span> <span class=n>base64</span><span class=o>.</span><span class=n>b64encode</span><span class=p>(</span><span class=sa>b</span><span class=s1>&#39;</span><span class=se>\xab\xac</span><span class=s1>&#39;</span><span class=p>),</span>
    <span class=s1>&#39;integer&#39;</span><span class=p>:</span> <span class=mi>5</span><span class=p>,</span>
    <span class=s1>&#39;float&#39;</span><span class=p>:</span> <span class=mf>0.5</span><span class=p>,</span>
    <span class=s1>&#39;numeric&#39;</span><span class=p>:</span> <span class=n>Decimal</span><span class=p>(</span><span class=s1>&#39;5&#39;</span><span class=p>),</span>
    <span class=s1>&#39;boolean&#39;</span><span class=p>:</span> <span class=bp>True</span><span class=p>,</span>
    <span class=s1>&#39;timestamp&#39;</span><span class=p>:</span> <span class=s1>&#39;2018-12-31 12:44:31.744957 UTC&#39;</span><span class=p>,</span>
    <span class=s1>&#39;date&#39;</span><span class=p>:</span> <span class=s1>&#39;2018-12-31&#39;</span><span class=p>,</span>
    <span class=s1>&#39;time&#39;</span><span class=p>:</span> <span class=s1>&#39;12:44:31&#39;</span><span class=p>,</span>
    <span class=s1>&#39;datetime&#39;</span><span class=p>:</span> <span class=s1>&#39;2018-12-31T12:44:31&#39;</span><span class=p>,</span>
    <span class=s1>&#39;geography&#39;</span><span class=p>:</span> <span class=s1>&#39;POINT(30 10)&#39;</span>
<span class=p>}]</span></code></pre></div></div><p class=language-java>As of Beam 2.7.0, the NUMERIC data type is supported. This data type supports
high-precision decimal numbers (precision of 38 digits, scale of 9 digits).
The GEOGRAPHY data type works with Well-Known Text (See <a href=https://en.wikipedia.org/wiki/Well-known_text>https://en.wikipedia.org/wiki/Well-known_text</a>
format for reading and writing to BigQuery.
BigQuery IO requires values of BYTES datatype to be encoded using base64
encoding when writing to BigQuery. When bytes are read from BigQuery they are
returned as base64-encoded strings.</p><p class=language-py>As of Beam 2.7.0, the NUMERIC data type is supported. This data type supports
high-precision decimal numbers (precision of 38 digits, scale of 9 digits).
The GEOGRAPHY data type works with Well-Known Text (See <a href=https://en.wikipedia.org/wiki/Well-known_text>https://en.wikipedia.org/wiki/Well-known_text</a>
format for reading and writing to BigQuery.
BigQuery IO requires values of BYTES datatype to be encoded using base64
encoding when writing to BigQuery. When bytes are read from BigQuery they are
returned as base64-encoded bytes.</p><h2 id=reading-from-bigquery>Reading from BigQuery</h2><p>BigQueryIO allows you to read from a BigQuery table, or read the results of an
arbitrary SQL query string. By default, Beam invokes a <a href=https://cloud.google.com/bigquery/docs/exporting-data>BigQuery export
request</a> when you apply a
BigQueryIO read transform. However, the Beam SDK for Java (version 2.11.0 and
later) adds support for the beta release of the <a href=https://cloud.google.com/bigquery/docs/reference/storage/>BigQuery Storage API</a>
as an <a href=https://beam.apache.org/releases/javadoc/current/index.html?org/apache/beam/sdk/annotations/Experimental.html>experimental feature</a>.
See <a href=#storage-api>Using the BigQuery Storage API</a> for more information and a
list of limitations.</p><blockquote><p>Beam’s use of BigQuery APIs is subject to BigQuery&rsquo;s
<a href=https://cloud.google.com/bigquery/quota-policy>Quota</a>
and <a href=https://cloud.google.com/bigquery/pricing>Pricing</a> policies.</p></blockquote><p class=language-java>The Beam SDK for Java has two BigQueryIO read methods. Both of these methods
allow you to read from a table, or read fields using a query string.</p><span class=language-java><ol><li><p><code>read(SerializableFunction)</code> reads Avro-formatted records and uses a
specified parsing function to parse them into a <code>PCollection</code> of custom typed
objects. Each element in the <code>PCollection</code> represents a single row in the
table. The <a href=#reading-with-a-query-string>example code</a> for reading with a
query string shows how to use <code>read(SerializableFunction)</code>.</p></li><li><p><code>readTableRows</code> returns a <code>PCollection</code> of BigQuery <code>TableRow</code>
objects. Each element in the <code>PCollection</code> represents a single row in the
table. Integer values in the <code>TableRow</code> objects are encoded as strings to
match BigQuery&rsquo;s exported JSON format. This method is convenient, but can be
2-3 times slower in performance compared to <code>read(SerializableFunction)</code>. The
<a href=#reading-from-a-table>example code</a> for reading from a table shows how to
use <code>readTableRows</code>.</p></li></ol></span><p class=language-java><em><strong>Note:</strong></em> <code>BigQueryIO.read()</code> is deprecated as of Beam SDK 2.2.0. Instead, use
<code>read(SerializableFunction&lt;SchemaAndRecord, T>)</code> to parse BigQuery rows from
Avro <code>GenericRecord</code> into your custom type, or use <code>readTableRows()</code> to parse
them into JSON <code>TableRow</code> objects.</p><p class=language-py>To read from a BigQuery table using the Beam SDK for Python, apply a <code>Read</code>
transform on a <code>BigQuerySource</code>. Read returns a <code>PCollection</code> of dictionaries,
where each element in the <code>PCollection</code> represents a single row in the table.
Integer values in the <code>TableRow</code> objects are encoded as strings to match
BigQuery&rsquo;s exported JSON format.</p><h3 id=reading-from-a-table>Reading from a table</h3><p class=language-java>To read an entire BigQuery table, use the <code>from</code> method with a BigQuery table
name. This example uses <code>readTableRows</code>.</p><p class=language-py>To read an entire BigQuery table, use the <code>table</code> parameter with the BigQuery
table name.</p><p>The following code reads an entire table that contains weather station data and
then extracts the <code>max_temperature</code> column.</p><div class=language-java><div class=highlight><pre class=chroma><code class=language-java data-lang=java><span class=n>PCollection</span><span class=o>&lt;</span><span class=n>Double</span><span class=o>&gt;</span> <span class=n>maxTemperatures</span> <span class=o>=</span>
    <span class=n>p</span><span class=o>.</span><span class=na>apply</span><span class=o>(</span><span class=n>BigQueryIO</span><span class=o>.</span><span class=na>readTableRows</span><span class=o>().</span><span class=na>from</span><span class=o>(</span><span class=n>tableSpec</span><span class=o>))</span>
        <span class=c1>// Each row is of type TableRow
</span><span class=c1></span>        <span class=o>.</span><span class=na>apply</span><span class=o>(</span>
            <span class=n>MapElements</span><span class=o>.</span><span class=na>into</span><span class=o>(</span><span class=n>TypeDescriptors</span><span class=o>.</span><span class=na>doubles</span><span class=o>())</span>
                <span class=o>.</span><span class=na>via</span><span class=o>((</span><span class=n>TableRow</span> <span class=n>row</span><span class=o>)</span> <span class=o>-&gt;</span> <span class=o>(</span><span class=n>Double</span><span class=o>)</span> <span class=n>row</span><span class=o>.</span><span class=na>get</span><span class=o>(</span><span class=s>&#34;max_temperature&#34;</span><span class=o>)));</span></code></pre></div></div><div class=language-py><div class=highlight><pre class=chroma><code class=language-py data-lang=py><span class=n>max_temperatures</span> <span class=o>=</span> <span class=p>(</span>
    <span class=n>p</span>
    <span class=o>|</span> <span class=s1>&#39;ReadTable&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>Read</span><span class=p>(</span><span class=n>beam</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>BigQuerySource</span><span class=p>(</span><span class=n>table_spec</span><span class=p>))</span>
    <span class=c1># Each row is a dictionary where the keys are the BigQuery columns</span>
    <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>elem</span><span class=p>:</span> <span class=n>elem</span><span class=p>[</span><span class=s1>&#39;max_temperature&#39;</span><span class=p>]))</span></code></pre></div></div><h3 id=reading-with-a-query-string>Reading with a query string</h3><p class=language-java>If you don&rsquo;t want to read an entire table, you can supply a query string with
the <code>fromQuery</code> method. This example uses
<code>read(SerializableFunction)</code>.</p><p class=language-py>If you don&rsquo;t want to read an entire table, you can supply a query string to
<code>BigQuerySource</code> by specifying the <code>query</code> parameter.</p><p>The following code uses a SQL query to only read the <code>max_temperature</code> column.</p><div class=language-java><div class=highlight><pre class=chroma><code class=language-java data-lang=java><span class=n>PCollection</span><span class=o>&lt;</span><span class=n>Double</span><span class=o>&gt;</span> <span class=n>maxTemperatures</span> <span class=o>=</span>
    <span class=n>p</span><span class=o>.</span><span class=na>apply</span><span class=o>(</span>
        <span class=n>BigQueryIO</span><span class=o>.</span><span class=na>read</span><span class=o>(</span>
                <span class=o>(</span><span class=n>SchemaAndRecord</span> <span class=n>elem</span><span class=o>)</span> <span class=o>-&gt;</span> <span class=o>(</span><span class=n>Double</span><span class=o>)</span> <span class=n>elem</span><span class=o>.</span><span class=na>getRecord</span><span class=o>().</span><span class=na>get</span><span class=o>(</span><span class=s>&#34;max_temperature&#34;</span><span class=o>))</span>
            <span class=o>.</span><span class=na>fromQuery</span><span class=o>(</span>
                <span class=s>&#34;SELECT max_temperature FROM [clouddataflow-readonly:samples.weather_stations]&#34;</span><span class=o>)</span>
            <span class=o>.</span><span class=na>withCoder</span><span class=o>(</span><span class=n>DoubleCoder</span><span class=o>.</span><span class=na>of</span><span class=o>()));</span></code></pre></div></div><div class=language-py><div class=highlight><pre class=chroma><code class=language-py data-lang=py><span class=n>max_temperatures</span> <span class=o>=</span> <span class=p>(</span>
    <span class=n>p</span>
    <span class=o>|</span> <span class=s1>&#39;QueryTable&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>Read</span><span class=p>(</span><span class=n>beam</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>BigQuerySource</span><span class=p>(</span>
        <span class=n>query</span><span class=o>=</span><span class=s1>&#39;SELECT max_temperature FROM &#39;</span>\
              <span class=s1>&#39;[clouddataflow-readonly:samples.weather_stations]&#39;</span><span class=p>))</span>
    <span class=c1># Each row is a dictionary where the keys are the BigQuery columns</span>
    <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>elem</span><span class=p>:</span> <span class=n>elem</span><span class=p>[</span><span class=s1>&#39;max_temperature&#39;</span><span class=p>]))</span></code></pre></div></div><p>You can also use BigQuery&rsquo;s standard SQL dialect with a query string, as shown
in the following example:</p><div class=language-java><div class=highlight><pre class=chroma><code class=language-java data-lang=java><span class=n>PCollection</span><span class=o>&lt;</span><span class=n>Double</span><span class=o>&gt;</span> <span class=n>maxTemperatures</span> <span class=o>=</span>
    <span class=n>p</span><span class=o>.</span><span class=na>apply</span><span class=o>(</span>
        <span class=n>BigQueryIO</span><span class=o>.</span><span class=na>read</span><span class=o>(</span>
                <span class=o>(</span><span class=n>SchemaAndRecord</span> <span class=n>elem</span><span class=o>)</span> <span class=o>-&gt;</span> <span class=o>(</span><span class=n>Double</span><span class=o>)</span> <span class=n>elem</span><span class=o>.</span><span class=na>getRecord</span><span class=o>().</span><span class=na>get</span><span class=o>(</span><span class=s>&#34;max_temperature&#34;</span><span class=o>))</span>
            <span class=o>.</span><span class=na>fromQuery</span><span class=o>(</span>
                <span class=s>&#34;SELECT max_temperature FROM `clouddataflow-readonly.samples.weather_stations`&#34;</span><span class=o>)</span>
            <span class=o>.</span><span class=na>usingStandardSql</span><span class=o>()</span>
            <span class=o>.</span><span class=na>withCoder</span><span class=o>(</span><span class=n>DoubleCoder</span><span class=o>.</span><span class=na>of</span><span class=o>()));</span></code></pre></div></div><div class=language-py><div class=highlight><pre class=chroma><code class=language-py data-lang=py><span class=n>max_temperatures</span> <span class=o>=</span> <span class=p>(</span>
    <span class=n>p</span>
    <span class=o>|</span> <span class=s1>&#39;QueryTableStdSQL&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>Read</span><span class=p>(</span><span class=n>beam</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>BigQuerySource</span><span class=p>(</span>
        <span class=n>query</span><span class=o>=</span><span class=s1>&#39;SELECT max_temperature FROM &#39;</span>\
              <span class=s1>&#39;`clouddataflow-readonly.samples.weather_stations`&#39;</span><span class=p>,</span>
        <span class=n>use_standard_sql</span><span class=o>=</span><span class=bp>True</span><span class=p>))</span>
    <span class=c1># Each row is a dictionary where the keys are the BigQuery columns</span>
    <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>elem</span><span class=p>:</span> <span class=n>elem</span><span class=p>[</span><span class=s1>&#39;max_temperature&#39;</span><span class=p>]))</span></code></pre></div></div><h3 id=storage-api>Using the BigQuery Storage API</h3><p>The <a href=https://cloud.google.com/bigquery/docs/reference/storage/>BigQuery Storage API</a>
allows you to directly access tables in BigQuery storage. As a result, your
pipeline can read from BigQuery storage faster than previously possible.</p><p>The Beam SDK for Java (version 2.11.0 and later) adds support for the beta
release of the BigQuery Storage API as an <a href=https://beam.apache.org/releases/javadoc/current/index.html?org/apache/beam/sdk/annotations/Experimental.html>experimental feature</a>.
Beam&rsquo;s support for the BigQuery Storage API has the following limitations:</p><ul><li>The SDK for Python does not support the BigQuery Storage API.</li><li>SDK versions 2.11.0 and 2.12.0 do not support reading with a query string; you
can only read from a table.</li><li>SDK versions before 2.15.0 do not support dynamic work rebalancing. As a
result, reads might be less efficient in the presence of stragglers.</li></ul><p>Because this is currently a Beam experimental feature, export based reads are
recommended for production jobs.</p><h4 id=updating-your-code>Updating your code</h4><p>Use the following methods when you read from a table:</p><ul><li>Required: Specify <a href=https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIO.TypedRead.html#withMethod-org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO.TypedRead.Method->withMethod(Method.DIRECT_READ)</a> to use the BigQuery Storage API for the read operation.</li><li>Optional: To use features such as <a href=https://cloud.google.com/bigquery/docs/reference/storage/>column projection and column filtering</a>, you must specify <a href=https://beam.apache.org/releases/javadoc/2.17.0/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIO.TypedRead.html#withSelectedFields-java.util.List->withSelectedFields</a> and <a href=https://beam.apache.org/releases/javadoc/2.17.0/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIO.TypedRead.html#withRowRestriction-java.lang.String->withRowRestriction</a> respectively.</li></ul><p>The following code snippet reads from a table. This example is from the <a href=https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/cookbook/BigQueryTornadoes.java>BigQueryTornadoes
example</a>.
When the example&rsquo;s read method option is set to <code>DIRECT_READ</code>, the pipeline uses
the BigQuery Storage API and column projection to read public samples of weather
data from a BigQuery table. You can view the <a href=https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/cookbook/BigQueryTornadoes.java>full source code on
GitHub</a>.</p><div class=language-java><div class=highlight><pre class=chroma><code class=language-java data-lang=java>   <span class=n>rowsFromBigQuery</span> <span class=o>=</span>
       <span class=n>p</span><span class=o>.</span><span class=na>apply</span><span class=o>(</span>
            <span class=n>BigQueryIO</span><span class=o>.</span><span class=na>readTableRows</span><span class=o>()</span>
               <span class=o>.</span><span class=na>from</span><span class=o>(</span><span class=n>options</span><span class=o>.</span><span class=na>getInput</span><span class=o>())</span>
               <span class=o>.</span><span class=na>withMethod</span><span class=o>(</span><span class=n>Method</span><span class=o>.</span><span class=na>DIRECT_READ</span><span class=o>)</span>
               <span class=o>.</span><span class=na>withSelectedFields</span><span class=o>(</span><span class=n>Lists</span><span class=o>.</span><span class=na>newArrayList</span><span class=o>(</span><span class=s>&#34;month&#34;</span><span class=o>,</span> <span class=s>&#34;tornado&#34;</span><span class=o>));</span></code></pre></div></div><div class=language-py><div class=highlight><pre class=chroma><code class=language-py data-lang=py><span class=c1># The SDK for Python does not support the BigQuery Storage API.</span></code></pre></div></div><p>The following code snippet reads with a query string.</p><div class=language-java><div class=highlight><pre class=chroma><code class=language-java data-lang=java><span class=o>//</span> <span class=n>Snippet</span> <span class=n>not</span> <span class=n>yet</span> <span class=nf>available</span> <span class=o>(</span><span class=n>BEAM</span><span class=o>-</span><span class=n>7034</span><span class=o>).</span></code></pre></div></div><div class=language-py><div class=highlight><pre class=chroma><code class=language-py data-lang=py><span class=c1># The SDK for Python does not support the BigQuery Storage API.</span></code></pre></div></div><h2 id=writing-to-bigquery>Writing to BigQuery</h2><p>BigQueryIO allows you to write to BigQuery tables. If you are using the Beam SDK
for Java, you can also write different rows to different tables.</p><blockquote><p>BigQueryIO write transforms use APIs that are subject to BigQuery&rsquo;s
<a href=https://cloud.google.com/bigquery/quota-policy>Quota</a> and
<a href=https://cloud.google.com/bigquery/pricing>Pricing</a> policies.</p></blockquote><p>When you apply a write transform, you must provide the following information
for the destination table(s):</p><ul><li>The table name.</li><li>The destination table&rsquo;s create disposition. The create disposition specifies
whether the destination table must exist or can be created by the write
operation.</li><li>The destination table&rsquo;s write disposition. The write disposition specifies
whether the data you write will replace an existing table, append rows to an
existing table, or write only to an empty table.</li></ul><p>In addition, if your write operation creates a new BigQuery table, you must also
supply a table schema for the destination table.</p><h3 id=create-disposition>Create disposition</h3><p>The create disposition controls whether or not your BigQuery write operation
should create a table if the destination table does not exist.</p><p class=language-java>Use <code>.withCreateDisposition</code> to specify the create disposition. Valid enum
values are:</p><span class=language-java><ul><li><p><code>Write.CreateDisposition.CREATE_IF_NEEDED</code>: Specifies that the
write operation should create a new table if one does not exist. If you use
this value, you must provide a table schema with the <code>withSchema</code> method.
<code>CREATE_IF_NEEDED</code> is the default behavior.</p></li><li><p><code>Write.CreateDisposition.CREATE_NEVER</code>: Specifies that a table
should never be created. If the destination table does not exist, the write
operation fails.</p></li></ul></span><p class=language-py>Use the <code>create_disposition</code> parameter to specify the create disposition. Valid
enum values are:</p><span class=language-py><ul><li><p><code>BigQueryDisposition.CREATE_IF_NEEDED</code>: Specifies that the write operation
should create a new table if one does not exist. If you use this value, you
must provide a table schema. <code>CREATE_IF_NEEDED</code> is the default behavior.</p></li><li><p><code>BigQueryDisposition.CREATE_NEVER</code>: Specifies that a table should never be
created. If the destination table does not exist, the write operation fails.</p></li></ul></span><p>If you specify <code>CREATE_IF_NEEDED</code> as the create disposition and you don&rsquo;t supply
a table schema, the transform might fail at runtime if the destination table does
not exist.</p><h3 id=write-disposition>Write disposition</h3><p>The write disposition controls how your BigQuery write operation applies to an
existing table.</p><p class=language-java>Use <code>.withWriteDisposition</code> to specify the write disposition. Valid enum values
are:</p><span class=language-java><ul><li><p><code>Write.WriteDisposition.WRITE_EMPTY</code>: Specifies that the write
operation should fail at runtime if the destination table is not empty.
<code>WRITE_EMPTY</code> is the default behavior.</p></li><li><p><code>Write.WriteDisposition.WRITE_TRUNCATE</code>: Specifies that the write
operation should replace an existing table. Any existing rows in the
destination table are removed, and the new rows are added to the table.</p></li><li><p><code>Write.WriteDisposition.WRITE_APPEND</code>: Specifies that the write
operation should append the rows to the end of the existing table.</p></li></ul></span><p class=language-py>Use the <code>write_disposition</code> parameter to specify the write disposition. Valid
enum values are:</p><span class=language-py><ul><li><p><code>BigQueryDisposition.WRITE_EMPTY</code>: Specifies that the write operation should
fail at runtime if the destination table is not empty. <code>WRITE_EMPTY</code> is the
default behavior.</p></li><li><p><code>BigQueryDisposition.WRITE_TRUNCATE</code>: Specifies that the write operation
should replace an existing table. Any existing rows in the destination table
are removed, and the new rows are added to the table.</p></li><li><p><code>BigQueryDisposition.WRITE_APPEND</code>: Specifies that the write operation should
append the rows to the end of the existing table.</p></li></ul></span><p>When you use <code>WRITE_EMPTY</code>, the check for whether or not the destination table
is empty can occur before the actual write operation. This check doesn&rsquo;t
guarantee that your pipeline will have exclusive access to the table. Two
concurrent pipelines that write to the same output table with a write
disposition of <code>WRITE_EMPTY</code> might start successfully, but both pipelines can
fail later when the write attempts happen.</p><h3 id=creating-a-table-schema>Creating a table schema</h3><p>If your BigQuery write operation creates a new table, you must provide schema
information. The schema contains information about each field in the table.</p><p class=language-java>To create a table schema in Java, you can either use a <code>TableSchema</code> object, or
use a string that contains a JSON-serialized <code>TableSchema</code> object.</p><p class=language-py>To create a table schema in Python, you can either use a <code>TableSchema</code> object,
or use a string that defines a list of fields. Single string based schemas do
not support nested fields, repeated fields, or specifying a BigQuery mode for
fields (the mode will always be set to <code>NULLABLE</code>).</p><h4 id=using-a-tableschema>Using a TableSchema</h4><p>To create and use a table schema as a <code>TableSchema</code> object, follow these steps.</p><span class=language-java><ol><li><p>Create a list of <code>TableFieldSchema</code> objects. Each <code>TableFieldSchema</code> object
represents a field in the table.</p></li><li><p>Create a <code>TableSchema</code> object and use the <code>setFields</code> method to specify your
list of fields.</p></li><li><p>Use the <code>withSchema</code> method to provide your table schema when you apply a
write transform.</p></li></ol></span><span class=language-py><ol><li><p>Create a <code>TableSchema</code> object.</p></li><li><p>Create and append a <code>TableFieldSchema</code> object for each field in your table.</p></li><li><p>Next, use the <code>schema</code> parameter to provide your table schema when you apply
a write transform. Set the parameter’s value to the <code>TableSchema</code> object.</p></li></ol></span><p>The following example code shows how to create a <code>TableSchema</code> for a table with
two fields (source and quote) of type string.</p><div class=language-java><div class=highlight><pre class=chroma><code class=language-java data-lang=java><span class=n>TableSchema</span> <span class=n>tableSchema</span> <span class=o>=</span>
    <span class=k>new</span> <span class=n>TableSchema</span><span class=o>()</span>
        <span class=o>.</span><span class=na>setFields</span><span class=o>(</span>
            <span class=n>ImmutableList</span><span class=o>.</span><span class=na>of</span><span class=o>(</span>
                <span class=k>new</span> <span class=n>TableFieldSchema</span><span class=o>()</span>
                    <span class=o>.</span><span class=na>setName</span><span class=o>(</span><span class=s>&#34;source&#34;</span><span class=o>)</span>
                    <span class=o>.</span><span class=na>setType</span><span class=o>(</span><span class=s>&#34;STRING&#34;</span><span class=o>)</span>
                    <span class=o>.</span><span class=na>setMode</span><span class=o>(</span><span class=s>&#34;NULLABLE&#34;</span><span class=o>),</span>
                <span class=k>new</span> <span class=n>TableFieldSchema</span><span class=o>()</span>
                    <span class=o>.</span><span class=na>setName</span><span class=o>(</span><span class=s>&#34;quote&#34;</span><span class=o>)</span>
                    <span class=o>.</span><span class=na>setType</span><span class=o>(</span><span class=s>&#34;STRING&#34;</span><span class=o>)</span>
                    <span class=o>.</span><span class=na>setMode</span><span class=o>(</span><span class=s>&#34;REQUIRED&#34;</span><span class=o>)));</span></code></pre></div></div><div class=language-py><div class=highlight><pre class=chroma><code class=language-py data-lang=py><span class=n>table_schema</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s1>&#39;fields&#39;</span><span class=p>:</span> <span class=p>[{</span>
        <span class=s1>&#39;name&#39;</span><span class=p>:</span> <span class=s1>&#39;source&#39;</span><span class=p>,</span> <span class=s1>&#39;type&#39;</span><span class=p>:</span> <span class=s1>&#39;STRING&#39;</span><span class=p>,</span> <span class=s1>&#39;mode&#39;</span><span class=p>:</span> <span class=s1>&#39;NULLABLE&#39;</span>
    <span class=p>},</span> <span class=p>{</span>
        <span class=s1>&#39;name&#39;</span><span class=p>:</span> <span class=s1>&#39;quote&#39;</span><span class=p>,</span> <span class=s1>&#39;type&#39;</span><span class=p>:</span> <span class=s1>&#39;STRING&#39;</span><span class=p>,</span> <span class=s1>&#39;mode&#39;</span><span class=p>:</span> <span class=s1>&#39;REQUIRED&#39;</span>
    <span class=p>}]</span>
<span class=p>}</span></code></pre></div></div><h4 id=using-a-string-1>Using a string</h4><p class=language-java>To create and use a table schema as a string that contains JSON-serialized
<code>TableSchema</code> object, follow these steps.</p><span class=language-java><ol><li><p>Create a string that contains a JSON-serialized <code>TableSchema</code> object.</p></li><li><p>Use the <code>withJsonSchema</code> method to provide your table schema when you apply a
write transform.</p></li></ol></span><p class=language-py>To create and use a table schema as a string, follow these steps.</p><span class=language-py><ol><li><p>Create a single comma separated string of the form
&ldquo;field1:type1,field2:type2,field3:type3&rdquo; that defines a list of fields. The
type should specify the field’s BigQuery type.</p></li><li><p>Use the <code>schema</code> parameter to provide your table schema when you apply a
write transform. Set the parameter’s value to the string.</p></li></ol></span><p>The following example shows how to use a string to specify the same table schema
as the previous example.</p><div class=language-java><div class=highlight><pre class=chroma><code class=language-java data-lang=java><span class=n>String</span> <span class=n>tableSchemaJson</span> <span class=o>=</span>
    <span class=s>&#34;&#34;</span>
        <span class=o>+</span> <span class=s>&#34;{&#34;</span>
        <span class=o>+</span> <span class=s>&#34;  \&#34;fields\&#34;: [&#34;</span>
        <span class=o>+</span> <span class=s>&#34;    {&#34;</span>
        <span class=o>+</span> <span class=s>&#34;      \&#34;name\&#34;: \&#34;source\&#34;,&#34;</span>
        <span class=o>+</span> <span class=s>&#34;      \&#34;type\&#34;: \&#34;STRING\&#34;,&#34;</span>
        <span class=o>+</span> <span class=s>&#34;      \&#34;mode\&#34;: \&#34;NULLABLE\&#34;&#34;</span>
        <span class=o>+</span> <span class=s>&#34;    },&#34;</span>
        <span class=o>+</span> <span class=s>&#34;    {&#34;</span>
        <span class=o>+</span> <span class=s>&#34;      \&#34;name\&#34;: \&#34;quote\&#34;,&#34;</span>
        <span class=o>+</span> <span class=s>&#34;      \&#34;type\&#34;: \&#34;STRING\&#34;,&#34;</span>
        <span class=o>+</span> <span class=s>&#34;      \&#34;mode\&#34;: \&#34;REQUIRED\&#34;&#34;</span>
        <span class=o>+</span> <span class=s>&#34;    }&#34;</span>
        <span class=o>+</span> <span class=s>&#34;  ]&#34;</span>
        <span class=o>+</span> <span class=s>&#34;}&#34;</span><span class=o>;</span></code></pre></div></div><div class=language-py><div class=highlight><pre class=chroma><code class=language-py data-lang=py><span class=c1># column_name:BIGQUERY_TYPE, ...</span>
<span class=n>table_schema</span> <span class=o>=</span> <span class=s1>&#39;source:STRING, quote:STRING&#39;</span></code></pre></div></div><h3 id=setting-the-insertion-method>Setting the insertion method</h3><p class=language-py><blockquote><p>The Beam SDK for Python does not currently support specifying the insertion
method.</p></blockquote></p><p>BigQueryIO supports two methods of inserting data into BigQuery: load jobs and
streaming inserts. Each insertion method provides different tradeoffs of cost,
quota, and data consistency. See the BigQuery documentation for
<a href=https://cloud.google.com/bigquery/loading-data>load jobs</a> and
<a href=https://cloud.google.com/bigquery/streaming-data-into-bigquery>streaming inserts</a>
for more information about these tradeoffs.</p><p>BigQueryIO chooses a default insertion method based on the input <code>PCollection</code>.</p><p class=language-py>BigQueryIO uses load jobs when you apply a BigQueryIO write transform to a
bounded <code>PCollection</code>.</p><p class=language-java>BigQueryIO uses load jobs in the following situations:</p><span class=language-java><ul><li>When you apply a BigQueryIO write transform to a bounded <code>PCollection</code>.</li><li>When you apply a BigQueryIO write transform to an unbounded <code>PCollection</code> and
use <code>BigQueryIO.write().withTriggeringFrequency()</code> to set the triggering
frequency.</li><li>When you specify load jobs as the insertion method using
<code>BigQueryIO.write().withMethod(FILE_LOADS)</code>.</li></ul></span><p class=language-py>BigQueryIO uses streaming inserts when you apply a BigQueryIO write transform to
an unbounded <code>PCollection</code>.</p><p class=language-java>BigQueryIO uses streaming inserts in the following situations:</p><span class=language-java><ul><li>When you apply a BigQueryIO write transform to an unbounded <code>PCollection</code> and
do not set the triggering frequency.</li><li>When you specify streaming inserts as the insertion method using
<code>BigQueryIO.write().withMethod(STREAMING_INSERTS)</code>.</li></ul></span><p class=language-java>You can use <code>withMethod</code> to specify the desired insertion method. See
<a href=https://beam.apache.org/releases/javadoc/2.23.0/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIO.Write.Method.html>Write.Method</a>
for the list of the available methods and their restrictions.</p><p class=language-java><em><strong>Note:</strong></em> If you use batch loads in a streaming pipeline, you must use
<code>withTriggeringFrequency</code> to specify a triggering frequency and <code>withNumFileShards</code> to specify number of file shards written.</p><h3 id=writing-to-a-table>Writing to a table</h3><p class=language-java>To write to a BigQuery table, apply either a <code>writeTableRows</code> or <code>write</code>
transform.</p><p class=language-py>To write to a BigQuery table, apply the <code>WriteToBigQuery</code> transform.
<code>WriteToBigQuery</code> supports both batch mode and streaming mode. You must apply
the transform to a <code>PCollection</code> of dictionaries. In general, you&rsquo;ll need to use
another transform, such as <code>ParDo</code>, to format your output data into a
collection.</p><p>The following examples use this <code>PCollection</code> that contains quotes.</p><div class=language-java><div class=highlight><pre class=chroma><code class=language-java data-lang=java><span class=cm>/*
</span><span class=cm>@DefaultCoder(AvroCoder.class)
</span><span class=cm>static class Quote {
</span><span class=cm>  final String source;
</span><span class=cm>  final String quote;
</span><span class=cm>
</span><span class=cm>  public Quote() {
</span><span class=cm>    this.source = &#34;&#34;;
</span><span class=cm>    this.quote = &#34;&#34;;
</span><span class=cm>  }
</span><span class=cm>  public Quote(String source, String quote) {
</span><span class=cm>    this.source = source;
</span><span class=cm>    this.quote = quote;
</span><span class=cm>  }
</span><span class=cm>}
</span><span class=cm>*/</span>

<span class=n>PCollection</span><span class=o>&lt;</span><span class=n>Quote</span><span class=o>&gt;</span> <span class=n>quotes</span> <span class=o>=</span>
    <span class=n>p</span><span class=o>.</span><span class=na>apply</span><span class=o>(</span>
        <span class=n>Create</span><span class=o>.</span><span class=na>of</span><span class=o>(</span>
            <span class=k>new</span> <span class=n>Quote</span><span class=o>(</span><span class=s>&#34;Mahatma Gandhi&#34;</span><span class=o>,</span> <span class=s>&#34;My life is my message.&#34;</span><span class=o>),</span>
            <span class=k>new</span> <span class=n>Quote</span><span class=o>(</span><span class=s>&#34;Yoda&#34;</span><span class=o>,</span> <span class=s>&#34;Do, or do not. There is no &#39;try&#39;.&#34;</span><span class=o>)));</span></code></pre></div></div><div class=language-py><div class=highlight><pre class=chroma><code class=language-py data-lang=py><span class=n>quotes</span> <span class=o>=</span> <span class=n>p</span> <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Create</span><span class=p>([</span>
    <span class=p>{</span>
        <span class=s1>&#39;source&#39;</span><span class=p>:</span> <span class=s1>&#39;Mahatma Gandhi&#39;</span><span class=p>,</span> <span class=s1>&#39;quote&#39;</span><span class=p>:</span> <span class=s1>&#39;My life is my message.&#39;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s1>&#39;source&#39;</span><span class=p>:</span> <span class=s1>&#39;Yoda&#39;</span><span class=p>,</span> <span class=s1>&#39;quote&#39;</span><span class=p>:</span> <span class=s2>&#34;Do, or do not. There is no &#39;try&#39;.&#34;</span>
    <span class=p>},</span>
<span class=p>])</span></code></pre></div></div><p class=language-java>The <code>writeTableRows</code> method writes a <code>PCollection</code> of BigQuery <code>TableRow</code>
objects to a BigQuery table. Each element in the <code>PCollection</code> represents a
single row in the table. This example uses <code>writeTableRows</code> to write quotes to a
<code>PCollection&lt;TableRow></code>. The write operation creates a table if needed; if the
table already exists, it will be replaced.</p><p class=language-py>The following example code shows how to apply a <code>WriteToBigQuery</code> transform to
write a <code>PCollection</code> of dictionaries to a BigQuery table. The write operation
creates a table if needed; if the table already exists, it will be replaced.</p><div class=language-java><div class=highlight><pre class=chroma><code class=language-java data-lang=java><span class=n>quotes</span>
    <span class=o>.</span><span class=na>apply</span><span class=o>(</span>
        <span class=n>MapElements</span><span class=o>.</span><span class=na>into</span><span class=o>(</span><span class=n>TypeDescriptor</span><span class=o>.</span><span class=na>of</span><span class=o>(</span><span class=n>TableRow</span><span class=o>.</span><span class=na>class</span><span class=o>))</span>
            <span class=o>.</span><span class=na>via</span><span class=o>(</span>
                <span class=o>(</span><span class=n>Quote</span> <span class=n>elem</span><span class=o>)</span> <span class=o>-&gt;</span>
                    <span class=k>new</span> <span class=n>TableRow</span><span class=o>().</span><span class=na>set</span><span class=o>(</span><span class=s>&#34;source&#34;</span><span class=o>,</span> <span class=n>elem</span><span class=o>.</span><span class=na>source</span><span class=o>).</span><span class=na>set</span><span class=o>(</span><span class=s>&#34;quote&#34;</span><span class=o>,</span> <span class=n>elem</span><span class=o>.</span><span class=na>quote</span><span class=o>)))</span>
    <span class=o>.</span><span class=na>apply</span><span class=o>(</span>
        <span class=n>BigQueryIO</span><span class=o>.</span><span class=na>writeTableRows</span><span class=o>()</span>
            <span class=o>.</span><span class=na>to</span><span class=o>(</span><span class=n>tableSpec</span><span class=o>)</span>
            <span class=o>.</span><span class=na>withSchema</span><span class=o>(</span><span class=n>tableSchema</span><span class=o>)</span>
            <span class=o>.</span><span class=na>withCreateDisposition</span><span class=o>(</span><span class=n>CreateDisposition</span><span class=o>.</span><span class=na>CREATE_IF_NEEDED</span><span class=o>)</span>
            <span class=o>.</span><span class=na>withWriteDisposition</span><span class=o>(</span><span class=n>WriteDisposition</span><span class=o>.</span><span class=na>WRITE_TRUNCATE</span><span class=o>));</span></code></pre></div></div><div class=language-py><div class=highlight><pre class=chroma><code class=language-py data-lang=py><span class=n>quotes</span> <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>WriteToBigQuery</span><span class=p>(</span>
    <span class=n>table_spec</span><span class=p>,</span>
    <span class=n>schema</span><span class=o>=</span><span class=n>table_schema</span><span class=p>,</span>
    <span class=n>write_disposition</span><span class=o>=</span><span class=n>beam</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>BigQueryDisposition</span><span class=o>.</span><span class=n>WRITE_TRUNCATE</span><span class=p>,</span>
    <span class=n>create_disposition</span><span class=o>=</span><span class=n>beam</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>BigQueryDisposition</span><span class=o>.</span><span class=n>CREATE_IF_NEEDED</span><span class=p>)</span></code></pre></div></div><p class=language-java>The <code>write</code> transform writes a <code>PCollection</code> of custom typed objects to a BigQuery
table. Use <code>.withFormatFunction(SerializableFunction)</code> to provide a formatting
function that converts each input element in the <code>PCollection</code> into a
<code>TableRow</code>. This example uses <code>write</code> to write a <code>PCollection&lt;String></code>. The
write operation creates a table if needed; if the table already exists, it will
be replaced.</p><div class=language-java><div class=highlight><pre class=chroma><code class=language-java data-lang=java><span class=n>quotes</span><span class=o>.</span><span class=na>apply</span><span class=o>(</span>
    <span class=n>BigQueryIO</span><span class=o>.&lt;</span><span class=n>Quote</span><span class=o>&gt;</span><span class=n>write</span><span class=o>()</span>
        <span class=o>.</span><span class=na>to</span><span class=o>(</span><span class=n>tableSpec</span><span class=o>)</span>
        <span class=o>.</span><span class=na>withSchema</span><span class=o>(</span><span class=n>tableSchema</span><span class=o>)</span>
        <span class=o>.</span><span class=na>withFormatFunction</span><span class=o>(</span>
            <span class=o>(</span><span class=n>Quote</span> <span class=n>elem</span><span class=o>)</span> <span class=o>-&gt;</span>
                <span class=k>new</span> <span class=n>TableRow</span><span class=o>().</span><span class=na>set</span><span class=o>(</span><span class=s>&#34;source&#34;</span><span class=o>,</span> <span class=n>elem</span><span class=o>.</span><span class=na>source</span><span class=o>).</span><span class=na>set</span><span class=o>(</span><span class=s>&#34;quote&#34;</span><span class=o>,</span> <span class=n>elem</span><span class=o>.</span><span class=na>quote</span><span class=o>))</span>
        <span class=o>.</span><span class=na>withCreateDisposition</span><span class=o>(</span><span class=n>CreateDisposition</span><span class=o>.</span><span class=na>CREATE_IF_NEEDED</span><span class=o>)</span>
        <span class=o>.</span><span class=na>withWriteDisposition</span><span class=o>(</span><span class=n>WriteDisposition</span><span class=o>.</span><span class=na>WRITE_TRUNCATE</span><span class=o>));</span></code></pre></div></div><p class=language-java>When you use streaming inserts, you can decide what to do with failed records.
You can either keep retrying, or return the failed records in a separate
<code>PCollection</code> using the <code>WriteResult.getFailedInserts()</code> method.</p><h3 id=using-dynamic-destinations>Using dynamic destinations</h3><p class=language-py><blockquote><p>The Beam SDK for Python does not currently support dynamic destinations.</p></blockquote></p><p>You can use the dynamic destinations feature to write elements in a
<code>PCollection</code> to different BigQuery tables, possibly with different schemas.</p><p>The dynamic destinations feature groups your user type by a user-defined
destination key, uses the key to compute a destination table and/or schema, and
writes each group&rsquo;s elements to the computed destination.</p><p>In addition, you can also write your own types that have a mapping function to
<code>TableRow</code>, and you can use side inputs in all <code>DynamicDestinations</code> methods.</p><p class=language-java>To use dynamic destinations, you must create a <code>DynamicDestinations</code> object and
implement the following methods:</p><span class=language-java><ul><li><p><code>getDestination</code>: Returns an object that <code>getTable</code> and <code>getSchema</code> can use as
the destination key to compute the destination table and/or schema.</p></li><li><p><code>getTable</code>: Returns the table (as a <code>TableDestination</code> object) for the
destination key. This method must return a unique table for each unique
destination.</p></li><li><p><code>getSchema</code>: Returns the table schema (as a <code>TableSchema</code> object) for the
destination key.</p></li></ul></span><p class=language-java>Then, use <code>write().to</code> with your <code>DynamicDestinations</code> object. This example
uses a <code>PCollection</code> that contains weather data and writes the data into a
different table for each year.</p><div class=language-java><div class=highlight><pre class=chroma><code class=language-java data-lang=java><span class=cm>/*
</span><span class=cm>@DefaultCoder(AvroCoder.class)
</span><span class=cm>static class WeatherData {
</span><span class=cm>  final long year;
</span><span class=cm>  final long month;
</span><span class=cm>  final long day;
</span><span class=cm>  final double maxTemp;
</span><span class=cm>
</span><span class=cm>  public WeatherData() {
</span><span class=cm>    this.year = 0;
</span><span class=cm>    this.month = 0;
</span><span class=cm>    this.day = 0;
</span><span class=cm>    this.maxTemp = 0.0f;
</span><span class=cm>  }
</span><span class=cm>  public WeatherData(long year, long month, long day, double maxTemp) {
</span><span class=cm>    this.year = year;
</span><span class=cm>    this.month = month;
</span><span class=cm>    this.day = day;
</span><span class=cm>    this.maxTemp = maxTemp;
</span><span class=cm>  }
</span><span class=cm>}
</span><span class=cm>*/</span>

<span class=n>PCollection</span><span class=o>&lt;</span><span class=n>WeatherData</span><span class=o>&gt;</span> <span class=n>weatherData</span> <span class=o>=</span>
    <span class=n>p</span><span class=o>.</span><span class=na>apply</span><span class=o>(</span>
        <span class=n>BigQueryIO</span><span class=o>.</span><span class=na>read</span><span class=o>(</span>
                <span class=o>(</span><span class=n>SchemaAndRecord</span> <span class=n>elem</span><span class=o>)</span> <span class=o>-&gt;</span> <span class=o>{</span>
                  <span class=n>GenericRecord</span> <span class=n>record</span> <span class=o>=</span> <span class=n>elem</span><span class=o>.</span><span class=na>getRecord</span><span class=o>();</span>
                  <span class=k>return</span> <span class=k>new</span> <span class=n>WeatherData</span><span class=o>(</span>
                      <span class=o>(</span><span class=n>Long</span><span class=o>)</span> <span class=n>record</span><span class=o>.</span><span class=na>get</span><span class=o>(</span><span class=s>&#34;year&#34;</span><span class=o>),</span>
                      <span class=o>(</span><span class=n>Long</span><span class=o>)</span> <span class=n>record</span><span class=o>.</span><span class=na>get</span><span class=o>(</span><span class=s>&#34;month&#34;</span><span class=o>),</span>
                      <span class=o>(</span><span class=n>Long</span><span class=o>)</span> <span class=n>record</span><span class=o>.</span><span class=na>get</span><span class=o>(</span><span class=s>&#34;day&#34;</span><span class=o>),</span>
                      <span class=o>(</span><span class=n>Double</span><span class=o>)</span> <span class=n>record</span><span class=o>.</span><span class=na>get</span><span class=o>(</span><span class=s>&#34;max_temperature&#34;</span><span class=o>));</span>
                <span class=o>})</span>
            <span class=o>.</span><span class=na>fromQuery</span><span class=o>(</span>
                <span class=s>&#34;SELECT year, month, day, max_temperature &#34;</span>
                    <span class=o>+</span> <span class=s>&#34;FROM [clouddataflow-readonly:samples.weather_stations] &#34;</span>
                    <span class=o>+</span> <span class=s>&#34;WHERE year BETWEEN 2007 AND 2009&#34;</span><span class=o>)</span>
            <span class=o>.</span><span class=na>withCoder</span><span class=o>(</span><span class=n>AvroCoder</span><span class=o>.</span><span class=na>of</span><span class=o>(</span><span class=n>WeatherData</span><span class=o>.</span><span class=na>class</span><span class=o>)));</span>

<span class=c1>// We will send the weather data into different tables for every year.
</span><span class=c1></span><span class=n>weatherData</span><span class=o>.</span><span class=na>apply</span><span class=o>(</span>
    <span class=n>BigQueryIO</span><span class=o>.&lt;</span><span class=n>WeatherData</span><span class=o>&gt;</span><span class=n>write</span><span class=o>()</span>
        <span class=o>.</span><span class=na>to</span><span class=o>(</span>
            <span class=k>new</span> <span class=n>DynamicDestinations</span><span class=o>&lt;</span><span class=n>WeatherData</span><span class=o>,</span> <span class=n>Long</span><span class=o>&gt;()</span> <span class=o>{</span>
              <span class=nd>@Override</span>
              <span class=kd>public</span> <span class=n>Long</span> <span class=nf>getDestination</span><span class=o>(</span><span class=n>ValueInSingleWindow</span><span class=o>&lt;</span><span class=n>WeatherData</span><span class=o>&gt;</span> <span class=n>elem</span><span class=o>)</span> <span class=o>{</span>
                <span class=k>return</span> <span class=n>elem</span><span class=o>.</span><span class=na>getValue</span><span class=o>().</span><span class=na>year</span><span class=o>;</span>
              <span class=o>}</span>

              <span class=nd>@Override</span>
              <span class=kd>public</span> <span class=n>TableDestination</span> <span class=nf>getTable</span><span class=o>(</span><span class=n>Long</span> <span class=n>destination</span><span class=o>)</span> <span class=o>{</span>
                <span class=k>return</span> <span class=k>new</span> <span class=n>TableDestination</span><span class=o>(</span>
                    <span class=k>new</span> <span class=n>TableReference</span><span class=o>()</span>
                        <span class=o>.</span><span class=na>setProjectId</span><span class=o>(</span><span class=n>writeProject</span><span class=o>)</span>
                        <span class=o>.</span><span class=na>setDatasetId</span><span class=o>(</span><span class=n>writeDataset</span><span class=o>)</span>
                        <span class=o>.</span><span class=na>setTableId</span><span class=o>(</span><span class=n>writeTable</span> <span class=o>+</span> <span class=s>&#34;_&#34;</span> <span class=o>+</span> <span class=n>destination</span><span class=o>),</span>
                    <span class=s>&#34;Table for year &#34;</span> <span class=o>+</span> <span class=n>destination</span><span class=o>);</span>
              <span class=o>}</span>

              <span class=nd>@Override</span>
              <span class=kd>public</span> <span class=n>TableSchema</span> <span class=nf>getSchema</span><span class=o>(</span><span class=n>Long</span> <span class=n>destination</span><span class=o>)</span> <span class=o>{</span>
                <span class=k>return</span> <span class=k>new</span> <span class=n>TableSchema</span><span class=o>()</span>
                    <span class=o>.</span><span class=na>setFields</span><span class=o>(</span>
                        <span class=n>ImmutableList</span><span class=o>.</span><span class=na>of</span><span class=o>(</span>
                            <span class=k>new</span> <span class=n>TableFieldSchema</span><span class=o>()</span>
                                <span class=o>.</span><span class=na>setName</span><span class=o>(</span><span class=s>&#34;year&#34;</span><span class=o>)</span>
                                <span class=o>.</span><span class=na>setType</span><span class=o>(</span><span class=s>&#34;INTEGER&#34;</span><span class=o>)</span>
                                <span class=o>.</span><span class=na>setMode</span><span class=o>(</span><span class=s>&#34;REQUIRED&#34;</span><span class=o>),</span>
                            <span class=k>new</span> <span class=n>TableFieldSchema</span><span class=o>()</span>
                                <span class=o>.</span><span class=na>setName</span><span class=o>(</span><span class=s>&#34;month&#34;</span><span class=o>)</span>
                                <span class=o>.</span><span class=na>setType</span><span class=o>(</span><span class=s>&#34;INTEGER&#34;</span><span class=o>)</span>
                                <span class=o>.</span><span class=na>setMode</span><span class=o>(</span><span class=s>&#34;REQUIRED&#34;</span><span class=o>),</span>
                            <span class=k>new</span> <span class=n>TableFieldSchema</span><span class=o>()</span>
                                <span class=o>.</span><span class=na>setName</span><span class=o>(</span><span class=s>&#34;day&#34;</span><span class=o>)</span>
                                <span class=o>.</span><span class=na>setType</span><span class=o>(</span><span class=s>&#34;INTEGER&#34;</span><span class=o>)</span>
                                <span class=o>.</span><span class=na>setMode</span><span class=o>(</span><span class=s>&#34;REQUIRED&#34;</span><span class=o>),</span>
                            <span class=k>new</span> <span class=n>TableFieldSchema</span><span class=o>()</span>
                                <span class=o>.</span><span class=na>setName</span><span class=o>(</span><span class=s>&#34;maxTemp&#34;</span><span class=o>)</span>
                                <span class=o>.</span><span class=na>setType</span><span class=o>(</span><span class=s>&#34;FLOAT&#34;</span><span class=o>)</span>
                                <span class=o>.</span><span class=na>setMode</span><span class=o>(</span><span class=s>&#34;NULLABLE&#34;</span><span class=o>)));</span>
              <span class=o>}</span>
            <span class=o>})</span>
        <span class=o>.</span><span class=na>withFormatFunction</span><span class=o>(</span>
            <span class=o>(</span><span class=n>WeatherData</span> <span class=n>elem</span><span class=o>)</span> <span class=o>-&gt;</span>
                <span class=k>new</span> <span class=n>TableRow</span><span class=o>()</span>
                    <span class=o>.</span><span class=na>set</span><span class=o>(</span><span class=s>&#34;year&#34;</span><span class=o>,</span> <span class=n>elem</span><span class=o>.</span><span class=na>year</span><span class=o>)</span>
                    <span class=o>.</span><span class=na>set</span><span class=o>(</span><span class=s>&#34;month&#34;</span><span class=o>,</span> <span class=n>elem</span><span class=o>.</span><span class=na>month</span><span class=o>)</span>
                    <span class=o>.</span><span class=na>set</span><span class=o>(</span><span class=s>&#34;day&#34;</span><span class=o>,</span> <span class=n>elem</span><span class=o>.</span><span class=na>day</span><span class=o>)</span>
                    <span class=o>.</span><span class=na>set</span><span class=o>(</span><span class=s>&#34;maxTemp&#34;</span><span class=o>,</span> <span class=n>elem</span><span class=o>.</span><span class=na>maxTemp</span><span class=o>))</span>
        <span class=o>.</span><span class=na>withCreateDisposition</span><span class=o>(</span><span class=n>CreateDisposition</span><span class=o>.</span><span class=na>CREATE_IF_NEEDED</span><span class=o>)</span>
        <span class=o>.</span><span class=na>withWriteDisposition</span><span class=o>(</span><span class=n>WriteDisposition</span><span class=o>.</span><span class=na>WRITE_TRUNCATE</span><span class=o>));</span></code></pre></div></div><div class=language-py><div class=highlight><pre class=chroma><code class=language-py data-lang=py><span class=c1># The Beam SDK for Python does not currently support dynamic destinations.</span></code></pre></div></div><h3 id=using-time-partitioning>Using time partitioning</h3><p class=language-py><blockquote><p>The Beam SDK for Python does not currently support time partitioning.</p></blockquote></p><p>BigQuery time partitioning divides your table into smaller partitions, which is
called a <a href=https://cloud.google.com/bigquery/docs/partitioned-tables>partitioned table</a>.
Partitioned tables make it easier for you to manage and query your data.</p><p class=language-java>To use BigQuery time partitioning, use one of these two methods:</p><span class=language-java><ul><li><p><code>withTimePartitioning</code>: This method takes a <code>TimePartitioning</code> class, and is
only usable if you are writing to a single table.</p></li><li><p><code>withJsonTimePartitioning</code>: This method is the same as
<code>withTimePartitioning</code>, but takes a JSON-serialized String object.</p></li></ul></span><p class=language-java>This example generates one partition per day.</p><div class=language-java><div class=highlight><pre class=chroma><code class=language-java data-lang=java><span class=n>weatherData</span><span class=o>.</span><span class=na>apply</span><span class=o>(</span>
    <span class=n>BigQueryIO</span><span class=o>.&lt;</span><span class=n>WeatherData</span><span class=o>&gt;</span><span class=n>write</span><span class=o>()</span>
        <span class=o>.</span><span class=na>to</span><span class=o>(</span><span class=n>tableSpec</span> <span class=o>+</span> <span class=s>&#34;_partitioning&#34;</span><span class=o>)</span>
        <span class=o>.</span><span class=na>withSchema</span><span class=o>(</span><span class=n>tableSchema</span><span class=o>)</span>
        <span class=o>.</span><span class=na>withFormatFunction</span><span class=o>(</span>
            <span class=o>(</span><span class=n>WeatherData</span> <span class=n>elem</span><span class=o>)</span> <span class=o>-&gt;</span>
                <span class=k>new</span> <span class=n>TableRow</span><span class=o>()</span>
                    <span class=o>.</span><span class=na>set</span><span class=o>(</span><span class=s>&#34;year&#34;</span><span class=o>,</span> <span class=n>elem</span><span class=o>.</span><span class=na>year</span><span class=o>)</span>
                    <span class=o>.</span><span class=na>set</span><span class=o>(</span><span class=s>&#34;month&#34;</span><span class=o>,</span> <span class=n>elem</span><span class=o>.</span><span class=na>month</span><span class=o>)</span>
                    <span class=o>.</span><span class=na>set</span><span class=o>(</span><span class=s>&#34;day&#34;</span><span class=o>,</span> <span class=n>elem</span><span class=o>.</span><span class=na>day</span><span class=o>)</span>
                    <span class=o>.</span><span class=na>set</span><span class=o>(</span><span class=s>&#34;maxTemp&#34;</span><span class=o>,</span> <span class=n>elem</span><span class=o>.</span><span class=na>maxTemp</span><span class=o>))</span>
        <span class=c1>// NOTE: an existing table without time partitioning set up will not work
</span><span class=c1></span>        <span class=o>.</span><span class=na>withTimePartitioning</span><span class=o>(</span><span class=k>new</span> <span class=n>TimePartitioning</span><span class=o>().</span><span class=na>setType</span><span class=o>(</span><span class=s>&#34;DAY&#34;</span><span class=o>))</span>
        <span class=o>.</span><span class=na>withCreateDisposition</span><span class=o>(</span><span class=n>CreateDisposition</span><span class=o>.</span><span class=na>CREATE_IF_NEEDED</span><span class=o>)</span>
        <span class=o>.</span><span class=na>withWriteDisposition</span><span class=o>(</span><span class=n>WriteDisposition</span><span class=o>.</span><span class=na>WRITE_TRUNCATE</span><span class=o>));</span></code></pre></div></div><div class=language-py><div class=highlight><pre class=chroma><code class=language-py data-lang=py><span class=c1># The Beam SDK for Python does not currently support time partitioning.</span></code></pre></div></div><h2 id=limitations>Limitations</h2><p>BigQueryIO currently has the following limitations.</p><ol><li><p>You can’t sequence the completion of a BigQuery write with other steps of
your pipeline.</p></li><li><p>If you are using the Beam SDK for Python, you might have import size quota
issues if you write a very large dataset. As a workaround, you can partition
the dataset (for example, using Beam&rsquo;s <code>Partition</code> transform) and write to
multiple BigQuery tables. The Beam SDK for Java does not have this limitation
as it partitions your dataset for you.</p></li></ol><h2 id=additional-examples>Additional examples</h2><p>You can find additional examples that use BigQuery in Beam&rsquo;s examples
directories.</p><h3 id=java-cookbook-examples>Java cookbook examples</h3><p>These examples are from the Java <a href=https://github.com/apache/beam/tree/master/examples/java/src/main/java/org/apache/beam/examples/cookbook>cookbook examples</a>
directory.</p><ul><li><p><a href=https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/cookbook/BigQueryTornadoes.java>BigQueryTornadoes</a>
reads the public samples of weather data from BigQuery, counts the number of
tornadoes that occur in each month, and writes the results to a BigQuery
table.</p></li><li><p><a href=https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/cookbook/CombinePerKeyExamples.java>CombinePerKeyExamples</a>
reads the public Shakespeare data from BigQuery, and for each word in the
dataset that exceeds a given length, generates a string containing the list of
play names in which that word appears. The pipeline then writes the results to
a BigQuery table.</p></li><li><p><a href=https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/cookbook/FilterExamples.java>FilterExamples</a>
reads public samples of weather data from BigQuery, performs a projection
on the data, finds the global mean of the temperature readings, filters on
readings for a single given month, and outputs only data (for that month)
that has a mean temp smaller than the derived global mean.</p></li><li><p><a href=https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/cookbook/JoinExamples.java>JoinExamples</a>
reads a sample of the <a href=https://goo.gl/OB6oin>GDELT &ldquo;world event&rdquo;</a> from
BigQuery and joins the event <code>action</code> country code against a table that maps
country codes to country names.</p></li><li><p><a href=https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/cookbook/MaxPerKeyExamples.java>MaxPerKeyExamples</a>
reads the public samples of weather data from BigQuery, finds the maximum
temperature for each month, and writes the results to a BigQuery table.</p></li><li><p><a href=https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/cookbook/TriggerExample.java>TriggerExample</a>
performs a streaming analysis of traffic data from San Diego freeways. The
pipeline looks at the data coming in from a text file and writes the results
to a BigQuery table.</p></li></ul><h3 id=java-complete-examples>Java complete examples</h3><p>These examples are from the Java <a href=https://github.com/apache/beam/tree/master/examples/java/src/main/java/org/apache/beam/examples/complete>complete examples</a>
directory.</p><ul><li><p><a href=https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/complete/AutoComplete.java>AutoComplete</a>
computes the most popular hash tags for every prefix, which can be used for
auto-completion. The pipeline can optionally write the results to a BigQuery
table.</p></li><li><p><a href=https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/complete/StreamingWordExtract.java>StreamingWordExtract</a>
reads lines of text, splits each line into individual words, capitalizes those
words, and writes the output to a BigQuery table.</p></li><li><p><a href=https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/complete/TrafficMaxLaneFlow.java>TrafficMaxLaneFlow</a>
reads traffic sensor data, finds the lane that had the highest recorded flow,
and writes the results to a BigQuery table.</p></li><li><p><a href=https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/complete/TrafficRoutes.java>TrafficRoutes</a>
reads traffic sensor data, calculates the average speed for each window and
looks for slowdowns in routes, and writes the results to a BigQuery table.</p></li></ul><h3 id=python-cookbook-examples>Python cookbook examples</h3><p>These examples are from the Python <a href=https://github.com/apache/beam/tree/master/sdks/python/apache_beam/examples/cookbook>cookbook examples</a>
directory.</p><ul><li><p><a href=https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/cookbook/bigquery_schema.py>BigQuery schema</a>
creates a <code>TableSchema</code> with nested and repeated fields, generates data with
nested and repeated fields, and writes the data to a BigQuery table.</p></li><li><p><a href=https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/cookbook/bigquery_side_input.py>BigQuery side inputs</a>
uses BigQuery sources as a side inputs. It illustrates how to insert
side-inputs into transforms in three different forms: as a singleton, as a
iterator, and as a list.</p></li><li><p><a href=https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/cookbook/bigquery_tornadoes.py>BigQuery tornadoes</a>
reads from a BigQuery table that has the &lsquo;month&rsquo; and &lsquo;tornado&rsquo; fields as part
of the table schema, computes the number of tornadoes in each month, and
outputs the results to a BigQuery table.</p></li><li><p><a href=https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/cookbook/filters.py>BigQuery filters</a>
reads weather station data from a BigQuery table, manipulates BigQuery rows in
memory, and writes the results to a BigQuery table.</p></li></ul></div></div><footer class=footer><div class=footer__contained><div class=footer__cols><div class=footer__cols__col><div class=footer__cols__col__logo><img src=/images/beam_logo_circle.svg class=footer__logo alt="Beam logo"></div><div class=footer__cols__col__logo><img src=/images/apache_logo_circle.svg class=footer__logo alt="Apache logo"></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Start</div><div class=footer__cols__col__link><a href=/get-started/beam-overview/>Overview</a></div><div class=footer__cols__col__link><a href=/get-started/quickstart-java/>Quickstart (Java)</a></div><div class=footer__cols__col__link><a href=/get-started/quickstart-py/>Quickstart (Python)</a></div><div class=footer__cols__col__link><a href=/get-started/quickstart-go/>Quickstart (Go)</a></div><div class=footer__cols__col__link><a href=/get-started/downloads/>Downloads</a></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Docs</div><div class=footer__cols__col__link><a href=/documentation/programming-guide/>Concepts</a></div><div class=footer__cols__col__link><a href=/documentation/pipelines/design-your-pipeline/>Pipelines</a></div><div class=footer__cols__col__link><a href=/documentation/runners/capability-matrix/>Runners</a></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Community</div><div class=footer__cols__col__link><a href=/contribute/>Contribute</a></div><div class=footer__cols__col__link><a href=https://projects.apache.org/committee.html?beam target=_blank>Team<img src=/images/external-link-icon.png width=14 height=14 alt="External link."></a></div><div class=footer__cols__col__link><a href=/community/presentation-materials/>Media</a></div><div class=footer__cols__col__link><a href=/community/in-person/>Events/Meetups</a></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Resources</div><div class=footer__cols__col__link><a href=/blog/>Blog</a></div><div class=footer__cols__col__link><a href=/community/contact-us/>Contact Us</a></div><div class=footer__cols__col__link><a href=https://github.com/apache/beam>GitHub</a></div></div></div></div><div class=footer__bottom>&copy;
<a href=http://www.apache.org>The Apache Software Foundation</a>
| <a href=/privacy_policy>Privacy Policy</a>
| <a href=/feed.xml>RSS Feed</a><br><br>Apache Beam, Apache, Beam, the Beam logo, and the Apache feather logo are either registered trademarks or trademarks of The Apache Software Foundation. All other products or name brands are trademarks of their respective holders, including The Apache Software Foundation.</div></footer></body></html>