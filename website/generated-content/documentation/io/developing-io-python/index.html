<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>Apache Beam: Developing I/O connectors for Python</title><meta name=description content="Apache Beam is an open source, unified model and set of language-specific SDKs for defining and executing data processing workflows, and also data ingestion and integration flows, supporting Enterprise Integration Patterns (EIPs) and Domain Specific Languages (DSLs). Dataflow pipelines simplify the mechanics of large-scale batch and streaming data processing and can run on a number of runtimes like Apache Flink, Apache Spark, and Google Cloud Dataflow (a cloud service). Beam also brings DSL in different languages, allowing users to easily implement their data integration processes."><link href="https://fonts.googleapis.com/css?family=Roboto:100,300,400" rel=stylesheet><link rel=preload href=/scss/main.min.7bfa213b38fe814e9a5d5af502d4d2e0d4e9e7dfe8a528843e32a858c6c92bc2.css as=style><link href=/scss/main.min.7bfa213b38fe814e9a5d5af502d4d2e0d4e9e7dfe8a528843e32a858c6c92bc2.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-2.2.4.min.js></script><style>.body__contained img{max-width:100%}</style><script src=/js/bootstrap.min.js></script><script src=/js/language-switch.js></script><script src=/js/fix-menu.js></script><script src=/js/section-nav.js></script><script src=/js/page-nav.js></script><link rel=alternate type=application/rss+xml title="Apache Beam" href=/feed.xml><link rel=canonical href=/documentation/io/developing-io-python/ data-proofer-ignore><link rel="shortcut icon" type=image/x-icon href=/images/favicon.ico><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.4.1/css/all.css integrity=sha384-5sAR7xN1Nv6T6+dT2mhtzEpVJvfS3NScPQTrOxhwjIuvcA67KV2R5Jz6kr4abQsz crossorigin=anonymous><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-73650088-1','auto');ga('send','pageview');</script></head><body class=body data-spy=scroll data-target=.page-nav data-offset=0><nav class="header navbar navbar-fixed-top"><div class=navbar-header><button type=button class=navbar-toggle aria-expanded=false aria-controls=navbar>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span><span class=icon-bar></span><span class=icon-bar></span></button>
<a href=/ class=navbar-brand><img alt=Brand style=height:25px src=/images/beam_logo_navbar.png></a></div><div class="navbar-mask closed"></div><div id=navbar class="navbar-container closed"><ul class="nav navbar-nav"><li><a href=/get-started/beam-overview/>Get Started</a></li><li><a href=/documentation/>Documentation</a></li><li><a href=/documentation/sdks/java/>Languages</a></li><li><a href=/documentation/runners/capability-matrix/>RUNNERS</a></li><li><a href=/roadmap/>Roadmap</a></li><li><a href=/contribute/>Contribute</a></li><li><a href=/community/contact-us/>Community</a></li><li><a href=/blog/>Blog</a></li></ul><ul class="nav navbar-nav navbar-right"><li><div style=width:300px><script>(function(){var cx='012923275103528129024:4emlchv9wzi';var gcse=document.createElement('script');gcse.type='text/javascript';gcse.async=true;gcse.src='https://cse.google.com/cse.js?cx='+cx;var s=document.getElementsByTagName('script')[0];s.parentNode.insertBefore(gcse,s);})();</script><gcse:search></gcse:search></div></li><li class=dropdown><a href=# class=dropdown-toggle data-toggle=dropdown role=button aria-haspopup=true aria-expanded=false><img src=https://www.apache.org/foundation/press/kit/feather_small.png alt="Apache Logo" style=height:20px><span class=caret></span></a><ul class="dropdown-menu dropdown-menu-right"><li><a href=http://www.apache.org/>ASF Homepage</a></li><li><a href=http://www.apache.org/licenses/>License</a></li><li><a href=http://www.apache.org/security/>Security</a></li><li><a href=http://www.apache.org/foundation/thanks.html>Thanks</a></li><li><a href=http://www.apache.org/foundation/sponsorship.html>Sponsorship</a></li><li><a href=https://www.apache.org/foundation/policies/conduct>Code of Conduct</a></li></ul></li><li><a href=https://github.com/apache/beam/edit/master/website/www/site/content/en/documentation/io/developing-io-python.md data-proofer-ignore><i class="far fa-edit fa-lg" alt="Edit on GitHub" title="Edit on GitHub"></i></a></li></ul></div></nav><div class="clearfix container-main-content"><div class="section-nav closed" data-offset-top=90 data-offset-bottom=500><span class="section-nav-back glyphicon glyphicon-menu-left"></span><nav><ul class=section-nav-list data-section-nav><li><span class=section-nav-list-main-title>Documentation</span></li><li><a href=/documentation>Using the Documentation</a></li><li><span class=section-nav-list-title>Pipeline development lifecycle</span><ul class=section-nav-list><li><a href=/documentation/pipelines/design-your-pipeline/>Design Your Pipeline</a></li><li><a href=/documentation/pipelines/create-your-pipeline/>Create Your Pipeline</a></li><li><a href=/documentation/pipelines/test-your-pipeline/>Test Your Pipeline</a></li></ul></li><li><span class=section-nav-list-title>Beam programming guide</span><ul class=section-nav-list><li><a href=/documentation/programming-guide/>Overview</a></li><li><a href=/documentation/programming-guide/#creating-a-pipeline>Pipelines</a></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>PCollections</span><ul class=section-nav-list><li><a href=/documentation/programming-guide/#pcollections>Creating a PCollection</a></li><li><a href=/documentation/programming-guide/#pcollection-characteristics>PCollection characteristics</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Transforms</span><ul class=section-nav-list><li><a href=/documentation/programming-guide/#applying-transforms>Applying transforms</a></li><li><span class=section-nav-list-title>Core Beam transforms</span><ul class=section-nav-list><li><a href=/documentation/programming-guide/#pardo>ParDo</a></li><li><a href=/documentation/programming-guide/#groupbykey>GroupByKey</a></li><li><a href=/documentation/programming-guide/#cogroupbykey>CoGroupByKey</a></li><li><a href=/documentation/programming-guide/#combine>Combine</a></li><li><a href=/documentation/programming-guide/#flatten>Flatten</a></li><li><a href=/documentation/programming-guide/#partition>Partition</a></li></ul></li><li><a href=/documentation/programming-guide/#requirements-for-writing-user-code-for-beam-transforms>Requirements for user code</a></li><li><a href=/documentation/programming-guide/#side-inputs>Side inputs</a></li><li><a href=/documentation/programming-guide/#additional-outputs>Additional outputs</a></li><li><a href=/documentation/programming-guide/#composite-transforms>Composite transforms</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Pipeline I/O</span><ul class=section-nav-list><li><a href=/documentation/programming-guide/#pipeline-io>Using I/O transforms</a></li><li><a href=/documentation/io/built-in/>Built-in I/O connectors</a></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Built-in I/O connector guides</span><ul class=section-nav-list><li><a href=/documentation/io/built-in/parquet/>Apache Parquet I/O connector</a></li><li><a href=/documentation/io/built-in/hadoop/>Hadoop Input/Output Format IO</a></li><li><a href=/documentation/io/built-in/hcatalog/>HCatalog IO</a></li><li><a href=/documentation/io/built-in/google-bigquery/>Google BigQuery I/O connector</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Developing new I/O connectors</span><ul class=section-nav-list><li><a href=/documentation/io/developing-io-overview/>Overview: Developing connectors</a></li><li><a href=/documentation/io/developing-io-java/>Developing connectors (Java)</a></li><li><a href=/documentation/io/developing-io-python/>Developing connectors (Python)</a></li></ul></li><li><a href=/documentation/io/testing/>Testing I/O transforms</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Schemas</span><ul class=section-nav-list><li><a href=/documentation/programming-guide/#what-is-a-schema>What is a schema</a></li><li><a href=/documentation/programming-guide/#schemas-for-pl-types>Schemas for programming language types</a></li><li><a href=/documentation/programming-guide/#schema-definition>Schema definition</a></li><li><a href=/documentation/programming-guide/#logical-types>Logical types</a></li><li><a href=/documentation/programming-guide/#creating-schemas>Creating schemas</a></li><li><a href=/documentation/programming-guide/#using-schemas>Using schemas</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Data encoding and type safety</span><ul class=section-nav-list><li><a href=/documentation/programming-guide/#data-encoding-and-type-safety>Data encoding basics</a></li><li><a href=/documentation/programming-guide/#specifying-coders>Specifying coders</a></li><li><a href=/documentation/programming-guide/#default-coders-and-the-coderregistry>Default coders and the CoderRegistry</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Windowing</span><ul class=section-nav-list><li><a href=/documentation/programming-guide/#windowing>Windowing basics</a></li><li><a href=/documentation/programming-guide/#provided-windowing-functions>Provided windowing functions</a></li><li><a href=/documentation/programming-guide/#setting-your-pcollections-windowing-function>Setting your PCollection’s windowing function</a></li><li><a href=/documentation/programming-guide/#watermarks-and-late-data>Watermarks and late data</a></li><li><a href=/documentation/programming-guide/#adding-timestamps-to-a-pcollections-elements>Adding timestamps to a PCollection’s elements</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Triggers</span><ul class=section-nav-list><li><a href=/documentation/programming-guide/#triggers>Trigger basics</a></li><li><a href=/documentation/programming-guide/#event-time-triggers>Event time triggers and the default trigger</a></li><li><a href=/documentation/programming-guide/#processing-time-triggers>Processing time triggers</a></li><li><a href=/documentation/programming-guide/#data-driven-triggers>Data-driven triggers</a></li><li><a href=/documentation/programming-guide/#setting-a-trigger>Setting a trigger</a></li><li><a href=/documentation/programming-guide/#composite-triggers>Composite triggers</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Metrics</span><ul class=section-nav-list><li><a href=/documentation/programming-guide/#metrics>Metrics basics</a></li><li><a href=/documentation/programming-guide/#types-of-metrics>Types of metrics</a></li><li><a href=/documentation/programming-guide/#querying-metrics>Querying metrics</a></li><li><a href=/documentation/programming-guide/#using-metrics>Using metrics in pipeline</a></li><li><a href=/documentation/programming-guide/#export-metrics>Export metrics</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>State and Timers</span><ul class=section-nav-list><li><a href=/documentation/programming-guide/#types-of-state>Types of state</a></li><li><a href=/documentation/programming-guide/#deferred-state-reads>Deferred state reads</a></li><li><a href=/documentation/programming-guide/#timers>Timers</a></li><li><a href=/documentation/programming-guide/#garbage-collecting-state>Garbage collecting state</a></li><li><a href=/documentation/programming-guide/#state-timers-examples>State and timers examples</a></li></ul></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Transform catalog</span><ul class=section-nav-list><li class=section-nav-item--collapsible><span class=section-nav-list-title>Python</span><ul class=section-nav-list><li><a href=/documentation/transforms/python/overview/>Overview</a></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Element-wise</span><ul class=section-nav-list><li><a href=/documentation/transforms/python/elementwise/filter/>Filter</a></li><li><a href=/documentation/transforms/python/elementwise/flatmap/>FlatMap</a></li><li><a href=/documentation/transforms/python/elementwise/keys/>Keys</a></li><li><a href=/documentation/transforms/python/elementwise/kvswap/>KvSwap</a></li><li><a href=/documentation/transforms/python/elementwise/map/>Map</a></li><li><a href=/documentation/transforms/python/elementwise/pardo/>ParDo</a></li><li><a href=/documentation/transforms/python/elementwise/partition/>Partition</a></li><li><a href=/documentation/transforms/python/elementwise/regex/>Regex</a></li><li><a href=/documentation/transforms/python/elementwise/reify/>Reify</a></li><li><a href=/documentation/transforms/python/elementwise/tostring/>ToString</a></li><li><a href=/documentation/transforms/python/elementwise/values/>Values</a></li><li><a href=/documentation/transforms/python/elementwise/withtimestamps/>WithTimestamps</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Aggregation</span><ul class=section-nav-list><li><a href=/documentation/transforms/python/aggregation/cogroupbykey/>CoGroupByKey</a></li><li><a href=/documentation/transforms/python/aggregation/combineglobally/>CombineGlobally</a></li><li><a href=/documentation/transforms/python/aggregation/combineperkey/>CombinePerKey</a></li><li><a href=/documentation/transforms/python/aggregation/count/>Count</a></li><li><a href=/documentation/transforms/python/aggregation/distinct/>Distinct</a></li><li><a href=/documentation/transforms/python/aggregation/groupbykey/>GroupByKey</a></li><li><a href=/documentation/transforms/python/aggregation/mean/>Mean</a></li><li><a href=/documentation/transforms/python/aggregation/sample/>Sample</a></li><li><a href=/documentation/transforms/python/aggregation/top/>Top</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Other</span><ul class=section-nav-list><li><a href=/documentation/transforms/python/other/create/>Create</a></li><li><a href=/documentation/transforms/python/other/flatten/>Flatten</a></li><li><a href=/documentation/transforms/python/other/reshuffle/>Reshuffle</a></li><li><a href=/documentation/transforms/python/other/windowinto/>WindowInto</a></li></ul></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Java</span><ul class=section-nav-list><li><a href=/documentation/transforms/java/overview/>Overview</a></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Element-wise</span><ul class=section-nav-list><li><a href=/documentation/transforms/java/elementwise/filter/>Filter</a></li><li><a href=/documentation/transforms/java/elementwise/flatmapelements/>FlatMapElements</a></li><li><a href=/documentation/transforms/java/elementwise/keys/>Keys</a></li><li><a href=/documentation/transforms/java/elementwise/kvswap/>KvSwap</a></li><li><a href=/documentation/transforms/java/elementwise/mapelements/>MapElements</a></li><li><a href=/documentation/transforms/java/elementwise/pardo/>ParDo</a></li><li><a href=/documentation/transforms/java/elementwise/partition/>Partition</a></li><li><a href=/documentation/transforms/java/elementwise/regex/>Regex</a></li><li><a href=/documentation/transforms/java/elementwise/reify/>Reify</a></li><li><a href=/documentation/transforms/java/elementwise/values/>Values</a></li><li><a href=/documentation/transforms/java/elementwise/tostring/>ToString</a></li><li><a href=/documentation/transforms/java/elementwise/withkeys/>WithKeys</a></li><li><a href=/documentation/transforms/java/elementwise/withtimestamps/>WithTimestamps</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Aggregation</span><ul class=section-nav-list><li><a href=/documentation/transforms/java/aggregation/approximatequantiles/>ApproximateQuantiles</a></li><li><a href=/documentation/transforms/java/aggregation/approximateunique/>ApproximateUnique</a></li><li><a href=/documentation/transforms/java/aggregation/cogroupbykey/>CoGroupByKey</a></li><li><a href=/documentation/transforms/java/aggregation/combine/>Combine</a></li><li><a href=/documentation/transforms/java/aggregation/combinewithcontext/>CombineWithContext</a></li><li><a href=/documentation/transforms/java/aggregation/count/>Count</a></li><li><a href=/documentation/transforms/java/aggregation/distinct/>Distinct</a></li><li><a href=/documentation/transforms/java/aggregation/groupbykey/>GroupByKey</a></li><li><a href=/documentation/transforms/java/aggregation/groupintobatches/>GroupIntoBatches</a></li><li><a href=/documentation/transforms/java/aggregation/hllcount/>HllCount</a></li><li><a href=/documentation/transforms/java/aggregation/latest/>Latest</a></li><li><a href=/documentation/transforms/java/aggregation/max/>Max</a></li><li><a href=/documentation/transforms/java/aggregation/mean/>Mean</a></li><li><a href=/documentation/transforms/java/aggregation/min/>Min</a></li><li><a href=/documentation/transforms/java/aggregation/sample/>Sample</a></li><li><a href=/documentation/transforms/java/aggregation/sum/>Sum</a></li><li><a href=/documentation/transforms/java/aggregation/top/>Top</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Other</span><ul class=section-nav-list><li><a href=/documentation/transforms/java/other/create/>Create</a></li><li><a href=/documentation/transforms/java/other/flatten/>Flatten</a></li><li><a href=/documentation/transforms/java/other/passert/>PAssert</a></li><li><a href=/documentation/transforms/java/other/view/>View</a></li><li><a href=/documentation/transforms/java/other/window/>Window</a></li></ul></li></ul></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Common pipeline patterns</span><ul class=section-nav-list><li><a href=/documentation/patterns/overview/>Overview</a></li><li><a href=/documentation/patterns/file-processing/>File processing</a></li><li><a href=/documentation/patterns/side-inputs/>Side inputs</a></li><li><a href=/documentation/patterns/pipeline-options/>Pipeline options</a></li><li><a href=/documentation/patterns/custom-io/>Custom I/O</a></li><li><a href=/documentation/patterns/custom-windows/>Custom windows</a></li><li><a href=/documentation/patterns/bigqueryio/>BigQueryIO</a></li><li><a href=/documentation/patterns/ai-platform/>AI Platform</a></li><li><a href=/documentation/patterns/schema/>Schema</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Runtime systems</span><ul class=section-nav-list><li><a href=/documentation/runtime/model/>Execution model</a></li><li><a href=/documentation/runtime/environments/>Container environments</a></li><li><a href=/documentation/runtime/sdk-harness-config/>SDK Harness Configuration</a></li></ul></li><li class=section-nav-item--collapsible><span class=section-nav-list-title>Learning resources</span><ul class=section-nav-list><li><a href=/documentation/resources/learning-resources/#getting-started>Getting Started</a></li><li><a href=/documentation/resources/learning-resources/#articles>Articles</a></li><li><a href=/documentation/resources/learning-resources/#interactive-labs>Interactive Labs</a></li><li><a href=/documentation/resources/learning-resources/#beam-katas>Beam Katas</a></li><li><a href=/documentation/resources/learning-resources/#code-examples>Code Examples</a></li><li><a href=/documentation/resources/learning-resources/#api-reference>API Reference</a></li><li><a href=/documentation/resources/learning-resources/#feedback-and-suggestions>Feedback and Suggestions</a></li><li><a href=/documentation/resources/learning-resources/#how-to-contribute>How to Contribute</a></li><li><a href=/documentation/resources/videos-and-podcasts>Videos and Podcasts</a></li></ul></li><li><a href=https://cwiki.apache.org/confluence/display/BEAM/Apache+Beam>Beam Wiki</a></li></ul></nav></div><nav class="page-nav clearfix" data-offset-top=90 data-offset-bottom=500><nav id=TableOfContents><ul><li><a href=#basic-code-reqs>Basic code requirements</a></li><li><a href=#implementing-the-source-interface>Implementing the Source interface</a><ul><li><a href=#implementing-the-boundedsource-subclass>Implementing the BoundedSource subclass</a></li><li><a href=#implementing-the-rangetracker-subclass>Implementing the RangeTracker subclass</a><ul><li><a href=#rangetracker-methods>RangeTracker methods</a></li></ul></li><li><a href=#convenience-source-base-classes>Convenience Source base classes</a><ul><li><a href=#filebasedsource>FileBasedSource</a></li></ul></li><li><a href=#reading-from-a-new-source>Reading from a new Source</a></li></ul></li><li><a href=#using-the-filebasedsink-abstraction>Using the FileBasedSink abstraction</a></li><li><a href=#ptransform-wrappers>PTransform wrappers</a></li></ul></nav></nav><div class="body__contained body__section-nav"><h1 id=developing-io-connectors-for-python>Developing I/O connectors for Python</h1><p>To connect to a data store that isn’t supported by Beam’s existing I/O
connectors, you must create a custom I/O connector that usually consist of a
source and a sink. All Beam sources and sinks are composite transforms; however,
the implementation of your custom I/O depends on your use case. Before you
start, read the <a href=/documentation/io/developing-io-overview/>new I/O connector overview</a>
for an overview of developing a new I/O connector, the available implementation
options, and how to choose the right option for your use case.</p><p>This guide covers using the <a href=https://beam.apache.org/releases/pydoc/2.22.0/apache_beam.io.iobase.html>Source and FileBasedSink interfaces</a>
for Python. The Java SDK offers the same functionality, but uses a slightly
different API. See <a href=/documentation/io/developing-io-java/>Developing I/O connectors for Java</a>
for information specific to the Java SDK.</p><h2 id=basic-code-reqs>Basic code requirements</h2><p>Beam runners use the classes you provide to read and/or write data using
multiple worker instances in parallel. As such, the code you provide for
<code>Source</code> and <code>FileBasedSink</code> subclasses must meet some basic requirements:</p><ol><li><p><strong>Serializability:</strong> Your <code>Source</code> or <code>FileBasedSink</code> subclass must be
serializable. The service may create multiple instances of your <code>Source</code>
or <code>FileBasedSink</code> subclass to be sent to multiple remote workers to
facilitate reading or writing in parallel. The <em>way</em> the source and sink
objects are serialized is runner specific.</p></li><li><p><strong>Immutability:</strong> Your <code>Source</code> or <code>FileBasedSink</code> subclass must be
effectively immutable. You should only use mutable state in your <code>Source</code>
or <code>FileBasedSink</code> subclass if you are using lazy evaluation of expensive
computations that you need to implement the source.</p></li><li><p><strong>Thread-Safety:</strong> Your code must be thread-safe. The Beam SDK for Python
provides the <code>RangeTracker</code> class to make this easier.</p></li><li><p><strong>Testability:</strong> It is critical to exhaustively unit-test all of your
<code>Source</code> and <code>FileBasedSink</code> subclasses. A minor implementation error can
lead to data corruption or data loss (such as skipping or duplicating
records) that can be hard to detect. You can use test harnesses and utility
methods available in the <a href=https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/source_test_utils.py>source_test_utils module</a>
to develop tests for your source.</p></li></ol><p>In addition, see the <a href=/contribute/ptransform-style-guide/>PTransform style guide</a>
for Beam&rsquo;s transform style guidance.</p><h2 id=implementing-the-source-interface>Implementing the Source interface</h2><p>To create a new data source for your pipeline, you&rsquo;ll need to provide the format-specific logic that tells the service how to read data from your input source, and how to split your data source into multiple parts so that multiple worker instances can read your data in parallel.</p><p>Supply the logic for your new source by creating the following classes:</p><ul><li>A subclass of <code>BoundedSource</code>. <code>BoundedSource</code> is a source that reads a
finite amount of input records. The class describes the data you want to
read, including the data&rsquo;s location and parameters (such as how much data to
read).</li><li>A subclass of <code>RangeTracker</code>. <code>RangeTracker</code> is a thread-safe object used to
manage a range for a given position type.</li><li>One or more user-facing wrapper composite transforms (<code>PTransform</code>) that
wrap read operations. <a href=#ptransform-wrappers>PTransform wrappers</a> discusses
why you should avoid exposing your sources, and walks through how to create
a wrapper.</li></ul><p>You can find these classes in the
<a href=https://beam.apache.org/releases/pydoc/2.22.0/apache_beam.io.iobase.html>apache_beam.io.iobase module</a>.</p><h3 id=implementing-the-boundedsource-subclass>Implementing the BoundedSource subclass</h3><p><code>BoundedSource</code> represents a finite data set from which the service reads, possibly in parallel. <code>BoundedSource</code> contains a set of methods that the service uses to split the data set for reading by multiple remote workers.</p><p>To implement a <code>BoundedSource</code>, your subclass must override the following methods:</p><ul><li><p><code>estimate_size</code>: Services use this method to estimate the <em>total size</em> of your data, in bytes. This estimate is in terms of external storage size, before performing decompression or other processing.</p></li><li><p><code>split</code>: Service use this method to split your finite data into bundles of a given size.</p></li><li><p><code>get_range_tracker</code>: Services use this method to get the <code>RangeTracker</code> for a given position range, and use the information to report progress and perform dynamic splitting of sources.</p></li><li><p><code>read</code>: This method returns an iterator that reads data from the source, with respect to the boundaries defined by the given <code>RangeTracker</code> object.</p></li></ul><h3 id=implementing-the-rangetracker-subclass>Implementing the RangeTracker subclass</h3><p>A <code>RangeTracker</code> is a thread-safe object used to manage the current range and current position of the reader of a <code>BoundedSource</code> and protect concurrent access to them.</p><p>To implement a <code>RangeTracker</code>, you should first familiarize yourself with the following definitions:</p><ul><li><p><strong>Position-based sources</strong> - A position-based source can be described by a range of positions of an ordered type, and the records read by the source can be described by positions of that type. For example, for a record within a file, the position can be the starting byte offset of the record. The position type for the record in this case is <code>long</code>.</p><p>The main requirement for position-based sources is <strong>associativity</strong>: Reading records in position range &lsquo;[A, B)&rsquo; and records in position range &lsquo;[B, C)&rsquo; should give the same records as reading records in position range &lsquo;[A, C)', where &lsquo;A&rsquo; &lt;= &lsquo;B&rsquo; &lt;= &lsquo;C&rsquo;. This property ensures that no matter how many arbitrary sub-ranges a range of positions is split into, the total set of records they describe stays the same.</p><p>The other important property is how the source&rsquo;s range relates to positions of records in the source. In many sources each record can be identified by a unique starting position. In this case:</p><ul><li>All records returned by a source &lsquo;[A, B)&rsquo; must have starting positions in this range.</li><li>All but the last record should end within this range. The last record may or may not extend past the end of the range.</li><li>Records must not overlap.</li></ul><p>Such sources should define &ldquo;read &lsquo;[A, B)'&rdquo; as &ldquo;read from the first record starting at or after &lsquo;A&rsquo;, up to but not including the first record starting at or after &lsquo;B&rsquo;".</p><p>Some examples of such sources include reading lines or CSV from a text file, reading keys and values from a database, etc.</p><p>The concept of <em>split points</em> allows to extend the definitions for dealing with sources where some records cannot be identified by a unique starting position.</p></li><li><p><strong>Split points</strong> - A split point describes a record that is the first one returned when reading the range from and including position <strong>A</strong> up to infinity (i.e. [A, infinity)).</p><p>Some sources may have records that are not directly addressable. For example, imagine a file format consisting of a sequence of compressed blocks. Each block can be assigned an offset, but records within the block cannot be directly addressed without decompressing the block. Let us refer to this hypothetical format as <em>CBF (Compressed Blocks Format)</em>.</p><p>Many such formats can still satisfy the associativity property. For example, in CBF, reading [A, B) can mean &ldquo;read all the records in all blocks whose starting offset is in [A, B)".</p><p>To support such complex formats, Beam introduces the notion of <em>split points</em>. A record is a split point if there exists a position <strong>A</strong> such that the record is the first one to be returned when reading the range [A, infinity). In CBF, the only split points would be the first records in each block.</p><p>Split points allow us to define the meaning of a record&rsquo;s position and a source&rsquo;s range in the following cases:</p><ul><li>For a record that is at a split point, its position is defined to be the largest <strong>A</strong> such that reading a source with the range [A, infinity) returns this record.</li><li>Positions of other records are only required to be non-decreasing.</li><li>Reading the source [A, B) must return records starting from the first split point at or after <strong>A</strong>, up to but not including the first split point at or after <strong>B</strong>. In particular, this means that the first record returned by a source MUST always be a split point.</li><li>Positions of split points must be unique.</li></ul><p>As a result, for any decomposition of the full range of the source into position ranges, the total set of records will be the full set of records in the source, and each record will be read exactly once.</p></li><li><p><strong>Consumed positions</strong> - Consumed positions refer to records that have been read.</p><p>As the source is being read, and records read from it are being passed to the downstream transforms in the pipeline, we say that positions in the source are being <em>consumed</em>. When a reader has read a record (or promised to a caller that a record will be returned), positions up to and including the record&rsquo;s start position are considered <em>consumed</em>.</p><p>Dynamic splitting can happen only at <em>unconsumed</em> positions. If the reader just returned a record at offset 42 in a file, dynamic splitting can happen only at offset 43 or beyond. Otherwise, that record could be read twice (by the current reader and the reader of the new task).</p></li></ul><h4 id=rangetracker-methods>RangeTracker methods</h4><p>To implement a <code>RangeTracker</code>, your subclass must override the following methods:</p><ul><li><p><code>start_position</code>: Returns the starting position of the current range, inclusive.</p></li><li><p><code>stop_position</code>: Returns the ending position of the current range, exclusive.</p></li><li><p><code>try_claim</code>: This method is used to determine if a record at a split point is within the range. This method should modify the internal state of the <code>RangeTracker</code> by updating the last-consumed position to the given starting <code>position</code> of the record being read by the source. The method returns true if the given position falls within the current range.</p></li><li><p><code>set_current_position</code>: This method updates the last-consumed position to the given starting position of a record being read by a source. You can invoke this method for records that do not start at split points, and this should modify the internal state of the <code>RangeTracker</code>. If the record starts at a split point, you must invoke <code>try_claim</code> instead of this method.</p></li><li><p><code>position_at_fraction</code>: Given a fraction within the range [0.0, 1.0), this method will return the position at the given fraction compared to the position range [<code>self.start_position</code>, <code>self.stop_position</code>).</p></li><li><p><code>try_split</code>: This method attempts to split the current range into two parts around a suggested position. It is allowed to split at a different position, but in most cases it will split at the suggested position.</p></li></ul><p>This method splits the current range [<code>self.start_position</code>, <code>self.stop_position</code>) into a &ldquo;primary&rdquo; part [<code>self.start_position</code>, <code>split_position</code>), and a &ldquo;residual&rdquo; part [<code>split_position</code>, <code>self.stop_position</code>), assuming that <code>split_position</code> has not been consumed yet.</p><p>If <code>split_position</code> has already been consumed, the method returns <code>None</code>. Otherwise, it updates the current range to be the primary and returns a tuple (<code>split_position</code>, <code>split_fraction</code>). <code>split_fraction</code> should be the fraction of size of range [<code>self.start_position</code>, <code>split_position</code>) compared to the original (before split) range [<code>self.start_position</code>, <code>self.stop_position</code>).</p><ul><li><code>fraction_consumed</code>: Returns the approximate fraction of consumed positions in the source.</li></ul><p><strong>Note:</strong> Methods of class <code>iobase.RangeTracker</code> may be invoked by multiple threads, hence this class must be made thread-safe, for example, by using a single lock object.</p><h3 id=convenience-source-base-classes>Convenience Source base classes</h3><p>The Beam SDK for Python contains some convenient abstract base classes to help you easily create new sources.</p><h4 id=filebasedsource>FileBasedSource</h4><p><code>FileBasedSource</code> is a framework for developing sources for new file types. You can derive your <code>BoundedSource</code> class from the <a href=https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/filebasedsource.py>FileBasedSource</a> class.</p><p>To create a source for a new file type, you need to create a sub-class of <code>FileBasedSource</code>. Sub-classes of <code>FileBasedSource</code> must implement the method <code>FileBasedSource.read_records()</code>.</p><p>See <a href=https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/avroio.py>AvroSource</a> for an example implementation of <code>FileBasedSource</code>.</p><h3 id=reading-from-a-new-source>Reading from a new Source</h3><p>The following example, <code>CountingSource</code>, demonstrates an implementation of <code>BoundedSource</code> and uses the SDK-provided <code>RangeTracker</code> called <code>OffsetRangeTracker</code>.</p><pre><code>class CountingSource(iobase.BoundedSource):
  def __init__(self, count):
    self.records_read = Metrics.counter(self.__class__, &#39;recordsRead&#39;)
    self._count = count

  def estimate_size(self):
    return self._count

  def get_range_tracker(self, start_position, stop_position):
    if start_position is None:
      start_position = 0
    if stop_position is None:
      stop_position = self._count

    return OffsetRangeTracker(start_position, stop_position)

  def read(self, range_tracker):
    for i in range(range_tracker.start_position(),
                   range_tracker.stop_position()):
      if not range_tracker.try_claim(i):
        return
      self.records_read.inc()
      yield i

  def split(self, desired_bundle_size, start_position=None, stop_position=None):
    if start_position is None:
      start_position = 0
    if stop_position is None:
      stop_position = self._count

    bundle_start = start_position
    while bundle_start &lt; stop_position:
      bundle_stop = min(stop_position, bundle_start + desired_bundle_size)
      yield iobase.SourceBundle(
          weight=(bundle_stop - bundle_start),
          source=self,
          start_position=bundle_start,
          stop_position=bundle_stop)
      bundle_start = bundle_stop</code></pre><p>To read data from the source in your pipeline, use the <code>Read</code> transform:</p><pre><code>with beam.Pipeline(options=PipelineOptions()) as p:
  numbers = p | &#39;ProduceNumbers&#39; &gt;&gt; beam.io.Read(CountingSource(count))</code></pre><p><strong>Note:</strong> When you create a source that end-users are going to use, we
recommended that you do not expose the code for the source itself as
demonstrated in the example above. Use a wrapping <code>PTransform</code> instead.
<a href=#ptransform-wrappers>PTransform wrappers</a> discusses why you should avoid
exposing your sources, and walks through how to create a wrapper.</p><h2 id=using-the-filebasedsink-abstraction>Using the FileBasedSink abstraction</h2><p>If your data source uses files, you can implement the <a href=https://beam.apache.org/releases/pydoc/2.22.0/apache_beam.io.filebasedsink.html>FileBasedSink</a>
abstraction to create a file-based sink. For other sinks, use <code>ParDo</code>,
<code>GroupByKey</code>, and other transforms offered by the Beam SDK for Python. See the
<a href=/documentation/io/developing-io-overview/>developing I/O connectors overview</a>
for more details.</p><p>When using the <code>FileBasedSink</code> interface, you must provide the format-specific
logic that tells the runner how to write bounded data from your pipeline&rsquo;s
<code>PCollection</code>s to an output sink. The runner writes bundles of data in parallel
using multiple workers.</p><p>Supply the logic for your file-based sink by implementing the following classes:</p><ul><li><p>A subclass of the abstract base class <code>FileBasedSink</code>. <code>FileBasedSink</code>
describes a location or resource that your pipeline can write to in
parallel. To avoid exposing your sink to end-users, use the <code>_</code> prefix when
creating your <code>FileBasedSink</code> subclass.</p></li><li><p>A user-facing wrapper <code>PTransform</code> that, as part of the logic, calls
<code>Write</code> and passes your <code>FileBasedSink</code> as a parameter. A user should not
need to call <code>Write</code> directly.</p></li></ul><p>The <code>FileBasedSink</code> abstract base class implements code that is common to Beam
sinks that interact with files, including:</p><ul><li>Setting file headers and footers</li><li>Sequential record writing</li><li>Setting the output MIME type</li></ul><p><code>FileBasedSink</code> and its subclasses support writing files to any Beam-supported
<code>FileSystem</code> implementations. See the following Beam-provided <code>FileBasedSink</code>
implementation for an example:</p><ul><li><a href=https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/textio.py>TextSink</a></li></ul><h2 id=ptransform-wrappers>PTransform wrappers</h2><p>When you create a source or sink that end-users will use, avoid exposing your
source or sink code. To avoid exposing your sources and sinks to end-users, your
new classes should use the <code>_</code> prefix. Then, implement a user-facing
wrapper <code>PTransform</code>.`By exposing your source or sink as a transform, your
implementation is hidden and can be arbitrarily complex or simple. The greatest
benefit of not exposing implementation details is that later on, you can add
additional functionality without breaking the existing implementation for users.</p><p>For example, if your users’ pipelines read from your source using
<code>beam.io.Read</code> and you want to insert a reshard into the pipeline, all
users would need to add the reshard themselves (using the <code>GroupByKey</code>
transform). To solve this, we recommended that you expose the source as a
composite <code>PTransform</code> that performs both the read operation and the reshard.</p><p>See Beam’s <a href=/contribute/ptransform-style-guide/#exposing-a-ptransform-vs-something-else>PTransform style guide</a>
for additional information about wrapping with a <code>PTransform</code>.</p><p>The following examples change the source and sink from the above sections so
that they are not exposed to end-users. For the source, rename <code>CountingSource</code>
to <code>_CountingSource</code>. Then, create the wrapper <code>PTransform</code>, called
<code>ReadFromCountingSource</code>:</p><pre><code>class ReadFromCountingSource(PTransform):
  def __init__(self, count):
    super(ReadFromCountingSource, self).__init__()
    self._count = count

  def expand(self, pcoll):
    return pcoll | iobase.Read(_CountingSource(self._count))</code></pre><p>Finally, read from the source:</p><pre><code>with beam.Pipeline(options=PipelineOptions()) as p:
  numbers = p | &#39;ProduceNumbers&#39; &gt;&gt; ReadFromCountingSource(count)</code></pre><p>For the sink, rename <code>SimpleKVSink</code> to <code>_SimpleKVSink</code>. Then, create the wrapper <code>PTransform</code>, called <code>WriteToKVSink</code>:</p><pre><code>class WriteToKVSink(PTransform):
  def __init__(self, simplekv, url, final_table_name):
    self._simplekv = simplekv
    super(WriteToKVSink, self).__init__()
    self._url = url
    self._final_table_name = final_table_name

  def expand(self, pcoll):
    return pcoll | iobase.Write(
        _SimpleKVSink(self._simplekv, self._url, self._final_table_name))</code></pre><p>Finally, write to the sink:</p><pre><code>with beam.Pipeline(options=PipelineOptions()) as p:
  kvs = p | &#39;CreateKVs&#39; &gt;&gt; beam.core.Create(KVs)
  kvs | &#39;WriteToSimpleKV&#39; &gt;&gt; WriteToKVSink(
      simplekv, &#39;http://url_to_simple_kv/&#39;, final_table_name)</code></pre></div></div><footer class=footer><div class=footer__contained><div class=footer__cols><div class=footer__cols__col><div class=footer__cols__col__logo><img src=/images/beam_logo_circle.svg class=footer__logo alt="Beam logo"></div><div class=footer__cols__col__logo><img src=/images/apache_logo_circle.svg class=footer__logo alt="Apache logo"></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Start</div><div class=footer__cols__col__link><a href=/get-started/beam-overview/>Overview</a></div><div class=footer__cols__col__link><a href=/get-started/quickstart-java/>Quickstart (Java)</a></div><div class=footer__cols__col__link><a href=/get-started/quickstart-py/>Quickstart (Python)</a></div><div class=footer__cols__col__link><a href=/get-started/quickstart-go/>Quickstart (Go)</a></div><div class=footer__cols__col__link><a href=/get-started/downloads/>Downloads</a></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Docs</div><div class=footer__cols__col__link><a href=/documentation/programming-guide/>Concepts</a></div><div class=footer__cols__col__link><a href=/documentation/pipelines/design-your-pipeline/>Pipelines</a></div><div class=footer__cols__col__link><a href=/documentation/runners/capability-matrix/>Runners</a></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Community</div><div class=footer__cols__col__link><a href=/contribute/>Contribute</a></div><div class=footer__cols__col__link><a href=https://projects.apache.org/committee.html?beam target=_blank>Team<img src=/images/external-link-icon.png width=14 height=14 alt="External link."></a></div><div class=footer__cols__col__link><a href=/community/presentation-materials/>Media</a></div><div class=footer__cols__col__link><a href=/community/in-person/>Events/Meetups</a></div></div><div class="footer__cols__col footer__cols__col--md"><div class=footer__cols__col__title>Resources</div><div class=footer__cols__col__link><a href=/blog/>Blog</a></div><div class=footer__cols__col__link><a href=/community/contact-us/>Contact Us</a></div><div class=footer__cols__col__link><a href=https://github.com/apache/beam>GitHub</a></div></div></div></div><div class=footer__bottom>&copy;
<a href=http://www.apache.org>The Apache Software Foundation</a>
| <a href=/privacy_policy>Privacy Policy</a>
| <a href=/feed.xml>RSS Feed</a><br><br>Apache Beam, Apache, Beam, the Beam logo, and the Apache feather logo are either registered trademarks or trademarks of The Apache Software Foundation. All other products or name brands are trademarks of their respective holders, including The Apache Software Foundation.</div></footer></body></html>