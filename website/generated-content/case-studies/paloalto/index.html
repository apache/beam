<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>Real-time Event Stream Processing at Scale for Palo Alto Networks</title><meta name=description content="Apache Beam is an open source, unified model and set of language-specific SDKs for defining and executing data processing workflows, and also data ingestion and integration flows, supporting Enterprise Integration Patterns (EIPs) and Domain Specific Languages (DSLs). Dataflow pipelines simplify the mechanics of large-scale batch and streaming data processing and can run on a number of runtimes like Apache Flink, Apache Spark, and Google Cloud Dataflow (a cloud service). Beam also brings DSL in different languages, allowing users to easily implement their data integration processes."><link href="https://fonts.googleapis.com/css?family=Roboto:100,300,400,500,700" rel=stylesheet><link rel=preload href=/scss/main.min.408fddfe3e8a45f87a5a8c9a839d77db667c1c534e5e5cd0d957ffc3dd6c14cf.css as=style><link href=/scss/main.min.408fddfe3e8a45f87a5a8c9a839d77db667c1c534e5e5cd0d957ffc3dd6c14cf.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-2.2.4.min.js></script><style>.body__contained img{max-width:100%}</style><script type=text/javascript src=/js/bootstrap.min.2979f9a6e32fc42c3e7406339ee9fe76b31d1b52059776a02b4a7fa6a4fd280a.js defer></script>
<script type=text/javascript src=/js/language-switch-v2.min.121952b7980b920320ab229551857669209945e39b05ba2b433a565385ca44c6.js defer></script>
<script type=text/javascript src=/js/fix-menu.min.039174b67107465f2090a493f91e126f7aa797f29420f9edab8a54d9dd4b3d2d.js defer></script>
<script type=text/javascript src=/js/section-nav.min.1405fd5e70fab5f6c54037c269b1d137487d8f3d1b3009032525f6db3fbce991.js defer></script>
<script type=text/javascript src=/js/page-nav.min.af231204c9c52c5089d53a4c02739eacbb7f939e3be1c6ffcc212e0ac4dbf879.js defer></script>
<script type=text/javascript src=/js/expandable-list.min.75a4526624a3b8898fe7fb9e3428c205b581f8b38c7926922467aef17eac69f2.js defer></script>
<script type=text/javascript src=/js/copy-to-clipboard.min.364c06423d7e8993fc42bb4abc38c03195bc8386db26d18774ce775d08d5b18d.js defer></script>
<script type=text/javascript src=/js/calendar.min.336664054fa0f52b08bbd4e3c59b5cb6d63dcfb2b4d602839746516b0817446b.js defer></script>
<script type=text/javascript src=/js/fix-playground-nested-scroll.min.0283f1037cb1b9d5074c6eaf041292b524a8148a7cdb803d5ccd6d1fc4eb3253.js defer></script>
<script type=text/javascript src=/js/anchor-content-jump-fix.min.22d3240f81632e4c11179b9d2aaf37a40da9414333c43aa97344e8b21a7df0e4.js defer></script>
<link rel=alternate type=application/rss+xml title="Apache Beam" href=/feed.xml><link rel=canonical href=/case-studies/paloalto/ data-proofer-ignore><link rel="shortcut icon" type=image/x-icon href=/images/favicon.ico><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.4.1/css/all.css integrity=sha384-5sAR7xN1Nv6T6+dT2mhtzEpVJvfS3NScPQTrOxhwjIuvcA67KV2R5Jz6kr4abQsz crossorigin=anonymous><link rel=stylesheet href=https://unpkg.com/swiper@8/swiper-bundle.min.css><script async src=https://platform.twitter.com/widgets.js></script>
<script>(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","//www.google-analytics.com/analytics.js","ga"),ga("create","UA-73650088-1","auto"),ga("send","pageview")</script><script>(function(e,t,n,s,o,i){e.hj=e.hj||function(){(e.hj.q=e.hj.q||[]).push(arguments)},e._hjSettings={hjid:2182187,hjsv:6},o=t.getElementsByTagName("head")[0],i=t.createElement("script"),i.async=1,i.src=n+e._hjSettings.hjid+s+e._hjSettings.hjsv,o.appendChild(i)})(window,document,"https://static.hotjar.com/c/hotjar-",".js?sv=")</script></head><body class=body data-spy=scroll data-target=.page-nav data-offset=0><nav class="navigation-bar-mobile header navbar navbar-fixed-top"><div class=navbar-header><a href=/ class=navbar-brand><img alt=Brand style=height:46px;width:43px src=/images/beam_logo_navbar_mobile.png></a>
<a class=navbar-link href=/get-started/>Get Started</a>
<a class=navbar-link href=/documentation/>Documentation</a>
<button type=button class="navbar-toggle menu-open" aria-expanded=false aria-controls=navbar onclick=openMenu()>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button></div><div class="navbar-mask closed"></div><div id=navbar class="navbar-container closed"><button type=button class=navbar-toggle aria-expanded=false aria-controls=navbar id=closeMenu>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button><ul class="nav navbar-nav"><li><div class=searchBar-mobile><script>(function(){var t,n="012923275103528129024:4emlchv9wzi",e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src="https://cse.google.com/cse.js?cx="+n,t=document.getElementsByTagName("script")[0],t.parentNode.insertBefore(e,t)})()</script><gcse:search></gcse:search></div></li><li><a class=navbar-link href=/about>About</a></li><li><a class=navbar-link href=/get-started/>Get Started</a></li><li><span class=navbar-link>Documentation</span><ul><li><a href=/documentation/>General</a></li><li><a href=/documentation/sdks/java/>Languages</a></li><li><a href=/documentation/runners/capability-matrix/>Runners</a></li><li><a href=/documentation/io/connectors/>I/O Connectors</a></li></ul></li><li><a class=navbar-link href=/roadmap/>Roadmap</a></li><li><a class=navbar-link href=/community/>Community</a></li><li><a class=navbar-link href=/contribute/>Contribute</a></li><li><a class=navbar-link href=/blog/>Blog</a></li><li><a class=navbar-link href=/case-studies/>Case Studies</a></li></ul><ul class="nav navbar-nav navbar-right"><li><a href=https://github.com/apache/beam/edit/master/website/www/site/content/en/case-studies/paloalto.md data-proofer-ignore><svg xmlns="http://www.w3.org/2000/svg" width="25" height="24" fill="none" viewBox="0 0 25 24"><path stroke="#ff6d00" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.75" d="M4.543 20h4l10.5-10.5c.53-.53.828-1.25.828-2s-.298-1.47-.828-2-1.25-.828-2-.828-1.47.298-2 .828L4.543 16v4zm9.5-13.5 4 4"/></svg></a></li><li class=dropdown><a href=# class=dropdown-toggle id=apache-dropdown data-toggle=dropdown role=button aria-haspopup=true aria-expanded=false><img src=https://www.apache.org/foundation/press/kit/feather_small.png alt="Apache Logo" style=height:20px>
&nbsp;Apache
<span class=arrow-icon><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="none" viewBox="0 0 20 20"><circle cx="10" cy="10" r="10" fill="#ff6d00"/><path stroke="#fff" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8.535 5.28l4.573 4.818-4.573 4.403"/></svg></span></a><ul class="dropdown-menu dropdown-menu-right"><li><a target=_blank href=https://www.apache.org/>ASF Homepage</a></li><li><a target=_blank href=https://www.apache.org/licenses/>License</a></li><li><a target=_blank href=https://www.apache.org/security/>Security</a></li><li><a target=_blank href=https://www.apache.org/foundation/thanks.html>Thanks</a></li><li><a target=_blank href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a></li><li><a target=_blank href=https://www.apache.org/foundation/policies/conduct>Code of Conduct</a></li></ul></li></ul></div></nav><nav class=navigation-bar-desktop><a href=/ class=navbar-logo><img src=/images/beam_logo_navbar.png alt="Beam Logo"></a><div class=navbar-bar-left><div class=navbar-links><a class=navbar-link href=/about>About</a>
<a class=navbar-link href=/get-started/>Get Started</a><li class="dropdown navbar-dropdown navbar-dropdown-documentation"><a href=# class="dropdown-toggle navbar-link" role=button aria-haspopup=true aria-expanded=false>Documentation
<span><svg xmlns="http://www.w3.org/2000/svg" width="12" height="11" fill="none" viewBox="0 0 12 11"><path stroke="#ff6d00" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10.666 4.535 5.847 9.108 1.444 4.535"/></svg></span></a><ul class=dropdown-menu><li><a class=navbar-dropdown-menu-link href=/documentation/>General</a></li><li><a class=navbar-dropdown-menu-link href=/documentation/sdks/java/>Languages</a></li><li><a class=navbar-dropdown-menu-link href=/documentation/runners/capability-matrix/>Runners</a></li><li><a class=navbar-dropdown-menu-link href=/documentation/io/connectors/>I/O Connectors</a></li></ul></li><a class=navbar-link href=/roadmap/>Roadmap</a>
<a class=navbar-link href=/community/>Community</a>
<a class=navbar-link href=/contribute/>Contribute</a>
<a class=navbar-link href=/blog/>Blog</a>
<a class=navbar-link href=/case-studies/>Case Studies</a></div><div id=iconsBar><a type=button onclick=showSearch()><svg xmlns="http://www.w3.org/2000/svg" width="25" height="24" fill="none" viewBox="0 0 25 24"><path stroke="#ff6d00" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.75" d="M10.191 17c3.866.0 7-3.134 7-7s-3.134-7-7-7-7 3.134-7 7 3.134 7 7 7zm11 4-6-6"/></svg></a><a target=_blank href=https://github.com/apache/beam/edit/master/website/www/site/content/en/case-studies/paloalto.md data-proofer-ignore><svg xmlns="http://www.w3.org/2000/svg" width="25" height="24" fill="none" viewBox="0 0 25 24"><path stroke="#ff6d00" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.75" d="M4.543 20h4l10.5-10.5c.53-.53.828-1.25.828-2s-.298-1.47-.828-2-1.25-.828-2-.828-1.47.298-2 .828L4.543 16v4zm9.5-13.5 4 4"/></svg></a><li class="dropdown navbar-dropdown navbar-dropdown-apache"><a href=# class=dropdown-toggle role=button aria-haspopup=true aria-expanded=false><img src=https://www.apache.org/foundation/press/kit/feather_small.png alt="Apache Logo" style=height:20px>
&nbsp;Apache
<span class=arrow-icon><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="none" viewBox="0 0 20 20"><circle cx="10" cy="10" r="10" fill="#ff6d00"/><path stroke="#fff" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8.535 5.28l4.573 4.818-4.573 4.403"/></svg></span></a><ul class=dropdown-menu><li><a class=navbar-dropdown-menu-link target=_blank href=https://www.apache.org/>ASF Homepage</a></li><li><a class=navbar-dropdown-menu-link target=_blank href=https://www.apache.org/licenses/>License</a></li><li><a class=navbar-dropdown-menu-link target=_blank href=https://www.apache.org/security/>Security</a></li><li><a class=navbar-dropdown-menu-link target=_blank href=https://www.apache.org/foundation/thanks.html>Thanks</a></li><li><a class=navbar-dropdown-menu-link target=_blank href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a></li><li><a class=navbar-dropdown-menu-link target=_blank href=https://www.apache.org/foundation/policies/conduct>Code of Conduct</a></li></ul></li></div><div class="searchBar disappear"><script>(function(){var t,n="012923275103528129024:4emlchv9wzi",e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src="https://cse.google.com/cse.js?cx="+n,t=document.getElementsByTagName("script")[0],t.parentNode.insertBefore(e,t)})()</script><gcse:search></gcse:search>
<a type=button onclick=endSearch()><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25"><path stroke="#ff6d00" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.75" d="M21.122 20.827 4.727 4.432M21.122 4.43 4.727 20.827"/></svg></a></div></div></nav><div class=header-push></div><div class="top-banners swiper"><div class=swiper-wrapper><div class=swiper-slide><a href=https://tour.beam.apache.org><img class=banner-img-desktop src=/images/banners/tour-of-beam/tour-of-beam-desktop.png alt="Start Tour of Beam">
<img class=banner-img-mobile src=/images/banners/tour-of-beam/tour-of-beam-mobile.png alt="Start Tour of Beam"></a></div><div class=swiper-slide><a href=https://beam.apache.org/documentation/ml/overview/><img class=banner-img-desktop src=/images/banners/machine-learning/machine-learning-desktop.jpg alt="Machine Learning">
<img class=banner-img-mobile src=/images/banners/machine-learning/machine-learning-mobile.jpg alt="Machine Learning"></a></div></div><div class=swiper-pagination></div><div class=swiper-button-prev></div><div class=swiper-button-next></div></div><script src=/js/swiper-bundle.min.min.e0e8f81b0b15728d35ff73c07f42ddbb17a108d6f23df4953cb3e60df7ade675.js></script>
<script src=/js/sliders/top-banners.min.afa7d0a19acf7a3b28ca369490b3d401a619562a2a4c9612577be2f66a4b9855.js></script>
<script>function showSearch(){addPlaceholder();var e,t=document.querySelector(".searchBar");t.classList.remove("disappear"),e=document.querySelector("#iconsBar"),e.classList.add("disappear")}function addPlaceholder(){$("input:text").attr("placeholder","What are you looking for?")}function endSearch(){var e,t=document.querySelector(".searchBar");t.classList.add("disappear"),e=document.querySelector("#iconsBar"),e.classList.remove("disappear")}function blockScroll(){$("body").toggleClass("fixedPosition")}function openMenu(){addPlaceholder(),blockScroll()}</script><div class="clearfix container-main-content"><nav class="page-nav clearfix" data-offset-top=90 data-offset-bottom=500><nav id=TableOfContents><ul><li><a href=#background>Background</a></li><li><a href=#large-scale-streaming-infrastructure>Large-scale Streaming Infrastructure</a></li><li><a href=#customizing-serialization-for-use-cases>Customizing Serialization for Use Cases</a></li><li><a href=#in-flight-streaming-job-updates>In-flight Streaming Job Updates</a></li><li><a href=#handling-schema-changes-in-beam-sql>Handling Schema Changes In Beam SQL</a></li><li><a href=#fine-tuning-performance-for-kafka-changes>Fine-tuning Performance for Kafka Changes</a></li><li><a href=#results>Results</a></li></ul></nav></nav><div class=case-study-page><article itemscope itemtype=http://schema.org/BlogPosting><div class="arrow-list header-top-margin" itemprop=articleBody><div class=case-study><div class=case-study-breadcrumbs><a href=/case-studies class=case-study-breadcrumbs-link>Case Studies</a><div class=case-study-breadcrumbs-separator><svg width="6" height="11" viewBox="0 0 6 11" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M1 9.5l4-4-4-4" stroke="#e6e6e6" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg></div><div>Palo Alto</div></div><div class=case-study-content><div class=case-study-opinion><div class=case-study-opinion-img><img src=/images/logos/powered-by/paloalto.png></div><blockquote class=case-study-quote-block><p class=case-study-quote-text>“I know one thing: Beam is very powerful and the abstraction is its most significant feature. With the right abstraction we have the flexibility to run workloads where needed. Thanks to Beam, we are not locked to any vendor, and we don’t need to change anything else if we make the switch.”</p><div class=case-study-quote-author><div class=case-study-quote-author-img><img src=/images/case-study/paloalto/talat_uyarer.png></div><div class=case-study-quote-author-info><div class=case-study-quote-author-name>Talat Uyarer</div><div class=case-study-quote-author-position>Sr Principal Software Engineer</div></div></div></blockquote></div><div class=case-study-post><h1 id=real-time-event-stream-processing-at-scale-for-palo-alto-networks>Real-time Event Stream Processing at Scale for Palo Alto Networks</h1><h2 id=background>Background</h2><p><a href=https://www.paloaltonetworks.com/>Palo Alto Networks, Inc.</a> is a global cybersecurity leader with a comprehensive
portfolio of enterprise products. Palo Alto Networks protects and provides visibility, trusted intelligence, automation,
and flexibility to <a href=https://www.paloaltonetworks.com/about-us>over 85K customers</a> across clouds, networks, and devices.</p><p>Palo Alto Networks’ integrated security operations platform - <a href=https://www.paloaltonetworks.com/cortex>Cortex™</a> -
applies AI and machine learning to enable security automation, advanced threat intelligence, and effective rapid
security responses for Palo Alto Networks’
customers. <a href=https://www.paloaltonetworks.com/cortex/cortex-data-lake>Cortex™ Data Lake</a> infrastructure collects,
integrates, and normalizes enterprises’ security data combined with trillions of multi-source artifacts.</p><p>Cortex™ data infrastructure processes ~10 millions of security log events per second currently, at ~3 PB per day, which
are on the high end of real-time streaming processing scale in the industry. Palo Alto Networks’ Sr Principal Software
Engineer, Talat Uyarer, shared insights on how Apache Beam provides a high-performing, reliable, and resilient data
processing framework to support this scale.</p><h2 id=large-scale-streaming-infrastructure>Large-scale Streaming Infrastructure</h2><p>When building the data infrastructure from the ground up, Palo Alto Networks’ Cortex Data Lake team faced a challenging
task. We needed to ensure that the Cortex platform could stream and process petabyte-sized data coming from customers’
firewalls, networks, and all kinds of devices to customers and internal apps with low latency and perfect quality.</p><div class=post-scheme><img src=/images/case-study/paloalto/data_lake_scheme.png alt="Cortex™ Data Lake"></div><p>To meet the SLAs, the Cortex Data Lake team had to design a large-scale data infrastructure for real-time processing and
reduce time-to-value. One of their initial architectural decisions was to leverage Apache Beam, the industry standard
for unified distributed processing, due to its portability and abstraction.</p><blockquote class="case-study-quote-block case-study-quote-wrapped"><p class=case-study-quote-text>Beam is very flexible, its abstraction from implementation details of distributed data processing is wonderful for delivering proofs of concept really fast.</p><div class=case-study-quote-author><div class=case-study-quote-author-img><img src=/images/case-study/paloalto/talat_uyarer.png></div><div class=case-study-quote-author-info><div class=case-study-quote-author-name>Talat Uyarer</div><div class=case-study-quote-author-position>Sr Principal Software Engineer</div></div></div></blockquote><p>Apache Beam provides a variety of runners, offering freedom of choice between different data processing engines. Palo
Alto Networks’ data infrastructure is hosted entirely on <a href=https://cloud.google.com/gcp/>Google Cloud Platform</a>,
and <a href=/documentation/runners/capability-matrix/>with Apache Beam Dataflow runner</a>, we could
easily benefit from <a href=https://cloud.google.com/dataflow>Google Cloud Dataflow</a>’s managed service and
<a href=https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#horizontal-autoscaling>autotuning</a> capabilities.
Apache Kafka was selected as the message broker for the backend, and all events were stored as binary data with a common
schema on multiple Kafka clusters.</p><p>The Cortex Data Lake team considered the option of having separate data processing infrastructures for each customer,
with multiple upstream applications creating their own streaming jobs, consuming and processing events from Kafka
directly. Therefore we are building a multi-tenants system. However, the team anticipated possible issues related to
Kafka migrations and partition creation, as well as a lack of visibility into the tenant use cases, which might arise
when having multiple infrastructures.</p><p>Hence, the Cortex Data Lake team took a common streaming infrastructure approach. At the core of the common data
infrastructure, Apache Beam served as a unified programming model to implement business logic just once for all internal
and customer tenant applications.</p><p>The first data workflows that the Cortex Data Lake team implemented were simple: reading from Kafka, creating a batch
job, and writing the results to sink. The release of
the <a href=/get-started/downloads/#releases>Apache Beam version with SQL support</a> opened up new
possibilities. <a href=/documentation/dsls/sql/calcite/overview/>Beam Calcite SQL</a> provides full
support for <a href=/documentation/dsls/sql/calcite/data-types/>complex Apache Calcite data types</a>,
including nested rows, in SQL statements, so developers can use SQL queries in an Apache Beam pipeline for composite
transforms. The Cortex Data Lake team decided to take advantage of the
<a href=/documentation/dsls/sql/overview/>Beam SQL</a> to write Beam pipelines with standard SQL
statements.</p><p>The main challenge of the common infrastructure was to support a variety of business logic customizations and
user-defined functions and transform them to a variety of sink formats. Tenant applications needed to consume data from
dynamically-changing Kafka clusters, and streaming pipeline <a href=https://en.wikipedia.org/wiki/Directed_acyclic_graph>DAGs</a>
had to be regenerated if the jobs’ source had been updated.</p><p>The Cortex Data Lake team developed their own “subscription” model that allows tenant applications to “subscribe” to the
streaming job when sending job deployment requests to the REST API service. The Subscription service abstracts tenant
applications from the changes in DAG by storing infrastructure-specific information in metadata service. This way, the
streaming jobs stay in sync with the dynamic Kafka infrastructure.</p><div class=post-scheme><img src=/images/case-study/paloalto/subscription_service_scheme.png alt="Cortex™ Data Lake Subscription Service"></div><p>Apache Beam is flexible, it allows creating streaming jobs dynamically, on the fly. The Apache Beam constructs allow for
generic pipeline coding, enabling pipelines that process data even if schemas are not fully defined in advance. Cortex’s
Subscription Service generates Apache Beam pipeline DAG based on the tenant application’s REST payload and submits the
job to the runner. When the job is
running, <a href=https://beam.apache.org/releases/javadoc/2.4.0/org/apache/beam/sdk/io/kafka/KafkaIO.html>Apache Beam SDK’s Kafka I/O</a>
returns an unbounded collection of Kafka records as
a <a href=https://beam.apache.org/releases/javadoc/2.1.0/org/apache/beam/sdk/values/PCollection.html>PCollection</a>
. <a href=https://avro.apache.org/>Apache Avro</a> turns the binary Kafka representation into generic records, which are further
converted to the <a href=https://beam.apache.org/releases/javadoc/2.4.0/org/apache/beam/sdk/values/Row.html>Apache Beam Row</a>
format. The Row structure supports primitives, byte arrays, and containers, and allows organizing values in the same
order as the schema definition.</p><p>Apache Beam’s cross-language transforms allow the Cortex Data Lake team to execute SQL with Java. The output of
an <a href=https://beam.apache.org/releases/javadoc/2.7.0/org/apache/beam/sdk/extensions/sql/SqlTransform.html>SQL Transform</a>
performed inside the Apache Beam pipeline is sequentially converted from Beam Row format to a generic record, then to
the output format required by a subscriber application, such as Avro, JSON, CSV, etc.</p><p>Once the base use cases had been implemented, the Cortex Data Lake team turned to more complex transformations, such as
filtering a subset of events directly inside Apache Beam pipelines, and kept looking into customization and
optimization.</p><blockquote class="case-study-quote-block case-study-quote-wrapped"><p class=case-study-quote-text>We have more than 10 use cases running across customers and apps. More are coming, like the machine learning use cases .... for these use cases, Beam provides a really good programming model.</p><div class=case-study-quote-author><div class=case-study-quote-author-img><img src=/images/case-study/paloalto/talat_uyarer.png></div><div class=case-study-quote-author-info><div class=case-study-quote-author-name>Talat Uyarer</div><div class=case-study-quote-author-position>Sr Principal Software Engineer</div></div></div></blockquote><p>Apache Beam provides a pluggable data processing model that seamlessly integrates with various tools and technologies,
which allowed the Cortex Data Lake team to customize their data processing to performance requirements and specific use
cases.</p><h2 id=customizing-serialization-for-use-cases>Customizing Serialization for Use Cases</h2><p>Palo Alto Networks’ streaming data infrastructure deals with hundreds of billions of real-time security events every
day, and even a sub-second difference in processing times is crucial.</p><p>To enhance performance, the Cortex Data Lake team developed their own library for direct serialization and
deserialization. The library reads Avro binary records from Kafka and turns them into the Beam Row format, then converts
the Beam Row format pipeline output to the required sink format.</p><p>This custom library replaced serializing data into generic records with steps optimized for Palo Alto Networks’ specific
use cases. Direct serialization eliminated shuffling and creating additional memory copies from processing steps.</p><p>This customization increased serialization performance 10x times, allowing to process up to 3K events per second per
vCPU with reduced latency and infrastructure costs.</p><div class="post-scheme vertical-scheme"><img src=/images/case-study/paloalto/direct_serialization.png alt="Direct Serialization from Avro to Beam Row"></div><h2 id=in-flight-streaming-job-updates>In-flight Streaming Job Updates</h2><p>At a scale of thousands of jobs running concurrently, the Cortex Data Lake team faced cases when needed to improve the
pipeline code or fix bugs for an ongoing job. Google Cloud Dataflow provides a way
to <a href=https://cloud.google.com/dataflow/docs/guides/updating-a-pipeline>replace an “in-flight” streaming job</a> with a new
job that runs an updated Apache Beam pipeline code. However, Palo Alto Networks needed to expand the supported
scenarios.</p><p>To address updating jobs in the dynamically-changing Kafka infrastructure, the Cortex Data Lake team created an
additional workflow in their deployment service
which <a href=https://cloud.google.com/dataflow/docs/guides/stopping-a-pipeline#drain>drains the jobs</a> if the change
is <a href=https://cloud.google.com/dataflow/docs/guides/updating-a-pipeline#UpdateSchemas>not permitted</a> by the Dataflow
update and starts a new job with the exact same naming. This internal job replacement workflow allows the Cortex Data
Lake to update the jobs and payloads automatically for all use cases.</p><h2 id=handling-schema-changes-in-beam-sql>Handling Schema Changes In Beam SQL</h2><p>Another use case that Palo Alto Networks tackled is handling changes in data schemas for ongoing jobs. Apache Beam
allows PCollections to have <a href=/documentation/programming-guide/#schemas>schemas</a> with named
fields, that are validated at pipeline construction step. When a job is submitted, an execution plan in the form of a
Beam pipeline fragment is generated based on the latest schema. Beam SQL does not yet have built-in support for relaxed
schema compatibility for running jobs. For optimized performance, Beam SQL’s
Schema <a href=https://beam.apache.org/releases/javadoc/2.4.0/org/apache/beam/sdk/coders/RowCoder.html>RowCoder</a> has a fixed
data format and doesn&rsquo;t handle schema evolution, so it is necessary to restart the jobs to regenerate their execution
plan. At a scale of 10K+ streaming jobs, Cortex Data Lake team wanted to avoid resubmitting the jobs as much as
possible.</p><p>We created an internal workflow to identify the jobs with SQL queries relevant to the schema change. The schema update
workflow stores Reader schema of each job (Avro schema) and Writer schema of each Kafka message (metadata on Kafka
header) in the internal Schema Registry, compares them to the SQL queries of the running jobs, and restarts the affected
jobs only. This optimization allowed them to utilize resources more efficiently.</p><h2 id=fine-tuning-performance-for-kafka-changes>Fine-tuning Performance for Kafka Changes</h2><p>With multiple clusters and topics, and over 100K partitions in Kafka, Palo Alto Networks needed to make sure that
actively-running jobs are not being affected by the frequent Kafka infrastructure changes such as cluster migrations or
changes in partition count.</p><p>The Cortex Data Lake team developed several internal Kafka lifecycle support tools, including a “Self Healing” service.
Depending on the amount of traffic per topic coming from a specific tenant, the internal service increases the number of
partitions or creates new topics with fewer partitions. The “Self Healing” service compares the Kafka states in the data
store and then finds and updates all related streaming Apache Beam jobs on Cloud Dataflow automatically.</p><p>With the <a href=/blog/beam-2.28.0/>release of Apache Beam 2.28.0</a> in early
2021, <a href=https://beam.apache.org/releases/javadoc/2.29.0/org/apache/beam/sdk/io/kafka/KafkaIO.html>the pre-built Kafka I/O dynamic read feature</a>
provides an out-of-the-box solution for detecting Kafka partition changes to enable cost savings and increased
performance. Kafka I/O uses WatchKafkaTopicPartitionDoFn to emit
new <a href=https://kafka.apache.org/24/javadoc/index.html?org/apache/kafka/common/TopicPartition.html>TopicPartitions</a>, and
allows reading from Kafka topics dynamically when certain partitions are added or stop reading from them once they are
deleted. This feature eliminated the need to create in-house Kafka monitoring tools.</p><p>In addition to performance optimization, the Cortex Data Lake team has been exploring ways to optimize the Cloud
Dataflow costs. We looked into resource usage optimization in cases when streaming jobs consume very few incoming
events. For cost efficiency, Google Cloud Dataflow provides
the <a href=https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#streaming-autoscaling>streaming autoscaling</a>
feature that adaptively changes the number of workers in response to changes in the load and resource utilization. For
some of Cortex Data Lake team’s use cases, where input data streams may quiesce for prolonged periods of time, we
implemented an internal “Cold Starter” service that analyzes Kafka topics traffic and hibernates pipelines whose input
dries up and reactivates them once their input resumes.</p><p>Talat Uyarer presented the Cortex Data Lake’s experience of building and customizing the large-scale streaming
infrastructure during <a href=https://2021.beamsummit.org/sessions/large-scale-streaming-infrastructure/>Beam Summit 2021</a>.</p><blockquote class="case-study-quote-block case-study-quote-wrapped"><p class=case-study-quote-text>I really enjoy working with Beam. If you understand its internals, the understanding empowers you to fine-tune the open source, customize it, so that it provides the best performance for your specific use case.</p><div class=case-study-quote-author><div class=case-study-quote-author-img><img src=/images/case-study/paloalto/talat_uyarer.png></div><div class=case-study-quote-author-info><div class=case-study-quote-author-name>Talat Uyarer</div><div class=case-study-quote-author-position>Sr Principal Software Engineer</div></div></div></blockquote><h2 id=results>Results</h2><p>The level of abstraction of Apache Beam empowered the Cortex Data Lake team to create a common infrastructure across
their internal apps and tens of thousands of customers. With Apache Beam, we implement business logic just once and
dynamically generate 10K+ streaming pipelines running in parallel for over 10 use cases.</p><p>The Cortex Data Lake team took advantage of Apache Beam’s portability and pluggability to fine-tune and enhance their
data processing infrastructure with custom libraries and services. Palo Alto Networks ultimately achieved high
performance and low latency, processing 3K+ streaming events per second per vCPU. Combining the benefits of open source
Apache Beam and Cloud Dataflow managed service, we were able to implement use-case specific customizations and reduced
their costs by more than 60%.</p><p>The Apache Beam open source community welcomes and encourages the contributions of its numerous members, such as Palo
Alto Networks, that leverage the powerful capabilities of Apache Beam, bring new optimizations, and empower future
innovation by sharing their expertise and actively participating in the community.</p><div class=case-study-feedback id=case-study-feedback><p class=case-study-feedback-title>Was this information useful?</p><div><button class="btn case-study-feedback-btn" onclick='sendCaseStudyFeedback(!0,"Palo Alto")'>Yes</button>
<button class="btn case-study-feedback-btn" onclick='sendCaseStudyFeedback(!1,"Palo Alto")'>No</button></div></div></div><div class=clear-nav></div></div></div></div></article></div></div><footer class=footer><div class=footer__contained><div class=footer__cols><div class="footer__cols__col footer__cols__col__logos"><div class=footer__cols__col__logo><img src=/images/beam_logo_circle.svg class=footer__logo alt="Beam logo"></div><div class=footer__cols__col__logo><img src=/images/apache_logo_circle.svg class=footer__logo alt="Apache logo"></div></div><div class=footer-wrapper><div class=wrapper-grid><div class=footer__cols__col><div class=footer__cols__col__title>Start</div><div class=footer__cols__col__link><a href=/get-started/beam-overview/>Overview</a></div><div class=footer__cols__col__link><a href=/get-started/quickstart-java/>Quickstart (Java)</a></div><div class=footer__cols__col__link><a href=/get-started/quickstart-py/>Quickstart (Python)</a></div><div class=footer__cols__col__link><a href=/get-started/quickstart-go/>Quickstart (Go)</a></div><div class=footer__cols__col__link><a href=/get-started/downloads/>Downloads</a></div></div><div class=footer__cols__col><div class=footer__cols__col__title>Docs</div><div class=footer__cols__col__link><a href=/documentation/programming-guide/>Concepts</a></div><div class=footer__cols__col__link><a href=/documentation/pipelines/design-your-pipeline/>Pipelines</a></div><div class=footer__cols__col__link><a href=/documentation/runners/capability-matrix/>Runners</a></div></div><div class=footer__cols__col><div class=footer__cols__col__title>Community</div><div class=footer__cols__col__link><a href=/contribute/>Contribute</a></div><div class=footer__cols__col__link><a href=https://projects.apache.org/committee.html?beam target=_blank>Team<img src=/images/external-link-icon.png width=14 height=14 alt="External link."></a></div><div class=footer__cols__col__link><a href=/community/presentation-materials/>Media</a></div><div class=footer__cols__col__link><a href=/community/in-person/>Events/Meetups</a></div><div class=footer__cols__col__link><a href=/community/contact-us/>Contact Us</a></div></div><div class=footer__cols__col><div class=footer__cols__col__title>Resources</div><div class=footer__cols__col__link><a href=/blog/>Blog</a></div><div class=footer__cols__col__link><a href=https://github.com/apache/beam>GitHub</a></div></div></div><div class=footer__bottom>&copy;
<a href=https://www.apache.org>The Apache Software Foundation</a>
| <a href=/privacy_policy>Privacy Policy</a>
| <a href=/feed.xml>RSS Feed</a><br><br>Apache Beam, Apache, Beam, the Beam logo, and the Apache feather logo are either registered trademarks or trademarks of The Apache Software Foundation. All other products or name brands are trademarks of their respective holders, including The Apache Software Foundation.</div></div><div class="footer__cols__col footer__cols__col__logos"><div class=footer__cols__col--group><div class=footer__cols__col__logo><a href=https://github.com/apache/beam><img src=/images/logos/social-icons/github-logo-150.png class=footer__logo alt="Github logo"></a></div><div class=footer__cols__col__logo><a href=https://www.linkedin.com/company/apache-beam/><img src=/images/logos/social-icons/linkedin-logo-150.png class=footer__logo alt="Linkedin logo"></a></div></div><div class=footer__cols__col--group><div class=footer__cols__col__logo><a href=https://twitter.com/apachebeam><img src=/images/logos/social-icons/twitter-logo-150.png class=footer__logo alt="Twitter logo"></a></div><div class=footer__cols__col__logo><a href=https://www.youtube.com/channel/UChNnb_YO_7B0HlW6FhAXZZQ><img src=/images/logos/social-icons/youtube-logo-150.png class=footer__logo alt="Youtube logo"></a></div></div></div></div></div></footer><script>function sendCaseStudyFeedback(e,t){ga("send","event","Case Study Feedback","Click",t+(e?", yes":", no"));var n="case-study-feedback";const s=document.getElementById(n);s.innerHTML='<p class="case-study-feedback-title">Thank you for your feedback!</p>'}</script></body></html>